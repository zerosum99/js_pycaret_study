2023-04-06 16:33:58,368:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-06 16:33:58,369:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-06 16:33:58,369:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-06 16:33:58,369:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-06 16:33:59,004:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-06 16:34:07,810:INFO:PyCaret RegressionExperiment
2023-04-06 16:34:07,810:INFO:Logging name: reg-default-name
2023-04-06 16:34:07,810:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-06 16:34:07,810:INFO:version 3.0.0
2023-04-06 16:34:07,810:INFO:Initializing setup()
2023-04-06 16:34:07,810:INFO:self.USI: f987
2023-04-06 16:34:07,810:INFO:self._variable_keys: {'pipeline', 'y_test', 'memory', 'y', 'X', 'target_param', 'gpu_n_jobs_param', 'X_train', 'fold_shuffle_param', 'fold_generator', 'exp_id', 'X_test', '_available_plots', 'n_jobs_param', 'seed', 'fold_groups_param', 'data', 'exp_name_log', 'html_param', 'idx', 'logging_param', '_ml_usecase', 'USI', 'log_plots_param', 'y_train', 'gpu_param', 'transform_target_param'}
2023-04-06 16:34:07,810:INFO:Checking environment
2023-04-06 16:34:07,810:INFO:python_version: 3.9.15
2023-04-06 16:34:07,810:INFO:python_build: ('main', 'Nov 24 2022 08:28:41')
2023-04-06 16:34:07,810:INFO:machine: arm64
2023-04-06 16:34:07,810:INFO:platform: macOS-13.2-arm64-arm-64bit
2023-04-06 16:34:07,810:INFO:Memory: svmem(total=17179869184, available=5218369536, percent=69.6, used=7342784512, free=103514112, active=5127684096, inactive=5085642752, wired=2215100416)
2023-04-06 16:34:07,810:INFO:Physical Core: 10
2023-04-06 16:34:07,810:INFO:Logical Core: 10
2023-04-06 16:34:07,810:INFO:Checking libraries
2023-04-06 16:34:07,810:INFO:System:
2023-04-06 16:34:07,810:INFO:    python: 3.9.15 (main, Nov 24 2022, 08:28:41)  [Clang 14.0.6 ]
2023-04-06 16:34:07,810:INFO:executable: /Users/a06411/opt/anaconda3/bin/python
2023-04-06 16:34:07,810:INFO:   machine: macOS-13.2-arm64-arm-64bit
2023-04-06 16:34:07,810:INFO:PyCaret required dependencies:
2023-04-06 16:34:07,811:INFO:                 pip: 22.3.1
2023-04-06 16:34:07,811:INFO:          setuptools: 65.5.0
2023-04-06 16:34:07,811:INFO:             pycaret: 3.0.0
2023-04-06 16:34:07,811:INFO:             IPython: 8.7.0
2023-04-06 16:34:07,811:INFO:          ipywidgets: 7.6.5
2023-04-06 16:34:07,811:INFO:                tqdm: 4.64.1
2023-04-06 16:34:07,811:INFO:               numpy: 1.21.5
2023-04-06 16:34:07,811:INFO:              pandas: 1.4.4
2023-04-06 16:34:07,811:INFO:              jinja2: 2.11.3
2023-04-06 16:34:07,811:INFO:               scipy: 1.9.3
2023-04-06 16:34:07,811:INFO:              joblib: 1.1.1
2023-04-06 16:34:07,811:INFO:             sklearn: 1.1.3
2023-04-06 16:34:07,811:INFO:                pyod: 1.0.9
2023-04-06 16:34:07,811:INFO:            imblearn: 0.10.1
2023-04-06 16:34:07,811:INFO:   category_encoders: 2.6.0
2023-04-06 16:34:07,811:INFO:            lightgbm: 3.3.5
2023-04-06 16:34:07,811:INFO:               numba: 0.56.4
2023-04-06 16:34:07,811:INFO:            requests: 2.28.1
2023-04-06 16:34:07,811:INFO:          matplotlib: 3.6.2
2023-04-06 16:34:07,811:INFO:          scikitplot: 0.3.7
2023-04-06 16:34:07,811:INFO:         yellowbrick: 1.5
2023-04-06 16:34:07,811:INFO:              plotly: 5.9.0
2023-04-06 16:34:07,811:INFO:             kaleido: Not installed
2023-04-06 16:34:07,811:INFO:         statsmodels: 0.13.2
2023-04-06 16:34:07,811:INFO:              sktime: 0.16.1
2023-04-06 16:34:07,811:INFO:               tbats: Not installed
2023-04-06 16:34:07,811:INFO:            pmdarima: 2.0.3
2023-04-06 16:34:07,811:INFO:              psutil: 5.9.0
2023-04-06 16:34:07,811:INFO:PyCaret optional dependencies:
2023-04-06 16:34:07,813:INFO:                shap: 0.41.0
2023-04-06 16:34:07,813:INFO:           interpret: Not installed
2023-04-06 16:34:07,813:INFO:                umap: 0.5.3
2023-04-06 16:34:07,813:INFO:    pandas_profiling: Not installed
2023-04-06 16:34:07,813:INFO:  explainerdashboard: 0.4.2.1
2023-04-06 16:34:07,813:INFO:             autoviz: Not installed
2023-04-06 16:34:07,813:INFO:           fairlearn: Not installed
2023-04-06 16:34:07,813:INFO:             xgboost: 1.7.2
2023-04-06 16:34:07,813:INFO:            catboost: 1.1.1
2023-04-06 16:34:07,813:INFO:              kmodes: Not installed
2023-04-06 16:34:07,813:INFO:             mlxtend: Not installed
2023-04-06 16:34:07,813:INFO:       statsforecast: Not installed
2023-04-06 16:34:07,813:INFO:        tune_sklearn: Not installed
2023-04-06 16:34:07,813:INFO:                 ray: Not installed
2023-04-06 16:34:07,813:INFO:            hyperopt: 0.2.7
2023-04-06 16:34:07,813:INFO:              optuna: 3.1.0
2023-04-06 16:34:07,813:INFO:               skopt: 0.9.0
2023-04-06 16:34:07,813:INFO:              mlflow: 2.2.2
2023-04-06 16:34:07,813:INFO:              gradio: Not installed
2023-04-06 16:34:07,813:INFO:             fastapi: Not installed
2023-04-06 16:34:07,813:INFO:             uvicorn: Not installed
2023-04-06 16:34:07,813:INFO:              m2cgen: Not installed
2023-04-06 16:34:07,813:INFO:           evidently: Not installed
2023-04-06 16:34:07,813:INFO:               fugue: Not installed
2023-04-06 16:34:07,813:INFO:           streamlit: Not installed
2023-04-06 16:34:07,813:INFO:             prophet: Not installed
2023-04-06 16:34:07,813:INFO:None
2023-04-06 16:34:07,813:INFO:Set up data.
2023-04-06 16:34:07,817:INFO:Set up train/test split.
2023-04-06 16:34:07,819:INFO:Set up index.
2023-04-06 16:34:07,819:INFO:Set up folding strategy.
2023-04-06 16:34:07,819:INFO:Assigning column types.
2023-04-06 16:34:07,820:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-06 16:34:07,820:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-06 16:34:07,822:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-06 16:34:07,823:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 16:34:07,847:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:34:07,865:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 16:34:07,865:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:34:08,005:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:34:08,041:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,043:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,045:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,069:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,087:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,088:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:34:08,089:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:34:08,089:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-06 16:34:08,091:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,093:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,117:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,136:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,136:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:34:08,137:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:34:08,139:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,141:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,165:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,184:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,184:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:34:08,186:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:34:08,186:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-06 16:34:08,190:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,213:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,233:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,233:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:34:08,234:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:34:08,238:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,262:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,280:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,281:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:34:08,282:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:34:08,282:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-06 16:34:08,310:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,329:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,329:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:34:08,330:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:34:08,358:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,377:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,377:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:34:08,378:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:34:08,378:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-06 16:34:08,406:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,424:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:34:08,425:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:34:08,454:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,472:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:34:08,473:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:34:08,473:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-06 16:34:08,520:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:34:08,521:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:34:08,571:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:34:08,572:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:34:08,574:INFO:Preparing preprocessing pipeline...
2023-04-06 16:34:08,574:INFO:Set up simple imputation.
2023-04-06 16:34:08,576:INFO:Set up encoding of ordinal features.
2023-04-06 16:34:08,577:INFO:Set up encoding of categorical features.
2023-04-06 16:34:08,577:INFO:Set up column name cleaning.
2023-04-06 16:34:08,640:INFO:Finished creating preprocessing pipeline.
2023-04-06 16:34:08,649:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry', 'Report'],
                                    transformer=SimpleImputer(strategy='most_frequent')...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': AGSL    0
GIA     1
NaN    -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry'],
                                    transformer=OneHotEncoder(cols=['Cut',
                                                                    'Color',
                                                                    'Clarity',
                                                                    'Polish',
                                                                    'Symmetry'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-06 16:34:08,649:INFO:Creating final display dataframe.
2023-04-06 16:34:08,775:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             Price
2                   Target type        Regression
3           Original data shape         (5400, 8)
4        Transformed data shape        (5400, 29)
5   Transformed train set shape        (3779, 29)
6    Transformed test set shape        (1621, 29)
7              Ordinal features                 1
8              Numeric features                 1
9          Categorical features                 6
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              f987
2023-04-06 16:34:08,826:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:34:08,827:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:34:08,874:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:34:08,875:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:34:08,876:INFO:setup() successfully completed in 1.55s...............
2023-04-06 16:36:45,372:INFO:Initializing compare_models()
2023-04-06 16:36:45,375:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-06 16:36:45,375:INFO:Checking exceptions
2023-04-06 16:36:45,379:INFO:Preparing display monitor
2023-04-06 16:36:45,414:INFO:Initializing Linear Regression
2023-04-06 16:36:45,414:INFO:Total runtime is 3.850460052490234e-06 minutes
2023-04-06 16:36:45,416:INFO:SubProcess create_model() called ==================================
2023-04-06 16:36:45,416:INFO:Initializing create_model()
2023-04-06 16:36:45,416:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:36:45,416:INFO:Checking exceptions
2023-04-06 16:36:45,417:INFO:Importing libraries
2023-04-06 16:36:45,417:INFO:Copying training dataset
2023-04-06 16:36:45,421:INFO:Defining folds
2023-04-06 16:36:45,421:INFO:Declaring metric variables
2023-04-06 16:36:45,423:INFO:Importing untrained model
2023-04-06 16:36:45,424:INFO:Linear Regression Imported successfully
2023-04-06 16:36:45,428:INFO:Starting cross validation
2023-04-06 16:36:45,434:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:36:51,843:INFO:Calculating mean and std
2023-04-06 16:36:51,844:INFO:Creating metrics dataframe
2023-04-06 16:36:52,239:INFO:Uploading results into container
2023-04-06 16:36:52,240:INFO:Uploading model into container now
2023-04-06 16:36:52,241:INFO:_master_model_container: 1
2023-04-06 16:36:52,241:INFO:_display_container: 2
2023-04-06 16:36:52,241:INFO:LinearRegression(n_jobs=-1)
2023-04-06 16:36:52,241:INFO:create_model() successfully completed......................................
2023-04-06 16:36:52,358:INFO:SubProcess create_model() end ==================================
2023-04-06 16:36:52,358:INFO:Creating metrics dataframe
2023-04-06 16:36:52,361:INFO:Initializing Lasso Regression
2023-04-06 16:36:52,361:INFO:Total runtime is 0.11578671932220459 minutes
2023-04-06 16:36:52,363:INFO:SubProcess create_model() called ==================================
2023-04-06 16:36:52,363:INFO:Initializing create_model()
2023-04-06 16:36:52,363:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:36:52,363:INFO:Checking exceptions
2023-04-06 16:36:52,363:INFO:Importing libraries
2023-04-06 16:36:52,363:INFO:Copying training dataset
2023-04-06 16:36:52,366:INFO:Defining folds
2023-04-06 16:36:52,366:INFO:Declaring metric variables
2023-04-06 16:36:52,367:INFO:Importing untrained model
2023-04-06 16:36:52,370:INFO:Lasso Regression Imported successfully
2023-04-06 16:36:52,373:INFO:Starting cross validation
2023-04-06 16:36:52,374:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:36:56,238:INFO:Calculating mean and std
2023-04-06 16:36:56,238:INFO:Creating metrics dataframe
2023-04-06 16:36:56,606:INFO:Uploading results into container
2023-04-06 16:36:56,606:INFO:Uploading model into container now
2023-04-06 16:36:56,606:INFO:_master_model_container: 2
2023-04-06 16:36:56,606:INFO:_display_container: 2
2023-04-06 16:36:56,607:INFO:Lasso(random_state=123)
2023-04-06 16:36:56,607:INFO:create_model() successfully completed......................................
2023-04-06 16:36:56,681:INFO:SubProcess create_model() end ==================================
2023-04-06 16:36:56,681:INFO:Creating metrics dataframe
2023-04-06 16:36:56,685:INFO:Initializing Ridge Regression
2023-04-06 16:36:56,686:INFO:Total runtime is 0.18785916566848754 minutes
2023-04-06 16:36:56,687:INFO:SubProcess create_model() called ==================================
2023-04-06 16:36:56,687:INFO:Initializing create_model()
2023-04-06 16:36:56,687:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:36:56,687:INFO:Checking exceptions
2023-04-06 16:36:56,687:INFO:Importing libraries
2023-04-06 16:36:56,687:INFO:Copying training dataset
2023-04-06 16:36:56,690:INFO:Defining folds
2023-04-06 16:36:56,690:INFO:Declaring metric variables
2023-04-06 16:36:56,691:INFO:Importing untrained model
2023-04-06 16:36:56,692:INFO:Ridge Regression Imported successfully
2023-04-06 16:36:56,695:INFO:Starting cross validation
2023-04-06 16:36:56,695:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:37:00,409:INFO:Calculating mean and std
2023-04-06 16:37:00,410:INFO:Creating metrics dataframe
2023-04-06 16:37:00,767:INFO:Uploading results into container
2023-04-06 16:37:00,768:INFO:Uploading model into container now
2023-04-06 16:37:00,768:INFO:_master_model_container: 3
2023-04-06 16:37:00,768:INFO:_display_container: 2
2023-04-06 16:37:00,768:INFO:Ridge(random_state=123)
2023-04-06 16:37:00,768:INFO:create_model() successfully completed......................................
2023-04-06 16:37:00,842:INFO:SubProcess create_model() end ==================================
2023-04-06 16:37:00,842:INFO:Creating metrics dataframe
2023-04-06 16:37:00,846:INFO:Initializing Elastic Net
2023-04-06 16:37:00,846:INFO:Total runtime is 0.25719326734542847 minutes
2023-04-06 16:37:00,847:INFO:SubProcess create_model() called ==================================
2023-04-06 16:37:00,847:INFO:Initializing create_model()
2023-04-06 16:37:00,847:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:37:00,847:INFO:Checking exceptions
2023-04-06 16:37:00,847:INFO:Importing libraries
2023-04-06 16:37:00,847:INFO:Copying training dataset
2023-04-06 16:37:00,850:INFO:Defining folds
2023-04-06 16:37:00,850:INFO:Declaring metric variables
2023-04-06 16:37:00,851:INFO:Importing untrained model
2023-04-06 16:37:00,852:INFO:Elastic Net Imported successfully
2023-04-06 16:37:00,855:INFO:Starting cross validation
2023-04-06 16:37:00,856:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:37:04,709:INFO:Calculating mean and std
2023-04-06 16:37:04,710:INFO:Creating metrics dataframe
2023-04-06 16:37:05,085:INFO:Uploading results into container
2023-04-06 16:37:05,086:INFO:Uploading model into container now
2023-04-06 16:37:05,086:INFO:_master_model_container: 4
2023-04-06 16:37:05,086:INFO:_display_container: 2
2023-04-06 16:37:05,086:INFO:ElasticNet(random_state=123)
2023-04-06 16:37:05,086:INFO:create_model() successfully completed......................................
2023-04-06 16:37:05,159:INFO:SubProcess create_model() end ==================================
2023-04-06 16:37:05,159:INFO:Creating metrics dataframe
2023-04-06 16:37:05,163:INFO:Initializing Least Angle Regression
2023-04-06 16:37:05,163:INFO:Total runtime is 0.3291534185409546 minutes
2023-04-06 16:37:05,165:INFO:SubProcess create_model() called ==================================
2023-04-06 16:37:05,165:INFO:Initializing create_model()
2023-04-06 16:37:05,165:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:37:05,165:INFO:Checking exceptions
2023-04-06 16:37:05,165:INFO:Importing libraries
2023-04-06 16:37:05,165:INFO:Copying training dataset
2023-04-06 16:37:05,167:INFO:Defining folds
2023-04-06 16:37:05,167:INFO:Declaring metric variables
2023-04-06 16:37:05,169:INFO:Importing untrained model
2023-04-06 16:37:05,170:INFO:Least Angle Regression Imported successfully
2023-04-06 16:37:05,173:INFO:Starting cross validation
2023-04-06 16:37:05,174:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:37:05,272:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:05,278:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:05,280:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:05,286:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:05,289:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:05,289:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=6.036e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 16:37:05,290:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=4.789e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 16:37:05,290:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.582e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 16:37:05,290:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.117e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 16:37:05,290:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.036e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 16:37:05,290:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:05,310:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:05,321:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:05,322:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:05,346:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:09,006:INFO:Calculating mean and std
2023-04-06 16:37:09,007:INFO:Creating metrics dataframe
2023-04-06 16:37:09,398:INFO:Uploading results into container
2023-04-06 16:37:09,399:INFO:Uploading model into container now
2023-04-06 16:37:09,399:INFO:_master_model_container: 5
2023-04-06 16:37:09,400:INFO:_display_container: 2
2023-04-06 16:37:09,400:INFO:Lars(random_state=123)
2023-04-06 16:37:09,400:INFO:create_model() successfully completed......................................
2023-04-06 16:37:09,485:INFO:SubProcess create_model() end ==================================
2023-04-06 16:37:09,485:INFO:Creating metrics dataframe
2023-04-06 16:37:09,490:INFO:Initializing Lasso Least Angle Regression
2023-04-06 16:37:09,490:INFO:Total runtime is 0.4012604514757792 minutes
2023-04-06 16:37:09,491:INFO:SubProcess create_model() called ==================================
2023-04-06 16:37:09,492:INFO:Initializing create_model()
2023-04-06 16:37:09,492:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:37:09,492:INFO:Checking exceptions
2023-04-06 16:37:09,492:INFO:Importing libraries
2023-04-06 16:37:09,492:INFO:Copying training dataset
2023-04-06 16:37:09,494:INFO:Defining folds
2023-04-06 16:37:09,494:INFO:Declaring metric variables
2023-04-06 16:37:09,496:INFO:Importing untrained model
2023-04-06 16:37:09,497:INFO:Lasso Least Angle Regression Imported successfully
2023-04-06 16:37:09,500:INFO:Starting cross validation
2023-04-06 16:37:09,501:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:37:09,584:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:37:09,584:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:37:09,596:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:37:09,606:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:37:09,612:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:37:09,626:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:37:09,630:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:37:09,643:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:37:09,663:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:37:09,672:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:37:13,209:INFO:Calculating mean and std
2023-04-06 16:37:13,209:INFO:Creating metrics dataframe
2023-04-06 16:37:13,584:INFO:Uploading results into container
2023-04-06 16:37:13,584:INFO:Uploading model into container now
2023-04-06 16:37:13,584:INFO:_master_model_container: 6
2023-04-06 16:37:13,584:INFO:_display_container: 2
2023-04-06 16:37:13,584:INFO:LassoLars(random_state=123)
2023-04-06 16:37:13,585:INFO:create_model() successfully completed......................................
2023-04-06 16:37:13,658:INFO:SubProcess create_model() end ==================================
2023-04-06 16:37:13,658:INFO:Creating metrics dataframe
2023-04-06 16:37:13,662:INFO:Initializing Orthogonal Matching Pursuit
2023-04-06 16:37:13,662:INFO:Total runtime is 0.4707941969235738 minutes
2023-04-06 16:37:13,663:INFO:SubProcess create_model() called ==================================
2023-04-06 16:37:13,663:INFO:Initializing create_model()
2023-04-06 16:37:13,663:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:37:13,663:INFO:Checking exceptions
2023-04-06 16:37:13,663:INFO:Importing libraries
2023-04-06 16:37:13,663:INFO:Copying training dataset
2023-04-06 16:37:13,665:INFO:Defining folds
2023-04-06 16:37:13,665:INFO:Declaring metric variables
2023-04-06 16:37:13,667:INFO:Importing untrained model
2023-04-06 16:37:13,668:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-06 16:37:13,670:INFO:Starting cross validation
2023-04-06 16:37:13,671:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:37:13,746:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:13,758:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:13,761:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:13,771:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:13,771:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:13,774:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:13,777:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:13,783:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:13,791:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:13,804:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:17,359:INFO:Calculating mean and std
2023-04-06 16:37:17,360:INFO:Creating metrics dataframe
2023-04-06 16:37:17,743:INFO:Uploading results into container
2023-04-06 16:37:17,744:INFO:Uploading model into container now
2023-04-06 16:37:17,744:INFO:_master_model_container: 7
2023-04-06 16:37:17,744:INFO:_display_container: 2
2023-04-06 16:37:17,744:INFO:OrthogonalMatchingPursuit()
2023-04-06 16:37:17,744:INFO:create_model() successfully completed......................................
2023-04-06 16:37:17,818:INFO:SubProcess create_model() end ==================================
2023-04-06 16:37:17,818:INFO:Creating metrics dataframe
2023-04-06 16:37:17,823:INFO:Initializing Bayesian Ridge
2023-04-06 16:37:17,823:INFO:Total runtime is 0.5401495019594829 minutes
2023-04-06 16:37:17,824:INFO:SubProcess create_model() called ==================================
2023-04-06 16:37:17,825:INFO:Initializing create_model()
2023-04-06 16:37:17,825:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:37:17,825:INFO:Checking exceptions
2023-04-06 16:37:17,825:INFO:Importing libraries
2023-04-06 16:37:17,825:INFO:Copying training dataset
2023-04-06 16:37:17,827:INFO:Defining folds
2023-04-06 16:37:17,827:INFO:Declaring metric variables
2023-04-06 16:37:17,829:INFO:Importing untrained model
2023-04-06 16:37:17,830:INFO:Bayesian Ridge Imported successfully
2023-04-06 16:37:17,832:INFO:Starting cross validation
2023-04-06 16:37:17,833:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:37:21,526:INFO:Calculating mean and std
2023-04-06 16:37:21,527:INFO:Creating metrics dataframe
2023-04-06 16:37:21,914:INFO:Uploading results into container
2023-04-06 16:37:21,915:INFO:Uploading model into container now
2023-04-06 16:37:21,915:INFO:_master_model_container: 8
2023-04-06 16:37:21,915:INFO:_display_container: 2
2023-04-06 16:37:21,915:INFO:BayesianRidge()
2023-04-06 16:37:21,915:INFO:create_model() successfully completed......................................
2023-04-06 16:37:21,993:INFO:SubProcess create_model() end ==================================
2023-04-06 16:37:21,993:INFO:Creating metrics dataframe
2023-04-06 16:37:21,997:INFO:Initializing Passive Aggressive Regressor
2023-04-06 16:37:21,998:INFO:Total runtime is 0.6097239176432292 minutes
2023-04-06 16:37:21,999:INFO:SubProcess create_model() called ==================================
2023-04-06 16:37:22,000:INFO:Initializing create_model()
2023-04-06 16:37:22,000:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:37:22,000:INFO:Checking exceptions
2023-04-06 16:37:22,000:INFO:Importing libraries
2023-04-06 16:37:22,000:INFO:Copying training dataset
2023-04-06 16:37:22,002:INFO:Defining folds
2023-04-06 16:37:22,002:INFO:Declaring metric variables
2023-04-06 16:37:22,004:INFO:Importing untrained model
2023-04-06 16:37:22,005:INFO:Passive Aggressive Regressor Imported successfully
2023-04-06 16:37:22,008:INFO:Starting cross validation
2023-04-06 16:37:22,008:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:37:25,776:INFO:Calculating mean and std
2023-04-06 16:37:25,777:INFO:Creating metrics dataframe
2023-04-06 16:37:26,166:INFO:Uploading results into container
2023-04-06 16:37:26,167:INFO:Uploading model into container now
2023-04-06 16:37:26,167:INFO:_master_model_container: 9
2023-04-06 16:37:26,167:INFO:_display_container: 2
2023-04-06 16:37:26,167:INFO:PassiveAggressiveRegressor(random_state=123)
2023-04-06 16:37:26,167:INFO:create_model() successfully completed......................................
2023-04-06 16:37:26,239:INFO:SubProcess create_model() end ==================================
2023-04-06 16:37:26,239:INFO:Creating metrics dataframe
2023-04-06 16:37:26,244:INFO:Initializing Huber Regressor
2023-04-06 16:37:26,244:INFO:Total runtime is 0.6804990967114767 minutes
2023-04-06 16:37:26,245:INFO:SubProcess create_model() called ==================================
2023-04-06 16:37:26,245:INFO:Initializing create_model()
2023-04-06 16:37:26,245:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:37:26,245:INFO:Checking exceptions
2023-04-06 16:37:26,246:INFO:Importing libraries
2023-04-06 16:37:26,246:INFO:Copying training dataset
2023-04-06 16:37:26,248:INFO:Defining folds
2023-04-06 16:37:26,248:INFO:Declaring metric variables
2023-04-06 16:37:26,249:INFO:Importing untrained model
2023-04-06 16:37:26,250:INFO:Huber Regressor Imported successfully
2023-04-06 16:37:26,253:INFO:Starting cross validation
2023-04-06 16:37:26,254:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:37:26,400:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 16:37:26,404:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 16:37:26,405:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 16:37:26,405:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 16:37:26,412:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 16:37:26,412:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 16:37:26,454:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 16:37:26,464:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 16:37:30,008:INFO:Calculating mean and std
2023-04-06 16:37:30,009:INFO:Creating metrics dataframe
2023-04-06 16:37:30,392:INFO:Uploading results into container
2023-04-06 16:37:30,392:INFO:Uploading model into container now
2023-04-06 16:37:30,392:INFO:_master_model_container: 10
2023-04-06 16:37:30,393:INFO:_display_container: 2
2023-04-06 16:37:30,393:INFO:HuberRegressor()
2023-04-06 16:37:30,393:INFO:create_model() successfully completed......................................
2023-04-06 16:37:30,470:INFO:SubProcess create_model() end ==================================
2023-04-06 16:37:30,470:INFO:Creating metrics dataframe
2023-04-06 16:37:30,476:INFO:Initializing K Neighbors Regressor
2023-04-06 16:37:30,476:INFO:Total runtime is 0.7510249654452006 minutes
2023-04-06 16:37:30,477:INFO:SubProcess create_model() called ==================================
2023-04-06 16:37:30,477:INFO:Initializing create_model()
2023-04-06 16:37:30,477:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:37:30,477:INFO:Checking exceptions
2023-04-06 16:37:30,477:INFO:Importing libraries
2023-04-06 16:37:30,477:INFO:Copying training dataset
2023-04-06 16:37:30,480:INFO:Defining folds
2023-04-06 16:37:30,480:INFO:Declaring metric variables
2023-04-06 16:37:30,481:INFO:Importing untrained model
2023-04-06 16:37:30,483:INFO:K Neighbors Regressor Imported successfully
2023-04-06 16:37:30,485:INFO:Starting cross validation
2023-04-06 16:37:30,486:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:37:34,293:INFO:Calculating mean and std
2023-04-06 16:37:34,294:INFO:Creating metrics dataframe
2023-04-06 16:37:34,661:INFO:Uploading results into container
2023-04-06 16:37:34,662:INFO:Uploading model into container now
2023-04-06 16:37:34,662:INFO:_master_model_container: 11
2023-04-06 16:37:34,662:INFO:_display_container: 2
2023-04-06 16:37:34,662:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-06 16:37:34,662:INFO:create_model() successfully completed......................................
2023-04-06 16:37:34,738:INFO:SubProcess create_model() end ==================================
2023-04-06 16:37:34,738:INFO:Creating metrics dataframe
2023-04-06 16:37:34,743:INFO:Initializing Decision Tree Regressor
2023-04-06 16:37:34,743:INFO:Total runtime is 0.8221426645914713 minutes
2023-04-06 16:37:34,744:INFO:SubProcess create_model() called ==================================
2023-04-06 16:37:34,744:INFO:Initializing create_model()
2023-04-06 16:37:34,744:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:37:34,744:INFO:Checking exceptions
2023-04-06 16:37:34,744:INFO:Importing libraries
2023-04-06 16:37:34,744:INFO:Copying training dataset
2023-04-06 16:37:34,747:INFO:Defining folds
2023-04-06 16:37:34,747:INFO:Declaring metric variables
2023-04-06 16:37:34,748:INFO:Importing untrained model
2023-04-06 16:37:34,754:INFO:Decision Tree Regressor Imported successfully
2023-04-06 16:37:34,758:INFO:Starting cross validation
2023-04-06 16:37:34,759:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:37:38,646:INFO:Calculating mean and std
2023-04-06 16:37:38,646:INFO:Creating metrics dataframe
2023-04-06 16:37:39,030:INFO:Uploading results into container
2023-04-06 16:37:39,030:INFO:Uploading model into container now
2023-04-06 16:37:39,031:INFO:_master_model_container: 12
2023-04-06 16:37:39,031:INFO:_display_container: 2
2023-04-06 16:37:39,031:INFO:DecisionTreeRegressor(random_state=123)
2023-04-06 16:37:39,031:INFO:create_model() successfully completed......................................
2023-04-06 16:37:39,106:INFO:SubProcess create_model() end ==================================
2023-04-06 16:37:39,106:INFO:Creating metrics dataframe
2023-04-06 16:37:39,111:INFO:Initializing Random Forest Regressor
2023-04-06 16:37:39,112:INFO:Total runtime is 0.8949593504269917 minutes
2023-04-06 16:37:39,113:INFO:SubProcess create_model() called ==================================
2023-04-06 16:37:39,113:INFO:Initializing create_model()
2023-04-06 16:37:39,114:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:37:39,114:INFO:Checking exceptions
2023-04-06 16:37:39,114:INFO:Importing libraries
2023-04-06 16:37:39,114:INFO:Copying training dataset
2023-04-06 16:37:39,116:INFO:Defining folds
2023-04-06 16:37:39,116:INFO:Declaring metric variables
2023-04-06 16:37:39,117:INFO:Importing untrained model
2023-04-06 16:37:39,119:INFO:Random Forest Regressor Imported successfully
2023-04-06 16:37:39,121:INFO:Starting cross validation
2023-04-06 16:37:39,122:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:37:43,756:INFO:Calculating mean and std
2023-04-06 16:37:43,757:INFO:Creating metrics dataframe
2023-04-06 16:37:44,138:INFO:Uploading results into container
2023-04-06 16:37:44,139:INFO:Uploading model into container now
2023-04-06 16:37:44,139:INFO:_master_model_container: 13
2023-04-06 16:37:44,139:INFO:_display_container: 2
2023-04-06 16:37:44,139:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-04-06 16:37:44,139:INFO:create_model() successfully completed......................................
2023-04-06 16:37:44,212:INFO:SubProcess create_model() end ==================================
2023-04-06 16:37:44,212:INFO:Creating metrics dataframe
2023-04-06 16:37:44,216:INFO:Initializing Extra Trees Regressor
2023-04-06 16:37:44,216:INFO:Total runtime is 0.980039616425832 minutes
2023-04-06 16:37:44,218:INFO:SubProcess create_model() called ==================================
2023-04-06 16:37:44,218:INFO:Initializing create_model()
2023-04-06 16:37:44,218:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:37:44,218:INFO:Checking exceptions
2023-04-06 16:37:44,218:INFO:Importing libraries
2023-04-06 16:37:44,218:INFO:Copying training dataset
2023-04-06 16:37:44,220:INFO:Defining folds
2023-04-06 16:37:44,220:INFO:Declaring metric variables
2023-04-06 16:37:44,221:INFO:Importing untrained model
2023-04-06 16:37:44,223:INFO:Extra Trees Regressor Imported successfully
2023-04-06 16:37:44,225:INFO:Starting cross validation
2023-04-06 16:37:44,226:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:37:49,133:INFO:Calculating mean and std
2023-04-06 16:37:49,134:INFO:Creating metrics dataframe
2023-04-06 16:37:49,520:INFO:Uploading results into container
2023-04-06 16:37:49,520:INFO:Uploading model into container now
2023-04-06 16:37:49,520:INFO:_master_model_container: 14
2023-04-06 16:37:49,520:INFO:_display_container: 2
2023-04-06 16:37:49,521:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-04-06 16:37:49,521:INFO:create_model() successfully completed......................................
2023-04-06 16:37:49,599:INFO:SubProcess create_model() end ==================================
2023-04-06 16:37:49,599:INFO:Creating metrics dataframe
2023-04-06 16:37:49,603:INFO:Initializing AdaBoost Regressor
2023-04-06 16:37:49,603:INFO:Total runtime is 1.0698230822881063 minutes
2023-04-06 16:37:49,605:INFO:SubProcess create_model() called ==================================
2023-04-06 16:37:49,605:INFO:Initializing create_model()
2023-04-06 16:37:49,605:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:37:49,605:INFO:Checking exceptions
2023-04-06 16:37:49,605:INFO:Importing libraries
2023-04-06 16:37:49,605:INFO:Copying training dataset
2023-04-06 16:37:49,608:INFO:Defining folds
2023-04-06 16:37:49,608:INFO:Declaring metric variables
2023-04-06 16:37:49,609:INFO:Importing untrained model
2023-04-06 16:37:49,611:INFO:AdaBoost Regressor Imported successfully
2023-04-06 16:37:49,613:INFO:Starting cross validation
2023-04-06 16:37:49,614:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:37:53,697:INFO:Calculating mean and std
2023-04-06 16:37:53,699:INFO:Creating metrics dataframe
2023-04-06 16:37:54,108:INFO:Uploading results into container
2023-04-06 16:37:54,109:INFO:Uploading model into container now
2023-04-06 16:37:54,110:INFO:_master_model_container: 15
2023-04-06 16:37:54,110:INFO:_display_container: 2
2023-04-06 16:37:54,110:INFO:AdaBoostRegressor(random_state=123)
2023-04-06 16:37:54,110:INFO:create_model() successfully completed......................................
2023-04-06 16:37:54,187:INFO:SubProcess create_model() end ==================================
2023-04-06 16:37:54,187:INFO:Creating metrics dataframe
2023-04-06 16:37:54,192:INFO:Initializing Gradient Boosting Regressor
2023-04-06 16:37:54,193:INFO:Total runtime is 1.1463085333506267 minutes
2023-04-06 16:37:54,194:INFO:SubProcess create_model() called ==================================
2023-04-06 16:37:54,194:INFO:Initializing create_model()
2023-04-06 16:37:54,194:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:37:54,194:INFO:Checking exceptions
2023-04-06 16:37:54,194:INFO:Importing libraries
2023-04-06 16:37:54,194:INFO:Copying training dataset
2023-04-06 16:37:54,197:INFO:Defining folds
2023-04-06 16:37:54,197:INFO:Declaring metric variables
2023-04-06 16:37:54,200:INFO:Importing untrained model
2023-04-06 16:37:54,202:INFO:Gradient Boosting Regressor Imported successfully
2023-04-06 16:37:54,206:INFO:Starting cross validation
2023-04-06 16:37:54,207:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:37:58,167:INFO:Calculating mean and std
2023-04-06 16:37:58,168:INFO:Creating metrics dataframe
2023-04-06 16:37:58,573:INFO:Uploading results into container
2023-04-06 16:37:58,574:INFO:Uploading model into container now
2023-04-06 16:37:58,574:INFO:_master_model_container: 16
2023-04-06 16:37:58,574:INFO:_display_container: 2
2023-04-06 16:37:58,575:INFO:GradientBoostingRegressor(random_state=123)
2023-04-06 16:37:58,575:INFO:create_model() successfully completed......................................
2023-04-06 16:37:58,652:INFO:SubProcess create_model() end ==================================
2023-04-06 16:37:58,652:INFO:Creating metrics dataframe
2023-04-06 16:37:58,657:INFO:Initializing Extreme Gradient Boosting
2023-04-06 16:37:58,657:INFO:Total runtime is 1.2207218170166017 minutes
2023-04-06 16:37:58,659:INFO:SubProcess create_model() called ==================================
2023-04-06 16:37:58,659:INFO:Initializing create_model()
2023-04-06 16:37:58,659:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:37:58,659:INFO:Checking exceptions
2023-04-06 16:37:58,659:INFO:Importing libraries
2023-04-06 16:37:58,660:INFO:Copying training dataset
2023-04-06 16:37:58,662:INFO:Defining folds
2023-04-06 16:37:58,662:INFO:Declaring metric variables
2023-04-06 16:37:58,663:INFO:Importing untrained model
2023-04-06 16:37:58,665:INFO:Extreme Gradient Boosting Imported successfully
2023-04-06 16:37:58,668:INFO:Starting cross validation
2023-04-06 16:37:58,669:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:38:03,010:INFO:Calculating mean and std
2023-04-06 16:38:03,011:INFO:Creating metrics dataframe
2023-04-06 16:38:03,399:INFO:Uploading results into container
2023-04-06 16:38:03,399:INFO:Uploading model into container now
2023-04-06 16:38:03,399:INFO:_master_model_container: 17
2023-04-06 16:38:03,399:INFO:_display_container: 2
2023-04-06 16:38:03,400:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=123, ...)
2023-04-06 16:38:03,400:INFO:create_model() successfully completed......................................
2023-04-06 16:38:03,479:INFO:SubProcess create_model() end ==================================
2023-04-06 16:38:03,479:INFO:Creating metrics dataframe
2023-04-06 16:38:03,485:INFO:Initializing Light Gradient Boosting Machine
2023-04-06 16:38:03,486:INFO:Total runtime is 1.301191798845927 minutes
2023-04-06 16:38:03,487:INFO:SubProcess create_model() called ==================================
2023-04-06 16:38:03,487:INFO:Initializing create_model()
2023-04-06 16:38:03,487:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:38:03,488:INFO:Checking exceptions
2023-04-06 16:38:03,488:INFO:Importing libraries
2023-04-06 16:38:03,488:INFO:Copying training dataset
2023-04-06 16:38:03,490:INFO:Defining folds
2023-04-06 16:38:03,490:INFO:Declaring metric variables
2023-04-06 16:38:03,492:INFO:Importing untrained model
2023-04-06 16:38:03,494:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-06 16:38:03,498:INFO:Starting cross validation
2023-04-06 16:38:03,499:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:38:08,047:INFO:Calculating mean and std
2023-04-06 16:38:08,049:INFO:Creating metrics dataframe
2023-04-06 16:38:08,427:INFO:Uploading results into container
2023-04-06 16:38:08,428:INFO:Uploading model into container now
2023-04-06 16:38:08,428:INFO:_master_model_container: 18
2023-04-06 16:38:08,428:INFO:_display_container: 2
2023-04-06 16:38:08,429:INFO:LGBMRegressor(random_state=123)
2023-04-06 16:38:08,429:INFO:create_model() successfully completed......................................
2023-04-06 16:38:08,501:INFO:SubProcess create_model() end ==================================
2023-04-06 16:38:08,502:INFO:Creating metrics dataframe
2023-04-06 16:38:08,507:INFO:Initializing CatBoost Regressor
2023-04-06 16:38:08,507:INFO:Total runtime is 1.3848868648211161 minutes
2023-04-06 16:38:08,509:INFO:SubProcess create_model() called ==================================
2023-04-06 16:38:08,509:INFO:Initializing create_model()
2023-04-06 16:38:08,509:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:38:08,509:INFO:Checking exceptions
2023-04-06 16:38:08,509:INFO:Importing libraries
2023-04-06 16:38:08,509:INFO:Copying training dataset
2023-04-06 16:38:08,511:INFO:Defining folds
2023-04-06 16:38:08,511:INFO:Declaring metric variables
2023-04-06 16:38:08,512:INFO:Importing untrained model
2023-04-06 16:38:08,515:INFO:CatBoost Regressor Imported successfully
2023-04-06 16:38:08,518:INFO:Starting cross validation
2023-04-06 16:38:08,518:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:38:13,900:INFO:Calculating mean and std
2023-04-06 16:38:13,900:INFO:Creating metrics dataframe
2023-04-06 16:38:14,292:INFO:Uploading results into container
2023-04-06 16:38:14,293:INFO:Uploading model into container now
2023-04-06 16:38:14,294:INFO:_master_model_container: 19
2023-04-06 16:38:14,294:INFO:_display_container: 2
2023-04-06 16:38:14,294:INFO:<catboost.core.CatBoostRegressor object at 0x177019f40>
2023-04-06 16:38:14,294:INFO:create_model() successfully completed......................................
2023-04-06 16:38:14,368:INFO:SubProcess create_model() end ==================================
2023-04-06 16:38:14,368:INFO:Creating metrics dataframe
2023-04-06 16:38:14,373:INFO:Initializing Dummy Regressor
2023-04-06 16:38:14,373:INFO:Total runtime is 1.4826469699541727 minutes
2023-04-06 16:38:14,374:INFO:SubProcess create_model() called ==================================
2023-04-06 16:38:14,374:INFO:Initializing create_model()
2023-04-06 16:38:14,374:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:38:14,374:INFO:Checking exceptions
2023-04-06 16:38:14,374:INFO:Importing libraries
2023-04-06 16:38:14,374:INFO:Copying training dataset
2023-04-06 16:38:14,377:INFO:Defining folds
2023-04-06 16:38:14,377:INFO:Declaring metric variables
2023-04-06 16:38:14,378:INFO:Importing untrained model
2023-04-06 16:38:14,379:INFO:Dummy Regressor Imported successfully
2023-04-06 16:38:14,381:INFO:Starting cross validation
2023-04-06 16:38:14,382:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:38:18,250:INFO:Calculating mean and std
2023-04-06 16:38:18,251:INFO:Creating metrics dataframe
2023-04-06 16:38:18,643:INFO:Uploading results into container
2023-04-06 16:38:18,644:INFO:Uploading model into container now
2023-04-06 16:38:18,644:INFO:_master_model_container: 20
2023-04-06 16:38:18,645:INFO:_display_container: 2
2023-04-06 16:38:18,645:INFO:DummyRegressor()
2023-04-06 16:38:18,645:INFO:create_model() successfully completed......................................
2023-04-06 16:38:18,721:INFO:SubProcess create_model() end ==================================
2023-04-06 16:38:18,721:INFO:Creating metrics dataframe
2023-04-06 16:38:18,731:INFO:Initializing create_model()
2023-04-06 16:38:18,732:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=<catboost.core.CatBoostRegressor object at 0x177019f40>, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:38:18,732:INFO:Checking exceptions
2023-04-06 16:38:18,733:INFO:Importing libraries
2023-04-06 16:38:18,733:INFO:Copying training dataset
2023-04-06 16:38:18,738:INFO:Defining folds
2023-04-06 16:38:18,738:INFO:Declaring metric variables
2023-04-06 16:38:18,739:INFO:Importing untrained model
2023-04-06 16:38:18,739:INFO:Declaring custom model
2023-04-06 16:38:18,739:INFO:CatBoost Regressor Imported successfully
2023-04-06 16:38:18,744:INFO:Cross validation set to False
2023-04-06 16:38:18,744:INFO:Fitting Model
2023-04-06 16:38:20,121:INFO:<catboost.core.CatBoostRegressor object at 0x176baee20>
2023-04-06 16:38:20,121:INFO:create_model() successfully completed......................................
2023-04-06 16:38:20,210:INFO:_master_model_container: 20
2023-04-06 16:38:20,210:INFO:_display_container: 2
2023-04-06 16:38:20,210:INFO:<catboost.core.CatBoostRegressor object at 0x176baee20>
2023-04-06 16:38:20,210:INFO:compare_models() successfully completed......................................
2023-04-06 16:38:58,855:INFO:Initializing create_model()
2023-04-06 16:38:58,856:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=ada, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:38:58,856:INFO:Checking exceptions
2023-04-06 16:38:58,878:INFO:Importing libraries
2023-04-06 16:38:58,878:INFO:Copying training dataset
2023-04-06 16:38:58,883:INFO:Defining folds
2023-04-06 16:38:58,883:INFO:Declaring metric variables
2023-04-06 16:38:58,885:INFO:Importing untrained model
2023-04-06 16:38:58,886:INFO:AdaBoost Regressor Imported successfully
2023-04-06 16:38:58,890:INFO:Starting cross validation
2023-04-06 16:38:58,891:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:39:02,604:INFO:Calculating mean and std
2023-04-06 16:39:02,604:INFO:Creating metrics dataframe
2023-04-06 16:39:02,607:INFO:Finalizing model
2023-04-06 16:39:03,196:INFO:Uploading results into container
2023-04-06 16:39:03,197:INFO:Uploading model into container now
2023-04-06 16:39:03,200:INFO:_master_model_container: 21
2023-04-06 16:39:03,200:INFO:_display_container: 3
2023-04-06 16:39:03,200:INFO:AdaBoostRegressor(random_state=123)
2023-04-06 16:39:03,200:INFO:create_model() successfully completed......................................
2023-04-06 16:39:03,285:INFO:Initializing create_model()
2023-04-06 16:39:03,286:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:39:03,286:INFO:Checking exceptions
2023-04-06 16:39:03,293:INFO:Importing libraries
2023-04-06 16:39:03,293:INFO:Copying training dataset
2023-04-06 16:39:03,297:INFO:Defining folds
2023-04-06 16:39:03,297:INFO:Declaring metric variables
2023-04-06 16:39:03,298:INFO:Importing untrained model
2023-04-06 16:39:03,299:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-06 16:39:03,302:INFO:Starting cross validation
2023-04-06 16:39:03,303:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:39:07,055:INFO:Calculating mean and std
2023-04-06 16:39:07,056:INFO:Creating metrics dataframe
2023-04-06 16:39:07,058:INFO:Finalizing model
2023-04-06 16:39:07,526:INFO:Uploading results into container
2023-04-06 16:39:07,527:INFO:Uploading model into container now
2023-04-06 16:39:07,530:INFO:_master_model_container: 22
2023-04-06 16:39:07,530:INFO:_display_container: 4
2023-04-06 16:39:07,530:INFO:LGBMRegressor(random_state=123)
2023-04-06 16:39:07,530:INFO:create_model() successfully completed......................................
2023-04-06 16:39:07,608:INFO:Initializing create_model()
2023-04-06 16:39:07,608:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:39:07,608:INFO:Checking exceptions
2023-04-06 16:39:07,615:INFO:Importing libraries
2023-04-06 16:39:07,615:INFO:Copying training dataset
2023-04-06 16:39:07,619:INFO:Defining folds
2023-04-06 16:39:07,620:INFO:Declaring metric variables
2023-04-06 16:39:07,621:INFO:Importing untrained model
2023-04-06 16:39:07,623:INFO:Decision Tree Regressor Imported successfully
2023-04-06 16:39:07,626:INFO:Starting cross validation
2023-04-06 16:39:07,627:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:39:11,458:INFO:Calculating mean and std
2023-04-06 16:39:11,460:INFO:Creating metrics dataframe
2023-04-06 16:39:11,462:INFO:Finalizing model
2023-04-06 16:39:11,926:INFO:Uploading results into container
2023-04-06 16:39:11,926:INFO:Uploading model into container now
2023-04-06 16:39:11,931:INFO:_master_model_container: 23
2023-04-06 16:39:11,931:INFO:_display_container: 5
2023-04-06 16:39:11,931:INFO:DecisionTreeRegressor(random_state=123)
2023-04-06 16:39:11,931:INFO:create_model() successfully completed......................................
2023-04-06 16:39:12,012:INFO:Initializing tune_model()
2023-04-06 16:39:12,012:INFO:tune_model(estimator=ada, fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>)
2023-04-06 16:39:12,012:INFO:Checking exceptions
2023-04-06 16:40:21,117:INFO:Initializing tune_model()
2023-04-06 16:40:21,118:INFO:tune_model(estimator=lightgbm, fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>)
2023-04-06 16:40:21,119:INFO:Checking exceptions
2023-04-06 16:40:28,849:INFO:Initializing tune_model()
2023-04-06 16:40:28,850:INFO:tune_model(estimator=dt, fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>)
2023-04-06 16:40:28,850:INFO:Checking exceptions
2023-04-06 16:43:27,395:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-06 16:43:27,396:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-06 16:43:27,396:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-06 16:43:27,396:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-06 16:43:27,990:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-06 16:43:28,617:INFO:PyCaret RegressionExperiment
2023-04-06 16:43:28,617:INFO:Logging name: reg-default-name
2023-04-06 16:43:28,617:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-06 16:43:28,617:INFO:version 3.0.0
2023-04-06 16:43:28,617:INFO:Initializing setup()
2023-04-06 16:43:28,617:INFO:self.USI: a2b4
2023-04-06 16:43:28,617:INFO:self._variable_keys: {'X_test', 'USI', 'fold_groups_param', 'X_train', 'transform_target_param', 'n_jobs_param', 'y_test', 'exp_name_log', 'y_train', 'exp_id', '_available_plots', 'idx', 'logging_param', 'fold_generator', 'target_param', 'data', 'log_plots_param', 'gpu_n_jobs_param', 'seed', 'pipeline', 'X', '_ml_usecase', 'html_param', 'gpu_param', 'fold_shuffle_param', 'y', 'memory'}
2023-04-06 16:43:28,617:INFO:Checking environment
2023-04-06 16:43:28,617:INFO:python_version: 3.9.15
2023-04-06 16:43:28,617:INFO:python_build: ('main', 'Nov 24 2022 08:28:41')
2023-04-06 16:43:28,617:INFO:machine: arm64
2023-04-06 16:43:28,617:INFO:platform: macOS-13.2-arm64-arm-64bit
2023-04-06 16:43:28,617:INFO:Memory: svmem(total=17179869184, available=4853432320, percent=71.7, used=6362988544, free=803487744, active=4054876160, inactive=3897278464, wired=2308112384)
2023-04-06 16:43:28,617:INFO:Physical Core: 10
2023-04-06 16:43:28,617:INFO:Logical Core: 10
2023-04-06 16:43:28,617:INFO:Checking libraries
2023-04-06 16:43:28,617:INFO:System:
2023-04-06 16:43:28,617:INFO:    python: 3.9.15 (main, Nov 24 2022, 08:28:41)  [Clang 14.0.6 ]
2023-04-06 16:43:28,617:INFO:executable: /Users/a06411/opt/anaconda3/bin/python
2023-04-06 16:43:28,617:INFO:   machine: macOS-13.2-arm64-arm-64bit
2023-04-06 16:43:28,617:INFO:PyCaret required dependencies:
2023-04-06 16:43:28,617:INFO:                 pip: 22.3.1
2023-04-06 16:43:28,617:INFO:          setuptools: 65.5.0
2023-04-06 16:43:28,617:INFO:             pycaret: 3.0.0
2023-04-06 16:43:28,617:INFO:             IPython: 8.7.0
2023-04-06 16:43:28,617:INFO:          ipywidgets: 7.6.5
2023-04-06 16:43:28,617:INFO:                tqdm: 4.64.1
2023-04-06 16:43:28,617:INFO:               numpy: 1.21.5
2023-04-06 16:43:28,617:INFO:              pandas: 1.4.4
2023-04-06 16:43:28,617:INFO:              jinja2: 2.11.3
2023-04-06 16:43:28,617:INFO:               scipy: 1.9.3
2023-04-06 16:43:28,617:INFO:              joblib: 1.2.0
2023-04-06 16:43:28,617:INFO:             sklearn: 1.1.3
2023-04-06 16:43:28,617:INFO:                pyod: 1.0.9
2023-04-06 16:43:28,617:INFO:            imblearn: 0.10.1
2023-04-06 16:43:28,617:INFO:   category_encoders: 2.6.0
2023-04-06 16:43:28,617:INFO:            lightgbm: 3.3.5
2023-04-06 16:43:28,617:INFO:               numba: 0.56.4
2023-04-06 16:43:28,617:INFO:            requests: 2.28.1
2023-04-06 16:43:28,617:INFO:          matplotlib: 3.6.2
2023-04-06 16:43:28,617:INFO:          scikitplot: 0.3.7
2023-04-06 16:43:28,617:INFO:         yellowbrick: 1.5
2023-04-06 16:43:28,617:INFO:              plotly: 5.9.0
2023-04-06 16:43:28,617:INFO:             kaleido: 0.2.1
2023-04-06 16:43:28,617:INFO:         statsmodels: 0.13.2
2023-04-06 16:43:28,617:INFO:              sktime: 0.16.1
2023-04-06 16:43:28,617:INFO:               tbats: 1.1.2
2023-04-06 16:43:28,617:INFO:            pmdarima: 2.0.3
2023-04-06 16:43:28,617:INFO:              psutil: 5.9.0
2023-04-06 16:43:28,617:INFO:PyCaret optional dependencies:
2023-04-06 16:43:28,622:INFO:                shap: 0.41.0
2023-04-06 16:43:28,622:INFO:           interpret: Not installed
2023-04-06 16:43:28,622:INFO:                umap: 0.5.3
2023-04-06 16:43:28,622:INFO:    pandas_profiling: Not installed
2023-04-06 16:43:28,622:INFO:  explainerdashboard: 0.4.2.1
2023-04-06 16:43:28,622:INFO:             autoviz: Not installed
2023-04-06 16:43:28,622:INFO:           fairlearn: Not installed
2023-04-06 16:43:28,622:INFO:             xgboost: 1.7.2
2023-04-06 16:43:28,622:INFO:            catboost: 1.1.1
2023-04-06 16:43:28,622:INFO:              kmodes: Not installed
2023-04-06 16:43:28,622:INFO:             mlxtend: Not installed
2023-04-06 16:43:28,622:INFO:       statsforecast: Not installed
2023-04-06 16:43:28,622:INFO:        tune_sklearn: Not installed
2023-04-06 16:43:28,622:INFO:                 ray: Not installed
2023-04-06 16:43:28,622:INFO:            hyperopt: 0.2.7
2023-04-06 16:43:28,622:INFO:              optuna: 3.1.0
2023-04-06 16:43:28,622:INFO:               skopt: 0.9.0
2023-04-06 16:43:28,622:INFO:              mlflow: 2.2.2
2023-04-06 16:43:28,622:INFO:              gradio: Not installed
2023-04-06 16:43:28,622:INFO:             fastapi: Not installed
2023-04-06 16:43:28,622:INFO:             uvicorn: Not installed
2023-04-06 16:43:28,622:INFO:              m2cgen: Not installed
2023-04-06 16:43:28,622:INFO:           evidently: Not installed
2023-04-06 16:43:28,622:INFO:               fugue: Not installed
2023-04-06 16:43:28,622:INFO:           streamlit: Not installed
2023-04-06 16:43:28,622:INFO:             prophet: Not installed
2023-04-06 16:43:28,622:INFO:None
2023-04-06 16:43:28,622:INFO:Set up data.
2023-04-06 16:43:28,626:INFO:Set up train/test split.
2023-04-06 16:43:28,627:INFO:Set up index.
2023-04-06 16:43:28,627:INFO:Set up folding strategy.
2023-04-06 16:43:28,627:INFO:Assigning column types.
2023-04-06 16:43:28,628:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-06 16:43:28,629:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,630:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,632:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,655:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,673:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,673:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:43:28,806:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:43:28,818:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,820:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,822:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,846:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,864:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,864:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:43:28,865:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:43:28,866:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-06 16:43:28,867:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,869:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,893:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,911:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,911:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:43:28,912:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:43:28,914:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,916:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,939:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,956:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,957:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:43:28,958:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:43:28,958:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-06 16:43:28,961:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,984:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:43:29,002:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 16:43:29,002:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:43:29,003:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:43:29,007:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 16:43:29,030:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:43:29,048:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 16:43:29,048:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:43:29,049:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:43:29,050:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-06 16:43:29,078:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:43:29,096:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 16:43:29,096:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:43:29,097:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:43:29,123:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:43:29,142:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 16:43:29,142:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:43:29,143:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:43:29,143:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-06 16:43:29,170:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:43:29,188:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:43:29,189:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:43:29,215:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:43:29,233:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:43:29,234:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:43:29,235:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-06 16:43:29,279:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:43:29,280:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:43:29,325:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:43:29,326:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:43:29,328:INFO:Preparing preprocessing pipeline...
2023-04-06 16:43:29,328:INFO:Set up simple imputation.
2023-04-06 16:43:29,330:INFO:Set up encoding of ordinal features.
2023-04-06 16:43:29,330:INFO:Set up encoding of categorical features.
2023-04-06 16:43:29,331:INFO:Set up column name cleaning.
2023-04-06 16:43:29,389:INFO:Finished creating preprocessing pipeline.
2023-04-06 16:43:29,400:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry', 'Report'],
                                    transformer=SimpleImputer(strategy='most_frequent')...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': AGSL    0
GIA     1
NaN    -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry'],
                                    transformer=OneHotEncoder(cols=['Cut',
                                                                    'Color',
                                                                    'Clarity',
                                                                    'Polish',
                                                                    'Symmetry'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-06 16:43:29,400:INFO:Creating final display dataframe.
2023-04-06 16:43:29,533:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             Price
2                   Target type        Regression
3           Original data shape         (5400, 8)
4        Transformed data shape        (5400, 29)
5   Transformed train set shape        (3779, 29)
6    Transformed test set shape        (1621, 29)
7              Ordinal features                 1
8              Numeric features                 1
9          Categorical features                 6
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              a2b4
2023-04-06 16:43:29,583:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:43:29,584:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:43:29,630:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:43:29,631:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:43:29,631:INFO:setup() successfully completed in 1.46s...............
2023-04-06 16:43:29,634:INFO:Initializing compare_models()
2023-04-06 16:43:29,634:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-06 16:43:29,634:INFO:Checking exceptions
2023-04-06 16:43:29,635:INFO:Preparing display monitor
2023-04-06 16:43:29,659:INFO:Initializing Linear Regression
2023-04-06 16:43:29,659:INFO:Total runtime is 3.417332967122396e-06 minutes
2023-04-06 16:43:29,661:INFO:SubProcess create_model() called ==================================
2023-04-06 16:43:29,662:INFO:Initializing create_model()
2023-04-06 16:43:29,662:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:43:29,662:INFO:Checking exceptions
2023-04-06 16:43:29,662:INFO:Importing libraries
2023-04-06 16:43:29,662:INFO:Copying training dataset
2023-04-06 16:43:29,666:INFO:Defining folds
2023-04-06 16:43:29,666:INFO:Declaring metric variables
2023-04-06 16:43:29,667:INFO:Importing untrained model
2023-04-06 16:43:29,669:INFO:Linear Regression Imported successfully
2023-04-06 16:43:29,672:INFO:Starting cross validation
2023-04-06 16:43:29,677:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:43:35,991:INFO:Calculating mean and std
2023-04-06 16:43:35,992:INFO:Creating metrics dataframe
2023-04-06 16:43:36,373:INFO:Uploading results into container
2023-04-06 16:43:36,374:INFO:Uploading model into container now
2023-04-06 16:43:36,374:INFO:_master_model_container: 1
2023-04-06 16:43:36,374:INFO:_display_container: 2
2023-04-06 16:43:36,374:INFO:LinearRegression(n_jobs=-1)
2023-04-06 16:43:36,375:INFO:create_model() successfully completed......................................
2023-04-06 16:43:36,442:INFO:SubProcess create_model() end ==================================
2023-04-06 16:43:36,442:INFO:Creating metrics dataframe
2023-04-06 16:43:36,445:INFO:Initializing Lasso Regression
2023-04-06 16:43:36,445:INFO:Total runtime is 0.11309589942296346 minutes
2023-04-06 16:43:36,446:INFO:SubProcess create_model() called ==================================
2023-04-06 16:43:36,447:INFO:Initializing create_model()
2023-04-06 16:43:36,447:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:43:36,447:INFO:Checking exceptions
2023-04-06 16:43:36,447:INFO:Importing libraries
2023-04-06 16:43:36,447:INFO:Copying training dataset
2023-04-06 16:43:36,449:INFO:Defining folds
2023-04-06 16:43:36,449:INFO:Declaring metric variables
2023-04-06 16:43:36,450:INFO:Importing untrained model
2023-04-06 16:43:36,451:INFO:Lasso Regression Imported successfully
2023-04-06 16:43:36,454:INFO:Starting cross validation
2023-04-06 16:43:36,455:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:43:40,174:INFO:Calculating mean and std
2023-04-06 16:43:40,174:INFO:Creating metrics dataframe
2023-04-06 16:43:40,565:INFO:Uploading results into container
2023-04-06 16:43:40,566:INFO:Uploading model into container now
2023-04-06 16:43:40,566:INFO:_master_model_container: 2
2023-04-06 16:43:40,566:INFO:_display_container: 2
2023-04-06 16:43:40,566:INFO:Lasso(random_state=123)
2023-04-06 16:43:40,566:INFO:create_model() successfully completed......................................
2023-04-06 16:43:40,621:INFO:SubProcess create_model() end ==================================
2023-04-06 16:43:40,621:INFO:Creating metrics dataframe
2023-04-06 16:43:40,624:INFO:Initializing Ridge Regression
2023-04-06 16:43:40,624:INFO:Total runtime is 0.18275176684061686 minutes
2023-04-06 16:43:40,626:INFO:SubProcess create_model() called ==================================
2023-04-06 16:43:40,626:INFO:Initializing create_model()
2023-04-06 16:43:40,626:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:43:40,626:INFO:Checking exceptions
2023-04-06 16:43:40,626:INFO:Importing libraries
2023-04-06 16:43:40,626:INFO:Copying training dataset
2023-04-06 16:43:40,628:INFO:Defining folds
2023-04-06 16:43:40,628:INFO:Declaring metric variables
2023-04-06 16:43:40,629:INFO:Importing untrained model
2023-04-06 16:43:40,630:INFO:Ridge Regression Imported successfully
2023-04-06 16:43:40,632:INFO:Starting cross validation
2023-04-06 16:43:40,633:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:43:44,334:INFO:Calculating mean and std
2023-04-06 16:43:44,335:INFO:Creating metrics dataframe
2023-04-06 16:43:44,720:INFO:Uploading results into container
2023-04-06 16:43:44,720:INFO:Uploading model into container now
2023-04-06 16:43:44,721:INFO:_master_model_container: 3
2023-04-06 16:43:44,721:INFO:_display_container: 2
2023-04-06 16:43:44,721:INFO:Ridge(random_state=123)
2023-04-06 16:43:44,721:INFO:create_model() successfully completed......................................
2023-04-06 16:43:44,777:INFO:SubProcess create_model() end ==================================
2023-04-06 16:43:44,777:INFO:Creating metrics dataframe
2023-04-06 16:43:44,781:INFO:Initializing Elastic Net
2023-04-06 16:43:44,781:INFO:Total runtime is 0.25202696720759077 minutes
2023-04-06 16:43:44,782:INFO:SubProcess create_model() called ==================================
2023-04-06 16:43:44,782:INFO:Initializing create_model()
2023-04-06 16:43:44,782:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:43:44,782:INFO:Checking exceptions
2023-04-06 16:43:44,782:INFO:Importing libraries
2023-04-06 16:43:44,782:INFO:Copying training dataset
2023-04-06 16:43:44,784:INFO:Defining folds
2023-04-06 16:43:44,784:INFO:Declaring metric variables
2023-04-06 16:43:44,785:INFO:Importing untrained model
2023-04-06 16:43:44,787:INFO:Elastic Net Imported successfully
2023-04-06 16:43:44,789:INFO:Starting cross validation
2023-04-06 16:43:44,790:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:43:48,617:INFO:Calculating mean and std
2023-04-06 16:43:48,618:INFO:Creating metrics dataframe
2023-04-06 16:43:48,988:INFO:Uploading results into container
2023-04-06 16:43:48,989:INFO:Uploading model into container now
2023-04-06 16:43:48,989:INFO:_master_model_container: 4
2023-04-06 16:43:48,989:INFO:_display_container: 2
2023-04-06 16:43:48,989:INFO:ElasticNet(random_state=123)
2023-04-06 16:43:48,989:INFO:create_model() successfully completed......................................
2023-04-06 16:43:49,046:INFO:SubProcess create_model() end ==================================
2023-04-06 16:43:49,046:INFO:Creating metrics dataframe
2023-04-06 16:43:49,050:INFO:Initializing Least Angle Regression
2023-04-06 16:43:49,050:INFO:Total runtime is 0.32318618297576907 minutes
2023-04-06 16:43:49,052:INFO:SubProcess create_model() called ==================================
2023-04-06 16:43:49,052:INFO:Initializing create_model()
2023-04-06 16:43:49,052:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:43:49,052:INFO:Checking exceptions
2023-04-06 16:43:49,052:INFO:Importing libraries
2023-04-06 16:43:49,052:INFO:Copying training dataset
2023-04-06 16:43:49,054:INFO:Defining folds
2023-04-06 16:43:49,054:INFO:Declaring metric variables
2023-04-06 16:43:49,055:INFO:Importing untrained model
2023-04-06 16:43:49,057:INFO:Least Angle Regression Imported successfully
2023-04-06 16:43:49,060:INFO:Starting cross validation
2023-04-06 16:43:49,061:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:43:49,144:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:49,149:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:49,157:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:49,162:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:49,173:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:49,175:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:49,176:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=6.036e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 16:43:49,176:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=4.789e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 16:43:49,176:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.582e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 16:43:49,176:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.117e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 16:43:49,176:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.036e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 16:43:49,180:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:49,194:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:49,207:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:49,231:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:52,873:INFO:Calculating mean and std
2023-04-06 16:43:52,874:INFO:Creating metrics dataframe
2023-04-06 16:43:53,278:INFO:Uploading results into container
2023-04-06 16:43:53,278:INFO:Uploading model into container now
2023-04-06 16:43:53,278:INFO:_master_model_container: 5
2023-04-06 16:43:53,278:INFO:_display_container: 2
2023-04-06 16:43:53,279:INFO:Lars(random_state=123)
2023-04-06 16:43:53,279:INFO:create_model() successfully completed......................................
2023-04-06 16:43:53,333:INFO:SubProcess create_model() end ==================================
2023-04-06 16:43:53,333:INFO:Creating metrics dataframe
2023-04-06 16:43:53,337:INFO:Initializing Lasso Least Angle Regression
2023-04-06 16:43:53,337:INFO:Total runtime is 0.39463286399841313 minutes
2023-04-06 16:43:53,338:INFO:SubProcess create_model() called ==================================
2023-04-06 16:43:53,339:INFO:Initializing create_model()
2023-04-06 16:43:53,339:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:43:53,339:INFO:Checking exceptions
2023-04-06 16:43:53,339:INFO:Importing libraries
2023-04-06 16:43:53,339:INFO:Copying training dataset
2023-04-06 16:43:53,341:INFO:Defining folds
2023-04-06 16:43:53,341:INFO:Declaring metric variables
2023-04-06 16:43:53,342:INFO:Importing untrained model
2023-04-06 16:43:53,344:INFO:Lasso Least Angle Regression Imported successfully
2023-04-06 16:43:53,346:INFO:Starting cross validation
2023-04-06 16:43:53,347:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:43:53,427:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:43:53,434:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:43:53,443:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:43:53,443:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:43:53,450:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:43:53,457:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:43:53,461:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:43:53,466:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:43:53,488:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:43:53,492:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:43:57,046:INFO:Calculating mean and std
2023-04-06 16:43:57,047:INFO:Creating metrics dataframe
2023-04-06 16:43:57,435:INFO:Uploading results into container
2023-04-06 16:43:57,436:INFO:Uploading model into container now
2023-04-06 16:43:57,436:INFO:_master_model_container: 6
2023-04-06 16:43:57,436:INFO:_display_container: 2
2023-04-06 16:43:57,436:INFO:LassoLars(random_state=123)
2023-04-06 16:43:57,436:INFO:create_model() successfully completed......................................
2023-04-06 16:43:57,493:INFO:SubProcess create_model() end ==================================
2023-04-06 16:43:57,493:INFO:Creating metrics dataframe
2023-04-06 16:43:57,498:INFO:Initializing Orthogonal Matching Pursuit
2023-04-06 16:43:57,498:INFO:Total runtime is 0.46398140192031867 minutes
2023-04-06 16:43:57,500:INFO:SubProcess create_model() called ==================================
2023-04-06 16:43:57,500:INFO:Initializing create_model()
2023-04-06 16:43:57,500:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:43:57,500:INFO:Checking exceptions
2023-04-06 16:43:57,500:INFO:Importing libraries
2023-04-06 16:43:57,500:INFO:Copying training dataset
2023-04-06 16:43:57,503:INFO:Defining folds
2023-04-06 16:43:57,503:INFO:Declaring metric variables
2023-04-06 16:43:57,504:INFO:Importing untrained model
2023-04-06 16:43:57,505:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-06 16:43:57,508:INFO:Starting cross validation
2023-04-06 16:43:57,508:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:43:57,589:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:57,598:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:57,601:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:57,601:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:57,612:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:57,624:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:57,625:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:57,636:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:57,648:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:57,649:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:44:01,286:INFO:Calculating mean and std
2023-04-06 16:44:01,286:INFO:Creating metrics dataframe
2023-04-06 16:44:01,676:INFO:Uploading results into container
2023-04-06 16:44:01,676:INFO:Uploading model into container now
2023-04-06 16:44:01,677:INFO:_master_model_container: 7
2023-04-06 16:44:01,677:INFO:_display_container: 2
2023-04-06 16:44:01,677:INFO:OrthogonalMatchingPursuit()
2023-04-06 16:44:01,677:INFO:create_model() successfully completed......................................
2023-04-06 16:44:01,735:INFO:SubProcess create_model() end ==================================
2023-04-06 16:44:01,736:INFO:Creating metrics dataframe
2023-04-06 16:44:01,740:INFO:Initializing Bayesian Ridge
2023-04-06 16:44:01,740:INFO:Total runtime is 0.5346790154774984 minutes
2023-04-06 16:44:01,742:INFO:SubProcess create_model() called ==================================
2023-04-06 16:44:01,742:INFO:Initializing create_model()
2023-04-06 16:44:01,742:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:44:01,742:INFO:Checking exceptions
2023-04-06 16:44:01,742:INFO:Importing libraries
2023-04-06 16:44:01,742:INFO:Copying training dataset
2023-04-06 16:44:01,744:INFO:Defining folds
2023-04-06 16:44:01,744:INFO:Declaring metric variables
2023-04-06 16:44:01,745:INFO:Importing untrained model
2023-04-06 16:44:01,747:INFO:Bayesian Ridge Imported successfully
2023-04-06 16:44:01,750:INFO:Starting cross validation
2023-04-06 16:44:01,751:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:44:05,764:INFO:Calculating mean and std
2023-04-06 16:44:05,765:INFO:Creating metrics dataframe
2023-04-06 16:44:06,165:INFO:Uploading results into container
2023-04-06 16:44:06,165:INFO:Uploading model into container now
2023-04-06 16:44:06,166:INFO:_master_model_container: 8
2023-04-06 16:44:06,166:INFO:_display_container: 2
2023-04-06 16:44:06,166:INFO:BayesianRidge()
2023-04-06 16:44:06,166:INFO:create_model() successfully completed......................................
2023-04-06 16:44:06,222:INFO:SubProcess create_model() end ==================================
2023-04-06 16:44:06,222:INFO:Creating metrics dataframe
2023-04-06 16:44:06,227:INFO:Initializing Passive Aggressive Regressor
2023-04-06 16:44:06,227:INFO:Total runtime is 0.6094612836837769 minutes
2023-04-06 16:44:06,228:INFO:SubProcess create_model() called ==================================
2023-04-06 16:44:06,228:INFO:Initializing create_model()
2023-04-06 16:44:06,228:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:44:06,229:INFO:Checking exceptions
2023-04-06 16:44:06,229:INFO:Importing libraries
2023-04-06 16:44:06,229:INFO:Copying training dataset
2023-04-06 16:44:06,231:INFO:Defining folds
2023-04-06 16:44:06,231:INFO:Declaring metric variables
2023-04-06 16:44:06,232:INFO:Importing untrained model
2023-04-06 16:44:06,234:INFO:Passive Aggressive Regressor Imported successfully
2023-04-06 16:44:06,236:INFO:Starting cross validation
2023-04-06 16:44:06,237:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:44:10,069:INFO:Calculating mean and std
2023-04-06 16:44:10,070:INFO:Creating metrics dataframe
2023-04-06 16:44:10,462:INFO:Uploading results into container
2023-04-06 16:44:10,462:INFO:Uploading model into container now
2023-04-06 16:44:10,462:INFO:_master_model_container: 9
2023-04-06 16:44:10,462:INFO:_display_container: 2
2023-04-06 16:44:10,462:INFO:PassiveAggressiveRegressor(random_state=123)
2023-04-06 16:44:10,462:INFO:create_model() successfully completed......................................
2023-04-06 16:44:10,517:INFO:SubProcess create_model() end ==================================
2023-04-06 16:44:10,518:INFO:Creating metrics dataframe
2023-04-06 16:44:10,522:INFO:Initializing Huber Regressor
2023-04-06 16:44:10,522:INFO:Total runtime is 0.681045432885488 minutes
2023-04-06 16:44:10,523:INFO:SubProcess create_model() called ==================================
2023-04-06 16:44:10,524:INFO:Initializing create_model()
2023-04-06 16:44:10,524:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:44:10,524:INFO:Checking exceptions
2023-04-06 16:44:10,524:INFO:Importing libraries
2023-04-06 16:44:10,524:INFO:Copying training dataset
2023-04-06 16:44:10,527:INFO:Defining folds
2023-04-06 16:44:10,527:INFO:Declaring metric variables
2023-04-06 16:44:10,528:INFO:Importing untrained model
2023-04-06 16:44:10,529:INFO:Huber Regressor Imported successfully
2023-04-06 16:44:10,532:INFO:Starting cross validation
2023-04-06 16:44:10,533:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:44:10,667:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 16:44:10,669:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 16:44:10,671:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 16:44:10,676:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 16:44:10,690:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 16:44:10,691:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 16:44:10,698:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 16:44:10,714:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 16:44:14,313:INFO:Calculating mean and std
2023-04-06 16:44:14,313:INFO:Creating metrics dataframe
2023-04-06 16:44:14,695:INFO:Uploading results into container
2023-04-06 16:44:14,695:INFO:Uploading model into container now
2023-04-06 16:44:14,696:INFO:_master_model_container: 10
2023-04-06 16:44:14,696:INFO:_display_container: 2
2023-04-06 16:44:14,696:INFO:HuberRegressor()
2023-04-06 16:44:14,696:INFO:create_model() successfully completed......................................
2023-04-06 16:44:14,754:INFO:SubProcess create_model() end ==================================
2023-04-06 16:44:14,754:INFO:Creating metrics dataframe
2023-04-06 16:44:14,759:INFO:Initializing K Neighbors Regressor
2023-04-06 16:44:14,759:INFO:Total runtime is 0.75166658560435 minutes
2023-04-06 16:44:14,761:INFO:SubProcess create_model() called ==================================
2023-04-06 16:44:14,761:INFO:Initializing create_model()
2023-04-06 16:44:14,761:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:44:14,761:INFO:Checking exceptions
2023-04-06 16:44:14,761:INFO:Importing libraries
2023-04-06 16:44:14,761:INFO:Copying training dataset
2023-04-06 16:44:14,764:INFO:Defining folds
2023-04-06 16:44:14,764:INFO:Declaring metric variables
2023-04-06 16:44:14,765:INFO:Importing untrained model
2023-04-06 16:44:14,767:INFO:K Neighbors Regressor Imported successfully
2023-04-06 16:44:14,770:INFO:Starting cross validation
2023-04-06 16:44:14,770:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:44:18,550:INFO:Calculating mean and std
2023-04-06 16:44:18,550:INFO:Creating metrics dataframe
2023-04-06 16:44:18,936:INFO:Uploading results into container
2023-04-06 16:44:18,936:INFO:Uploading model into container now
2023-04-06 16:44:18,936:INFO:_master_model_container: 11
2023-04-06 16:44:18,936:INFO:_display_container: 2
2023-04-06 16:44:18,937:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-06 16:44:18,937:INFO:create_model() successfully completed......................................
2023-04-06 16:44:18,993:INFO:SubProcess create_model() end ==================================
2023-04-06 16:44:18,994:INFO:Creating metrics dataframe
2023-04-06 16:44:18,998:INFO:Initializing Decision Tree Regressor
2023-04-06 16:44:18,998:INFO:Total runtime is 0.8223115324974062 minutes
2023-04-06 16:44:18,999:INFO:SubProcess create_model() called ==================================
2023-04-06 16:44:18,999:INFO:Initializing create_model()
2023-04-06 16:44:18,999:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:44:18,999:INFO:Checking exceptions
2023-04-06 16:44:18,999:INFO:Importing libraries
2023-04-06 16:44:18,999:INFO:Copying training dataset
2023-04-06 16:44:19,001:INFO:Defining folds
2023-04-06 16:44:19,001:INFO:Declaring metric variables
2023-04-06 16:44:19,003:INFO:Importing untrained model
2023-04-06 16:44:19,004:INFO:Decision Tree Regressor Imported successfully
2023-04-06 16:44:19,006:INFO:Starting cross validation
2023-04-06 16:44:19,007:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:44:22,807:INFO:Calculating mean and std
2023-04-06 16:44:22,807:INFO:Creating metrics dataframe
2023-04-06 16:44:23,193:INFO:Uploading results into container
2023-04-06 16:44:23,194:INFO:Uploading model into container now
2023-04-06 16:44:23,194:INFO:_master_model_container: 12
2023-04-06 16:44:23,194:INFO:_display_container: 2
2023-04-06 16:44:23,194:INFO:DecisionTreeRegressor(random_state=123)
2023-04-06 16:44:23,194:INFO:create_model() successfully completed......................................
2023-04-06 16:44:23,252:INFO:SubProcess create_model() end ==================================
2023-04-06 16:44:23,253:INFO:Creating metrics dataframe
2023-04-06 16:44:23,258:INFO:Initializing Random Forest Regressor
2023-04-06 16:44:23,258:INFO:Total runtime is 0.8933154503504437 minutes
2023-04-06 16:44:23,260:INFO:SubProcess create_model() called ==================================
2023-04-06 16:44:23,260:INFO:Initializing create_model()
2023-04-06 16:44:23,260:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:44:23,260:INFO:Checking exceptions
2023-04-06 16:44:23,260:INFO:Importing libraries
2023-04-06 16:44:23,260:INFO:Copying training dataset
2023-04-06 16:44:23,263:INFO:Defining folds
2023-04-06 16:44:23,263:INFO:Declaring metric variables
2023-04-06 16:44:23,264:INFO:Importing untrained model
2023-04-06 16:44:23,266:INFO:Random Forest Regressor Imported successfully
2023-04-06 16:44:23,268:INFO:Starting cross validation
2023-04-06 16:44:23,269:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:44:27,142:INFO:Calculating mean and std
2023-04-06 16:44:27,143:INFO:Creating metrics dataframe
2023-04-06 16:44:27,532:INFO:Uploading results into container
2023-04-06 16:44:27,533:INFO:Uploading model into container now
2023-04-06 16:44:27,533:INFO:_master_model_container: 13
2023-04-06 16:44:27,533:INFO:_display_container: 2
2023-04-06 16:44:27,533:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-04-06 16:44:27,533:INFO:create_model() successfully completed......................................
2023-04-06 16:44:27,593:INFO:SubProcess create_model() end ==================================
2023-04-06 16:44:27,594:INFO:Creating metrics dataframe
2023-04-06 16:44:27,599:INFO:Initializing Extra Trees Regressor
2023-04-06 16:44:27,599:INFO:Total runtime is 0.9656657814979555 minutes
2023-04-06 16:44:27,601:INFO:SubProcess create_model() called ==================================
2023-04-06 16:44:27,601:INFO:Initializing create_model()
2023-04-06 16:44:27,601:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:44:27,601:INFO:Checking exceptions
2023-04-06 16:44:27,601:INFO:Importing libraries
2023-04-06 16:44:27,601:INFO:Copying training dataset
2023-04-06 16:44:27,603:INFO:Defining folds
2023-04-06 16:44:27,603:INFO:Declaring metric variables
2023-04-06 16:44:27,605:INFO:Importing untrained model
2023-04-06 16:44:27,606:INFO:Extra Trees Regressor Imported successfully
2023-04-06 16:44:27,609:INFO:Starting cross validation
2023-04-06 16:44:27,610:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:44:31,637:INFO:Calculating mean and std
2023-04-06 16:44:31,638:INFO:Creating metrics dataframe
2023-04-06 16:44:32,044:INFO:Uploading results into container
2023-04-06 16:44:32,046:INFO:Uploading model into container now
2023-04-06 16:44:32,047:INFO:_master_model_container: 14
2023-04-06 16:44:32,047:INFO:_display_container: 2
2023-04-06 16:44:32,047:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-04-06 16:44:32,047:INFO:create_model() successfully completed......................................
2023-04-06 16:44:32,147:INFO:SubProcess create_model() end ==================================
2023-04-06 16:44:32,147:INFO:Creating metrics dataframe
2023-04-06 16:44:32,152:INFO:Initializing AdaBoost Regressor
2023-04-06 16:44:32,152:INFO:Total runtime is 1.0415479501088463 minutes
2023-04-06 16:44:32,153:INFO:SubProcess create_model() called ==================================
2023-04-06 16:44:32,154:INFO:Initializing create_model()
2023-04-06 16:44:32,154:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:44:32,154:INFO:Checking exceptions
2023-04-06 16:44:32,154:INFO:Importing libraries
2023-04-06 16:44:32,154:INFO:Copying training dataset
2023-04-06 16:44:32,156:INFO:Defining folds
2023-04-06 16:44:32,156:INFO:Declaring metric variables
2023-04-06 16:44:32,158:INFO:Importing untrained model
2023-04-06 16:44:32,160:INFO:AdaBoost Regressor Imported successfully
2023-04-06 16:44:32,163:INFO:Starting cross validation
2023-04-06 16:44:32,164:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:44:35,924:INFO:Calculating mean and std
2023-04-06 16:44:35,925:INFO:Creating metrics dataframe
2023-04-06 16:44:36,311:INFO:Uploading results into container
2023-04-06 16:44:36,311:INFO:Uploading model into container now
2023-04-06 16:44:36,312:INFO:_master_model_container: 15
2023-04-06 16:44:36,312:INFO:_display_container: 2
2023-04-06 16:44:36,312:INFO:AdaBoostRegressor(random_state=123)
2023-04-06 16:44:36,312:INFO:create_model() successfully completed......................................
2023-04-06 16:44:36,369:INFO:SubProcess create_model() end ==================================
2023-04-06 16:44:36,369:INFO:Creating metrics dataframe
2023-04-06 16:44:36,374:INFO:Initializing Gradient Boosting Regressor
2023-04-06 16:44:36,374:INFO:Total runtime is 1.1119085669517519 minutes
2023-04-06 16:44:36,375:INFO:SubProcess create_model() called ==================================
2023-04-06 16:44:36,375:INFO:Initializing create_model()
2023-04-06 16:44:36,375:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:44:36,375:INFO:Checking exceptions
2023-04-06 16:44:36,375:INFO:Importing libraries
2023-04-06 16:44:36,375:INFO:Copying training dataset
2023-04-06 16:44:36,377:INFO:Defining folds
2023-04-06 16:44:36,377:INFO:Declaring metric variables
2023-04-06 16:44:36,378:INFO:Importing untrained model
2023-04-06 16:44:36,380:INFO:Gradient Boosting Regressor Imported successfully
2023-04-06 16:44:36,382:INFO:Starting cross validation
2023-04-06 16:44:36,383:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:44:40,184:INFO:Calculating mean and std
2023-04-06 16:44:40,184:INFO:Creating metrics dataframe
2023-04-06 16:44:40,574:INFO:Uploading results into container
2023-04-06 16:44:40,574:INFO:Uploading model into container now
2023-04-06 16:44:40,575:INFO:_master_model_container: 16
2023-04-06 16:44:40,575:INFO:_display_container: 2
2023-04-06 16:44:40,575:INFO:GradientBoostingRegressor(random_state=123)
2023-04-06 16:44:40,575:INFO:create_model() successfully completed......................................
2023-04-06 16:44:40,629:INFO:SubProcess create_model() end ==================================
2023-04-06 16:44:40,630:INFO:Creating metrics dataframe
2023-04-06 16:44:40,635:INFO:Initializing Extreme Gradient Boosting
2023-04-06 16:44:40,635:INFO:Total runtime is 1.1829238017400108 minutes
2023-04-06 16:44:40,636:INFO:SubProcess create_model() called ==================================
2023-04-06 16:44:40,636:INFO:Initializing create_model()
2023-04-06 16:44:40,636:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:44:40,636:INFO:Checking exceptions
2023-04-06 16:44:40,636:INFO:Importing libraries
2023-04-06 16:44:40,636:INFO:Copying training dataset
2023-04-06 16:44:40,638:INFO:Defining folds
2023-04-06 16:44:40,639:INFO:Declaring metric variables
2023-04-06 16:44:40,640:INFO:Importing untrained model
2023-04-06 16:44:40,641:INFO:Extreme Gradient Boosting Imported successfully
2023-04-06 16:44:40,643:INFO:Starting cross validation
2023-04-06 16:44:40,644:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:44:44,415:INFO:Calculating mean and std
2023-04-06 16:44:44,415:INFO:Creating metrics dataframe
2023-04-06 16:44:44,802:INFO:Uploading results into container
2023-04-06 16:44:44,803:INFO:Uploading model into container now
2023-04-06 16:44:44,803:INFO:_master_model_container: 17
2023-04-06 16:44:44,803:INFO:_display_container: 2
2023-04-06 16:44:44,804:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=123, ...)
2023-04-06 16:44:44,804:INFO:create_model() successfully completed......................................
2023-04-06 16:44:44,862:INFO:SubProcess create_model() end ==================================
2023-04-06 16:44:44,862:INFO:Creating metrics dataframe
2023-04-06 16:44:44,867:INFO:Initializing Light Gradient Boosting Machine
2023-04-06 16:44:44,867:INFO:Total runtime is 1.2534611304601035 minutes
2023-04-06 16:44:44,868:INFO:SubProcess create_model() called ==================================
2023-04-06 16:44:44,868:INFO:Initializing create_model()
2023-04-06 16:44:44,868:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:44:44,868:INFO:Checking exceptions
2023-04-06 16:44:44,869:INFO:Importing libraries
2023-04-06 16:44:44,869:INFO:Copying training dataset
2023-04-06 16:44:44,870:INFO:Defining folds
2023-04-06 16:44:44,870:INFO:Declaring metric variables
2023-04-06 16:44:44,871:INFO:Importing untrained model
2023-04-06 16:44:44,873:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-06 16:44:44,875:INFO:Starting cross validation
2023-04-06 16:44:44,876:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:44:49,406:INFO:Calculating mean and std
2023-04-06 16:44:49,407:INFO:Creating metrics dataframe
2023-04-06 16:44:49,803:INFO:Uploading results into container
2023-04-06 16:44:49,803:INFO:Uploading model into container now
2023-04-06 16:44:49,803:INFO:_master_model_container: 18
2023-04-06 16:44:49,803:INFO:_display_container: 2
2023-04-06 16:44:49,804:INFO:LGBMRegressor(random_state=123)
2023-04-06 16:44:49,804:INFO:create_model() successfully completed......................................
2023-04-06 16:44:49,863:INFO:SubProcess create_model() end ==================================
2023-04-06 16:44:49,864:INFO:Creating metrics dataframe
2023-04-06 16:44:49,869:INFO:Initializing CatBoost Regressor
2023-04-06 16:44:49,869:INFO:Total runtime is 1.3368359684944155 minutes
2023-04-06 16:44:49,871:INFO:SubProcess create_model() called ==================================
2023-04-06 16:44:49,872:INFO:Initializing create_model()
2023-04-06 16:44:49,872:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:44:49,872:INFO:Checking exceptions
2023-04-06 16:44:49,872:INFO:Importing libraries
2023-04-06 16:44:49,872:INFO:Copying training dataset
2023-04-06 16:44:49,874:INFO:Defining folds
2023-04-06 16:44:49,874:INFO:Declaring metric variables
2023-04-06 16:44:49,875:INFO:Importing untrained model
2023-04-06 16:44:49,880:INFO:CatBoost Regressor Imported successfully
2023-04-06 16:44:49,883:INFO:Starting cross validation
2023-04-06 16:44:49,884:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:44:54,247:INFO:Calculating mean and std
2023-04-06 16:44:54,248:INFO:Creating metrics dataframe
2023-04-06 16:44:54,642:INFO:Uploading results into container
2023-04-06 16:44:54,642:INFO:Uploading model into container now
2023-04-06 16:44:54,642:INFO:_master_model_container: 19
2023-04-06 16:44:54,642:INFO:_display_container: 2
2023-04-06 16:44:54,642:INFO:<catboost.core.CatBoostRegressor object at 0x16b5790d0>
2023-04-06 16:44:54,642:INFO:create_model() successfully completed......................................
2023-04-06 16:44:54,698:INFO:SubProcess create_model() end ==================================
2023-04-06 16:44:54,698:INFO:Creating metrics dataframe
2023-04-06 16:44:54,704:INFO:Initializing Dummy Regressor
2023-04-06 16:44:54,704:INFO:Total runtime is 1.4174164017041526 minutes
2023-04-06 16:44:54,706:INFO:SubProcess create_model() called ==================================
2023-04-06 16:44:54,706:INFO:Initializing create_model()
2023-04-06 16:44:54,706:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:44:54,706:INFO:Checking exceptions
2023-04-06 16:44:54,706:INFO:Importing libraries
2023-04-06 16:44:54,706:INFO:Copying training dataset
2023-04-06 16:44:54,708:INFO:Defining folds
2023-04-06 16:44:54,708:INFO:Declaring metric variables
2023-04-06 16:44:54,709:INFO:Importing untrained model
2023-04-06 16:44:54,711:INFO:Dummy Regressor Imported successfully
2023-04-06 16:44:54,713:INFO:Starting cross validation
2023-04-06 16:44:54,714:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:44:58,515:INFO:Calculating mean and std
2023-04-06 16:44:58,516:INFO:Creating metrics dataframe
2023-04-06 16:44:58,934:INFO:Uploading results into container
2023-04-06 16:44:58,935:INFO:Uploading model into container now
2023-04-06 16:44:58,935:INFO:_master_model_container: 20
2023-04-06 16:44:58,935:INFO:_display_container: 2
2023-04-06 16:44:58,935:INFO:DummyRegressor()
2023-04-06 16:44:58,935:INFO:create_model() successfully completed......................................
2023-04-06 16:44:58,991:INFO:SubProcess create_model() end ==================================
2023-04-06 16:44:58,991:INFO:Creating metrics dataframe
2023-04-06 16:44:58,999:INFO:Initializing create_model()
2023-04-06 16:44:59,000:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=<catboost.core.CatBoostRegressor object at 0x16b5790d0>, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:44:59,000:INFO:Checking exceptions
2023-04-06 16:44:59,001:INFO:Importing libraries
2023-04-06 16:44:59,001:INFO:Copying training dataset
2023-04-06 16:44:59,003:INFO:Defining folds
2023-04-06 16:44:59,003:INFO:Declaring metric variables
2023-04-06 16:44:59,003:INFO:Importing untrained model
2023-04-06 16:44:59,003:INFO:Declaring custom model
2023-04-06 16:44:59,004:INFO:CatBoost Regressor Imported successfully
2023-04-06 16:44:59,004:INFO:Cross validation set to False
2023-04-06 16:44:59,004:INFO:Fitting Model
2023-04-06 16:44:59,391:INFO:<catboost.core.CatBoostRegressor object at 0x16b579b80>
2023-04-06 16:44:59,391:INFO:create_model() successfully completed......................................
2023-04-06 16:44:59,459:INFO:_master_model_container: 20
2023-04-06 16:44:59,459:INFO:_display_container: 2
2023-04-06 16:44:59,459:INFO:<catboost.core.CatBoostRegressor object at 0x16b579b80>
2023-04-06 16:44:59,459:INFO:compare_models() successfully completed......................................
2023-04-06 16:44:59,463:INFO:Initializing create_model()
2023-04-06 16:44:59,463:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=ada, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:44:59,463:INFO:Checking exceptions
2023-04-06 16:44:59,470:INFO:Importing libraries
2023-04-06 16:44:59,470:INFO:Copying training dataset
2023-04-06 16:44:59,476:INFO:Defining folds
2023-04-06 16:44:59,476:INFO:Declaring metric variables
2023-04-06 16:44:59,477:INFO:Importing untrained model
2023-04-06 16:44:59,479:INFO:AdaBoost Regressor Imported successfully
2023-04-06 16:44:59,482:INFO:Starting cross validation
2023-04-06 16:44:59,483:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:45:03,213:INFO:Calculating mean and std
2023-04-06 16:45:03,214:INFO:Creating metrics dataframe
2023-04-06 16:45:03,216:INFO:Finalizing model
2023-04-06 16:45:03,693:INFO:Uploading results into container
2023-04-06 16:45:03,694:INFO:Uploading model into container now
2023-04-06 16:45:03,698:INFO:_master_model_container: 21
2023-04-06 16:45:03,698:INFO:_display_container: 3
2023-04-06 16:45:03,698:INFO:AdaBoostRegressor(random_state=123)
2023-04-06 16:45:03,698:INFO:create_model() successfully completed......................................
2023-04-06 16:45:03,764:INFO:Initializing create_model()
2023-04-06 16:45:03,764:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:45:03,764:INFO:Checking exceptions
2023-04-06 16:45:03,771:INFO:Importing libraries
2023-04-06 16:45:03,771:INFO:Copying training dataset
2023-04-06 16:45:03,775:INFO:Defining folds
2023-04-06 16:45:03,775:INFO:Declaring metric variables
2023-04-06 16:45:03,777:INFO:Importing untrained model
2023-04-06 16:45:03,778:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-06 16:45:03,781:INFO:Starting cross validation
2023-04-06 16:45:03,782:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:45:07,575:INFO:Calculating mean and std
2023-04-06 16:45:07,576:INFO:Creating metrics dataframe
2023-04-06 16:45:07,578:INFO:Finalizing model
2023-04-06 16:45:08,054:INFO:Uploading results into container
2023-04-06 16:45:08,054:INFO:Uploading model into container now
2023-04-06 16:45:08,058:INFO:_master_model_container: 22
2023-04-06 16:45:08,058:INFO:_display_container: 4
2023-04-06 16:45:08,058:INFO:LGBMRegressor(random_state=123)
2023-04-06 16:45:08,059:INFO:create_model() successfully completed......................................
2023-04-06 16:45:08,125:INFO:Initializing create_model()
2023-04-06 16:45:08,125:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:45:08,125:INFO:Checking exceptions
2023-04-06 16:45:08,132:INFO:Importing libraries
2023-04-06 16:45:08,132:INFO:Copying training dataset
2023-04-06 16:45:08,137:INFO:Defining folds
2023-04-06 16:45:08,137:INFO:Declaring metric variables
2023-04-06 16:45:08,139:INFO:Importing untrained model
2023-04-06 16:45:08,140:INFO:Decision Tree Regressor Imported successfully
2023-04-06 16:45:08,143:INFO:Starting cross validation
2023-04-06 16:45:08,144:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:45:11,950:INFO:Calculating mean and std
2023-04-06 16:45:11,951:INFO:Creating metrics dataframe
2023-04-06 16:45:11,953:INFO:Finalizing model
2023-04-06 16:45:12,403:INFO:Uploading results into container
2023-04-06 16:45:12,404:INFO:Uploading model into container now
2023-04-06 16:45:12,407:INFO:_master_model_container: 23
2023-04-06 16:45:12,407:INFO:_display_container: 5
2023-04-06 16:45:12,407:INFO:DecisionTreeRegressor(random_state=123)
2023-04-06 16:45:12,407:INFO:create_model() successfully completed......................................
2023-04-06 16:45:12,468:INFO:Initializing tune_model()
2023-04-06 16:45:12,468:INFO:tune_model(estimator=ada, fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>)
2023-04-06 16:45:12,468:INFO:Checking exceptions
2023-04-06 16:45:37,311:INFO:Initializing tune_model()
2023-04-06 16:45:37,312:INFO:tune_model(estimator=LGBMRegressor(random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>)
2023-04-06 16:45:37,313:INFO:Checking exceptions
2023-04-06 16:45:37,332:INFO:Copying training dataset
2023-04-06 16:45:37,336:INFO:Checking base model
2023-04-06 16:45:37,336:INFO:Base model : Light Gradient Boosting Machine
2023-04-06 16:45:37,338:INFO:Declaring metric variables
2023-04-06 16:45:37,340:INFO:Defining Hyperparameters
2023-04-06 16:45:37,426:INFO:Tuning with n_jobs=-1
2023-04-06 16:45:37,426:INFO:Initializing RandomizedSearchCV
2023-04-06 16:46:14,438:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-04-06 16:46:14,439:INFO:Hyperparameter search completed
2023-04-06 16:46:14,439:INFO:SubProcess create_model() called ==================================
2023-04-06 16:46:14,440:INFO:Initializing create_model()
2023-04-06 16:46:14,440:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=LGBMRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1758acb50>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-04-06 16:46:14,440:INFO:Checking exceptions
2023-04-06 16:46:14,440:INFO:Importing libraries
2023-04-06 16:46:14,440:INFO:Copying training dataset
2023-04-06 16:46:14,442:INFO:Defining folds
2023-04-06 16:46:14,442:INFO:Declaring metric variables
2023-04-06 16:46:14,443:INFO:Importing untrained model
2023-04-06 16:46:14,443:INFO:Declaring custom model
2023-04-06 16:46:14,445:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-06 16:46:14,447:INFO:Starting cross validation
2023-04-06 16:46:14,448:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:46:18,117:INFO:Calculating mean and std
2023-04-06 16:46:18,118:INFO:Creating metrics dataframe
2023-04-06 16:46:18,120:INFO:Finalizing model
2023-04-06 16:46:18,710:INFO:Uploading results into container
2023-04-06 16:46:18,710:INFO:Uploading model into container now
2023-04-06 16:46:18,711:INFO:_master_model_container: 24
2023-04-06 16:46:18,711:INFO:_display_container: 6
2023-04-06 16:46:18,711:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              num_leaves=70, random_state=123, reg_alpha=2, reg_lambda=3)
2023-04-06 16:46:18,711:INFO:create_model() successfully completed......................................
2023-04-06 16:46:18,788:INFO:SubProcess create_model() end ==================================
2023-04-06 16:46:18,788:INFO:choose_better activated
2023-04-06 16:46:18,790:INFO:SubProcess create_model() called ==================================
2023-04-06 16:46:18,790:INFO:Initializing create_model()
2023-04-06 16:46:18,790:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=LGBMRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:46:18,790:INFO:Checking exceptions
2023-04-06 16:46:18,790:INFO:Importing libraries
2023-04-06 16:46:18,790:INFO:Copying training dataset
2023-04-06 16:46:18,793:INFO:Defining folds
2023-04-06 16:46:18,793:INFO:Declaring metric variables
2023-04-06 16:46:18,793:INFO:Importing untrained model
2023-04-06 16:46:18,793:INFO:Declaring custom model
2023-04-06 16:46:18,793:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-06 16:46:18,793:INFO:Starting cross validation
2023-04-06 16:46:18,794:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:46:22,566:INFO:Calculating mean and std
2023-04-06 16:46:22,566:INFO:Creating metrics dataframe
2023-04-06 16:46:22,567:INFO:Finalizing model
2023-04-06 16:46:23,029:INFO:Uploading results into container
2023-04-06 16:46:23,030:INFO:Uploading model into container now
2023-04-06 16:46:23,030:INFO:_master_model_container: 25
2023-04-06 16:46:23,030:INFO:_display_container: 7
2023-04-06 16:46:23,030:INFO:LGBMRegressor(random_state=123)
2023-04-06 16:46:23,030:INFO:create_model() successfully completed......................................
2023-04-06 16:46:23,108:INFO:SubProcess create_model() end ==================================
2023-04-06 16:46:23,109:INFO:LGBMRegressor(random_state=123) result for R2 is 0.9711
2023-04-06 16:46:23,109:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              num_leaves=70, random_state=123, reg_alpha=2, reg_lambda=3) result for R2 is 0.9651
2023-04-06 16:46:23,109:INFO:LGBMRegressor(random_state=123) is best model
2023-04-06 16:46:23,109:INFO:choose_better completed
2023-04-06 16:46:23,109:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-04-06 16:46:23,113:INFO:_master_model_container: 25
2023-04-06 16:46:23,113:INFO:_display_container: 6
2023-04-06 16:46:23,114:INFO:LGBMRegressor(random_state=123)
2023-04-06 16:46:23,114:INFO:tune_model() successfully completed......................................
2023-04-06 16:46:23,559:INFO:Initializing create_model()
2023-04-06 16:46:23,560:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=catboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:46:23,560:INFO:Checking exceptions
2023-04-06 16:46:23,566:INFO:Importing libraries
2023-04-06 16:46:23,567:INFO:Copying training dataset
2023-04-06 16:46:23,571:INFO:Defining folds
2023-04-06 16:46:23,571:INFO:Declaring metric variables
2023-04-06 16:46:23,573:INFO:Importing untrained model
2023-04-06 16:46:23,574:INFO:CatBoost Regressor Imported successfully
2023-04-06 16:46:23,577:INFO:Starting cross validation
2023-04-06 16:46:23,578:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:46:27,326:INFO:Calculating mean and std
2023-04-06 16:46:27,328:INFO:Creating metrics dataframe
2023-04-06 16:46:27,331:INFO:Finalizing model
2023-04-06 16:46:27,790:INFO:Uploading results into container
2023-04-06 16:46:27,790:INFO:Uploading model into container now
2023-04-06 16:46:27,794:INFO:_master_model_container: 26
2023-04-06 16:46:27,794:INFO:_display_container: 7
2023-04-06 16:46:27,794:INFO:<catboost.core.CatBoostRegressor object at 0x177e598b0>
2023-04-06 16:46:27,794:INFO:create_model() successfully completed......................................
2023-04-06 16:46:32,965:INFO:Initializing tune_model()
2023-04-06 16:46:32,966:INFO:tune_model(estimator=DecisionTreeRegressor(random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>)
2023-04-06 16:46:32,966:INFO:Checking exceptions
2023-04-06 16:46:32,986:INFO:Copying training dataset
2023-04-06 16:46:32,990:INFO:Checking base model
2023-04-06 16:46:32,990:INFO:Base model : Decision Tree Regressor
2023-04-06 16:46:32,992:INFO:Declaring metric variables
2023-04-06 16:46:32,994:INFO:Defining Hyperparameters
2023-04-06 16:46:33,076:INFO:Tuning with n_jobs=-1
2023-04-06 16:46:33,076:INFO:Initializing RandomizedSearchCV
2023-04-06 16:47:10,448:INFO:best_params: {'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.01, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 10, 'actual_estimator__criterion': 'friedman_mse'}
2023-04-06 16:47:10,449:INFO:Hyperparameter search completed
2023-04-06 16:47:10,449:INFO:SubProcess create_model() called ==================================
2023-04-06 16:47:10,449:INFO:Initializing create_model()
2023-04-06 16:47:10,449:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=DecisionTreeRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17b00afd0>, model_only=True, return_train_score=False, kwargs={'min_samples_split': 9, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.01, 'max_features': 1.0, 'max_depth': 10, 'criterion': 'friedman_mse'})
2023-04-06 16:47:10,449:INFO:Checking exceptions
2023-04-06 16:47:10,450:INFO:Importing libraries
2023-04-06 16:47:10,450:INFO:Copying training dataset
2023-04-06 16:47:10,452:INFO:Defining folds
2023-04-06 16:47:10,452:INFO:Declaring metric variables
2023-04-06 16:47:10,453:INFO:Importing untrained model
2023-04-06 16:47:10,453:INFO:Declaring custom model
2023-04-06 16:47:10,454:INFO:Decision Tree Regressor Imported successfully
2023-04-06 16:47:10,457:INFO:Starting cross validation
2023-04-06 16:47:10,458:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:47:14,262:INFO:Calculating mean and std
2023-04-06 16:47:14,263:INFO:Creating metrics dataframe
2023-04-06 16:47:14,265:INFO:Finalizing model
2023-04-06 16:47:14,717:INFO:Uploading results into container
2023-04-06 16:47:14,717:INFO:Uploading model into container now
2023-04-06 16:47:14,717:INFO:_master_model_container: 27
2023-04-06 16:47:14,717:INFO:_display_container: 8
2023-04-06 16:47:14,718:INFO:DecisionTreeRegressor(criterion='friedman_mse', max_depth=10, max_features=1.0,
                      min_impurity_decrease=0.01, min_samples_leaf=2,
                      min_samples_split=9, random_state=123)
2023-04-06 16:47:14,718:INFO:create_model() successfully completed......................................
2023-04-06 16:47:14,796:INFO:SubProcess create_model() end ==================================
2023-04-06 16:47:14,796:INFO:choose_better activated
2023-04-06 16:47:14,798:INFO:SubProcess create_model() called ==================================
2023-04-06 16:47:14,798:INFO:Initializing create_model()
2023-04-06 16:47:14,798:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=DecisionTreeRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:47:14,798:INFO:Checking exceptions
2023-04-06 16:47:14,798:INFO:Importing libraries
2023-04-06 16:47:14,799:INFO:Copying training dataset
2023-04-06 16:47:14,801:INFO:Defining folds
2023-04-06 16:47:14,801:INFO:Declaring metric variables
2023-04-06 16:47:14,801:INFO:Importing untrained model
2023-04-06 16:47:14,801:INFO:Declaring custom model
2023-04-06 16:47:14,801:INFO:Decision Tree Regressor Imported successfully
2023-04-06 16:47:14,801:INFO:Starting cross validation
2023-04-06 16:47:14,802:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:47:18,582:INFO:Calculating mean and std
2023-04-06 16:47:18,583:INFO:Creating metrics dataframe
2023-04-06 16:47:18,584:INFO:Finalizing model
2023-04-06 16:47:19,034:INFO:Uploading results into container
2023-04-06 16:47:19,035:INFO:Uploading model into container now
2023-04-06 16:47:19,035:INFO:_master_model_container: 28
2023-04-06 16:47:19,035:INFO:_display_container: 9
2023-04-06 16:47:19,035:INFO:DecisionTreeRegressor(random_state=123)
2023-04-06 16:47:19,035:INFO:create_model() successfully completed......................................
2023-04-06 16:47:19,110:INFO:SubProcess create_model() end ==================================
2023-04-06 16:47:19,111:INFO:DecisionTreeRegressor(random_state=123) result for R2 is 0.9465
2023-04-06 16:47:19,111:INFO:DecisionTreeRegressor(criterion='friedman_mse', max_depth=10, max_features=1.0,
                      min_impurity_decrease=0.01, min_samples_leaf=2,
                      min_samples_split=9, random_state=123) result for R2 is 0.9473
2023-04-06 16:47:19,111:INFO:DecisionTreeRegressor(criterion='friedman_mse', max_depth=10, max_features=1.0,
                      min_impurity_decrease=0.01, min_samples_leaf=2,
                      min_samples_split=9, random_state=123) is best model
2023-04-06 16:47:19,111:INFO:choose_better completed
2023-04-06 16:47:19,114:INFO:_master_model_container: 28
2023-04-06 16:47:19,115:INFO:_display_container: 8
2023-04-06 16:47:19,115:INFO:DecisionTreeRegressor(criterion='friedman_mse', max_depth=10, max_features=1.0,
                      min_impurity_decrease=0.01, min_samples_leaf=2,
                      min_samples_split=9, random_state=123)
2023-04-06 16:47:19,115:INFO:tune_model() successfully completed......................................
2023-04-06 16:48:11,885:INFO:Initializing tune_model()
2023-04-06 16:48:11,887:INFO:tune_model(estimator=<catboost.core.CatBoostRegressor object at 0x177e598b0>, fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>)
2023-04-06 16:48:11,887:INFO:Checking exceptions
2023-04-06 16:48:11,904:INFO:Copying training dataset
2023-04-06 16:48:11,909:INFO:Checking base model
2023-04-06 16:48:11,909:INFO:Base model : CatBoost Regressor
2023-04-06 16:48:11,911:INFO:Declaring metric variables
2023-04-06 16:48:11,913:INFO:Defining Hyperparameters
2023-04-06 16:48:12,000:INFO:Tuning with n_jobs=-1
2023-04-06 16:48:12,000:INFO:Initializing RandomizedSearchCV
2023-04-06 16:48:51,739:INFO:best_params: {'actual_estimator__random_strength': 0.2, 'actual_estimator__n_estimators': 180, 'actual_estimator__l2_leaf_reg': 30, 'actual_estimator__eta': 0.4, 'actual_estimator__depth': 8}
2023-04-06 16:48:51,740:INFO:Hyperparameter search completed
2023-04-06 16:48:51,740:INFO:SubProcess create_model() called ==================================
2023-04-06 16:48:51,741:INFO:Initializing create_model()
2023-04-06 16:48:51,741:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=<catboost.core.CatBoostRegressor object at 0x17b091fd0>, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x175b7cd30>, model_only=True, return_train_score=False, kwargs={'random_strength': 0.2, 'n_estimators': 180, 'l2_leaf_reg': 30, 'eta': 0.4, 'depth': 8})
2023-04-06 16:48:51,741:INFO:Checking exceptions
2023-04-06 16:48:51,741:INFO:Importing libraries
2023-04-06 16:48:51,741:INFO:Copying training dataset
2023-04-06 16:48:51,743:INFO:Defining folds
2023-04-06 16:48:51,743:INFO:Declaring metric variables
2023-04-06 16:48:51,745:INFO:Importing untrained model
2023-04-06 16:48:51,745:INFO:Declaring custom model
2023-04-06 16:48:51,747:INFO:CatBoost Regressor Imported successfully
2023-04-06 16:48:51,750:INFO:Starting cross validation
2023-04-06 16:48:51,751:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:48:55,879:INFO:Calculating mean and std
2023-04-06 16:48:55,880:INFO:Creating metrics dataframe
2023-04-06 16:48:55,883:INFO:Finalizing model
2023-04-06 16:48:56,680:INFO:Uploading results into container
2023-04-06 16:48:56,681:INFO:Uploading model into container now
2023-04-06 16:48:56,681:INFO:_master_model_container: 29
2023-04-06 16:48:56,681:INFO:_display_container: 9
2023-04-06 16:48:56,681:INFO:<catboost.core.CatBoostRegressor object at 0x17afb8e80>
2023-04-06 16:48:56,681:INFO:create_model() successfully completed......................................
2023-04-06 16:48:56,768:INFO:SubProcess create_model() end ==================================
2023-04-06 16:48:56,768:INFO:choose_better activated
2023-04-06 16:48:56,770:INFO:SubProcess create_model() called ==================================
2023-04-06 16:48:56,770:INFO:Initializing create_model()
2023-04-06 16:48:56,770:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=<catboost.core.CatBoostRegressor object at 0x177e598b0>, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:48:56,770:INFO:Checking exceptions
2023-04-06 16:48:56,771:INFO:Importing libraries
2023-04-06 16:48:56,771:INFO:Copying training dataset
2023-04-06 16:48:56,774:INFO:Defining folds
2023-04-06 16:48:56,774:INFO:Declaring metric variables
2023-04-06 16:48:56,774:INFO:Importing untrained model
2023-04-06 16:48:56,774:INFO:Declaring custom model
2023-04-06 16:48:56,774:INFO:CatBoost Regressor Imported successfully
2023-04-06 16:48:56,774:INFO:Starting cross validation
2023-04-06 16:48:56,775:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:49:00,739:INFO:Calculating mean and std
2023-04-06 16:49:00,740:INFO:Creating metrics dataframe
2023-04-06 16:49:00,741:INFO:Finalizing model
2023-04-06 16:49:01,200:INFO:Uploading results into container
2023-04-06 16:49:01,200:INFO:Uploading model into container now
2023-04-06 16:49:01,201:INFO:_master_model_container: 30
2023-04-06 16:49:01,201:INFO:_display_container: 10
2023-04-06 16:49:01,201:INFO:<catboost.core.CatBoostRegressor object at 0x17afd4d90>
2023-04-06 16:49:01,201:INFO:create_model() successfully completed......................................
2023-04-06 16:49:01,279:INFO:SubProcess create_model() end ==================================
2023-04-06 16:49:01,279:INFO:<catboost.core.CatBoostRegressor object at 0x17afd4d90> result for R2 is 0.9807
2023-04-06 16:49:01,279:INFO:<catboost.core.CatBoostRegressor object at 0x17afb8e80> result for R2 is 0.9769
2023-04-06 16:49:01,279:INFO:<catboost.core.CatBoostRegressor object at 0x17afd4d90> is best model
2023-04-06 16:49:01,279:INFO:choose_better completed
2023-04-06 16:49:01,280:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-04-06 16:49:01,284:INFO:_master_model_container: 30
2023-04-06 16:49:01,284:INFO:_display_container: 9
2023-04-06 16:49:01,284:INFO:<catboost.core.CatBoostRegressor object at 0x17afd4d90>
2023-04-06 16:49:01,284:INFO:tune_model() successfully completed......................................
2023-04-06 16:49:01,723:INFO:Initializing plot_model()
2023-04-06 16:49:01,723:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, system=True)
2023-04-06 16:49:01,723:INFO:Checking exceptions
2023-04-06 16:49:01,725:INFO:Preloading libraries
2023-04-06 16:49:01,731:INFO:Copying training dataset
2023-04-06 16:49:01,732:INFO:Plot type: residuals
2023-04-06 16:49:01,876:INFO:Fitting Model
2023-04-06 16:49:01,949:INFO:Scoring test/hold-out set
2023-04-06 16:49:02,281:INFO:Visual Rendered Successfully
2023-04-06 16:49:02,365:INFO:plot_model() successfully completed......................................
2023-04-06 16:49:02,370:INFO:Initializing plot_model()
2023-04-06 16:49:02,370:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, system=True)
2023-04-06 16:49:02,370:INFO:Checking exceptions
2023-04-06 16:49:02,372:INFO:Preloading libraries
2023-04-06 16:49:02,379:INFO:Copying training dataset
2023-04-06 16:49:02,379:INFO:Plot type: feature
2023-04-06 16:49:02,379:WARNING:No coef_ found. Trying feature_importances_
2023-04-06 16:49:02,472:INFO:Visual Rendered Successfully
2023-04-06 16:49:02,552:INFO:plot_model() successfully completed......................................
2023-04-06 16:49:02,556:INFO:Initializing plot_model()
2023-04-06 16:49:02,556:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, system=True)
2023-04-06 16:49:02,556:INFO:Checking exceptions
2023-04-06 16:49:02,558:INFO:Preloading libraries
2023-04-06 16:49:02,565:INFO:Copying training dataset
2023-04-06 16:49:02,565:INFO:Plot type: error
2023-04-06 16:49:02,729:INFO:Fitting Model
2023-04-06 16:49:02,729:INFO:Scoring test/hold-out set
2023-04-06 16:49:02,848:INFO:Visual Rendered Successfully
2023-04-06 16:49:02,928:INFO:plot_model() successfully completed......................................
2023-04-06 16:49:19,536:INFO:Initializing predict_model()
2023-04-06 16:49:19,537:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=LGBMRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x17afe09d0>)
2023-04-06 16:49:19,537:INFO:Checking exceptions
2023-04-06 16:49:19,538:INFO:Preloading libraries
2023-04-06 16:49:37,311:INFO:Initializing finalize_model()
2023-04-06 16:49:37,311:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=LGBMRegressor(random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-04-06 16:49:37,312:INFO:Finalizing LGBMRegressor(random_state=123)
2023-04-06 16:49:37,317:INFO:Initializing create_model()
2023-04-06 16:49:37,317:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=LGBMRegressor(random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-04-06 16:49:37,317:INFO:Checking exceptions
2023-04-06 16:49:37,321:INFO:Importing libraries
2023-04-06 16:49:37,321:INFO:Copying training dataset
2023-04-06 16:49:37,321:INFO:Defining folds
2023-04-06 16:49:37,321:INFO:Declaring metric variables
2023-04-06 16:49:37,321:INFO:Importing untrained model
2023-04-06 16:49:37,322:INFO:Declaring custom model
2023-04-06 16:49:37,323:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-06 16:49:37,325:INFO:Cross validation set to False
2023-04-06 16:49:37,325:INFO:Fitting Model
2023-04-06 16:49:37,450:INFO:Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry', 'Report'],
                                    transformer=SimpleImputer(strategy='most_frequent')...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry'],
                                    transformer=OneHotEncoder(cols=['Cut',
                                                                    'Color',
                                                                    'Clarity',
                                                                    'Polish',
                                                                    'Symmetry'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', LGBMRegressor(random_state=123))])
2023-04-06 16:49:37,450:INFO:create_model() successfully completed......................................
2023-04-06 16:49:37,528:INFO:_master_model_container: 30
2023-04-06 16:49:37,528:INFO:_display_container: 10
2023-04-06 16:49:37,537:INFO:Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry', 'Report'],
                                    transformer=SimpleImputer(strategy='most_frequent')...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry'],
                                    transformer=OneHotEncoder(cols=['Cut',
                                                                    'Color',
                                                                    'Clarity',
                                                                    'Polish',
                                                                    'Symmetry'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', LGBMRegressor(random_state=123))])
2023-04-06 16:49:37,537:INFO:finalize_model() successfully completed......................................
2023-04-06 16:50:01,724:INFO:Initializing predict_model()
2023-04-06 16:50:01,725:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry', 'Report'],
                                    transformer=SimpleImputer(strategy='most_frequent')...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry'],
                                    transformer=OneHotEncoder(cols=['Cut',
                                                                    'Color',
                                                                    'Clarity',
                                                                    'Polish',
                                                                    'Symmetry'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', LGBMRegressor(random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x17afe0820>)
2023-04-06 16:50:01,725:INFO:Checking exceptions
2023-04-06 16:50:01,725:INFO:Preloading libraries
2023-04-06 16:50:13,236:INFO:Initializing predict_model()
2023-04-06 16:50:13,236:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry', 'Report'],
                                    transformer=SimpleImputer(strategy='most_frequent')...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry'],
                                    transformer=OneHotEncoder(cols=['Cut',
                                                                    'Color',
                                                                    'Clarity',
                                                                    'Polish',
                                                                    'Symmetry'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', LGBMRegressor(random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x17afe00d0>)
2023-04-06 16:50:13,236:INFO:Checking exceptions
2023-04-06 16:50:13,237:INFO:Preloading libraries
2023-04-06 16:50:13,238:INFO:Set up data.
2023-04-06 16:50:13,242:INFO:Set up index.
2023-04-06 16:50:27,773:INFO:Initializing save_model()
2023-04-06 16:50:27,773:INFO:save_model(model=Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry', 'Report'],
                                    transformer=SimpleImputer(strategy='most_frequent')...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry'],
                                    transformer=OneHotEncoder(cols=['Cut',
                                                                    'Color',
                                                                    'Clarity',
                                                                    'Polish',
                                                                    'Symmetry'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', LGBMRegressor(random_state=123))]), model_name=Final Lightgbm Model 08Feb2020, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry', 'Report'],
                                    transformer=SimpleImputer(strategy='most_frequent')...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': AGSL    0
GIA     1
NaN    -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry'],
                                    transformer=OneHotEncoder(cols=['Cut',
                                                                    'Color',
                                                                    'Clarity',
                                                                    'Polish',
                                                                    'Symmetry'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-04-06 16:50:27,773:INFO:Adding model into prep_pipe
2023-04-06 16:50:27,784:WARNING:Only Model saved as it was a pipeline.
2023-04-06 16:50:27,798:INFO:Final Lightgbm Model 08Feb2020.pkl saved in current working directory
2023-04-06 16:50:27,809:INFO:Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry', 'Report'],
                                    transformer=SimpleImputer(strategy='most_frequent')...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry'],
                                    transformer=OneHotEncoder(cols=['Cut',
                                                                    'Color',
                                                                    'Clarity',
                                                                    'Polish',
                                                                    'Symmetry'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', LGBMRegressor(random_state=123))])
2023-04-06 16:50:27,809:INFO:save_model() successfully completed......................................
2023-04-06 16:51:33,177:INFO:Initializing load_model()
2023-04-06 16:51:33,179:INFO:load_model(model_name=Final Lightgbm Model 08Feb2020, platform=None, authentication=None, verbose=True)
2023-04-06 16:51:33,863:INFO:Initializing predict_model()
2023-04-06 16:51:33,863:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry', 'Report'],
                                    transformer=SimpleImputer(strategy='most_frequent')...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry'],
                                    transformer=OneHotEncoder(cols=['Cut',
                                                                    'Color',
                                                                    'Clarity',
                                                                    'Polish',
                                                                    'Symmetry'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', LGBMRegressor(random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x17afe0ca0>)
2023-04-06 16:51:33,863:INFO:Checking exceptions
2023-04-06 16:51:33,863:INFO:Preloading libraries
2023-04-06 16:51:33,864:INFO:Set up data.
2023-04-06 16:51:33,868:INFO:Set up index.
2023-04-06 17:03:48,745:INFO:Initializing create_model()
2023-04-06 17:03:48,747:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=catboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:03:48,747:INFO:Checking exceptions
2023-04-06 17:03:48,767:INFO:Importing libraries
2023-04-06 17:03:48,768:INFO:Copying training dataset
2023-04-06 17:03:48,772:INFO:Defining folds
2023-04-06 17:03:48,772:INFO:Declaring metric variables
2023-04-06 17:03:48,774:INFO:Importing untrained model
2023-04-06 17:03:48,776:INFO:CatBoost Regressor Imported successfully
2023-04-06 17:03:48,779:INFO:Starting cross validation
2023-04-06 17:03:48,781:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:03:56,366:INFO:Calculating mean and std
2023-04-06 17:03:56,368:INFO:Creating metrics dataframe
2023-04-06 17:03:56,371:INFO:Finalizing model
2023-04-06 17:03:56,850:INFO:Uploading results into container
2023-04-06 17:03:56,850:INFO:Uploading model into container now
2023-04-06 17:03:56,855:INFO:_master_model_container: 31
2023-04-06 17:03:56,855:INFO:_display_container: 14
2023-04-06 17:03:56,855:INFO:<catboost.core.CatBoostRegressor object at 0x17af98e80>
2023-04-06 17:03:56,855:INFO:create_model() successfully completed......................................
2023-04-06 17:04:06,139:INFO:Initializing tune_model()
2023-04-06 17:04:06,140:INFO:tune_model(estimator=<catboost.core.CatBoostRegressor object at 0x17af98e80>, fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>)
2023-04-06 17:04:06,141:INFO:Checking exceptions
2023-04-06 17:04:06,161:INFO:Copying training dataset
2023-04-06 17:04:06,165:INFO:Checking base model
2023-04-06 17:04:06,165:INFO:Base model : CatBoost Regressor
2023-04-06 17:04:06,167:INFO:Declaring metric variables
2023-04-06 17:04:06,169:INFO:Defining Hyperparameters
2023-04-06 17:04:06,254:INFO:Tuning with n_jobs=-1
2023-04-06 17:04:06,254:INFO:Initializing RandomizedSearchCV
2023-04-06 17:04:46,187:INFO:best_params: {'actual_estimator__random_strength': 0.2, 'actual_estimator__n_estimators': 180, 'actual_estimator__l2_leaf_reg': 30, 'actual_estimator__eta': 0.4, 'actual_estimator__depth': 8}
2023-04-06 17:04:46,189:INFO:Hyperparameter search completed
2023-04-06 17:04:46,189:INFO:SubProcess create_model() called ==================================
2023-04-06 17:04:46,189:INFO:Initializing create_model()
2023-04-06 17:04:46,189:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=<catboost.core.CatBoostRegressor object at 0x17ffb9280>, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16b574a90>, model_only=True, return_train_score=False, kwargs={'random_strength': 0.2, 'n_estimators': 180, 'l2_leaf_reg': 30, 'eta': 0.4, 'depth': 8})
2023-04-06 17:04:46,189:INFO:Checking exceptions
2023-04-06 17:04:46,189:INFO:Importing libraries
2023-04-06 17:04:46,189:INFO:Copying training dataset
2023-04-06 17:04:46,193:INFO:Defining folds
2023-04-06 17:04:46,193:INFO:Declaring metric variables
2023-04-06 17:04:46,196:INFO:Importing untrained model
2023-04-06 17:04:46,196:INFO:Declaring custom model
2023-04-06 17:04:46,197:INFO:CatBoost Regressor Imported successfully
2023-04-06 17:04:46,200:INFO:Starting cross validation
2023-04-06 17:04:46,201:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:04:50,142:INFO:Calculating mean and std
2023-04-06 17:04:50,143:INFO:Creating metrics dataframe
2023-04-06 17:04:50,145:INFO:Finalizing model
2023-04-06 17:04:50,618:INFO:Uploading results into container
2023-04-06 17:04:50,618:INFO:Uploading model into container now
2023-04-06 17:04:50,619:INFO:_master_model_container: 32
2023-04-06 17:04:50,619:INFO:_display_container: 15
2023-04-06 17:04:50,619:INFO:<catboost.core.CatBoostRegressor object at 0x17b0cb640>
2023-04-06 17:04:50,619:INFO:create_model() successfully completed......................................
2023-04-06 17:04:50,707:INFO:SubProcess create_model() end ==================================
2023-04-06 17:04:50,707:INFO:choose_better activated
2023-04-06 17:04:50,709:INFO:SubProcess create_model() called ==================================
2023-04-06 17:04:50,709:INFO:Initializing create_model()
2023-04-06 17:04:50,709:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=<catboost.core.CatBoostRegressor object at 0x17af98e80>, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:04:50,709:INFO:Checking exceptions
2023-04-06 17:04:50,709:INFO:Importing libraries
2023-04-06 17:04:50,710:INFO:Copying training dataset
2023-04-06 17:04:50,712:INFO:Defining folds
2023-04-06 17:04:50,712:INFO:Declaring metric variables
2023-04-06 17:04:50,712:INFO:Importing untrained model
2023-04-06 17:04:50,712:INFO:Declaring custom model
2023-04-06 17:04:50,712:INFO:CatBoost Regressor Imported successfully
2023-04-06 17:04:50,712:INFO:Starting cross validation
2023-04-06 17:04:50,713:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:04:54,574:INFO:Calculating mean and std
2023-04-06 17:04:54,574:INFO:Creating metrics dataframe
2023-04-06 17:04:54,575:INFO:Finalizing model
2023-04-06 17:04:55,036:INFO:Uploading results into container
2023-04-06 17:04:55,037:INFO:Uploading model into container now
2023-04-06 17:04:55,037:INFO:_master_model_container: 33
2023-04-06 17:04:55,037:INFO:_display_container: 16
2023-04-06 17:04:55,037:INFO:<catboost.core.CatBoostRegressor object at 0x1789ea970>
2023-04-06 17:04:55,037:INFO:create_model() successfully completed......................................
2023-04-06 17:04:55,119:INFO:SubProcess create_model() end ==================================
2023-04-06 17:04:55,119:INFO:<catboost.core.CatBoostRegressor object at 0x1789ea970> result for R2 is 0.9807
2023-04-06 17:04:55,119:INFO:<catboost.core.CatBoostRegressor object at 0x17b0cb640> result for R2 is 0.9769
2023-04-06 17:04:55,119:INFO:<catboost.core.CatBoostRegressor object at 0x1789ea970> is best model
2023-04-06 17:04:55,119:INFO:choose_better completed
2023-04-06 17:04:55,119:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-04-06 17:04:55,123:INFO:_master_model_container: 33
2023-04-06 17:04:55,124:INFO:_display_container: 15
2023-04-06 17:04:55,124:INFO:<catboost.core.CatBoostRegressor object at 0x1789ea970>
2023-04-06 17:04:55,124:INFO:tune_model() successfully completed......................................
2023-04-06 17:05:27,075:INFO:Initializing plot_model()
2023-04-06 17:05:27,077:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=<catboost.core.CatBoostRegressor object at 0x1789ea970>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, system=True)
2023-04-06 17:05:27,077:INFO:Checking exceptions
2023-04-06 17:05:27,086:INFO:Preloading libraries
2023-04-06 17:05:27,091:INFO:Copying training dataset
2023-04-06 17:05:27,091:INFO:Plot type: residuals
2023-04-06 17:05:27,252:INFO:Fitting Model
2023-04-06 17:05:27,272:INFO:Scoring test/hold-out set
2023-04-06 17:05:27,461:INFO:Visual Rendered Successfully
2023-04-06 17:05:27,579:INFO:plot_model() successfully completed......................................
2023-04-06 17:05:40,611:INFO:Initializing plot_model()
2023-04-06 17:05:40,611:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=<catboost.core.CatBoostRegressor object at 0x1789ea970>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, system=True)
2023-04-06 17:05:40,611:INFO:Checking exceptions
2023-04-06 17:05:40,621:INFO:Preloading libraries
2023-04-06 17:05:40,623:INFO:Copying training dataset
2023-04-06 17:05:40,623:INFO:Plot type: error
2023-04-06 17:05:40,781:INFO:Fitting Model
2023-04-06 17:05:40,781:INFO:Scoring test/hold-out set
2023-04-06 17:05:40,872:INFO:Visual Rendered Successfully
2023-04-06 17:05:40,952:INFO:plot_model() successfully completed......................................
2023-04-06 17:05:53,227:INFO:Initializing plot_model()
2023-04-06 17:05:53,229:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=<catboost.core.CatBoostRegressor object at 0x1789ea970>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, system=True)
2023-04-06 17:05:53,229:INFO:Checking exceptions
2023-04-06 17:05:53,237:INFO:Preloading libraries
2023-04-06 17:05:53,238:INFO:Copying training dataset
2023-04-06 17:05:53,239:INFO:Plot type: feature
2023-04-06 17:05:53,244:WARNING:No coef_ found. Trying feature_importances_
2023-04-06 17:05:53,353:INFO:Visual Rendered Successfully
2023-04-06 17:05:53,434:INFO:plot_model() successfully completed......................................
2023-04-06 17:06:26,646:INFO:Initializing interpret_model()
2023-04-06 17:06:26,648:INFO:interpret_model(estimator=DecisionTreeRegressor(criterion='friedman_mse', max_depth=10, max_features=1.0,
                      min_impurity_decrease=0.01, min_samples_leaf=2,
                      min_samples_split=9, random_state=123), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>)
2023-04-06 17:06:26,648:INFO:Checking exceptions
2023-04-06 17:06:26,648:INFO:Soft dependency imported: shap: 0.41.0
2023-04-06 17:06:27,340:INFO:plot type: summary
2023-04-06 17:06:27,340:INFO:Creating TreeExplainer
2023-04-06 17:06:27,341:INFO:Compiling shap values
2023-04-06 17:06:27,400:WARNING:No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored

2023-04-06 17:06:27,662:INFO:Visual Rendered Successfully
2023-04-06 17:06:27,663:INFO:interpret_model() successfully completed......................................
2023-04-06 17:06:46,054:INFO:Initializing interpret_model()
2023-04-06 17:06:46,056:INFO:interpret_model(estimator=<catboost.core.CatBoostRegressor object at 0x1789ea970>, use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>)
2023-04-06 17:06:46,056:INFO:Checking exceptions
2023-04-06 17:06:46,056:INFO:Soft dependency imported: shap: 0.41.0
2023-04-06 17:06:46,117:INFO:plot type: summary
2023-04-06 17:06:46,117:INFO:Creating TreeExplainer
2023-04-06 17:06:46,117:INFO:Compiling shap values
2023-04-06 17:06:46,360:WARNING:No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored

2023-04-06 17:06:46,621:INFO:Visual Rendered Successfully
2023-04-06 17:06:46,621:INFO:interpret_model() successfully completed......................................
2023-04-06 17:07:11,058:INFO:Initializing plot_model()
2023-04-06 17:07:11,060:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=DecisionTreeRegressor(criterion='friedman_mse', max_depth=10, max_features=1.0,
                      min_impurity_decrease=0.01, min_samples_leaf=2,
                      min_samples_split=9, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, system=True)
2023-04-06 17:07:11,060:INFO:Checking exceptions
2023-04-06 17:07:11,073:INFO:Preloading libraries
2023-04-06 17:07:11,074:INFO:Copying training dataset
2023-04-06 17:07:11,074:INFO:Plot type: feature
2023-04-06 17:07:11,076:WARNING:No coef_ found. Trying feature_importances_
2023-04-06 17:07:11,200:INFO:Visual Rendered Successfully
2023-04-06 17:07:11,287:INFO:plot_model() successfully completed......................................
2023-04-06 17:15:08,174:ERROR:
'pandas_profiling' is a soft dependency and not included in the pycaret installation. Please run: `pip install pandas-profiling` to install.
Alternately, you can install this by running `pip install pycaret[analysis]`
NoneType: None
2023-04-06 17:15:41,105:ERROR:
'pandas_profiling' is a soft dependency and not included in the pycaret installation. Please run: `pip install pandas-profiling` to install.
Alternately, you can install this by running `pip install pycaret[analysis]`
NoneType: None
2023-04-06 17:15:51,241:ERROR:
'pandas_profiling' is a soft dependency and not included in the pycaret installation. Please run: `pip install pandas-profiling` to install.
Alternately, you can install this by running `pip install pycaret[analysis]`
NoneType: None
2023-04-06 17:17:33,796:INFO:Soft dependency imported: pandas_profiling: 4.1.2
2023-04-06 17:21:49,730:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-06 17:21:49,730:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-06 17:21:49,731:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-06 17:21:49,731:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-06 17:21:50,269:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-06 17:22:35,718:INFO:PyCaret RegressionExperiment
2023-04-06 17:22:35,718:INFO:Logging name: reg-default-name
2023-04-06 17:22:35,718:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-06 17:22:35,718:INFO:version 3.0.0
2023-04-06 17:22:35,718:INFO:Initializing setup()
2023-04-06 17:22:35,718:INFO:self.USI: 187f
2023-04-06 17:22:35,718:INFO:self._variable_keys: {'y', 'X', 'exp_name_log', 'logging_param', 'gpu_param', 'gpu_n_jobs_param', 'log_plots_param', 'X_train', 'X_test', 'n_jobs_param', 'y_test', 'y_train', 'idx', 'USI', 'seed', 'data', 'pipeline', '_available_plots', 'exp_id', '_ml_usecase', 'fold_groups_param', 'fold_generator', 'fold_shuffle_param', 'html_param', 'target_param', 'transform_target_param', 'memory'}
2023-04-06 17:22:35,718:INFO:Checking environment
2023-04-06 17:22:35,718:INFO:python_version: 3.9.15
2023-04-06 17:22:35,718:INFO:python_build: ('main', 'Nov 24 2022 08:28:41')
2023-04-06 17:22:35,718:INFO:machine: arm64
2023-04-06 17:22:35,718:INFO:platform: macOS-13.2-arm64-arm-64bit
2023-04-06 17:22:35,718:INFO:Memory: svmem(total=17179869184, available=4919017472, percent=71.4, used=6899171328, free=133545984, active=4807901184, inactive=4749688832, wired=2091270144)
2023-04-06 17:22:35,718:INFO:Physical Core: 10
2023-04-06 17:22:35,718:INFO:Logical Core: 10
2023-04-06 17:22:35,718:INFO:Checking libraries
2023-04-06 17:22:35,718:INFO:System:
2023-04-06 17:22:35,718:INFO:    python: 3.9.15 (main, Nov 24 2022, 08:28:41)  [Clang 14.0.6 ]
2023-04-06 17:22:35,718:INFO:executable: /Users/a06411/opt/anaconda3/bin/python
2023-04-06 17:22:35,718:INFO:   machine: macOS-13.2-arm64-arm-64bit
2023-04-06 17:22:35,718:INFO:PyCaret required dependencies:
2023-04-06 17:22:35,718:INFO:                 pip: 22.3.1
2023-04-06 17:22:35,718:INFO:          setuptools: 65.5.0
2023-04-06 17:22:35,718:INFO:             pycaret: 3.0.0
2023-04-06 17:22:35,718:INFO:             IPython: 8.7.0
2023-04-06 17:22:35,718:INFO:          ipywidgets: 7.6.5
2023-04-06 17:22:35,718:INFO:                tqdm: 4.64.1
2023-04-06 17:22:35,718:INFO:               numpy: 1.21.5
2023-04-06 17:22:35,718:INFO:              pandas: 1.4.4
2023-04-06 17:22:35,718:INFO:              jinja2: 2.11.3
2023-04-06 17:22:35,719:INFO:               scipy: 1.9.3
2023-04-06 17:22:35,719:INFO:              joblib: 1.2.0
2023-04-06 17:22:35,719:INFO:             sklearn: 1.1.3
2023-04-06 17:22:35,719:INFO:                pyod: 1.0.9
2023-04-06 17:22:35,719:INFO:            imblearn: 0.10.1
2023-04-06 17:22:35,719:INFO:   category_encoders: 2.6.0
2023-04-06 17:22:35,719:INFO:            lightgbm: 3.3.5
2023-04-06 17:22:35,719:INFO:               numba: 0.56.4
2023-04-06 17:22:35,719:INFO:            requests: 2.28.1
2023-04-06 17:22:35,719:INFO:          matplotlib: 3.6.2
2023-04-06 17:22:35,719:INFO:          scikitplot: 0.3.7
2023-04-06 17:22:35,719:INFO:         yellowbrick: 1.5
2023-04-06 17:22:35,719:INFO:              plotly: 5.9.0
2023-04-06 17:22:35,719:INFO:             kaleido: 0.2.1
2023-04-06 17:22:35,719:INFO:         statsmodels: 0.13.2
2023-04-06 17:22:35,719:INFO:              sktime: 0.16.1
2023-04-06 17:22:35,719:INFO:               tbats: 1.1.2
2023-04-06 17:22:35,719:INFO:            pmdarima: 2.0.3
2023-04-06 17:22:35,719:INFO:              psutil: 5.9.0
2023-04-06 17:22:35,719:INFO:PyCaret optional dependencies:
2023-04-06 17:22:35,723:INFO:                shap: 0.41.0
2023-04-06 17:22:35,723:INFO:           interpret: Not installed
2023-04-06 17:22:35,723:INFO:                umap: 0.5.3
2023-04-06 17:22:35,723:INFO:    pandas_profiling: 4.1.2
2023-04-06 17:22:35,723:INFO:  explainerdashboard: 0.4.2.1
2023-04-06 17:22:35,723:INFO:             autoviz: Not installed
2023-04-06 17:22:35,723:INFO:           fairlearn: Not installed
2023-04-06 17:22:35,723:INFO:             xgboost: 1.7.2
2023-04-06 17:22:35,723:INFO:            catboost: 1.1.1
2023-04-06 17:22:35,723:INFO:              kmodes: Not installed
2023-04-06 17:22:35,723:INFO:             mlxtend: Not installed
2023-04-06 17:22:35,723:INFO:       statsforecast: Not installed
2023-04-06 17:22:35,723:INFO:        tune_sklearn: Not installed
2023-04-06 17:22:35,723:INFO:                 ray: Not installed
2023-04-06 17:22:35,723:INFO:            hyperopt: 0.2.7
2023-04-06 17:22:35,723:INFO:              optuna: 3.1.0
2023-04-06 17:22:35,723:INFO:               skopt: 0.9.0
2023-04-06 17:22:35,723:INFO:              mlflow: 2.2.2
2023-04-06 17:22:35,723:INFO:              gradio: Not installed
2023-04-06 17:22:35,723:INFO:             fastapi: Not installed
2023-04-06 17:22:35,723:INFO:             uvicorn: Not installed
2023-04-06 17:22:35,723:INFO:              m2cgen: Not installed
2023-04-06 17:22:35,723:INFO:           evidently: Not installed
2023-04-06 17:22:35,723:INFO:               fugue: Not installed
2023-04-06 17:22:35,723:INFO:           streamlit: Not installed
2023-04-06 17:22:35,723:INFO:             prophet: Not installed
2023-04-06 17:22:35,723:INFO:None
2023-04-06 17:22:35,723:INFO:Set up data.
2023-04-06 17:22:35,727:INFO:Set up train/test split.
2023-04-06 17:22:35,729:INFO:Set up index.
2023-04-06 17:22:35,729:INFO:Set up folding strategy.
2023-04-06 17:22:35,729:INFO:Assigning column types.
2023-04-06 17:22:35,730:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-06 17:22:35,730:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-06 17:22:35,732:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-06 17:22:35,734:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 17:22:35,757:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 17:22:35,776:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 17:22:35,776:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:22:35,900:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:22:35,912:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-06 17:22:35,914:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-06 17:22:35,916:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 17:22:35,939:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 17:22:35,957:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 17:22:35,957:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:22:35,958:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:22:35,959:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-06 17:22:35,960:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-06 17:22:35,962:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 17:22:35,985:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 17:22:36,004:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 17:22:36,004:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:22:36,005:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:22:36,007:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-06 17:22:36,009:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 17:22:36,033:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 17:22:36,051:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 17:22:36,051:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:22:36,052:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:22:36,052:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-06 17:22:36,056:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 17:22:36,079:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 17:22:36,097:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 17:22:36,097:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:22:36,098:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:22:36,102:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 17:22:36,125:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 17:22:36,143:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 17:22:36,143:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:22:36,145:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:22:36,145:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-06 17:22:36,171:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 17:22:36,189:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 17:22:36,190:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:22:36,191:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:22:36,217:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 17:22:36,235:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 17:22:36,235:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:22:36,236:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:22:36,236:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-06 17:22:36,263:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 17:22:36,281:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:22:36,282:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:22:36,309:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 17:22:36,328:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:22:36,331:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:22:36,331:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-06 17:22:36,376:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:22:36,377:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:22:36,423:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:22:36,424:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:22:36,426:INFO:Preparing preprocessing pipeline...
2023-04-06 17:22:36,426:INFO:Set up target transformation.
2023-04-06 17:22:36,426:INFO:Set up simple imputation.
2023-04-06 17:22:36,428:INFO:Set up encoding of ordinal features.
2023-04-06 17:22:36,428:INFO:Set up encoding of categorical features.
2023-04-06 17:22:36,428:INFO:Set up removing multicollinearity.
2023-04-06 17:22:36,428:INFO:Set up binning of numerical features.
2023-04-06 17:22:36,428:INFO:Set up column transformation.
2023-04-06 17:22:36,428:INFO:Set up feature normalization.
2023-04-06 17:22:36,429:INFO:Set up column name cleaning.
2023-04-06 17:22:36,566:INFO:Finished creating preprocessing pipeline.
2023-04-06 17:22:36,577:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer'...
                ('bin_numeric_features',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=KBinsDiscretizer(encode='ordinal',
                                                                 strategy='kmeans'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-06 17:22:36,577:INFO:Creating final display dataframe.
2023-04-06 17:22:36,748:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             Price
2                   Target type        Regression
3           Original data shape         (5400, 8)
4        Transformed data shape        (5400, 28)
5   Transformed train set shape        (3779, 28)
6    Transformed test set shape        (1621, 28)
7              Ordinal features                 1
8              Numeric features                 1
9          Categorical features                 6
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16     Remove multicollinearity              True
17  Multicollinearity threshold              0.95
18               Transformation              True
19        Transformation method       yeo-johnson
20                    Normalize              True
21             Normalize method            zscore
22             Transform target              True
23      Transform target method       yeo-johnson
24               Fold Generator             KFold
25                  Fold Number                10
26                     CPU Jobs                -1
27                      Use GPU             False
28               Log Experiment             False
29              Experiment Name  reg-default-name
30                          USI              187f
2023-04-06 17:22:36,798:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:22:36,799:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:22:36,845:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:22:36,846:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:22:36,846:INFO:setup() successfully completed in 1.58s...............
2023-04-06 17:22:58,621:INFO:Initializing compare_models()
2023-04-06 17:22:58,622:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-06 17:22:58,622:INFO:Checking exceptions
2023-04-06 17:22:58,631:INFO:Preparing display monitor
2023-04-06 17:22:58,652:INFO:Initializing Linear Regression
2023-04-06 17:22:58,652:INFO:Total runtime is 2.6305516560872396e-06 minutes
2023-04-06 17:22:58,655:INFO:SubProcess create_model() called ==================================
2023-04-06 17:22:58,655:INFO:Initializing create_model()
2023-04-06 17:22:58,655:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103dc2130>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:22:58,655:INFO:Checking exceptions
2023-04-06 17:22:58,655:INFO:Importing libraries
2023-04-06 17:22:58,655:INFO:Copying training dataset
2023-04-06 17:22:58,660:INFO:Defining folds
2023-04-06 17:22:58,660:INFO:Declaring metric variables
2023-04-06 17:22:58,662:INFO:Importing untrained model
2023-04-06 17:22:58,664:INFO:Linear Regression Imported successfully
2023-04-06 17:22:58,668:INFO:Starting cross validation
2023-04-06 17:22:58,674:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:23:06,080:INFO:Calculating mean and std
2023-04-06 17:23:06,082:INFO:Creating metrics dataframe
2023-04-06 17:23:06,481:INFO:Uploading results into container
2023-04-06 17:23:06,482:INFO:Uploading model into container now
2023-04-06 17:23:06,482:INFO:_master_model_container: 1
2023-04-06 17:23:06,482:INFO:_display_container: 2
2023-04-06 17:23:06,482:INFO:LinearRegression(n_jobs=-1)
2023-04-06 17:23:06,482:INFO:create_model() successfully completed......................................
2023-04-06 17:23:06,587:INFO:SubProcess create_model() end ==================================
2023-04-06 17:23:06,587:INFO:Creating metrics dataframe
2023-04-06 17:23:06,590:INFO:Initializing Lasso Regression
2023-04-06 17:23:06,591:INFO:Total runtime is 0.13230396509170533 minutes
2023-04-06 17:23:06,592:INFO:SubProcess create_model() called ==================================
2023-04-06 17:23:06,592:INFO:Initializing create_model()
2023-04-06 17:23:06,592:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103dc2130>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:23:06,592:INFO:Checking exceptions
2023-04-06 17:23:06,592:INFO:Importing libraries
2023-04-06 17:23:06,592:INFO:Copying training dataset
2023-04-06 17:23:06,594:INFO:Defining folds
2023-04-06 17:23:06,594:INFO:Declaring metric variables
2023-04-06 17:23:06,596:INFO:Importing untrained model
2023-04-06 17:23:06,597:INFO:Lasso Regression Imported successfully
2023-04-06 17:23:06,599:INFO:Starting cross validation
2023-04-06 17:23:06,600:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:23:10,835:INFO:Calculating mean and std
2023-04-06 17:23:10,836:INFO:Creating metrics dataframe
2023-04-06 17:23:11,239:INFO:Uploading results into container
2023-04-06 17:23:11,240:INFO:Uploading model into container now
2023-04-06 17:23:11,240:INFO:_master_model_container: 2
2023-04-06 17:23:11,240:INFO:_display_container: 2
2023-04-06 17:23:11,240:INFO:Lasso(random_state=123)
2023-04-06 17:23:11,240:INFO:create_model() successfully completed......................................
2023-04-06 17:23:11,329:INFO:SubProcess create_model() end ==================================
2023-04-06 17:23:11,329:INFO:Creating metrics dataframe
2023-04-06 17:23:11,333:INFO:Initializing Ridge Regression
2023-04-06 17:23:11,333:INFO:Total runtime is 0.2113534172375997 minutes
2023-04-06 17:23:11,335:INFO:SubProcess create_model() called ==================================
2023-04-06 17:23:11,335:INFO:Initializing create_model()
2023-04-06 17:23:11,335:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103dc2130>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:23:11,335:INFO:Checking exceptions
2023-04-06 17:23:11,335:INFO:Importing libraries
2023-04-06 17:23:11,335:INFO:Copying training dataset
2023-04-06 17:23:11,337:INFO:Defining folds
2023-04-06 17:23:11,337:INFO:Declaring metric variables
2023-04-06 17:23:11,339:INFO:Importing untrained model
2023-04-06 17:23:11,340:INFO:Ridge Regression Imported successfully
2023-04-06 17:23:11,343:INFO:Starting cross validation
2023-04-06 17:23:11,344:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:23:15,376:INFO:Calculating mean and std
2023-04-06 17:23:15,377:INFO:Creating metrics dataframe
2023-04-06 17:23:15,787:INFO:Uploading results into container
2023-04-06 17:23:15,787:INFO:Uploading model into container now
2023-04-06 17:23:15,787:INFO:_master_model_container: 3
2023-04-06 17:23:15,787:INFO:_display_container: 2
2023-04-06 17:23:15,788:INFO:Ridge(random_state=123)
2023-04-06 17:23:15,788:INFO:create_model() successfully completed......................................
2023-04-06 17:23:15,879:INFO:SubProcess create_model() end ==================================
2023-04-06 17:23:15,879:INFO:Creating metrics dataframe
2023-04-06 17:23:15,883:INFO:Initializing Elastic Net
2023-04-06 17:23:15,884:INFO:Total runtime is 0.28718894720077515 minutes
2023-04-06 17:23:15,885:INFO:SubProcess create_model() called ==================================
2023-04-06 17:23:15,885:INFO:Initializing create_model()
2023-04-06 17:23:15,885:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103dc2130>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:23:15,885:INFO:Checking exceptions
2023-04-06 17:23:15,885:INFO:Importing libraries
2023-04-06 17:23:15,885:INFO:Copying training dataset
2023-04-06 17:23:15,888:INFO:Defining folds
2023-04-06 17:23:15,888:INFO:Declaring metric variables
2023-04-06 17:23:15,889:INFO:Importing untrained model
2023-04-06 17:23:15,890:INFO:Elastic Net Imported successfully
2023-04-06 17:23:15,893:INFO:Starting cross validation
2023-04-06 17:23:15,894:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:23:19,985:INFO:Calculating mean and std
2023-04-06 17:23:19,986:INFO:Creating metrics dataframe
2023-04-06 17:23:20,397:INFO:Uploading results into container
2023-04-06 17:23:20,397:INFO:Uploading model into container now
2023-04-06 17:23:20,397:INFO:_master_model_container: 4
2023-04-06 17:23:20,397:INFO:_display_container: 2
2023-04-06 17:23:20,398:INFO:ElasticNet(random_state=123)
2023-04-06 17:23:20,398:INFO:create_model() successfully completed......................................
2023-04-06 17:23:20,497:INFO:SubProcess create_model() end ==================================
2023-04-06 17:23:20,497:INFO:Creating metrics dataframe
2023-04-06 17:23:20,501:INFO:Initializing Least Angle Regression
2023-04-06 17:23:20,501:INFO:Total runtime is 0.36414484977722167 minutes
2023-04-06 17:23:20,502:INFO:SubProcess create_model() called ==================================
2023-04-06 17:23:20,502:INFO:Initializing create_model()
2023-04-06 17:23:20,502:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103dc2130>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:23:20,503:INFO:Checking exceptions
2023-04-06 17:23:20,503:INFO:Importing libraries
2023-04-06 17:23:20,503:INFO:Copying training dataset
2023-04-06 17:23:20,505:INFO:Defining folds
2023-04-06 17:23:20,505:INFO:Declaring metric variables
2023-04-06 17:23:20,506:INFO:Importing untrained model
2023-04-06 17:23:20,507:INFO:Least Angle Regression Imported successfully
2023-04-06 17:23:20,510:INFO:Starting cross validation
2023-04-06 17:23:20,511:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:23:20,682:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 17:23:20,685:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=5.022e-07, with an active set of 23 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,685:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.599e-07, with an active set of 23 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,685:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.264e-07, with an active set of 23 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,685:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.221e-07, with an active set of 23 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,695:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 17:23:20,697:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=7.522e-07, with an active set of 22 regressors, and the smallest cholesky pivot element being 8.752e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,698:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=2.079e-07, with an active set of 22 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,698:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.626e-07, with an active set of 22 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,698:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.612e-07, with an active set of 22 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,698:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 17:23:20,698:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 17:23:20,700:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.172e-06, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,700:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=3.093e-06, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,700:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=3.157e-07, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,701:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=2.754e-07, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,701:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.089e-06, with an active set of 22 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,701:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=2.588e-07, with an active set of 23 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,701:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.534e-06, with an active set of 23 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,701:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=3.535e-07, with an active set of 23 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,701:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.639e-07, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,701:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.387e-07, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,709:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 17:23:20,713:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=3.439e-07, with an active set of 24 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,713:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=3.177e-07, with an active set of 24 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,723:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 17:23:20,723:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 17:23:20,726:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=4.304e-07, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,726:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.088e-06, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,740:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 17:23:20,741:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 17:23:20,743:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.207e-06, with an active set of 22 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,743:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=4.443e-07, with an active set of 23 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,743:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.590e-07, with an active set of 23 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,743:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.505e-07, with an active set of 23 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,744:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.610e-06, with an active set of 23 regressors, and the smallest cholesky pivot element being 9.940e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,752:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 17:23:20,754:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=3.418e-07, with an active set of 22 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:24,687:INFO:Calculating mean and std
2023-04-06 17:23:24,688:INFO:Creating metrics dataframe
2023-04-06 17:23:25,061:INFO:Uploading results into container
2023-04-06 17:23:25,061:INFO:Uploading model into container now
2023-04-06 17:23:25,062:INFO:_master_model_container: 5
2023-04-06 17:23:25,062:INFO:_display_container: 2
2023-04-06 17:23:25,062:INFO:Lars(random_state=123)
2023-04-06 17:23:25,062:INFO:create_model() successfully completed......................................
2023-04-06 17:23:25,154:INFO:SubProcess create_model() end ==================================
2023-04-06 17:23:25,154:INFO:Creating metrics dataframe
2023-04-06 17:23:25,158:INFO:Initializing Lasso Least Angle Regression
2023-04-06 17:23:25,158:INFO:Total runtime is 0.44176859458287554 minutes
2023-04-06 17:23:25,160:INFO:SubProcess create_model() called ==================================
2023-04-06 17:23:25,160:INFO:Initializing create_model()
2023-04-06 17:23:25,160:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103dc2130>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:23:25,160:INFO:Checking exceptions
2023-04-06 17:23:25,160:INFO:Importing libraries
2023-04-06 17:23:25,160:INFO:Copying training dataset
2023-04-06 17:23:25,163:INFO:Defining folds
2023-04-06 17:23:25,163:INFO:Declaring metric variables
2023-04-06 17:23:25,164:INFO:Importing untrained model
2023-04-06 17:23:25,166:INFO:Lasso Least Angle Regression Imported successfully
2023-04-06 17:23:25,169:INFO:Starting cross validation
2023-04-06 17:23:25,170:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:23:25,342:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 17:23:25,343:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 17:23:25,349:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 17:23:25,369:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 17:23:25,376:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 17:23:25,391:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 17:23:25,392:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 17:23:25,398:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 17:23:25,430:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 17:23:25,430:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 17:23:29,330:INFO:Calculating mean and std
2023-04-06 17:23:29,331:INFO:Creating metrics dataframe
2023-04-06 17:23:29,760:INFO:Uploading results into container
2023-04-06 17:23:29,761:INFO:Uploading model into container now
2023-04-06 17:23:29,761:INFO:_master_model_container: 6
2023-04-06 17:23:29,761:INFO:_display_container: 2
2023-04-06 17:23:29,761:INFO:LassoLars(random_state=123)
2023-04-06 17:23:29,761:INFO:create_model() successfully completed......................................
2023-04-06 17:23:29,850:INFO:SubProcess create_model() end ==================================
2023-04-06 17:23:29,850:INFO:Creating metrics dataframe
2023-04-06 17:23:29,854:INFO:Initializing Orthogonal Matching Pursuit
2023-04-06 17:23:29,854:INFO:Total runtime is 0.5200272003809611 minutes
2023-04-06 17:23:29,855:INFO:SubProcess create_model() called ==================================
2023-04-06 17:23:29,855:INFO:Initializing create_model()
2023-04-06 17:23:29,855:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103dc2130>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:23:29,855:INFO:Checking exceptions
2023-04-06 17:23:29,855:INFO:Importing libraries
2023-04-06 17:23:29,855:INFO:Copying training dataset
2023-04-06 17:23:29,858:INFO:Defining folds
2023-04-06 17:23:29,858:INFO:Declaring metric variables
2023-04-06 17:23:29,859:INFO:Importing untrained model
2023-04-06 17:23:29,861:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-06 17:23:29,864:INFO:Starting cross validation
2023-04-06 17:23:29,865:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:23:30,067:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 17:23:30,067:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 17:23:30,068:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 17:23:30,074:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 17:23:30,079:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 17:23:30,082:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 17:23:30,093:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 17:23:30,119:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 17:23:30,121:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 17:23:30,138:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 17:23:34,012:INFO:Calculating mean and std
2023-04-06 17:23:34,013:INFO:Creating metrics dataframe
2023-04-06 17:23:34,419:INFO:Uploading results into container
2023-04-06 17:23:34,419:INFO:Uploading model into container now
2023-04-06 17:23:34,420:INFO:_master_model_container: 7
2023-04-06 17:23:34,420:INFO:_display_container: 2
2023-04-06 17:23:34,420:INFO:OrthogonalMatchingPursuit()
2023-04-06 17:23:34,420:INFO:create_model() successfully completed......................................
2023-04-06 17:23:34,508:INFO:SubProcess create_model() end ==================================
2023-04-06 17:23:34,508:INFO:Creating metrics dataframe
2023-04-06 17:23:34,513:INFO:Initializing Bayesian Ridge
2023-04-06 17:23:34,513:INFO:Total runtime is 0.5976743141810099 minutes
2023-04-06 17:23:34,514:INFO:SubProcess create_model() called ==================================
2023-04-06 17:23:34,514:INFO:Initializing create_model()
2023-04-06 17:23:34,514:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103dc2130>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:23:34,514:INFO:Checking exceptions
2023-04-06 17:23:34,514:INFO:Importing libraries
2023-04-06 17:23:34,514:INFO:Copying training dataset
2023-04-06 17:23:34,517:INFO:Defining folds
2023-04-06 17:23:34,517:INFO:Declaring metric variables
2023-04-06 17:23:34,518:INFO:Importing untrained model
2023-04-06 17:23:34,519:INFO:Bayesian Ridge Imported successfully
2023-04-06 17:23:34,523:INFO:Starting cross validation
2023-04-06 17:23:34,524:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:23:38,714:INFO:Calculating mean and std
2023-04-06 17:23:38,716:INFO:Creating metrics dataframe
2023-04-06 17:23:39,137:INFO:Uploading results into container
2023-04-06 17:23:39,137:INFO:Uploading model into container now
2023-04-06 17:23:39,137:INFO:_master_model_container: 8
2023-04-06 17:23:39,138:INFO:_display_container: 2
2023-04-06 17:23:39,138:INFO:BayesianRidge()
2023-04-06 17:23:39,138:INFO:create_model() successfully completed......................................
2023-04-06 17:23:39,222:INFO:SubProcess create_model() end ==================================
2023-04-06 17:23:39,222:INFO:Creating metrics dataframe
2023-04-06 17:23:39,226:INFO:Initializing Passive Aggressive Regressor
2023-04-06 17:23:39,227:INFO:Total runtime is 0.6762371778488159 minutes
2023-04-06 17:23:39,228:INFO:SubProcess create_model() called ==================================
2023-04-06 17:23:39,228:INFO:Initializing create_model()
2023-04-06 17:23:39,228:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103dc2130>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:23:39,228:INFO:Checking exceptions
2023-04-06 17:23:39,228:INFO:Importing libraries
2023-04-06 17:23:39,228:INFO:Copying training dataset
2023-04-06 17:23:39,231:INFO:Defining folds
2023-04-06 17:23:39,231:INFO:Declaring metric variables
2023-04-06 17:23:39,232:INFO:Importing untrained model
2023-04-06 17:23:39,234:INFO:Passive Aggressive Regressor Imported successfully
2023-04-06 17:23:39,237:INFO:Starting cross validation
2023-04-06 17:23:39,238:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:23:39,488:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 267, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 899, in check_array
    _assert_all_finite(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 146, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-06 17:23:39,489:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 267, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 899, in check_array
    _assert_all_finite(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 146, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-06 17:23:39,506:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 267, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 899, in check_array
    _assert_all_finite(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 146, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-06 17:23:39,517:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 267, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 899, in check_array
    _assert_all_finite(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 146, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-06 17:23:39,543:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 267, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 899, in check_array
    _assert_all_finite(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 146, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-06 17:23:39,548:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 267, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 899, in check_array
    _assert_all_finite(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 146, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-06 17:23:43,527:INFO:Calculating mean and std
2023-04-06 17:23:43,528:INFO:Creating metrics dataframe
2023-04-06 17:23:43,937:INFO:Uploading results into container
2023-04-06 17:23:43,938:INFO:Uploading model into container now
2023-04-06 17:23:43,938:INFO:_master_model_container: 9
2023-04-06 17:23:43,938:INFO:_display_container: 2
2023-04-06 17:23:43,938:INFO:PassiveAggressiveRegressor(random_state=123)
2023-04-06 17:23:43,938:INFO:create_model() successfully completed......................................
2023-04-06 17:23:44,026:WARNING:create_model() for PassiveAggressiveRegressor(random_state=123) raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-06 17:23:44,029:WARNING:Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 796, in compare_models
    assert (
AssertionError

2023-04-06 17:23:44,029:INFO:Initializing create_model()
2023-04-06 17:23:44,029:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103dc2130>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:23:44,029:INFO:Checking exceptions
2023-04-06 17:23:44,029:INFO:Importing libraries
2023-04-06 17:23:44,029:INFO:Copying training dataset
2023-04-06 17:23:44,030:INFO:Defining folds
2023-04-06 17:23:44,030:INFO:Declaring metric variables
2023-04-06 17:23:44,032:INFO:Importing untrained model
2023-04-06 17:23:44,033:INFO:Passive Aggressive Regressor Imported successfully
2023-04-06 17:23:44,036:INFO:Starting cross validation
2023-04-06 17:23:44,037:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:23:44,265:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 267, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 899, in check_array
    _assert_all_finite(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 146, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-06 17:23:44,286:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 267, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 899, in check_array
    _assert_all_finite(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 146, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-06 17:23:44,297:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 267, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 899, in check_array
    _assert_all_finite(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 146, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-06 17:23:44,305:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 267, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 899, in check_array
    _assert_all_finite(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 146, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-06 17:23:44,308:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 267, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 899, in check_array
    _assert_all_finite(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 146, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-06 17:23:44,318:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 267, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 899, in check_array
    _assert_all_finite(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 146, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-06 17:23:48,087:INFO:Calculating mean and std
2023-04-06 17:23:48,088:INFO:Creating metrics dataframe
2023-04-06 17:23:48,496:INFO:Uploading results into container
2023-04-06 17:23:48,497:INFO:Uploading model into container now
2023-04-06 17:23:48,497:INFO:_master_model_container: 10
2023-04-06 17:23:48,497:INFO:_display_container: 2
2023-04-06 17:23:48,497:INFO:PassiveAggressiveRegressor(random_state=123)
2023-04-06 17:23:48,497:INFO:create_model() successfully completed......................................
2023-04-06 17:23:48,584:ERROR:create_model() for PassiveAggressiveRegressor(random_state=123) raised an exception or returned all 0.0:
2023-04-06 17:23:48,584:ERROR:Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 796, in compare_models
    assert (
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 812, in compare_models
    assert (
AssertionError

2023-04-06 17:23:48,584:INFO:Initializing Huber Regressor
2023-04-06 17:23:48,584:INFO:Total runtime is 0.832192595799764 minutes
2023-04-06 17:23:48,585:INFO:SubProcess create_model() called ==================================
2023-04-06 17:23:48,585:INFO:Initializing create_model()
2023-04-06 17:23:48,585:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103dc2130>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:23:48,585:INFO:Checking exceptions
2023-04-06 17:23:48,586:INFO:Importing libraries
2023-04-06 17:23:48,586:INFO:Copying training dataset
2023-04-06 17:23:48,587:INFO:Defining folds
2023-04-06 17:23:48,587:INFO:Declaring metric variables
2023-04-06 17:23:48,589:INFO:Importing untrained model
2023-04-06 17:23:48,590:INFO:Huber Regressor Imported successfully
2023-04-06 17:23:48,592:INFO:Starting cross validation
2023-04-06 17:23:48,593:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:23:52,631:INFO:Calculating mean and std
2023-04-06 17:23:52,632:INFO:Creating metrics dataframe
2023-04-06 17:23:53,026:INFO:Uploading results into container
2023-04-06 17:23:53,026:INFO:Uploading model into container now
2023-04-06 17:23:53,026:INFO:_master_model_container: 11
2023-04-06 17:23:53,026:INFO:_display_container: 2
2023-04-06 17:23:53,026:INFO:HuberRegressor()
2023-04-06 17:23:53,026:INFO:create_model() successfully completed......................................
2023-04-06 17:23:53,112:INFO:SubProcess create_model() end ==================================
2023-04-06 17:23:53,112:INFO:Creating metrics dataframe
2023-04-06 17:23:53,117:INFO:Initializing K Neighbors Regressor
2023-04-06 17:23:53,117:INFO:Total runtime is 0.9077428301175435 minutes
2023-04-06 17:23:53,118:INFO:SubProcess create_model() called ==================================
2023-04-06 17:23:53,118:INFO:Initializing create_model()
2023-04-06 17:23:53,118:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103dc2130>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:23:53,118:INFO:Checking exceptions
2023-04-06 17:23:53,118:INFO:Importing libraries
2023-04-06 17:23:53,118:INFO:Copying training dataset
2023-04-06 17:23:53,120:INFO:Defining folds
2023-04-06 17:23:53,121:INFO:Declaring metric variables
2023-04-06 17:23:53,122:INFO:Importing untrained model
2023-04-06 17:23:53,123:INFO:K Neighbors Regressor Imported successfully
2023-04-06 17:23:53,125:INFO:Starting cross validation
2023-04-06 17:23:53,126:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:23:57,049:INFO:Calculating mean and std
2023-04-06 17:23:57,050:INFO:Creating metrics dataframe
2023-04-06 17:23:57,453:INFO:Uploading results into container
2023-04-06 17:23:57,454:INFO:Uploading model into container now
2023-04-06 17:23:57,454:INFO:_master_model_container: 12
2023-04-06 17:23:57,454:INFO:_display_container: 2
2023-04-06 17:23:57,454:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-06 17:23:57,454:INFO:create_model() successfully completed......................................
2023-04-06 17:23:57,539:INFO:SubProcess create_model() end ==================================
2023-04-06 17:23:57,540:INFO:Creating metrics dataframe
2023-04-06 17:23:57,544:INFO:Initializing Decision Tree Regressor
2023-04-06 17:23:57,544:INFO:Total runtime is 0.981529446442922 minutes
2023-04-06 17:23:57,545:INFO:SubProcess create_model() called ==================================
2023-04-06 17:23:57,545:INFO:Initializing create_model()
2023-04-06 17:23:57,545:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103dc2130>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:23:57,545:INFO:Checking exceptions
2023-04-06 17:23:57,545:INFO:Importing libraries
2023-04-06 17:23:57,546:INFO:Copying training dataset
2023-04-06 17:23:57,548:INFO:Defining folds
2023-04-06 17:23:57,548:INFO:Declaring metric variables
2023-04-06 17:23:57,549:INFO:Importing untrained model
2023-04-06 17:23:57,550:INFO:Decision Tree Regressor Imported successfully
2023-04-06 17:23:57,552:INFO:Starting cross validation
2023-04-06 17:23:57,553:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:24:01,722:INFO:Calculating mean and std
2023-04-06 17:24:01,723:INFO:Creating metrics dataframe
2023-04-06 17:24:02,129:INFO:Uploading results into container
2023-04-06 17:24:02,130:INFO:Uploading model into container now
2023-04-06 17:24:02,130:INFO:_master_model_container: 13
2023-04-06 17:24:02,130:INFO:_display_container: 2
2023-04-06 17:24:02,130:INFO:DecisionTreeRegressor(random_state=123)
2023-04-06 17:24:02,130:INFO:create_model() successfully completed......................................
2023-04-06 17:24:02,219:INFO:SubProcess create_model() end ==================================
2023-04-06 17:24:02,219:INFO:Creating metrics dataframe
2023-04-06 17:24:02,223:INFO:Initializing Random Forest Regressor
2023-04-06 17:24:02,223:INFO:Total runtime is 1.0595136443773905 minutes
2023-04-06 17:24:02,224:INFO:SubProcess create_model() called ==================================
2023-04-06 17:24:02,224:INFO:Initializing create_model()
2023-04-06 17:24:02,224:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103dc2130>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:24:02,225:INFO:Checking exceptions
2023-04-06 17:24:02,225:INFO:Importing libraries
2023-04-06 17:24:02,225:INFO:Copying training dataset
2023-04-06 17:24:02,227:INFO:Defining folds
2023-04-06 17:24:02,227:INFO:Declaring metric variables
2023-04-06 17:24:02,228:INFO:Importing untrained model
2023-04-06 17:24:02,230:INFO:Random Forest Regressor Imported successfully
2023-04-06 17:24:02,233:INFO:Starting cross validation
2023-04-06 17:24:02,235:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:24:07,063:INFO:Calculating mean and std
2023-04-06 17:24:07,064:INFO:Creating metrics dataframe
2023-04-06 17:24:07,478:INFO:Uploading results into container
2023-04-06 17:24:07,479:INFO:Uploading model into container now
2023-04-06 17:24:07,479:INFO:_master_model_container: 14
2023-04-06 17:24:07,479:INFO:_display_container: 2
2023-04-06 17:24:07,479:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-04-06 17:24:07,479:INFO:create_model() successfully completed......................................
2023-04-06 17:24:07,567:INFO:SubProcess create_model() end ==================================
2023-04-06 17:24:07,567:INFO:Creating metrics dataframe
2023-04-06 17:24:07,572:INFO:Initializing Extra Trees Regressor
2023-04-06 17:24:07,572:INFO:Total runtime is 1.1486610968907673 minutes
2023-04-06 17:24:07,573:INFO:SubProcess create_model() called ==================================
2023-04-06 17:24:07,573:INFO:Initializing create_model()
2023-04-06 17:24:07,574:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103dc2130>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:24:07,574:INFO:Checking exceptions
2023-04-06 17:24:07,574:INFO:Importing libraries
2023-04-06 17:24:07,574:INFO:Copying training dataset
2023-04-06 17:24:07,577:INFO:Defining folds
2023-04-06 17:24:07,577:INFO:Declaring metric variables
2023-04-06 17:24:07,578:INFO:Importing untrained model
2023-04-06 17:24:07,580:INFO:Extra Trees Regressor Imported successfully
2023-04-06 17:24:07,582:INFO:Starting cross validation
2023-04-06 17:24:07,583:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:24:12,502:INFO:Calculating mean and std
2023-04-06 17:24:12,503:INFO:Creating metrics dataframe
2023-04-06 17:24:12,912:INFO:Uploading results into container
2023-04-06 17:24:12,912:INFO:Uploading model into container now
2023-04-06 17:24:12,913:INFO:_master_model_container: 15
2023-04-06 17:24:12,913:INFO:_display_container: 2
2023-04-06 17:24:12,913:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-04-06 17:24:12,913:INFO:create_model() successfully completed......................................
2023-04-06 17:24:13,000:INFO:SubProcess create_model() end ==================================
2023-04-06 17:24:13,001:INFO:Creating metrics dataframe
2023-04-06 17:24:13,005:INFO:Initializing AdaBoost Regressor
2023-04-06 17:24:13,005:INFO:Total runtime is 1.2392182826995848 minutes
2023-04-06 17:24:13,007:INFO:SubProcess create_model() called ==================================
2023-04-06 17:24:13,007:INFO:Initializing create_model()
2023-04-06 17:24:13,007:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103dc2130>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:24:13,007:INFO:Checking exceptions
2023-04-06 17:24:13,007:INFO:Importing libraries
2023-04-06 17:24:13,007:INFO:Copying training dataset
2023-04-06 17:24:13,010:INFO:Defining folds
2023-04-06 17:24:13,010:INFO:Declaring metric variables
2023-04-06 17:24:13,011:INFO:Importing untrained model
2023-04-06 17:24:13,013:INFO:AdaBoost Regressor Imported successfully
2023-04-06 17:24:13,016:INFO:Starting cross validation
2023-04-06 17:24:13,017:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:24:17,531:INFO:Calculating mean and std
2023-04-06 17:24:17,531:INFO:Creating metrics dataframe
2023-04-06 17:24:17,937:INFO:Uploading results into container
2023-04-06 17:24:17,937:INFO:Uploading model into container now
2023-04-06 17:24:17,938:INFO:_master_model_container: 16
2023-04-06 17:24:17,938:INFO:_display_container: 2
2023-04-06 17:24:17,938:INFO:AdaBoostRegressor(random_state=123)
2023-04-06 17:24:17,938:INFO:create_model() successfully completed......................................
2023-04-06 17:24:18,028:INFO:SubProcess create_model() end ==================================
2023-04-06 17:24:18,028:INFO:Creating metrics dataframe
2023-04-06 17:24:18,034:INFO:Initializing Gradient Boosting Regressor
2023-04-06 17:24:18,034:INFO:Total runtime is 1.32302801211675 minutes
2023-04-06 17:24:18,036:INFO:SubProcess create_model() called ==================================
2023-04-06 17:24:18,036:INFO:Initializing create_model()
2023-04-06 17:24:18,036:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103dc2130>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:24:18,036:INFO:Checking exceptions
2023-04-06 17:24:18,036:INFO:Importing libraries
2023-04-06 17:24:18,036:INFO:Copying training dataset
2023-04-06 17:24:18,039:INFO:Defining folds
2023-04-06 17:24:18,039:INFO:Declaring metric variables
2023-04-06 17:24:18,040:INFO:Importing untrained model
2023-04-06 17:24:18,042:INFO:Gradient Boosting Regressor Imported successfully
2023-04-06 17:24:18,045:INFO:Starting cross validation
2023-04-06 17:24:18,046:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:24:22,503:INFO:Calculating mean and std
2023-04-06 17:24:22,504:INFO:Creating metrics dataframe
2023-04-06 17:24:22,926:INFO:Uploading results into container
2023-04-06 17:24:22,926:INFO:Uploading model into container now
2023-04-06 17:24:22,927:INFO:_master_model_container: 17
2023-04-06 17:24:22,927:INFO:_display_container: 2
2023-04-06 17:24:22,927:INFO:GradientBoostingRegressor(random_state=123)
2023-04-06 17:24:22,927:INFO:create_model() successfully completed......................................
2023-04-06 17:24:23,013:INFO:SubProcess create_model() end ==================================
2023-04-06 17:24:23,013:INFO:Creating metrics dataframe
2023-04-06 17:24:23,018:INFO:Initializing Extreme Gradient Boosting
2023-04-06 17:24:23,018:INFO:Total runtime is 1.406098131338755 minutes
2023-04-06 17:24:23,020:INFO:SubProcess create_model() called ==================================
2023-04-06 17:24:23,020:INFO:Initializing create_model()
2023-04-06 17:24:23,020:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103dc2130>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:24:23,020:INFO:Checking exceptions
2023-04-06 17:24:23,020:INFO:Importing libraries
2023-04-06 17:24:23,020:INFO:Copying training dataset
2023-04-06 17:24:23,022:INFO:Defining folds
2023-04-06 17:24:23,023:INFO:Declaring metric variables
2023-04-06 17:24:23,024:INFO:Importing untrained model
2023-04-06 17:24:23,026:INFO:Extreme Gradient Boosting Imported successfully
2023-04-06 17:24:23,028:INFO:Starting cross validation
2023-04-06 17:24:23,029:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:24:27,515:INFO:Calculating mean and std
2023-04-06 17:24:27,515:INFO:Creating metrics dataframe
2023-04-06 17:24:27,936:INFO:Uploading results into container
2023-04-06 17:24:27,936:INFO:Uploading model into container now
2023-04-06 17:24:27,937:INFO:_master_model_container: 18
2023-04-06 17:24:27,937:INFO:_display_container: 2
2023-04-06 17:24:27,937:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=123, ...)
2023-04-06 17:24:27,937:INFO:create_model() successfully completed......................................
2023-04-06 17:24:28,025:INFO:SubProcess create_model() end ==================================
2023-04-06 17:24:28,025:INFO:Creating metrics dataframe
2023-04-06 17:24:28,030:INFO:Initializing Light Gradient Boosting Machine
2023-04-06 17:24:28,030:INFO:Total runtime is 1.4896260301272073 minutes
2023-04-06 17:24:28,031:INFO:SubProcess create_model() called ==================================
2023-04-06 17:24:28,031:INFO:Initializing create_model()
2023-04-06 17:24:28,031:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103dc2130>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:24:28,031:INFO:Checking exceptions
2023-04-06 17:24:28,031:INFO:Importing libraries
2023-04-06 17:24:28,031:INFO:Copying training dataset
2023-04-06 17:24:28,034:INFO:Defining folds
2023-04-06 17:24:28,034:INFO:Declaring metric variables
2023-04-06 17:24:28,035:INFO:Importing untrained model
2023-04-06 17:24:28,036:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-06 17:24:28,039:INFO:Starting cross validation
2023-04-06 17:24:28,040:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:24:32,813:INFO:Calculating mean and std
2023-04-06 17:24:32,814:INFO:Creating metrics dataframe
2023-04-06 17:24:33,220:INFO:Uploading results into container
2023-04-06 17:24:33,221:INFO:Uploading model into container now
2023-04-06 17:24:33,221:INFO:_master_model_container: 19
2023-04-06 17:24:33,222:INFO:_display_container: 2
2023-04-06 17:24:33,222:INFO:LGBMRegressor(random_state=123)
2023-04-06 17:24:33,222:INFO:create_model() successfully completed......................................
2023-04-06 17:24:33,310:INFO:SubProcess create_model() end ==================================
2023-04-06 17:24:33,310:INFO:Creating metrics dataframe
2023-04-06 17:24:33,315:INFO:Initializing CatBoost Regressor
2023-04-06 17:24:33,315:INFO:Total runtime is 1.5777198950449625 minutes
2023-04-06 17:24:33,317:INFO:SubProcess create_model() called ==================================
2023-04-06 17:24:33,317:INFO:Initializing create_model()
2023-04-06 17:24:33,317:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103dc2130>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:24:33,317:INFO:Checking exceptions
2023-04-06 17:24:33,317:INFO:Importing libraries
2023-04-06 17:24:33,317:INFO:Copying training dataset
2023-04-06 17:24:33,319:INFO:Defining folds
2023-04-06 17:24:33,319:INFO:Declaring metric variables
2023-04-06 17:24:33,321:INFO:Importing untrained model
2023-04-06 17:24:33,322:INFO:CatBoost Regressor Imported successfully
2023-04-06 17:24:33,325:INFO:Starting cross validation
2023-04-06 17:24:33,326:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:24:39,034:INFO:Calculating mean and std
2023-04-06 17:24:39,034:INFO:Creating metrics dataframe
2023-04-06 17:24:39,470:INFO:Uploading results into container
2023-04-06 17:24:39,471:INFO:Uploading model into container now
2023-04-06 17:24:39,471:INFO:_master_model_container: 20
2023-04-06 17:24:39,471:INFO:_display_container: 2
2023-04-06 17:24:39,472:INFO:<catboost.core.CatBoostRegressor object at 0x283db4760>
2023-04-06 17:24:39,472:INFO:create_model() successfully completed......................................
2023-04-06 17:24:39,565:INFO:SubProcess create_model() end ==================================
2023-04-06 17:24:39,565:INFO:Creating metrics dataframe
2023-04-06 17:24:39,571:INFO:Initializing Dummy Regressor
2023-04-06 17:24:39,571:INFO:Total runtime is 1.681976815064748 minutes
2023-04-06 17:24:39,572:INFO:SubProcess create_model() called ==================================
2023-04-06 17:24:39,573:INFO:Initializing create_model()
2023-04-06 17:24:39,573:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103dc2130>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:24:39,573:INFO:Checking exceptions
2023-04-06 17:24:39,573:INFO:Importing libraries
2023-04-06 17:24:39,573:INFO:Copying training dataset
2023-04-06 17:24:39,576:INFO:Defining folds
2023-04-06 17:24:39,576:INFO:Declaring metric variables
2023-04-06 17:24:39,578:INFO:Importing untrained model
2023-04-06 17:24:39,580:INFO:Dummy Regressor Imported successfully
2023-04-06 17:24:39,582:INFO:Starting cross validation
2023-04-06 17:24:39,583:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:24:43,897:INFO:Calculating mean and std
2023-04-06 17:24:43,900:INFO:Creating metrics dataframe
2023-04-06 17:24:44,321:INFO:Uploading results into container
2023-04-06 17:24:44,322:INFO:Uploading model into container now
2023-04-06 17:24:44,322:INFO:_master_model_container: 21
2023-04-06 17:24:44,322:INFO:_display_container: 2
2023-04-06 17:24:44,322:INFO:DummyRegressor()
2023-04-06 17:24:44,322:INFO:create_model() successfully completed......................................
2023-04-06 17:24:44,411:INFO:SubProcess create_model() end ==================================
2023-04-06 17:24:44,411:INFO:Creating metrics dataframe
2023-04-06 17:24:44,420:INFO:Initializing create_model()
2023-04-06 17:24:44,420:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:24:44,420:INFO:Checking exceptions
2023-04-06 17:24:44,421:INFO:Importing libraries
2023-04-06 17:24:44,421:INFO:Copying training dataset
2023-04-06 17:24:44,423:INFO:Defining folds
2023-04-06 17:24:44,423:INFO:Declaring metric variables
2023-04-06 17:24:44,423:INFO:Importing untrained model
2023-04-06 17:24:44,423:INFO:Declaring custom model
2023-04-06 17:24:44,423:INFO:Gradient Boosting Regressor Imported successfully
2023-04-06 17:24:44,424:INFO:Cross validation set to False
2023-04-06 17:24:44,424:INFO:Fitting Model
2023-04-06 17:24:45,189:INFO:GradientBoostingRegressor(random_state=123)
2023-04-06 17:24:45,189:INFO:create_model() successfully completed......................................
2023-04-06 17:24:45,287:INFO:_master_model_container: 21
2023-04-06 17:24:45,287:INFO:_display_container: 2
2023-04-06 17:24:45,287:INFO:GradientBoostingRegressor(random_state=123)
2023-04-06 17:24:45,287:INFO:compare_models() successfully completed......................................
2023-04-06 17:24:45,291:INFO:Initializing create_model()
2023-04-06 17:24:45,291:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=dt, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:24:45,291:INFO:Checking exceptions
2023-04-06 17:24:45,299:INFO:Importing libraries
2023-04-06 17:24:45,301:INFO:Copying training dataset
2023-04-06 17:24:45,307:INFO:Defining folds
2023-04-06 17:24:45,307:INFO:Declaring metric variables
2023-04-06 17:24:45,309:INFO:Importing untrained model
2023-04-06 17:24:45,311:INFO:Decision Tree Regressor Imported successfully
2023-04-06 17:24:45,315:INFO:Starting cross validation
2023-04-06 17:24:45,316:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:24:47,234:INFO:Calculating mean and std
2023-04-06 17:24:47,235:INFO:Creating metrics dataframe
2023-04-06 17:24:47,237:INFO:Finalizing model
2023-04-06 17:24:47,844:INFO:Uploading results into container
2023-04-06 17:24:47,844:INFO:Uploading model into container now
2023-04-06 17:24:47,848:INFO:_master_model_container: 22
2023-04-06 17:24:47,848:INFO:_display_container: 3
2023-04-06 17:24:47,848:INFO:DecisionTreeRegressor(random_state=123)
2023-04-06 17:24:47,848:INFO:create_model() successfully completed......................................
2023-04-06 17:24:47,939:INFO:Initializing create_model()
2023-04-06 17:24:47,939:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=dt, fold=5, round=2, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:24:47,940:INFO:Checking exceptions
2023-04-06 17:24:47,946:INFO:Importing libraries
2023-04-06 17:24:47,946:INFO:Copying training dataset
2023-04-06 17:24:47,949:INFO:Defining folds
2023-04-06 17:24:47,949:INFO:Declaring metric variables
2023-04-06 17:24:47,951:INFO:Importing untrained model
2023-04-06 17:24:47,952:INFO:Decision Tree Regressor Imported successfully
2023-04-06 17:24:47,955:INFO:Starting cross validation
2023-04-06 17:24:47,956:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:24:49,905:INFO:Calculating mean and std
2023-04-06 17:24:49,906:INFO:Creating metrics dataframe
2023-04-06 17:24:49,908:INFO:Finalizing model
2023-04-06 17:24:50,488:INFO:Uploading results into container
2023-04-06 17:24:50,489:INFO:Uploading model into container now
2023-04-06 17:24:50,493:INFO:_master_model_container: 23
2023-04-06 17:24:50,493:INFO:_display_container: 4
2023-04-06 17:24:50,493:INFO:DecisionTreeRegressor(random_state=123)
2023-04-06 17:24:50,493:INFO:create_model() successfully completed......................................
2023-04-06 17:24:50,587:INFO:Initializing tune_model()
2023-04-06 17:24:50,587:INFO:tune_model(estimator=knn, fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>)
2023-04-06 17:24:50,587:INFO:Checking exceptions
2023-04-06 17:25:43,763:INFO:Initializing create_model()
2023-04-06 17:25:43,766:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=knn, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:25:43,767:INFO:Checking exceptions
2023-04-06 17:25:43,783:INFO:Importing libraries
2023-04-06 17:25:43,784:INFO:Copying training dataset
2023-04-06 17:25:43,789:INFO:Defining folds
2023-04-06 17:25:43,789:INFO:Declaring metric variables
2023-04-06 17:25:43,791:INFO:Importing untrained model
2023-04-06 17:25:43,793:INFO:K Neighbors Regressor Imported successfully
2023-04-06 17:25:43,796:INFO:Starting cross validation
2023-04-06 17:25:43,798:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:25:45,748:INFO:Calculating mean and std
2023-04-06 17:25:45,749:INFO:Creating metrics dataframe
2023-04-06 17:25:45,752:INFO:Finalizing model
2023-04-06 17:25:46,312:INFO:Uploading results into container
2023-04-06 17:25:46,313:INFO:Uploading model into container now
2023-04-06 17:25:46,316:INFO:_master_model_container: 24
2023-04-06 17:25:46,316:INFO:_display_container: 5
2023-04-06 17:25:46,317:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-06 17:25:46,317:INFO:create_model() successfully completed......................................
2023-04-06 17:25:52,104:INFO:Initializing tune_model()
2023-04-06 17:25:52,105:INFO:tune_model(estimator=KNeighborsRegressor(n_jobs=-1), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>)
2023-04-06 17:25:52,105:INFO:Checking exceptions
2023-04-06 17:25:52,122:INFO:Copying training dataset
2023-04-06 17:25:52,126:INFO:Checking base model
2023-04-06 17:25:52,126:INFO:Base model : K Neighbors Regressor
2023-04-06 17:25:52,128:INFO:Declaring metric variables
2023-04-06 17:25:52,130:INFO:Defining Hyperparameters
2023-04-06 17:25:52,246:INFO:Tuning with n_jobs=-1
2023-04-06 17:25:52,246:INFO:Initializing RandomizedSearchCV
2023-04-06 17:26:32,297:INFO:best_params: {'actual_estimator__weights': 'distance', 'actual_estimator__n_neighbors': 13, 'actual_estimator__metric': 'manhattan'}
2023-04-06 17:26:32,298:INFO:Hyperparameter search completed
2023-04-06 17:26:32,298:INFO:SubProcess create_model() called ==================================
2023-04-06 17:26:32,298:INFO:Initializing create_model()
2023-04-06 17:26:32,298:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=KNeighborsRegressor(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x283d9af70>, model_only=True, return_train_score=False, kwargs={'weights': 'distance', 'n_neighbors': 13, 'metric': 'manhattan'})
2023-04-06 17:26:32,298:INFO:Checking exceptions
2023-04-06 17:26:32,298:INFO:Importing libraries
2023-04-06 17:26:32,298:INFO:Copying training dataset
2023-04-06 17:26:32,301:INFO:Defining folds
2023-04-06 17:26:32,301:INFO:Declaring metric variables
2023-04-06 17:26:32,303:INFO:Importing untrained model
2023-04-06 17:26:32,303:INFO:Declaring custom model
2023-04-06 17:26:32,304:INFO:K Neighbors Regressor Imported successfully
2023-04-06 17:26:32,307:INFO:Starting cross validation
2023-04-06 17:26:32,309:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:26:36,899:INFO:Calculating mean and std
2023-04-06 17:26:36,900:INFO:Creating metrics dataframe
2023-04-06 17:26:36,902:INFO:Finalizing model
2023-04-06 17:26:37,508:INFO:Uploading results into container
2023-04-06 17:26:37,508:INFO:Uploading model into container now
2023-04-06 17:26:37,509:INFO:_master_model_container: 25
2023-04-06 17:26:37,509:INFO:_display_container: 6
2023-04-06 17:26:37,509:INFO:KNeighborsRegressor(metric='manhattan', n_jobs=-1, n_neighbors=13,
                    weights='distance')
2023-04-06 17:26:37,509:INFO:create_model() successfully completed......................................
2023-04-06 17:26:37,617:INFO:SubProcess create_model() end ==================================
2023-04-06 17:26:37,618:INFO:choose_better activated
2023-04-06 17:26:37,619:INFO:SubProcess create_model() called ==================================
2023-04-06 17:26:37,620:INFO:Initializing create_model()
2023-04-06 17:26:37,620:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=KNeighborsRegressor(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:26:37,620:INFO:Checking exceptions
2023-04-06 17:26:37,621:INFO:Importing libraries
2023-04-06 17:26:37,621:INFO:Copying training dataset
2023-04-06 17:26:37,623:INFO:Defining folds
2023-04-06 17:26:37,623:INFO:Declaring metric variables
2023-04-06 17:26:37,623:INFO:Importing untrained model
2023-04-06 17:26:37,624:INFO:Declaring custom model
2023-04-06 17:26:37,624:INFO:K Neighbors Regressor Imported successfully
2023-04-06 17:26:37,624:INFO:Starting cross validation
2023-04-06 17:26:37,625:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:26:41,995:INFO:Calculating mean and std
2023-04-06 17:26:41,996:INFO:Creating metrics dataframe
2023-04-06 17:26:41,996:INFO:Finalizing model
2023-04-06 17:26:42,606:INFO:Uploading results into container
2023-04-06 17:26:42,607:INFO:Uploading model into container now
2023-04-06 17:26:42,607:INFO:_master_model_container: 26
2023-04-06 17:26:42,607:INFO:_display_container: 7
2023-04-06 17:26:42,607:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-06 17:26:42,607:INFO:create_model() successfully completed......................................
2023-04-06 17:26:42,712:INFO:SubProcess create_model() end ==================================
2023-04-06 17:26:42,713:INFO:KNeighborsRegressor(n_jobs=-1) result for R2 is 0.4787
2023-04-06 17:26:42,713:INFO:KNeighborsRegressor(metric='manhattan', n_jobs=-1, n_neighbors=13,
                    weights='distance') result for R2 is 0.6353
2023-04-06 17:26:42,713:INFO:KNeighborsRegressor(metric='manhattan', n_jobs=-1, n_neighbors=13,
                    weights='distance') is best model
2023-04-06 17:26:42,713:INFO:choose_better completed
2023-04-06 17:26:42,717:INFO:_master_model_container: 26
2023-04-06 17:26:42,717:INFO:_display_container: 6
2023-04-06 17:26:42,717:INFO:KNeighborsRegressor(metric='manhattan', n_jobs=-1, n_neighbors=13,
                    weights='distance')
2023-04-06 17:26:42,717:INFO:tune_model() successfully completed......................................
2023-04-06 17:26:43,214:INFO:Initializing tune_model()
2023-04-06 17:26:43,215:INFO:tune_model(estimator=KNeighborsRegressor(n_jobs=-1), fold=None, round=4, n_iter=25, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>)
2023-04-06 17:26:43,215:INFO:Checking exceptions
2023-04-06 17:26:43,222:INFO:Copying training dataset
2023-04-06 17:26:43,225:INFO:Checking base model
2023-04-06 17:26:43,225:INFO:Base model : K Neighbors Regressor
2023-04-06 17:26:43,227:INFO:Declaring metric variables
2023-04-06 17:26:43,229:INFO:Defining Hyperparameters
2023-04-06 17:26:43,337:INFO:Tuning with n_jobs=-1
2023-04-06 17:26:43,337:INFO:Initializing RandomizedSearchCV
2023-04-06 17:28:21,377:INFO:best_params: {'actual_estimator__weights': 'distance', 'actual_estimator__n_neighbors': 6, 'actual_estimator__metric': 'euclidean'}
2023-04-06 17:28:21,378:INFO:Hyperparameter search completed
2023-04-06 17:28:21,378:INFO:SubProcess create_model() called ==================================
2023-04-06 17:28:21,378:INFO:Initializing create_model()
2023-04-06 17:28:21,379:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=KNeighborsRegressor(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x2817afac0>, model_only=True, return_train_score=False, kwargs={'weights': 'distance', 'n_neighbors': 6, 'metric': 'euclidean'})
2023-04-06 17:28:21,379:INFO:Checking exceptions
2023-04-06 17:28:21,379:INFO:Importing libraries
2023-04-06 17:28:21,379:INFO:Copying training dataset
2023-04-06 17:28:21,381:INFO:Defining folds
2023-04-06 17:28:21,381:INFO:Declaring metric variables
2023-04-06 17:28:21,383:INFO:Importing untrained model
2023-04-06 17:28:21,383:INFO:Declaring custom model
2023-04-06 17:28:21,385:INFO:K Neighbors Regressor Imported successfully
2023-04-06 17:28:21,388:INFO:Starting cross validation
2023-04-06 17:28:21,389:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:28:25,691:INFO:Calculating mean and std
2023-04-06 17:28:25,691:INFO:Creating metrics dataframe
2023-04-06 17:28:25,694:INFO:Finalizing model
2023-04-06 17:28:26,299:INFO:Uploading results into container
2023-04-06 17:28:26,299:INFO:Uploading model into container now
2023-04-06 17:28:26,299:INFO:_master_model_container: 27
2023-04-06 17:28:26,299:INFO:_display_container: 7
2023-04-06 17:28:26,300:INFO:KNeighborsRegressor(metric='euclidean', n_jobs=-1, n_neighbors=6,
                    weights='distance')
2023-04-06 17:28:26,300:INFO:create_model() successfully completed......................................
2023-04-06 17:28:26,402:INFO:SubProcess create_model() end ==================================
2023-04-06 17:28:26,403:INFO:choose_better activated
2023-04-06 17:28:26,404:INFO:SubProcess create_model() called ==================================
2023-04-06 17:28:26,404:INFO:Initializing create_model()
2023-04-06 17:28:26,404:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=KNeighborsRegressor(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:28:26,404:INFO:Checking exceptions
2023-04-06 17:28:26,405:INFO:Importing libraries
2023-04-06 17:28:26,405:INFO:Copying training dataset
2023-04-06 17:28:26,407:INFO:Defining folds
2023-04-06 17:28:26,407:INFO:Declaring metric variables
2023-04-06 17:28:26,408:INFO:Importing untrained model
2023-04-06 17:28:26,408:INFO:Declaring custom model
2023-04-06 17:28:26,408:INFO:K Neighbors Regressor Imported successfully
2023-04-06 17:28:26,408:INFO:Starting cross validation
2023-04-06 17:28:26,409:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:28:30,692:INFO:Calculating mean and std
2023-04-06 17:28:30,692:INFO:Creating metrics dataframe
2023-04-06 17:28:30,693:INFO:Finalizing model
2023-04-06 17:28:31,275:INFO:Uploading results into container
2023-04-06 17:28:31,276:INFO:Uploading model into container now
2023-04-06 17:28:31,276:INFO:_master_model_container: 28
2023-04-06 17:28:31,276:INFO:_display_container: 8
2023-04-06 17:28:31,276:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-06 17:28:31,276:INFO:create_model() successfully completed......................................
2023-04-06 17:28:31,387:INFO:SubProcess create_model() end ==================================
2023-04-06 17:28:31,387:INFO:KNeighborsRegressor(n_jobs=-1) result for R2 is 0.4787
2023-04-06 17:28:31,387:INFO:KNeighborsRegressor(metric='euclidean', n_jobs=-1, n_neighbors=6,
                    weights='distance') result for R2 is 0.6419
2023-04-06 17:28:31,388:INFO:KNeighborsRegressor(metric='euclidean', n_jobs=-1, n_neighbors=6,
                    weights='distance') is best model
2023-04-06 17:28:31,388:INFO:choose_better completed
2023-04-06 17:28:31,392:INFO:_master_model_container: 28
2023-04-06 17:28:31,392:INFO:_display_container: 7
2023-04-06 17:28:31,392:INFO:KNeighborsRegressor(metric='euclidean', n_jobs=-1, n_neighbors=6,
                    weights='distance')
2023-04-06 17:28:31,392:INFO:tune_model() successfully completed......................................
2023-04-06 17:28:31,907:INFO:Initializing plot_model()
2023-04-06 17:28:31,907:INFO:plot_model(plot=parameter, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=KNeighborsRegressor(metric='manhattan', n_jobs=-1, n_neighbors=13,
                    weights='distance'), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, system=True)
2023-04-06 17:28:31,907:INFO:Checking exceptions
2023-04-06 17:28:31,910:INFO:Preloading libraries
2023-04-06 17:28:31,910:INFO:Copying training dataset
2023-04-06 17:28:31,910:INFO:Plot type: parameter
2023-04-06 17:28:31,912:INFO:Visual Rendered Successfully
2023-04-06 17:28:32,016:INFO:plot_model() successfully completed......................................
2023-04-06 17:28:32,020:INFO:Initializing plot_model()
2023-04-06 17:28:32,021:INFO:plot_model(plot=parameter, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=KNeighborsRegressor(metric='euclidean', n_jobs=-1, n_neighbors=6,
                    weights='distance'), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, system=True)
2023-04-06 17:28:32,021:INFO:Checking exceptions
2023-04-06 17:28:32,023:INFO:Preloading libraries
2023-04-06 17:28:32,026:INFO:Copying training dataset
2023-04-06 17:28:32,026:INFO:Plot type: parameter
2023-04-06 17:28:32,028:INFO:Visual Rendered Successfully
2023-04-06 17:28:32,138:INFO:plot_model() successfully completed......................................
2023-04-06 17:28:32,141:INFO:Initializing ensemble_model()
2023-04-06 17:28:32,141:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=DecisionTreeRegressor(random_state=123), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-04-06 17:28:32,141:INFO:Checking exceptions
2023-04-06 17:28:32,149:INFO:Importing libraries
2023-04-06 17:28:32,149:INFO:Copying training dataset
2023-04-06 17:28:32,149:INFO:Checking base model
2023-04-06 17:28:32,150:INFO:Base model : Decision Tree Regressor
2023-04-06 17:28:32,153:INFO:Importing untrained ensembler
2023-04-06 17:28:32,153:INFO:Ensemble method set to Bagging
2023-04-06 17:28:32,153:INFO:SubProcess create_model() called ==================================
2023-04-06 17:28:32,154:INFO:Initializing create_model()
2023-04-06 17:28:32,154:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=BaggingRegressor(base_estimator=DecisionTreeRegressor(random_state=123),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x2817d86d0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:28:32,154:INFO:Checking exceptions
2023-04-06 17:28:32,154:INFO:Importing libraries
2023-04-06 17:28:32,154:INFO:Copying training dataset
2023-04-06 17:28:32,158:INFO:Defining folds
2023-04-06 17:28:32,158:INFO:Declaring metric variables
2023-04-06 17:28:32,159:INFO:Importing untrained model
2023-04-06 17:28:32,159:INFO:Declaring custom model
2023-04-06 17:28:32,161:INFO:Decision Tree Regressor Imported successfully
2023-04-06 17:28:32,164:INFO:Starting cross validation
2023-04-06 17:28:32,165:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:28:36,556:INFO:Calculating mean and std
2023-04-06 17:28:36,556:INFO:Creating metrics dataframe
2023-04-06 17:28:36,559:INFO:Finalizing model
2023-04-06 17:28:37,192:INFO:Uploading results into container
2023-04-06 17:28:37,192:INFO:Uploading model into container now
2023-04-06 17:28:37,192:INFO:_master_model_container: 29
2023-04-06 17:28:37,192:INFO:_display_container: 8
2023-04-06 17:28:37,193:INFO:BaggingRegressor(base_estimator=DecisionTreeRegressor(random_state=123),
                 random_state=123)
2023-04-06 17:28:37,193:INFO:create_model() successfully completed......................................
2023-04-06 17:28:37,298:INFO:SubProcess create_model() end ==================================
2023-04-06 17:28:37,302:INFO:_master_model_container: 29
2023-04-06 17:28:37,302:INFO:_display_container: 8
2023-04-06 17:28:37,302:INFO:BaggingRegressor(base_estimator=DecisionTreeRegressor(random_state=123),
                 random_state=123)
2023-04-06 17:28:37,302:INFO:ensemble_model() successfully completed......................................
2023-04-06 17:28:37,415:INFO:Initializing ensemble_model()
2023-04-06 17:28:37,415:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=DecisionTreeRegressor(random_state=123), method=Boosting, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-04-06 17:28:37,416:INFO:Checking exceptions
2023-04-06 17:28:37,585:INFO:Importing libraries
2023-04-06 17:28:37,585:INFO:Copying training dataset
2023-04-06 17:28:37,589:INFO:Checking base model
2023-04-06 17:28:37,589:INFO:Base model : Decision Tree Regressor
2023-04-06 17:28:37,592:INFO:Importing untrained ensembler
2023-04-06 17:28:37,593:INFO:Ensemble method set to Boosting
2023-04-06 17:28:37,593:INFO:SubProcess create_model() called ==================================
2023-04-06 17:28:37,593:INFO:Initializing create_model()
2023-04-06 17:28:37,593:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=AdaBoostRegressor(base_estimator=DecisionTreeRegressor(random_state=123),
                  n_estimators=10, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x28149cf70>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:28:37,593:INFO:Checking exceptions
2023-04-06 17:28:37,593:INFO:Importing libraries
2023-04-06 17:28:37,593:INFO:Copying training dataset
2023-04-06 17:28:37,598:INFO:Defining folds
2023-04-06 17:28:37,598:INFO:Declaring metric variables
2023-04-06 17:28:37,600:INFO:Importing untrained model
2023-04-06 17:28:37,600:INFO:Declaring custom model
2023-04-06 17:28:37,602:INFO:Decision Tree Regressor Imported successfully
2023-04-06 17:28:37,605:INFO:Starting cross validation
2023-04-06 17:28:37,607:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:28:42,024:INFO:Calculating mean and std
2023-04-06 17:28:42,025:INFO:Creating metrics dataframe
2023-04-06 17:28:42,027:INFO:Finalizing model
2023-04-06 17:28:42,660:INFO:Uploading results into container
2023-04-06 17:28:42,661:INFO:Uploading model into container now
2023-04-06 17:28:42,661:INFO:_master_model_container: 30
2023-04-06 17:28:42,661:INFO:_display_container: 9
2023-04-06 17:28:42,662:INFO:AdaBoostRegressor(base_estimator=DecisionTreeRegressor(random_state=123),
                  n_estimators=10, random_state=123)
2023-04-06 17:28:42,662:INFO:create_model() successfully completed......................................
2023-04-06 17:28:42,765:INFO:SubProcess create_model() end ==================================
2023-04-06 17:28:42,769:INFO:_master_model_container: 30
2023-04-06 17:28:42,769:INFO:_display_container: 9
2023-04-06 17:28:42,769:INFO:AdaBoostRegressor(base_estimator=DecisionTreeRegressor(random_state=123),
                  n_estimators=10, random_state=123)
2023-04-06 17:28:42,769:INFO:ensemble_model() successfully completed......................................
2023-04-06 17:28:42,875:INFO:Initializing ensemble_model()
2023-04-06 17:28:42,875:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=DecisionTreeRegressor(random_state=123), method=Bagging, fold=None, n_estimators=50, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-04-06 17:28:42,876:INFO:Checking exceptions
2023-04-06 17:28:42,884:INFO:Importing libraries
2023-04-06 17:28:42,884:INFO:Copying training dataset
2023-04-06 17:28:42,884:INFO:Checking base model
2023-04-06 17:28:42,884:INFO:Base model : Decision Tree Regressor
2023-04-06 17:28:42,887:INFO:Importing untrained ensembler
2023-04-06 17:28:42,887:INFO:Ensemble method set to Bagging
2023-04-06 17:28:42,887:INFO:SubProcess create_model() called ==================================
2023-04-06 17:28:42,888:INFO:Initializing create_model()
2023-04-06 17:28:42,888:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=BaggingRegressor(base_estimator=DecisionTreeRegressor(random_state=123),
                 n_estimators=50, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x2817ee1c0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:28:42,888:INFO:Checking exceptions
2023-04-06 17:28:42,888:INFO:Importing libraries
2023-04-06 17:28:42,888:INFO:Copying training dataset
2023-04-06 17:28:42,892:INFO:Defining folds
2023-04-06 17:28:42,892:INFO:Declaring metric variables
2023-04-06 17:28:42,893:INFO:Importing untrained model
2023-04-06 17:28:42,894:INFO:Declaring custom model
2023-04-06 17:28:42,896:INFO:Decision Tree Regressor Imported successfully
2023-04-06 17:28:42,899:INFO:Starting cross validation
2023-04-06 17:28:42,900:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:28:47,588:INFO:Calculating mean and std
2023-04-06 17:28:47,588:INFO:Creating metrics dataframe
2023-04-06 17:28:47,591:INFO:Finalizing model
2023-04-06 17:28:48,430:INFO:Uploading results into container
2023-04-06 17:28:48,431:INFO:Uploading model into container now
2023-04-06 17:28:48,431:INFO:_master_model_container: 31
2023-04-06 17:28:48,431:INFO:_display_container: 10
2023-04-06 17:28:48,431:INFO:BaggingRegressor(base_estimator=DecisionTreeRegressor(random_state=123),
                 n_estimators=50, random_state=123)
2023-04-06 17:28:48,431:INFO:create_model() successfully completed......................................
2023-04-06 17:28:48,536:INFO:SubProcess create_model() end ==================================
2023-04-06 17:28:48,541:INFO:_master_model_container: 31
2023-04-06 17:28:48,541:INFO:_display_container: 10
2023-04-06 17:28:48,541:INFO:BaggingRegressor(base_estimator=DecisionTreeRegressor(random_state=123),
                 n_estimators=50, random_state=123)
2023-04-06 17:28:48,541:INFO:ensemble_model() successfully completed......................................
2023-04-06 17:28:48,646:INFO:Initializing tune_model()
2023-04-06 17:28:48,646:INFO:tune_model(estimator=dt, fold=None, round=4, n_iter=100, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={'ensemble': True, 'method': 'Bagging'}, self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>)
2023-04-06 17:28:48,646:INFO:Checking exceptions
2023-04-06 17:28:58,379:INFO:Initializing tune_model()
2023-04-06 17:28:58,380:INFO:tune_model(estimator=DecisionTreeRegressor(random_state=123), fold=None, round=4, n_iter=100, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={'ensemble': True, 'method': 'Bagging'}, self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>)
2023-04-06 17:28:58,380:INFO:Checking exceptions
2023-04-06 17:28:58,395:INFO:Copying training dataset
2023-04-06 17:28:58,399:INFO:Checking base model
2023-04-06 17:28:58,399:INFO:Base model : Decision Tree Regressor
2023-04-06 17:28:58,401:INFO:Declaring metric variables
2023-04-06 17:28:58,402:INFO:Defining Hyperparameters
2023-04-06 17:28:58,514:INFO:Tuning with n_jobs=-1
2023-04-06 17:28:58,514:INFO:Initializing RandomizedSearchCV
2023-04-06 17:29:22,182:INFO:Initializing tune_model()
2023-04-06 17:29:22,183:INFO:tune_model(estimator=DecisionTreeRegressor(random_state=123), fold=None, round=4, n_iter=100, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={'method': 'Bagging'}, self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>)
2023-04-06 17:29:22,184:INFO:Checking exceptions
2023-04-06 17:29:22,199:INFO:Copying training dataset
2023-04-06 17:29:22,203:INFO:Checking base model
2023-04-06 17:29:22,203:INFO:Base model : Decision Tree Regressor
2023-04-06 17:29:22,205:INFO:Declaring metric variables
2023-04-06 17:29:22,207:INFO:Defining Hyperparameters
2023-04-06 17:29:22,317:INFO:Tuning with n_jobs=-1
2023-04-06 17:29:22,317:INFO:Initializing RandomizedSearchCV
2023-04-06 17:31:19,847:INFO:Initializing blend_models()
2023-04-06 17:31:19,849:INFO:blend_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator_list=['dt', 'catboost'], fold=None, round=4, choose_better=False, optimize=R2, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-04-06 17:31:19,849:INFO:Checking exceptions
2023-04-06 17:32:35,910:INFO:Initializing blend_models()
2023-04-06 17:32:35,911:INFO:blend_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator_list=[DecisionTreeRegressor(random_state=123), KNeighborsRegressor(n_jobs=-1)], fold=None, round=4, choose_better=False, optimize=R2, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-04-06 17:32:35,911:INFO:Checking exceptions
2023-04-06 17:32:35,932:INFO:Importing libraries
2023-04-06 17:32:35,932:INFO:Copying training dataset
2023-04-06 17:32:35,935:INFO:Getting model names
2023-04-06 17:32:35,937:INFO:SubProcess create_model() called ==================================
2023-04-06 17:32:35,938:INFO:Initializing create_model()
2023-04-06 17:32:35,938:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=VotingRegressor(estimators=[('Decision Tree Regressor',
                             DecisionTreeRegressor(random_state=123)),
                            ('K Neighbors Regressor',
                             KNeighborsRegressor(n_jobs=-1))],
                n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x2816db4f0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:32:35,938:INFO:Checking exceptions
2023-04-06 17:32:35,938:INFO:Importing libraries
2023-04-06 17:32:35,938:INFO:Copying training dataset
2023-04-06 17:32:35,943:INFO:Defining folds
2023-04-06 17:32:35,943:INFO:Declaring metric variables
2023-04-06 17:32:35,945:INFO:Importing untrained model
2023-04-06 17:32:35,945:INFO:Declaring custom model
2023-04-06 17:32:35,948:INFO:Voting Regressor Imported successfully
2023-04-06 17:32:35,951:INFO:Starting cross validation
2023-04-06 17:32:35,953:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:32:40,202:INFO:Calculating mean and std
2023-04-06 17:32:40,203:INFO:Creating metrics dataframe
2023-04-06 17:32:40,205:INFO:Finalizing model
2023-04-06 17:32:41,093:INFO:Uploading results into container
2023-04-06 17:32:41,093:INFO:Uploading model into container now
2023-04-06 17:32:41,093:INFO:_master_model_container: 32
2023-04-06 17:32:41,093:INFO:_display_container: 11
2023-04-06 17:32:41,094:INFO:VotingRegressor(estimators=[('Decision Tree Regressor',
                             DecisionTreeRegressor(random_state=123)),
                            ('K Neighbors Regressor',
                             KNeighborsRegressor(n_jobs=-1))],
                n_jobs=-1)
2023-04-06 17:32:41,094:INFO:create_model() successfully completed......................................
2023-04-06 17:32:41,959:INFO:SubProcess create_model() end ==================================
2023-04-06 17:32:41,963:INFO:_master_model_container: 32
2023-04-06 17:32:41,963:INFO:_display_container: 11
2023-04-06 17:32:41,964:INFO:VotingRegressor(estimators=[('Decision Tree Regressor',
                             DecisionTreeRegressor(random_state=123)),
                            ('K Neighbors Regressor',
                             KNeighborsRegressor(n_jobs=-1))],
                n_jobs=-1)
2023-04-06 17:32:41,964:INFO:blend_models() successfully completed......................................
2023-04-06 17:33:55,666:INFO:Initializing stack_models()
2023-04-06 17:33:55,669:INFO:stack_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator_list=[DecisionTreeRegressor(random_state=123), KNeighborsRegressor(n_jobs=-1)], meta_model=None, meta_model_fold=5, fold=None, round=4, method=auto, restack=True, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-04-06 17:33:55,669:INFO:Checking exceptions
2023-04-06 17:33:55,680:INFO:Defining meta model
2023-04-06 17:33:55,696:INFO:Getting model names
2023-04-06 17:33:55,696:INFO:[('Decision Tree Regressor', DecisionTreeRegressor(random_state=123)), ('K Neighbors Regressor', KNeighborsRegressor(n_jobs=-1))]
2023-04-06 17:33:55,698:INFO:SubProcess create_model() called ==================================
2023-04-06 17:33:55,700:INFO:Initializing create_model()
2023-04-06 17:33:55,700:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=StackingRegressor(cv=5,
                  estimators=[('Decision Tree Regressor',
                               DecisionTreeRegressor(random_state=123)),
                              ('K Neighbors Regressor',
                               KNeighborsRegressor(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x283dedaf0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:33:55,700:INFO:Checking exceptions
2023-04-06 17:33:55,700:INFO:Importing libraries
2023-04-06 17:33:55,700:INFO:Copying training dataset
2023-04-06 17:33:55,705:INFO:Defining folds
2023-04-06 17:33:55,706:INFO:Declaring metric variables
2023-04-06 17:33:55,708:INFO:Importing untrained model
2023-04-06 17:33:55,708:INFO:Declaring custom model
2023-04-06 17:33:55,711:INFO:Stacking Regressor Imported successfully
2023-04-06 17:33:55,716:INFO:Starting cross validation
2023-04-06 17:33:55,717:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:34:00,118:INFO:Calculating mean and std
2023-04-06 17:34:00,118:INFO:Creating metrics dataframe
2023-04-06 17:34:00,121:INFO:Finalizing model
2023-04-06 17:34:01,037:INFO:Uploading results into container
2023-04-06 17:34:01,038:INFO:Uploading model into container now
2023-04-06 17:34:01,038:INFO:_master_model_container: 33
2023-04-06 17:34:01,038:INFO:_display_container: 12
2023-04-06 17:34:01,039:INFO:StackingRegressor(cv=5,
                  estimators=[('Decision Tree Regressor',
                               DecisionTreeRegressor(random_state=123)),
                              ('K Neighbors Regressor',
                               KNeighborsRegressor(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True)
2023-04-06 17:34:01,039:INFO:create_model() successfully completed......................................
2023-04-06 17:34:01,149:INFO:SubProcess create_model() end ==================================
2023-04-06 17:34:01,153:INFO:_master_model_container: 33
2023-04-06 17:34:01,153:INFO:_display_container: 12
2023-04-06 17:34:01,153:INFO:StackingRegressor(cv=5,
                  estimators=[('Decision Tree Regressor',
                               DecisionTreeRegressor(random_state=123)),
                              ('K Neighbors Regressor',
                               KNeighborsRegressor(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True)
2023-04-06 17:34:01,154:INFO:stack_models() successfully completed......................................
2023-04-06 17:34:30,461:INFO:Initializing stack_models()
2023-04-06 17:34:30,463:INFO:stack_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator_list=[DecisionTreeRegressor(random_state=123), KNeighborsRegressor(n_jobs=-1)], meta_model=DecisionTreeRegressor(random_state=123), meta_model_fold=5, fold=None, round=4, method=auto, restack=True, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-04-06 17:34:30,464:INFO:Checking exceptions
2023-04-06 17:34:30,469:INFO:Defining meta model
2023-04-06 17:34:30,485:INFO:Getting model names
2023-04-06 17:34:30,486:INFO:[('Decision Tree Regressor', DecisionTreeRegressor(random_state=123)), ('K Neighbors Regressor', KNeighborsRegressor(n_jobs=-1))]
2023-04-06 17:34:30,488:INFO:SubProcess create_model() called ==================================
2023-04-06 17:34:30,489:INFO:Initializing create_model()
2023-04-06 17:34:30,489:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=StackingRegressor(cv=5,
                  estimators=[('Decision Tree Regressor',
                               DecisionTreeRegressor(random_state=123)),
                              ('K Neighbors Regressor',
                               KNeighborsRegressor(n_jobs=-1))],
                  final_estimator=DecisionTreeRegressor(random_state=123),
                  n_jobs=-1, passthrough=True), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x283dedaf0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:34:30,489:INFO:Checking exceptions
2023-04-06 17:34:30,489:INFO:Importing libraries
2023-04-06 17:34:30,489:INFO:Copying training dataset
2023-04-06 17:34:30,494:INFO:Defining folds
2023-04-06 17:34:30,495:INFO:Declaring metric variables
2023-04-06 17:34:30,497:INFO:Importing untrained model
2023-04-06 17:34:30,497:INFO:Declaring custom model
2023-04-06 17:34:30,499:INFO:Stacking Regressor Imported successfully
2023-04-06 17:34:30,503:INFO:Starting cross validation
2023-04-06 17:34:30,504:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:34:34,919:INFO:Calculating mean and std
2023-04-06 17:34:34,920:INFO:Creating metrics dataframe
2023-04-06 17:34:34,923:INFO:Finalizing model
2023-04-06 17:34:35,832:INFO:Uploading results into container
2023-04-06 17:34:35,832:INFO:Uploading model into container now
2023-04-06 17:34:35,833:INFO:_master_model_container: 34
2023-04-06 17:34:35,833:INFO:_display_container: 13
2023-04-06 17:34:35,833:INFO:StackingRegressor(cv=5,
                  estimators=[('Decision Tree Regressor',
                               DecisionTreeRegressor(random_state=123)),
                              ('K Neighbors Regressor',
                               KNeighborsRegressor(n_jobs=-1))],
                  final_estimator=DecisionTreeRegressor(random_state=123),
                  n_jobs=-1, passthrough=True)
2023-04-06 17:34:35,834:INFO:create_model() successfully completed......................................
2023-04-06 17:34:35,937:INFO:SubProcess create_model() end ==================================
2023-04-06 17:34:35,940:INFO:_master_model_container: 34
2023-04-06 17:34:35,941:INFO:_display_container: 13
2023-04-06 17:34:35,941:INFO:StackingRegressor(cv=5,
                  estimators=[('Decision Tree Regressor',
                               DecisionTreeRegressor(random_state=123)),
                              ('K Neighbors Regressor',
                               KNeighborsRegressor(n_jobs=-1))],
                  final_estimator=DecisionTreeRegressor(random_state=123),
                  n_jobs=-1, passthrough=True)
2023-04-06 17:34:35,941:INFO:stack_models() successfully completed......................................
2023-04-06 17:35:02,140:INFO:Initializing stack_models()
2023-04-06 17:35:02,142:INFO:stack_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator_list=[DecisionTreeRegressor(random_state=123), KNeighborsRegressor(n_jobs=-1)], meta_model=None, meta_model_fold=5, fold=None, round=4, method=auto, restack=False, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-04-06 17:35:02,143:INFO:Checking exceptions
2023-04-06 17:35:02,147:INFO:Defining meta model
2023-04-06 17:35:02,159:INFO:Getting model names
2023-04-06 17:35:02,160:INFO:[('Decision Tree Regressor', DecisionTreeRegressor(random_state=123)), ('K Neighbors Regressor', KNeighborsRegressor(n_jobs=-1))]
2023-04-06 17:35:02,162:INFO:SubProcess create_model() called ==================================
2023-04-06 17:35:02,163:INFO:Initializing create_model()
2023-04-06 17:35:02,163:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=StackingRegressor(cv=5,
                  estimators=[('Decision Tree Regressor',
                               DecisionTreeRegressor(random_state=123)),
                              ('K Neighbors Regressor',
                               KNeighborsRegressor(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x2979b8880>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:35:02,164:INFO:Checking exceptions
2023-04-06 17:35:02,164:INFO:Importing libraries
2023-04-06 17:35:02,164:INFO:Copying training dataset
2023-04-06 17:35:02,168:INFO:Defining folds
2023-04-06 17:35:02,168:INFO:Declaring metric variables
2023-04-06 17:35:02,170:INFO:Importing untrained model
2023-04-06 17:35:02,170:INFO:Declaring custom model
2023-04-06 17:35:02,172:INFO:Stacking Regressor Imported successfully
2023-04-06 17:35:02,176:INFO:Starting cross validation
2023-04-06 17:35:02,177:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:35:06,634:INFO:Calculating mean and std
2023-04-06 17:35:06,634:INFO:Creating metrics dataframe
2023-04-06 17:35:06,637:INFO:Finalizing model
2023-04-06 17:35:07,536:INFO:Uploading results into container
2023-04-06 17:35:07,537:INFO:Uploading model into container now
2023-04-06 17:35:07,537:INFO:_master_model_container: 35
2023-04-06 17:35:07,537:INFO:_display_container: 14
2023-04-06 17:35:07,538:INFO:StackingRegressor(cv=5,
                  estimators=[('Decision Tree Regressor',
                               DecisionTreeRegressor(random_state=123)),
                              ('K Neighbors Regressor',
                               KNeighborsRegressor(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1)
2023-04-06 17:35:07,538:INFO:create_model() successfully completed......................................
2023-04-06 17:35:07,643:INFO:SubProcess create_model() end ==================================
2023-04-06 17:35:07,647:INFO:_master_model_container: 35
2023-04-06 17:35:07,647:INFO:_display_container: 14
2023-04-06 17:35:07,648:INFO:StackingRegressor(cv=5,
                  estimators=[('Decision Tree Regressor',
                               DecisionTreeRegressor(random_state=123)),
                              ('K Neighbors Regressor',
                               KNeighborsRegressor(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1)
2023-04-06 17:35:07,648:INFO:stack_models() successfully completed......................................
2023-04-06 17:35:36,054:INFO:Initializing predict_model()
2023-04-06 17:35:36,056:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=StackingRegressor(cv=5,
                  estimators=[('Decision Tree Regressor',
                               DecisionTreeRegressor(random_state=123)),
                              ('K Neighbors Regressor',
                               KNeighborsRegressor(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x2b491b940>)
2023-04-06 17:35:36,056:INFO:Checking exceptions
2023-04-06 17:35:36,056:INFO:Preloading libraries
2023-04-06 17:35:50,567:INFO:Initializing finalize_model()
2023-04-06 17:35:50,569:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=StackingRegressor(cv=5,
                  estimators=[('Decision Tree Regressor',
                               DecisionTreeRegressor(random_state=123)),
                              ('K Neighbors Regressor',
                               KNeighborsRegressor(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-04-06 17:35:50,574:INFO:Finalizing StackingRegressor(cv=5,
                  estimators=[('Decision Tree Regressor',
                               DecisionTreeRegressor(random_state=123)),
                              ('K Neighbors Regressor',
                               KNeighborsRegressor(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True)
2023-04-06 17:35:50,580:INFO:Initializing create_model()
2023-04-06 17:35:50,581:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=StackingRegressor(cv=5,
                  estimators=[('Decision Tree Regressor',
                               DecisionTreeRegressor(random_state=123)),
                              ('K Neighbors Regressor',
                               KNeighborsRegressor(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-04-06 17:35:50,581:INFO:Checking exceptions
2023-04-06 17:35:50,582:INFO:Importing libraries
2023-04-06 17:35:50,583:INFO:Copying training dataset
2023-04-06 17:35:50,583:INFO:Defining folds
2023-04-06 17:35:50,583:INFO:Declaring metric variables
2023-04-06 17:35:50,583:INFO:Importing untrained model
2023-04-06 17:35:50,583:INFO:Declaring custom model
2023-04-06 17:35:50,584:INFO:Stacking Regressor Imported successfully
2023-04-06 17:35:50,585:INFO:Cross validation set to False
2023-04-06 17:35:50,585:INFO:Fitting Model
2023-04-06 17:35:51,072:INFO:Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer'...
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 StackingRegressor(cv=5,
                                   estimators=[('Decision Tree Regressor',
                                                DecisionTreeRegressor(random_state=123)),
                                               ('K Neighbors Regressor',
                                                KNeighborsRegressor(n_jobs=-1))],
                                   final_estimator=LinearRegression(n_jobs=-1),
                                   n_jobs=-1, passthrough=True))])
2023-04-06 17:35:51,072:INFO:create_model() successfully completed......................................
2023-04-06 17:35:51,176:INFO:_master_model_container: 35
2023-04-06 17:35:51,176:INFO:_display_container: 15
2023-04-06 17:35:51,189:INFO:Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer'...
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 StackingRegressor(cv=5,
                                   estimators=[('Decision Tree Regressor',
                                                DecisionTreeRegressor(random_state=123)),
                                               ('K Neighbors Regressor',
                                                KNeighborsRegressor(n_jobs=-1))],
                                   final_estimator=LinearRegression(n_jobs=-1),
                                   n_jobs=-1, passthrough=True))])
2023-04-06 17:35:51,189:INFO:finalize_model() successfully completed......................................
2023-04-06 17:36:38,063:INFO:Initializing predict_model()
2023-04-06 17:36:38,063:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer'...
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 StackingRegressor(cv=5,
                                   estimators=[('Decision Tree Regressor',
                                                DecisionTreeRegressor(random_state=123)),
                                               ('K Neighbors Regressor',
                                                KNeighborsRegressor(n_jobs=-1))],
                                   final_estimator=LinearRegression(n_jobs=-1),
                                   n_jobs=-1, passthrough=True))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=0, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x2b491ba60>)
2023-04-06 17:36:38,063:INFO:Checking exceptions
2023-04-06 17:36:38,063:INFO:Preloading libraries
2023-04-06 17:36:38,064:INFO:Set up data.
2023-04-06 17:36:38,068:INFO:Set up index.
2023-04-06 17:39:47,943:INFO:PyCaret RegressionExperiment
2023-04-06 17:39:47,943:INFO:Logging name: reg-default-name
2023-04-06 17:39:47,943:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-06 17:39:47,943:INFO:version 3.0.0
2023-04-06 17:39:47,943:INFO:Initializing setup()
2023-04-06 17:39:47,943:INFO:self.USI: 6603
2023-04-06 17:39:47,943:INFO:self._variable_keys: {'logging_param', 'gpu_param', 'X_train', 'X_test', 'y_train', 'pipeline', '_available_plots', 'exp_id', '_ml_usecase', 'html_param', 'transform_target_param', 'n_jobs_param', 'memory', 'y', 'X', 'exp_name_log', 'gpu_n_jobs_param', 'log_plots_param', 'y_test', 'USI', 'idx', 'seed', 'data', 'fold_groups_param', 'fold_generator', 'fold_shuffle_param', 'target_param'}
2023-04-06 17:39:47,943:INFO:Checking environment
2023-04-06 17:39:47,943:INFO:python_version: 3.9.15
2023-04-06 17:39:47,943:INFO:python_build: ('main', 'Nov 24 2022 08:28:41')
2023-04-06 17:39:47,943:INFO:machine: arm64
2023-04-06 17:39:47,943:INFO:platform: macOS-13.2-arm64-arm-64bit
2023-04-06 17:39:47,943:INFO:Memory: svmem(total=17179869184, available=4056104960, percent=76.4, used=6179979264, free=68419584, active=3999858688, inactive=3984556032, wired=2180120576)
2023-04-06 17:39:47,943:INFO:Physical Core: 10
2023-04-06 17:39:47,943:INFO:Logical Core: 10
2023-04-06 17:39:47,943:INFO:Checking libraries
2023-04-06 17:39:47,943:INFO:System:
2023-04-06 17:39:47,943:INFO:    python: 3.9.15 (main, Nov 24 2022, 08:28:41)  [Clang 14.0.6 ]
2023-04-06 17:39:47,943:INFO:executable: /Users/a06411/opt/anaconda3/bin/python
2023-04-06 17:39:47,943:INFO:   machine: macOS-13.2-arm64-arm-64bit
2023-04-06 17:39:47,943:INFO:PyCaret required dependencies:
2023-04-06 17:39:47,943:INFO:                 pip: 22.3.1
2023-04-06 17:39:47,943:INFO:          setuptools: 65.5.0
2023-04-06 17:39:47,943:INFO:             pycaret: 3.0.0
2023-04-06 17:39:47,943:INFO:             IPython: 8.7.0
2023-04-06 17:39:47,943:INFO:          ipywidgets: 7.6.5
2023-04-06 17:39:47,943:INFO:                tqdm: 4.64.1
2023-04-06 17:39:47,944:INFO:               numpy: 1.21.5
2023-04-06 17:39:47,944:INFO:              pandas: 1.4.4
2023-04-06 17:39:47,944:INFO:              jinja2: 2.11.3
2023-04-06 17:39:47,944:INFO:               scipy: 1.9.3
2023-04-06 17:39:47,944:INFO:              joblib: 1.2.0
2023-04-06 17:39:47,944:INFO:             sklearn: 1.1.3
2023-04-06 17:39:47,944:INFO:                pyod: 1.0.9
2023-04-06 17:39:47,944:INFO:            imblearn: 0.10.1
2023-04-06 17:39:47,944:INFO:   category_encoders: 2.6.0
2023-04-06 17:39:47,944:INFO:            lightgbm: 3.3.5
2023-04-06 17:39:47,944:INFO:               numba: 0.56.4
2023-04-06 17:39:47,944:INFO:            requests: 2.28.1
2023-04-06 17:39:47,944:INFO:          matplotlib: 3.6.2
2023-04-06 17:39:47,944:INFO:          scikitplot: 0.3.7
2023-04-06 17:39:47,944:INFO:         yellowbrick: 1.5
2023-04-06 17:39:47,944:INFO:              plotly: 5.9.0
2023-04-06 17:39:47,944:INFO:             kaleido: 0.2.1
2023-04-06 17:39:47,944:INFO:         statsmodels: 0.13.2
2023-04-06 17:39:47,944:INFO:              sktime: 0.16.1
2023-04-06 17:39:47,944:INFO:               tbats: 1.1.2
2023-04-06 17:39:47,944:INFO:            pmdarima: 2.0.3
2023-04-06 17:39:47,944:INFO:              psutil: 5.9.0
2023-04-06 17:39:47,944:INFO:PyCaret optional dependencies:
2023-04-06 17:39:47,944:INFO:                shap: 0.41.0
2023-04-06 17:39:47,944:INFO:           interpret: Not installed
2023-04-06 17:39:47,944:INFO:                umap: 0.5.3
2023-04-06 17:39:47,944:INFO:    pandas_profiling: 4.1.2
2023-04-06 17:39:47,944:INFO:  explainerdashboard: 0.4.2.1
2023-04-06 17:39:47,944:INFO:             autoviz: Not installed
2023-04-06 17:39:47,944:INFO:           fairlearn: Not installed
2023-04-06 17:39:47,944:INFO:             xgboost: 1.7.2
2023-04-06 17:39:47,944:INFO:            catboost: 1.1.1
2023-04-06 17:39:47,944:INFO:              kmodes: Not installed
2023-04-06 17:39:47,944:INFO:             mlxtend: Not installed
2023-04-06 17:39:47,944:INFO:       statsforecast: Not installed
2023-04-06 17:39:47,944:INFO:        tune_sklearn: Not installed
2023-04-06 17:39:47,944:INFO:                 ray: Not installed
2023-04-06 17:39:47,944:INFO:            hyperopt: 0.2.7
2023-04-06 17:39:47,944:INFO:              optuna: 3.1.0
2023-04-06 17:39:47,944:INFO:               skopt: 0.9.0
2023-04-06 17:39:47,944:INFO:              mlflow: 2.2.2
2023-04-06 17:39:47,944:INFO:              gradio: Not installed
2023-04-06 17:39:47,944:INFO:             fastapi: Not installed
2023-04-06 17:39:47,944:INFO:             uvicorn: Not installed
2023-04-06 17:39:47,944:INFO:              m2cgen: Not installed
2023-04-06 17:39:47,944:INFO:           evidently: Not installed
2023-04-06 17:39:47,944:INFO:               fugue: Not installed
2023-04-06 17:39:47,944:INFO:           streamlit: Not installed
2023-04-06 17:39:47,944:INFO:             prophet: Not installed
2023-04-06 17:39:47,944:INFO:None
2023-04-06 17:39:47,944:INFO:Set up data.
2023-04-06 17:39:47,947:INFO:Set up train/test split.
2023-04-06 17:39:47,949:INFO:Set up index.
2023-04-06 17:39:47,949:INFO:Set up folding strategy.
2023-04-06 17:39:47,949:INFO:Assigning column types.
2023-04-06 17:39:47,950:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-06 17:39:47,995:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:39:47,996:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:39:48,041:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:39:48,042:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:39:48,042:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-06 17:39:48,087:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:39:48,088:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:39:48,136:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:39:48,138:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:39:48,138:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-06 17:39:48,186:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:39:48,187:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:39:48,235:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:39:48,236:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:39:48,236:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-06 17:39:48,283:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:39:48,285:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:39:48,332:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:39:48,333:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:39:48,334:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-06 17:39:48,380:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:39:48,382:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:39:48,428:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:39:48,429:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:39:48,430:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-06 17:39:48,477:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:39:48,478:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:39:48,527:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:39:48,528:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:39:48,528:INFO:Preparing preprocessing pipeline...
2023-04-06 17:39:48,528:INFO:Set up target transformation.
2023-04-06 17:39:48,528:INFO:Set up simple imputation.
2023-04-06 17:39:48,530:INFO:Set up encoding of ordinal features.
2023-04-06 17:39:48,530:INFO:Set up encoding of categorical features.
2023-04-06 17:39:48,530:INFO:Set up removing multicollinearity.
2023-04-06 17:39:48,530:INFO:Set up binning of numerical features.
2023-04-06 17:39:48,530:INFO:Set up column transformation.
2023-04-06 17:39:48,530:INFO:Set up feature normalization.
2023-04-06 17:39:48,531:INFO:Set up column name cleaning.
2023-04-06 17:39:48,630:INFO:Finished creating preprocessing pipeline.
2023-04-06 17:39:48,641:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer'...
                ('bin_numeric_features',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=KBinsDiscretizer(encode='ordinal',
                                                                 strategy='kmeans'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-06 17:39:48,641:INFO:Creating final display dataframe.
2023-04-06 17:39:48,817:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             Price
2                   Target type        Regression
3           Original data shape          (600, 8)
4        Transformed data shape         (600, 27)
5   Transformed train set shape         (420, 27)
6    Transformed test set shape         (180, 27)
7              Ordinal features                 1
8              Numeric features                 1
9          Categorical features                 6
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16     Remove multicollinearity              True
17  Multicollinearity threshold              0.95
18               Transformation              True
19        Transformation method       yeo-johnson
20                    Normalize              True
21             Normalize method            zscore
22             Transform target              True
23      Transform target method       yeo-johnson
24               Fold Generator             KFold
25                  Fold Number                10
26                     CPU Jobs                -1
27                      Use GPU             False
28               Log Experiment             False
29              Experiment Name  reg-default-name
30                          USI              6603
2023-04-06 17:39:48,869:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:39:48,870:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:39:48,916:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:39:48,918:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:39:48,918:INFO:setup() successfully completed in 1.49s...............
2023-04-06 17:41:27,537:INFO:gpu_param set to False
2023-04-06 17:44:46,915:INFO:Initializing save_model()
2023-04-06 17:44:46,915:INFO:save_model(model=Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer'...
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 StackingRegressor(cv=5,
                                   estimators=[('Decision Tree Regressor',
                                                DecisionTreeRegressor(random_state=123)),
                                               ('K Neighbors Regressor',
                                                KNeighborsRegressor(n_jobs=-1))],
                                   final_estimator=LinearRegression(n_jobs=-1),
                                   n_jobs=-1, passthrough=True))]), model_name=Experiment_123 08Feb2020, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer'...
                ('bin_numeric_features',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=KBinsDiscretizer(encode='ordinal',
                                                                 strategy='kmeans'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-04-06 17:44:46,915:INFO:Adding model into prep_pipe
2023-04-06 17:44:46,917:WARNING:Only Model saved as it was a pipeline.
2023-04-06 17:44:46,925:INFO:Experiment_123 08Feb2020.pkl saved in current working directory
2023-04-06 17:44:46,941:INFO:Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer'...
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 StackingRegressor(cv=5,
                                   estimators=[('Decision Tree Regressor',
                                                DecisionTreeRegressor(random_state=123)),
                                               ('K Neighbors Regressor',
                                                KNeighborsRegressor(n_jobs=-1))],
                                   final_estimator=LinearRegression(n_jobs=-1),
                                   n_jobs=-1, passthrough=True))])
2023-04-06 17:44:46,941:INFO:save_model() successfully completed......................................
2023-04-06 17:44:59,837:INFO:PyCaret RegressionExperiment
2023-04-06 17:44:59,837:INFO:Logging name: reg-default-name
2023-04-06 17:44:59,837:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-06 17:44:59,837:INFO:version 3.0.0
2023-04-06 17:44:59,837:INFO:Initializing setup()
2023-04-06 17:44:59,837:INFO:self.USI: 2e64
2023-04-06 17:44:59,837:INFO:self._variable_keys: {'logging_param', 'gpu_param', 'X_train', 'X_test', 'y_train', 'pipeline', '_available_plots', 'exp_id', '_ml_usecase', 'html_param', 'transform_target_param', 'n_jobs_param', 'memory', 'y', 'X', 'exp_name_log', 'gpu_n_jobs_param', 'log_plots_param', 'y_test', 'USI', 'idx', 'seed', 'data', 'fold_groups_param', 'fold_generator', 'fold_shuffle_param', 'target_param'}
2023-04-06 17:44:59,837:INFO:Checking environment
2023-04-06 17:44:59,837:INFO:python_version: 3.9.15
2023-04-06 17:44:59,837:INFO:python_build: ('main', 'Nov 24 2022 08:28:41')
2023-04-06 17:44:59,837:INFO:machine: arm64
2023-04-06 17:44:59,837:INFO:platform: macOS-13.2-arm64-arm-64bit
2023-04-06 17:44:59,837:INFO:Memory: svmem(total=17179869184, available=4911153152, percent=71.4, used=6863699968, free=220528640, active=4707581952, inactive=4584292352, wired=2156118016)
2023-04-06 17:44:59,838:INFO:Physical Core: 10
2023-04-06 17:44:59,838:INFO:Logical Core: 10
2023-04-06 17:44:59,838:INFO:Checking libraries
2023-04-06 17:44:59,838:INFO:System:
2023-04-06 17:44:59,838:INFO:    python: 3.9.15 (main, Nov 24 2022, 08:28:41)  [Clang 14.0.6 ]
2023-04-06 17:44:59,838:INFO:executable: /Users/a06411/opt/anaconda3/bin/python
2023-04-06 17:44:59,838:INFO:   machine: macOS-13.2-arm64-arm-64bit
2023-04-06 17:44:59,838:INFO:PyCaret required dependencies:
2023-04-06 17:44:59,838:INFO:                 pip: 22.3.1
2023-04-06 17:44:59,838:INFO:          setuptools: 65.5.0
2023-04-06 17:44:59,838:INFO:             pycaret: 3.0.0
2023-04-06 17:44:59,838:INFO:             IPython: 8.7.0
2023-04-06 17:44:59,838:INFO:          ipywidgets: 7.6.5
2023-04-06 17:44:59,838:INFO:                tqdm: 4.64.1
2023-04-06 17:44:59,838:INFO:               numpy: 1.21.5
2023-04-06 17:44:59,838:INFO:              pandas: 1.4.4
2023-04-06 17:44:59,838:INFO:              jinja2: 2.11.3
2023-04-06 17:44:59,838:INFO:               scipy: 1.9.3
2023-04-06 17:44:59,838:INFO:              joblib: 1.2.0
2023-04-06 17:44:59,838:INFO:             sklearn: 1.1.3
2023-04-06 17:44:59,838:INFO:                pyod: 1.0.9
2023-04-06 17:44:59,838:INFO:            imblearn: 0.10.1
2023-04-06 17:44:59,838:INFO:   category_encoders: 2.6.0
2023-04-06 17:44:59,838:INFO:            lightgbm: 3.3.5
2023-04-06 17:44:59,838:INFO:               numba: 0.56.4
2023-04-06 17:44:59,838:INFO:            requests: 2.28.1
2023-04-06 17:44:59,838:INFO:          matplotlib: 3.6.2
2023-04-06 17:44:59,838:INFO:          scikitplot: 0.3.7
2023-04-06 17:44:59,838:INFO:         yellowbrick: 1.5
2023-04-06 17:44:59,838:INFO:              plotly: 5.9.0
2023-04-06 17:44:59,838:INFO:             kaleido: 0.2.1
2023-04-06 17:44:59,838:INFO:         statsmodels: 0.13.2
2023-04-06 17:44:59,838:INFO:              sktime: 0.16.1
2023-04-06 17:44:59,838:INFO:               tbats: 1.1.2
2023-04-06 17:44:59,838:INFO:            pmdarima: 2.0.3
2023-04-06 17:44:59,838:INFO:              psutil: 5.9.0
2023-04-06 17:44:59,838:INFO:PyCaret optional dependencies:
2023-04-06 17:44:59,838:INFO:                shap: 0.41.0
2023-04-06 17:44:59,838:INFO:           interpret: Not installed
2023-04-06 17:44:59,838:INFO:                umap: 0.5.3
2023-04-06 17:44:59,838:INFO:    pandas_profiling: 4.1.2
2023-04-06 17:44:59,838:INFO:  explainerdashboard: 0.4.2.1
2023-04-06 17:44:59,838:INFO:             autoviz: Not installed
2023-04-06 17:44:59,838:INFO:           fairlearn: Not installed
2023-04-06 17:44:59,838:INFO:             xgboost: 1.7.2
2023-04-06 17:44:59,838:INFO:            catboost: 1.1.1
2023-04-06 17:44:59,838:INFO:              kmodes: Not installed
2023-04-06 17:44:59,838:INFO:             mlxtend: Not installed
2023-04-06 17:44:59,838:INFO:       statsforecast: Not installed
2023-04-06 17:44:59,838:INFO:        tune_sklearn: Not installed
2023-04-06 17:44:59,838:INFO:                 ray: Not installed
2023-04-06 17:44:59,838:INFO:            hyperopt: 0.2.7
2023-04-06 17:44:59,838:INFO:              optuna: 3.1.0
2023-04-06 17:44:59,838:INFO:               skopt: 0.9.0
2023-04-06 17:44:59,838:INFO:              mlflow: 2.2.2
2023-04-06 17:44:59,838:INFO:              gradio: Not installed
2023-04-06 17:44:59,838:INFO:             fastapi: Not installed
2023-04-06 17:44:59,838:INFO:             uvicorn: Not installed
2023-04-06 17:44:59,838:INFO:              m2cgen: Not installed
2023-04-06 17:44:59,838:INFO:           evidently: Not installed
2023-04-06 17:44:59,838:INFO:               fugue: Not installed
2023-04-06 17:44:59,838:INFO:           streamlit: Not installed
2023-04-06 17:44:59,838:INFO:             prophet: Not installed
2023-04-06 17:44:59,838:INFO:None
2023-04-06 17:44:59,838:INFO:Set up data.
2023-04-06 17:44:59,840:INFO:Set up train/test split.
2023-04-06 17:44:59,842:INFO:Set up index.
2023-04-06 17:44:59,842:INFO:Set up folding strategy.
2023-04-06 17:44:59,842:INFO:Assigning column types.
2023-04-06 17:44:59,843:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-06 17:44:59,888:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:44:59,889:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:44:59,935:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:44:59,936:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:44:59,936:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-06 17:44:59,980:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:44:59,981:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:45:00,026:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:45:00,027:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:45:00,027:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-06 17:45:00,071:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:45:00,072:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:45:00,116:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:45:00,117:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:45:00,118:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-06 17:45:00,161:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:45:00,162:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:45:00,207:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:45:00,208:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:45:00,209:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-06 17:45:00,252:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:45:00,254:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:45:00,297:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:45:00,298:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:45:00,298:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-06 17:45:00,342:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:45:00,345:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:45:00,389:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:45:00,390:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:45:00,391:INFO:Preparing preprocessing pipeline...
2023-04-06 17:45:00,391:INFO:Set up target transformation.
2023-04-06 17:45:00,391:INFO:Set up simple imputation.
2023-04-06 17:45:00,392:INFO:Set up encoding of ordinal features.
2023-04-06 17:45:00,392:INFO:Set up encoding of categorical features.
2023-04-06 17:45:00,392:INFO:Set up removing multicollinearity.
2023-04-06 17:45:00,392:INFO:Set up binning of numerical features.
2023-04-06 17:45:00,393:INFO:Set up column transformation.
2023-04-06 17:45:00,393:INFO:Set up feature normalization.
2023-04-06 17:45:00,393:INFO:Set up column name cleaning.
2023-04-06 17:45:00,483:INFO:Finished creating preprocessing pipeline.
2023-04-06 17:45:00,494:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer'...
                ('bin_numeric_features',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=KBinsDiscretizer(encode='ordinal',
                                                                 strategy='kmeans'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-06 17:45:00,494:INFO:Creating final display dataframe.
2023-04-06 17:45:00,645:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             Price
2                   Target type        Regression
3           Original data shape          (600, 8)
4        Transformed data shape         (600, 27)
5   Transformed train set shape         (420, 27)
6    Transformed test set shape         (180, 27)
7              Ordinal features                 1
8              Numeric features                 1
9          Categorical features                 6
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16     Remove multicollinearity              True
17  Multicollinearity threshold              0.95
18               Transformation              True
19        Transformation method       yeo-johnson
20                    Normalize              True
21             Normalize method            zscore
22             Transform target              True
23      Transform target method       yeo-johnson
24               Fold Generator             KFold
25                  Fold Number                10
26                     CPU Jobs                -1
27                      Use GPU             False
28               Log Experiment             False
29              Experiment Name  reg-default-name
30                          USI              2e64
2023-04-06 17:45:00,695:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:45:00,696:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:45:00,742:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:45:00,743:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:45:00,744:INFO:setup() successfully completed in 1.26s...............
2023-04-06 17:45:12,940:INFO:gpu_param set to False
