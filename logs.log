2023-04-06 16:33:58,368:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-06 16:33:58,369:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-06 16:33:58,369:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-06 16:33:58,369:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-06 16:33:59,004:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-06 16:34:07,810:INFO:PyCaret RegressionExperiment
2023-04-06 16:34:07,810:INFO:Logging name: reg-default-name
2023-04-06 16:34:07,810:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-06 16:34:07,810:INFO:version 3.0.0
2023-04-06 16:34:07,810:INFO:Initializing setup()
2023-04-06 16:34:07,810:INFO:self.USI: f987
2023-04-06 16:34:07,810:INFO:self._variable_keys: {'pipeline', 'y_test', 'memory', 'y', 'X', 'target_param', 'gpu_n_jobs_param', 'X_train', 'fold_shuffle_param', 'fold_generator', 'exp_id', 'X_test', '_available_plots', 'n_jobs_param', 'seed', 'fold_groups_param', 'data', 'exp_name_log', 'html_param', 'idx', 'logging_param', '_ml_usecase', 'USI', 'log_plots_param', 'y_train', 'gpu_param', 'transform_target_param'}
2023-04-06 16:34:07,810:INFO:Checking environment
2023-04-06 16:34:07,810:INFO:python_version: 3.9.15
2023-04-06 16:34:07,810:INFO:python_build: ('main', 'Nov 24 2022 08:28:41')
2023-04-06 16:34:07,810:INFO:machine: arm64
2023-04-06 16:34:07,810:INFO:platform: macOS-13.2-arm64-arm-64bit
2023-04-06 16:34:07,810:INFO:Memory: svmem(total=17179869184, available=5218369536, percent=69.6, used=7342784512, free=103514112, active=5127684096, inactive=5085642752, wired=2215100416)
2023-04-06 16:34:07,810:INFO:Physical Core: 10
2023-04-06 16:34:07,810:INFO:Logical Core: 10
2023-04-06 16:34:07,810:INFO:Checking libraries
2023-04-06 16:34:07,810:INFO:System:
2023-04-06 16:34:07,810:INFO:    python: 3.9.15 (main, Nov 24 2022, 08:28:41)  [Clang 14.0.6 ]
2023-04-06 16:34:07,810:INFO:executable: /Users/a06411/opt/anaconda3/bin/python
2023-04-06 16:34:07,810:INFO:   machine: macOS-13.2-arm64-arm-64bit
2023-04-06 16:34:07,810:INFO:PyCaret required dependencies:
2023-04-06 16:34:07,811:INFO:                 pip: 22.3.1
2023-04-06 16:34:07,811:INFO:          setuptools: 65.5.0
2023-04-06 16:34:07,811:INFO:             pycaret: 3.0.0
2023-04-06 16:34:07,811:INFO:             IPython: 8.7.0
2023-04-06 16:34:07,811:INFO:          ipywidgets: 7.6.5
2023-04-06 16:34:07,811:INFO:                tqdm: 4.64.1
2023-04-06 16:34:07,811:INFO:               numpy: 1.21.5
2023-04-06 16:34:07,811:INFO:              pandas: 1.4.4
2023-04-06 16:34:07,811:INFO:              jinja2: 2.11.3
2023-04-06 16:34:07,811:INFO:               scipy: 1.9.3
2023-04-06 16:34:07,811:INFO:              joblib: 1.1.1
2023-04-06 16:34:07,811:INFO:             sklearn: 1.1.3
2023-04-06 16:34:07,811:INFO:                pyod: 1.0.9
2023-04-06 16:34:07,811:INFO:            imblearn: 0.10.1
2023-04-06 16:34:07,811:INFO:   category_encoders: 2.6.0
2023-04-06 16:34:07,811:INFO:            lightgbm: 3.3.5
2023-04-06 16:34:07,811:INFO:               numba: 0.56.4
2023-04-06 16:34:07,811:INFO:            requests: 2.28.1
2023-04-06 16:34:07,811:INFO:          matplotlib: 3.6.2
2023-04-06 16:34:07,811:INFO:          scikitplot: 0.3.7
2023-04-06 16:34:07,811:INFO:         yellowbrick: 1.5
2023-04-06 16:34:07,811:INFO:              plotly: 5.9.0
2023-04-06 16:34:07,811:INFO:             kaleido: Not installed
2023-04-06 16:34:07,811:INFO:         statsmodels: 0.13.2
2023-04-06 16:34:07,811:INFO:              sktime: 0.16.1
2023-04-06 16:34:07,811:INFO:               tbats: Not installed
2023-04-06 16:34:07,811:INFO:            pmdarima: 2.0.3
2023-04-06 16:34:07,811:INFO:              psutil: 5.9.0
2023-04-06 16:34:07,811:INFO:PyCaret optional dependencies:
2023-04-06 16:34:07,813:INFO:                shap: 0.41.0
2023-04-06 16:34:07,813:INFO:           interpret: Not installed
2023-04-06 16:34:07,813:INFO:                umap: 0.5.3
2023-04-06 16:34:07,813:INFO:    pandas_profiling: Not installed
2023-04-06 16:34:07,813:INFO:  explainerdashboard: 0.4.2.1
2023-04-06 16:34:07,813:INFO:             autoviz: Not installed
2023-04-06 16:34:07,813:INFO:           fairlearn: Not installed
2023-04-06 16:34:07,813:INFO:             xgboost: 1.7.2
2023-04-06 16:34:07,813:INFO:            catboost: 1.1.1
2023-04-06 16:34:07,813:INFO:              kmodes: Not installed
2023-04-06 16:34:07,813:INFO:             mlxtend: Not installed
2023-04-06 16:34:07,813:INFO:       statsforecast: Not installed
2023-04-06 16:34:07,813:INFO:        tune_sklearn: Not installed
2023-04-06 16:34:07,813:INFO:                 ray: Not installed
2023-04-06 16:34:07,813:INFO:            hyperopt: 0.2.7
2023-04-06 16:34:07,813:INFO:              optuna: 3.1.0
2023-04-06 16:34:07,813:INFO:               skopt: 0.9.0
2023-04-06 16:34:07,813:INFO:              mlflow: 2.2.2
2023-04-06 16:34:07,813:INFO:              gradio: Not installed
2023-04-06 16:34:07,813:INFO:             fastapi: Not installed
2023-04-06 16:34:07,813:INFO:             uvicorn: Not installed
2023-04-06 16:34:07,813:INFO:              m2cgen: Not installed
2023-04-06 16:34:07,813:INFO:           evidently: Not installed
2023-04-06 16:34:07,813:INFO:               fugue: Not installed
2023-04-06 16:34:07,813:INFO:           streamlit: Not installed
2023-04-06 16:34:07,813:INFO:             prophet: Not installed
2023-04-06 16:34:07,813:INFO:None
2023-04-06 16:34:07,813:INFO:Set up data.
2023-04-06 16:34:07,817:INFO:Set up train/test split.
2023-04-06 16:34:07,819:INFO:Set up index.
2023-04-06 16:34:07,819:INFO:Set up folding strategy.
2023-04-06 16:34:07,819:INFO:Assigning column types.
2023-04-06 16:34:07,820:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-06 16:34:07,820:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-06 16:34:07,822:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-06 16:34:07,823:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 16:34:07,847:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:34:07,865:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 16:34:07,865:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:34:08,005:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:34:08,041:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,043:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,045:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,069:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,087:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,088:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:34:08,089:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:34:08,089:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-06 16:34:08,091:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,093:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,117:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,136:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,136:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:34:08,137:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:34:08,139:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,141:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,165:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,184:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,184:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:34:08,186:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:34:08,186:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-06 16:34:08,190:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,213:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,233:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,233:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:34:08,234:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:34:08,238:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,262:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,280:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,281:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:34:08,282:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:34:08,282:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-06 16:34:08,310:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,329:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,329:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:34:08,330:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:34:08,358:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,377:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,377:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:34:08,378:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:34:08,378:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-06 16:34:08,406:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,424:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:34:08,425:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:34:08,454:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,472:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:34:08,473:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:34:08,473:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-06 16:34:08,520:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:34:08,521:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:34:08,571:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:34:08,572:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:34:08,574:INFO:Preparing preprocessing pipeline...
2023-04-06 16:34:08,574:INFO:Set up simple imputation.
2023-04-06 16:34:08,576:INFO:Set up encoding of ordinal features.
2023-04-06 16:34:08,577:INFO:Set up encoding of categorical features.
2023-04-06 16:34:08,577:INFO:Set up column name cleaning.
2023-04-06 16:34:08,640:INFO:Finished creating preprocessing pipeline.
2023-04-06 16:34:08,649:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry', 'Report'],
                                    transformer=SimpleImputer(strategy='most_frequent')...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': AGSL    0
GIA     1
NaN    -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry'],
                                    transformer=OneHotEncoder(cols=['Cut',
                                                                    'Color',
                                                                    'Clarity',
                                                                    'Polish',
                                                                    'Symmetry'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-06 16:34:08,649:INFO:Creating final display dataframe.
2023-04-06 16:34:08,775:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             Price
2                   Target type        Regression
3           Original data shape         (5400, 8)
4        Transformed data shape        (5400, 29)
5   Transformed train set shape        (3779, 29)
6    Transformed test set shape        (1621, 29)
7              Ordinal features                 1
8              Numeric features                 1
9          Categorical features                 6
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              f987
2023-04-06 16:34:08,826:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:34:08,827:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:34:08,874:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:34:08,875:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:34:08,876:INFO:setup() successfully completed in 1.55s...............
2023-04-06 16:36:45,372:INFO:Initializing compare_models()
2023-04-06 16:36:45,375:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-06 16:36:45,375:INFO:Checking exceptions
2023-04-06 16:36:45,379:INFO:Preparing display monitor
2023-04-06 16:36:45,414:INFO:Initializing Linear Regression
2023-04-06 16:36:45,414:INFO:Total runtime is 3.850460052490234e-06 minutes
2023-04-06 16:36:45,416:INFO:SubProcess create_model() called ==================================
2023-04-06 16:36:45,416:INFO:Initializing create_model()
2023-04-06 16:36:45,416:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:36:45,416:INFO:Checking exceptions
2023-04-06 16:36:45,417:INFO:Importing libraries
2023-04-06 16:36:45,417:INFO:Copying training dataset
2023-04-06 16:36:45,421:INFO:Defining folds
2023-04-06 16:36:45,421:INFO:Declaring metric variables
2023-04-06 16:36:45,423:INFO:Importing untrained model
2023-04-06 16:36:45,424:INFO:Linear Regression Imported successfully
2023-04-06 16:36:45,428:INFO:Starting cross validation
2023-04-06 16:36:45,434:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:36:51,843:INFO:Calculating mean and std
2023-04-06 16:36:51,844:INFO:Creating metrics dataframe
2023-04-06 16:36:52,239:INFO:Uploading results into container
2023-04-06 16:36:52,240:INFO:Uploading model into container now
2023-04-06 16:36:52,241:INFO:_master_model_container: 1
2023-04-06 16:36:52,241:INFO:_display_container: 2
2023-04-06 16:36:52,241:INFO:LinearRegression(n_jobs=-1)
2023-04-06 16:36:52,241:INFO:create_model() successfully completed......................................
2023-04-06 16:36:52,358:INFO:SubProcess create_model() end ==================================
2023-04-06 16:36:52,358:INFO:Creating metrics dataframe
2023-04-06 16:36:52,361:INFO:Initializing Lasso Regression
2023-04-06 16:36:52,361:INFO:Total runtime is 0.11578671932220459 minutes
2023-04-06 16:36:52,363:INFO:SubProcess create_model() called ==================================
2023-04-06 16:36:52,363:INFO:Initializing create_model()
2023-04-06 16:36:52,363:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:36:52,363:INFO:Checking exceptions
2023-04-06 16:36:52,363:INFO:Importing libraries
2023-04-06 16:36:52,363:INFO:Copying training dataset
2023-04-06 16:36:52,366:INFO:Defining folds
2023-04-06 16:36:52,366:INFO:Declaring metric variables
2023-04-06 16:36:52,367:INFO:Importing untrained model
2023-04-06 16:36:52,370:INFO:Lasso Regression Imported successfully
2023-04-06 16:36:52,373:INFO:Starting cross validation
2023-04-06 16:36:52,374:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:36:56,238:INFO:Calculating mean and std
2023-04-06 16:36:56,238:INFO:Creating metrics dataframe
2023-04-06 16:36:56,606:INFO:Uploading results into container
2023-04-06 16:36:56,606:INFO:Uploading model into container now
2023-04-06 16:36:56,606:INFO:_master_model_container: 2
2023-04-06 16:36:56,606:INFO:_display_container: 2
2023-04-06 16:36:56,607:INFO:Lasso(random_state=123)
2023-04-06 16:36:56,607:INFO:create_model() successfully completed......................................
2023-04-06 16:36:56,681:INFO:SubProcess create_model() end ==================================
2023-04-06 16:36:56,681:INFO:Creating metrics dataframe
2023-04-06 16:36:56,685:INFO:Initializing Ridge Regression
2023-04-06 16:36:56,686:INFO:Total runtime is 0.18785916566848754 minutes
2023-04-06 16:36:56,687:INFO:SubProcess create_model() called ==================================
2023-04-06 16:36:56,687:INFO:Initializing create_model()
2023-04-06 16:36:56,687:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:36:56,687:INFO:Checking exceptions
2023-04-06 16:36:56,687:INFO:Importing libraries
2023-04-06 16:36:56,687:INFO:Copying training dataset
2023-04-06 16:36:56,690:INFO:Defining folds
2023-04-06 16:36:56,690:INFO:Declaring metric variables
2023-04-06 16:36:56,691:INFO:Importing untrained model
2023-04-06 16:36:56,692:INFO:Ridge Regression Imported successfully
2023-04-06 16:36:56,695:INFO:Starting cross validation
2023-04-06 16:36:56,695:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:37:00,409:INFO:Calculating mean and std
2023-04-06 16:37:00,410:INFO:Creating metrics dataframe
2023-04-06 16:37:00,767:INFO:Uploading results into container
2023-04-06 16:37:00,768:INFO:Uploading model into container now
2023-04-06 16:37:00,768:INFO:_master_model_container: 3
2023-04-06 16:37:00,768:INFO:_display_container: 2
2023-04-06 16:37:00,768:INFO:Ridge(random_state=123)
2023-04-06 16:37:00,768:INFO:create_model() successfully completed......................................
2023-04-06 16:37:00,842:INFO:SubProcess create_model() end ==================================
2023-04-06 16:37:00,842:INFO:Creating metrics dataframe
2023-04-06 16:37:00,846:INFO:Initializing Elastic Net
2023-04-06 16:37:00,846:INFO:Total runtime is 0.25719326734542847 minutes
2023-04-06 16:37:00,847:INFO:SubProcess create_model() called ==================================
2023-04-06 16:37:00,847:INFO:Initializing create_model()
2023-04-06 16:37:00,847:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:37:00,847:INFO:Checking exceptions
2023-04-06 16:37:00,847:INFO:Importing libraries
2023-04-06 16:37:00,847:INFO:Copying training dataset
2023-04-06 16:37:00,850:INFO:Defining folds
2023-04-06 16:37:00,850:INFO:Declaring metric variables
2023-04-06 16:37:00,851:INFO:Importing untrained model
2023-04-06 16:37:00,852:INFO:Elastic Net Imported successfully
2023-04-06 16:37:00,855:INFO:Starting cross validation
2023-04-06 16:37:00,856:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:37:04,709:INFO:Calculating mean and std
2023-04-06 16:37:04,710:INFO:Creating metrics dataframe
2023-04-06 16:37:05,085:INFO:Uploading results into container
2023-04-06 16:37:05,086:INFO:Uploading model into container now
2023-04-06 16:37:05,086:INFO:_master_model_container: 4
2023-04-06 16:37:05,086:INFO:_display_container: 2
2023-04-06 16:37:05,086:INFO:ElasticNet(random_state=123)
2023-04-06 16:37:05,086:INFO:create_model() successfully completed......................................
2023-04-06 16:37:05,159:INFO:SubProcess create_model() end ==================================
2023-04-06 16:37:05,159:INFO:Creating metrics dataframe
2023-04-06 16:37:05,163:INFO:Initializing Least Angle Regression
2023-04-06 16:37:05,163:INFO:Total runtime is 0.3291534185409546 minutes
2023-04-06 16:37:05,165:INFO:SubProcess create_model() called ==================================
2023-04-06 16:37:05,165:INFO:Initializing create_model()
2023-04-06 16:37:05,165:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:37:05,165:INFO:Checking exceptions
2023-04-06 16:37:05,165:INFO:Importing libraries
2023-04-06 16:37:05,165:INFO:Copying training dataset
2023-04-06 16:37:05,167:INFO:Defining folds
2023-04-06 16:37:05,167:INFO:Declaring metric variables
2023-04-06 16:37:05,169:INFO:Importing untrained model
2023-04-06 16:37:05,170:INFO:Least Angle Regression Imported successfully
2023-04-06 16:37:05,173:INFO:Starting cross validation
2023-04-06 16:37:05,174:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:37:05,272:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:05,278:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:05,280:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:05,286:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:05,289:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:05,289:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=6.036e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 16:37:05,290:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=4.789e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 16:37:05,290:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.582e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 16:37:05,290:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.117e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 16:37:05,290:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.036e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 16:37:05,290:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:05,310:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:05,321:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:05,322:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:05,346:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:09,006:INFO:Calculating mean and std
2023-04-06 16:37:09,007:INFO:Creating metrics dataframe
2023-04-06 16:37:09,398:INFO:Uploading results into container
2023-04-06 16:37:09,399:INFO:Uploading model into container now
2023-04-06 16:37:09,399:INFO:_master_model_container: 5
2023-04-06 16:37:09,400:INFO:_display_container: 2
2023-04-06 16:37:09,400:INFO:Lars(random_state=123)
2023-04-06 16:37:09,400:INFO:create_model() successfully completed......................................
2023-04-06 16:37:09,485:INFO:SubProcess create_model() end ==================================
2023-04-06 16:37:09,485:INFO:Creating metrics dataframe
2023-04-06 16:37:09,490:INFO:Initializing Lasso Least Angle Regression
2023-04-06 16:37:09,490:INFO:Total runtime is 0.4012604514757792 minutes
2023-04-06 16:37:09,491:INFO:SubProcess create_model() called ==================================
2023-04-06 16:37:09,492:INFO:Initializing create_model()
2023-04-06 16:37:09,492:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:37:09,492:INFO:Checking exceptions
2023-04-06 16:37:09,492:INFO:Importing libraries
2023-04-06 16:37:09,492:INFO:Copying training dataset
2023-04-06 16:37:09,494:INFO:Defining folds
2023-04-06 16:37:09,494:INFO:Declaring metric variables
2023-04-06 16:37:09,496:INFO:Importing untrained model
2023-04-06 16:37:09,497:INFO:Lasso Least Angle Regression Imported successfully
2023-04-06 16:37:09,500:INFO:Starting cross validation
2023-04-06 16:37:09,501:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:37:09,584:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:37:09,584:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:37:09,596:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:37:09,606:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:37:09,612:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:37:09,626:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:37:09,630:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:37:09,643:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:37:09,663:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:37:09,672:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:37:13,209:INFO:Calculating mean and std
2023-04-06 16:37:13,209:INFO:Creating metrics dataframe
2023-04-06 16:37:13,584:INFO:Uploading results into container
2023-04-06 16:37:13,584:INFO:Uploading model into container now
2023-04-06 16:37:13,584:INFO:_master_model_container: 6
2023-04-06 16:37:13,584:INFO:_display_container: 2
2023-04-06 16:37:13,584:INFO:LassoLars(random_state=123)
2023-04-06 16:37:13,585:INFO:create_model() successfully completed......................................
2023-04-06 16:37:13,658:INFO:SubProcess create_model() end ==================================
2023-04-06 16:37:13,658:INFO:Creating metrics dataframe
2023-04-06 16:37:13,662:INFO:Initializing Orthogonal Matching Pursuit
2023-04-06 16:37:13,662:INFO:Total runtime is 0.4707941969235738 minutes
2023-04-06 16:37:13,663:INFO:SubProcess create_model() called ==================================
2023-04-06 16:37:13,663:INFO:Initializing create_model()
2023-04-06 16:37:13,663:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:37:13,663:INFO:Checking exceptions
2023-04-06 16:37:13,663:INFO:Importing libraries
2023-04-06 16:37:13,663:INFO:Copying training dataset
2023-04-06 16:37:13,665:INFO:Defining folds
2023-04-06 16:37:13,665:INFO:Declaring metric variables
2023-04-06 16:37:13,667:INFO:Importing untrained model
2023-04-06 16:37:13,668:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-06 16:37:13,670:INFO:Starting cross validation
2023-04-06 16:37:13,671:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:37:13,746:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:13,758:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:13,761:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:13,771:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:13,771:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:13,774:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:13,777:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:13,783:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:13,791:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:13,804:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:17,359:INFO:Calculating mean and std
2023-04-06 16:37:17,360:INFO:Creating metrics dataframe
2023-04-06 16:37:17,743:INFO:Uploading results into container
2023-04-06 16:37:17,744:INFO:Uploading model into container now
2023-04-06 16:37:17,744:INFO:_master_model_container: 7
2023-04-06 16:37:17,744:INFO:_display_container: 2
2023-04-06 16:37:17,744:INFO:OrthogonalMatchingPursuit()
2023-04-06 16:37:17,744:INFO:create_model() successfully completed......................................
2023-04-06 16:37:17,818:INFO:SubProcess create_model() end ==================================
2023-04-06 16:37:17,818:INFO:Creating metrics dataframe
2023-04-06 16:37:17,823:INFO:Initializing Bayesian Ridge
2023-04-06 16:37:17,823:INFO:Total runtime is 0.5401495019594829 minutes
2023-04-06 16:37:17,824:INFO:SubProcess create_model() called ==================================
2023-04-06 16:37:17,825:INFO:Initializing create_model()
2023-04-06 16:37:17,825:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:37:17,825:INFO:Checking exceptions
2023-04-06 16:37:17,825:INFO:Importing libraries
2023-04-06 16:37:17,825:INFO:Copying training dataset
2023-04-06 16:37:17,827:INFO:Defining folds
2023-04-06 16:37:17,827:INFO:Declaring metric variables
2023-04-06 16:37:17,829:INFO:Importing untrained model
2023-04-06 16:37:17,830:INFO:Bayesian Ridge Imported successfully
2023-04-06 16:37:17,832:INFO:Starting cross validation
2023-04-06 16:37:17,833:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:37:21,526:INFO:Calculating mean and std
2023-04-06 16:37:21,527:INFO:Creating metrics dataframe
2023-04-06 16:37:21,914:INFO:Uploading results into container
2023-04-06 16:37:21,915:INFO:Uploading model into container now
2023-04-06 16:37:21,915:INFO:_master_model_container: 8
2023-04-06 16:37:21,915:INFO:_display_container: 2
2023-04-06 16:37:21,915:INFO:BayesianRidge()
2023-04-06 16:37:21,915:INFO:create_model() successfully completed......................................
2023-04-06 16:37:21,993:INFO:SubProcess create_model() end ==================================
2023-04-06 16:37:21,993:INFO:Creating metrics dataframe
2023-04-06 16:37:21,997:INFO:Initializing Passive Aggressive Regressor
2023-04-06 16:37:21,998:INFO:Total runtime is 0.6097239176432292 minutes
2023-04-06 16:37:21,999:INFO:SubProcess create_model() called ==================================
2023-04-06 16:37:22,000:INFO:Initializing create_model()
2023-04-06 16:37:22,000:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:37:22,000:INFO:Checking exceptions
2023-04-06 16:37:22,000:INFO:Importing libraries
2023-04-06 16:37:22,000:INFO:Copying training dataset
2023-04-06 16:37:22,002:INFO:Defining folds
2023-04-06 16:37:22,002:INFO:Declaring metric variables
2023-04-06 16:37:22,004:INFO:Importing untrained model
2023-04-06 16:37:22,005:INFO:Passive Aggressive Regressor Imported successfully
2023-04-06 16:37:22,008:INFO:Starting cross validation
2023-04-06 16:37:22,008:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:37:25,776:INFO:Calculating mean and std
2023-04-06 16:37:25,777:INFO:Creating metrics dataframe
2023-04-06 16:37:26,166:INFO:Uploading results into container
2023-04-06 16:37:26,167:INFO:Uploading model into container now
2023-04-06 16:37:26,167:INFO:_master_model_container: 9
2023-04-06 16:37:26,167:INFO:_display_container: 2
2023-04-06 16:37:26,167:INFO:PassiveAggressiveRegressor(random_state=123)
2023-04-06 16:37:26,167:INFO:create_model() successfully completed......................................
2023-04-06 16:37:26,239:INFO:SubProcess create_model() end ==================================
2023-04-06 16:37:26,239:INFO:Creating metrics dataframe
2023-04-06 16:37:26,244:INFO:Initializing Huber Regressor
2023-04-06 16:37:26,244:INFO:Total runtime is 0.6804990967114767 minutes
2023-04-06 16:37:26,245:INFO:SubProcess create_model() called ==================================
2023-04-06 16:37:26,245:INFO:Initializing create_model()
2023-04-06 16:37:26,245:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:37:26,245:INFO:Checking exceptions
2023-04-06 16:37:26,246:INFO:Importing libraries
2023-04-06 16:37:26,246:INFO:Copying training dataset
2023-04-06 16:37:26,248:INFO:Defining folds
2023-04-06 16:37:26,248:INFO:Declaring metric variables
2023-04-06 16:37:26,249:INFO:Importing untrained model
2023-04-06 16:37:26,250:INFO:Huber Regressor Imported successfully
2023-04-06 16:37:26,253:INFO:Starting cross validation
2023-04-06 16:37:26,254:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:37:26,400:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 16:37:26,404:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 16:37:26,405:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 16:37:26,405:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 16:37:26,412:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 16:37:26,412:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 16:37:26,454:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 16:37:26,464:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 16:37:30,008:INFO:Calculating mean and std
2023-04-06 16:37:30,009:INFO:Creating metrics dataframe
2023-04-06 16:37:30,392:INFO:Uploading results into container
2023-04-06 16:37:30,392:INFO:Uploading model into container now
2023-04-06 16:37:30,392:INFO:_master_model_container: 10
2023-04-06 16:37:30,393:INFO:_display_container: 2
2023-04-06 16:37:30,393:INFO:HuberRegressor()
2023-04-06 16:37:30,393:INFO:create_model() successfully completed......................................
2023-04-06 16:37:30,470:INFO:SubProcess create_model() end ==================================
2023-04-06 16:37:30,470:INFO:Creating metrics dataframe
2023-04-06 16:37:30,476:INFO:Initializing K Neighbors Regressor
2023-04-06 16:37:30,476:INFO:Total runtime is 0.7510249654452006 minutes
2023-04-06 16:37:30,477:INFO:SubProcess create_model() called ==================================
2023-04-06 16:37:30,477:INFO:Initializing create_model()
2023-04-06 16:37:30,477:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:37:30,477:INFO:Checking exceptions
2023-04-06 16:37:30,477:INFO:Importing libraries
2023-04-06 16:37:30,477:INFO:Copying training dataset
2023-04-06 16:37:30,480:INFO:Defining folds
2023-04-06 16:37:30,480:INFO:Declaring metric variables
2023-04-06 16:37:30,481:INFO:Importing untrained model
2023-04-06 16:37:30,483:INFO:K Neighbors Regressor Imported successfully
2023-04-06 16:37:30,485:INFO:Starting cross validation
2023-04-06 16:37:30,486:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:37:34,293:INFO:Calculating mean and std
2023-04-06 16:37:34,294:INFO:Creating metrics dataframe
2023-04-06 16:37:34,661:INFO:Uploading results into container
2023-04-06 16:37:34,662:INFO:Uploading model into container now
2023-04-06 16:37:34,662:INFO:_master_model_container: 11
2023-04-06 16:37:34,662:INFO:_display_container: 2
2023-04-06 16:37:34,662:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-06 16:37:34,662:INFO:create_model() successfully completed......................................
2023-04-06 16:37:34,738:INFO:SubProcess create_model() end ==================================
2023-04-06 16:37:34,738:INFO:Creating metrics dataframe
2023-04-06 16:37:34,743:INFO:Initializing Decision Tree Regressor
2023-04-06 16:37:34,743:INFO:Total runtime is 0.8221426645914713 minutes
2023-04-06 16:37:34,744:INFO:SubProcess create_model() called ==================================
2023-04-06 16:37:34,744:INFO:Initializing create_model()
2023-04-06 16:37:34,744:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:37:34,744:INFO:Checking exceptions
2023-04-06 16:37:34,744:INFO:Importing libraries
2023-04-06 16:37:34,744:INFO:Copying training dataset
2023-04-06 16:37:34,747:INFO:Defining folds
2023-04-06 16:37:34,747:INFO:Declaring metric variables
2023-04-06 16:37:34,748:INFO:Importing untrained model
2023-04-06 16:37:34,754:INFO:Decision Tree Regressor Imported successfully
2023-04-06 16:37:34,758:INFO:Starting cross validation
2023-04-06 16:37:34,759:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:37:38,646:INFO:Calculating mean and std
2023-04-06 16:37:38,646:INFO:Creating metrics dataframe
2023-04-06 16:37:39,030:INFO:Uploading results into container
2023-04-06 16:37:39,030:INFO:Uploading model into container now
2023-04-06 16:37:39,031:INFO:_master_model_container: 12
2023-04-06 16:37:39,031:INFO:_display_container: 2
2023-04-06 16:37:39,031:INFO:DecisionTreeRegressor(random_state=123)
2023-04-06 16:37:39,031:INFO:create_model() successfully completed......................................
2023-04-06 16:37:39,106:INFO:SubProcess create_model() end ==================================
2023-04-06 16:37:39,106:INFO:Creating metrics dataframe
2023-04-06 16:37:39,111:INFO:Initializing Random Forest Regressor
2023-04-06 16:37:39,112:INFO:Total runtime is 0.8949593504269917 minutes
2023-04-06 16:37:39,113:INFO:SubProcess create_model() called ==================================
2023-04-06 16:37:39,113:INFO:Initializing create_model()
2023-04-06 16:37:39,114:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:37:39,114:INFO:Checking exceptions
2023-04-06 16:37:39,114:INFO:Importing libraries
2023-04-06 16:37:39,114:INFO:Copying training dataset
2023-04-06 16:37:39,116:INFO:Defining folds
2023-04-06 16:37:39,116:INFO:Declaring metric variables
2023-04-06 16:37:39,117:INFO:Importing untrained model
2023-04-06 16:37:39,119:INFO:Random Forest Regressor Imported successfully
2023-04-06 16:37:39,121:INFO:Starting cross validation
2023-04-06 16:37:39,122:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:37:43,756:INFO:Calculating mean and std
2023-04-06 16:37:43,757:INFO:Creating metrics dataframe
2023-04-06 16:37:44,138:INFO:Uploading results into container
2023-04-06 16:37:44,139:INFO:Uploading model into container now
2023-04-06 16:37:44,139:INFO:_master_model_container: 13
2023-04-06 16:37:44,139:INFO:_display_container: 2
2023-04-06 16:37:44,139:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-04-06 16:37:44,139:INFO:create_model() successfully completed......................................
2023-04-06 16:37:44,212:INFO:SubProcess create_model() end ==================================
2023-04-06 16:37:44,212:INFO:Creating metrics dataframe
2023-04-06 16:37:44,216:INFO:Initializing Extra Trees Regressor
2023-04-06 16:37:44,216:INFO:Total runtime is 0.980039616425832 minutes
2023-04-06 16:37:44,218:INFO:SubProcess create_model() called ==================================
2023-04-06 16:37:44,218:INFO:Initializing create_model()
2023-04-06 16:37:44,218:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:37:44,218:INFO:Checking exceptions
2023-04-06 16:37:44,218:INFO:Importing libraries
2023-04-06 16:37:44,218:INFO:Copying training dataset
2023-04-06 16:37:44,220:INFO:Defining folds
2023-04-06 16:37:44,220:INFO:Declaring metric variables
2023-04-06 16:37:44,221:INFO:Importing untrained model
2023-04-06 16:37:44,223:INFO:Extra Trees Regressor Imported successfully
2023-04-06 16:37:44,225:INFO:Starting cross validation
2023-04-06 16:37:44,226:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:37:49,133:INFO:Calculating mean and std
2023-04-06 16:37:49,134:INFO:Creating metrics dataframe
2023-04-06 16:37:49,520:INFO:Uploading results into container
2023-04-06 16:37:49,520:INFO:Uploading model into container now
2023-04-06 16:37:49,520:INFO:_master_model_container: 14
2023-04-06 16:37:49,520:INFO:_display_container: 2
2023-04-06 16:37:49,521:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-04-06 16:37:49,521:INFO:create_model() successfully completed......................................
2023-04-06 16:37:49,599:INFO:SubProcess create_model() end ==================================
2023-04-06 16:37:49,599:INFO:Creating metrics dataframe
2023-04-06 16:37:49,603:INFO:Initializing AdaBoost Regressor
2023-04-06 16:37:49,603:INFO:Total runtime is 1.0698230822881063 minutes
2023-04-06 16:37:49,605:INFO:SubProcess create_model() called ==================================
2023-04-06 16:37:49,605:INFO:Initializing create_model()
2023-04-06 16:37:49,605:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:37:49,605:INFO:Checking exceptions
2023-04-06 16:37:49,605:INFO:Importing libraries
2023-04-06 16:37:49,605:INFO:Copying training dataset
2023-04-06 16:37:49,608:INFO:Defining folds
2023-04-06 16:37:49,608:INFO:Declaring metric variables
2023-04-06 16:37:49,609:INFO:Importing untrained model
2023-04-06 16:37:49,611:INFO:AdaBoost Regressor Imported successfully
2023-04-06 16:37:49,613:INFO:Starting cross validation
2023-04-06 16:37:49,614:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:37:53,697:INFO:Calculating mean and std
2023-04-06 16:37:53,699:INFO:Creating metrics dataframe
2023-04-06 16:37:54,108:INFO:Uploading results into container
2023-04-06 16:37:54,109:INFO:Uploading model into container now
2023-04-06 16:37:54,110:INFO:_master_model_container: 15
2023-04-06 16:37:54,110:INFO:_display_container: 2
2023-04-06 16:37:54,110:INFO:AdaBoostRegressor(random_state=123)
2023-04-06 16:37:54,110:INFO:create_model() successfully completed......................................
2023-04-06 16:37:54,187:INFO:SubProcess create_model() end ==================================
2023-04-06 16:37:54,187:INFO:Creating metrics dataframe
2023-04-06 16:37:54,192:INFO:Initializing Gradient Boosting Regressor
2023-04-06 16:37:54,193:INFO:Total runtime is 1.1463085333506267 minutes
2023-04-06 16:37:54,194:INFO:SubProcess create_model() called ==================================
2023-04-06 16:37:54,194:INFO:Initializing create_model()
2023-04-06 16:37:54,194:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:37:54,194:INFO:Checking exceptions
2023-04-06 16:37:54,194:INFO:Importing libraries
2023-04-06 16:37:54,194:INFO:Copying training dataset
2023-04-06 16:37:54,197:INFO:Defining folds
2023-04-06 16:37:54,197:INFO:Declaring metric variables
2023-04-06 16:37:54,200:INFO:Importing untrained model
2023-04-06 16:37:54,202:INFO:Gradient Boosting Regressor Imported successfully
2023-04-06 16:37:54,206:INFO:Starting cross validation
2023-04-06 16:37:54,207:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:37:58,167:INFO:Calculating mean and std
2023-04-06 16:37:58,168:INFO:Creating metrics dataframe
2023-04-06 16:37:58,573:INFO:Uploading results into container
2023-04-06 16:37:58,574:INFO:Uploading model into container now
2023-04-06 16:37:58,574:INFO:_master_model_container: 16
2023-04-06 16:37:58,574:INFO:_display_container: 2
2023-04-06 16:37:58,575:INFO:GradientBoostingRegressor(random_state=123)
2023-04-06 16:37:58,575:INFO:create_model() successfully completed......................................
2023-04-06 16:37:58,652:INFO:SubProcess create_model() end ==================================
2023-04-06 16:37:58,652:INFO:Creating metrics dataframe
2023-04-06 16:37:58,657:INFO:Initializing Extreme Gradient Boosting
2023-04-06 16:37:58,657:INFO:Total runtime is 1.2207218170166017 minutes
2023-04-06 16:37:58,659:INFO:SubProcess create_model() called ==================================
2023-04-06 16:37:58,659:INFO:Initializing create_model()
2023-04-06 16:37:58,659:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:37:58,659:INFO:Checking exceptions
2023-04-06 16:37:58,659:INFO:Importing libraries
2023-04-06 16:37:58,660:INFO:Copying training dataset
2023-04-06 16:37:58,662:INFO:Defining folds
2023-04-06 16:37:58,662:INFO:Declaring metric variables
2023-04-06 16:37:58,663:INFO:Importing untrained model
2023-04-06 16:37:58,665:INFO:Extreme Gradient Boosting Imported successfully
2023-04-06 16:37:58,668:INFO:Starting cross validation
2023-04-06 16:37:58,669:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:38:03,010:INFO:Calculating mean and std
2023-04-06 16:38:03,011:INFO:Creating metrics dataframe
2023-04-06 16:38:03,399:INFO:Uploading results into container
2023-04-06 16:38:03,399:INFO:Uploading model into container now
2023-04-06 16:38:03,399:INFO:_master_model_container: 17
2023-04-06 16:38:03,399:INFO:_display_container: 2
2023-04-06 16:38:03,400:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=123, ...)
2023-04-06 16:38:03,400:INFO:create_model() successfully completed......................................
2023-04-06 16:38:03,479:INFO:SubProcess create_model() end ==================================
2023-04-06 16:38:03,479:INFO:Creating metrics dataframe
2023-04-06 16:38:03,485:INFO:Initializing Light Gradient Boosting Machine
2023-04-06 16:38:03,486:INFO:Total runtime is 1.301191798845927 minutes
2023-04-06 16:38:03,487:INFO:SubProcess create_model() called ==================================
2023-04-06 16:38:03,487:INFO:Initializing create_model()
2023-04-06 16:38:03,487:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:38:03,488:INFO:Checking exceptions
2023-04-06 16:38:03,488:INFO:Importing libraries
2023-04-06 16:38:03,488:INFO:Copying training dataset
2023-04-06 16:38:03,490:INFO:Defining folds
2023-04-06 16:38:03,490:INFO:Declaring metric variables
2023-04-06 16:38:03,492:INFO:Importing untrained model
2023-04-06 16:38:03,494:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-06 16:38:03,498:INFO:Starting cross validation
2023-04-06 16:38:03,499:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:38:08,047:INFO:Calculating mean and std
2023-04-06 16:38:08,049:INFO:Creating metrics dataframe
2023-04-06 16:38:08,427:INFO:Uploading results into container
2023-04-06 16:38:08,428:INFO:Uploading model into container now
2023-04-06 16:38:08,428:INFO:_master_model_container: 18
2023-04-06 16:38:08,428:INFO:_display_container: 2
2023-04-06 16:38:08,429:INFO:LGBMRegressor(random_state=123)
2023-04-06 16:38:08,429:INFO:create_model() successfully completed......................................
2023-04-06 16:38:08,501:INFO:SubProcess create_model() end ==================================
2023-04-06 16:38:08,502:INFO:Creating metrics dataframe
2023-04-06 16:38:08,507:INFO:Initializing CatBoost Regressor
2023-04-06 16:38:08,507:INFO:Total runtime is 1.3848868648211161 minutes
2023-04-06 16:38:08,509:INFO:SubProcess create_model() called ==================================
2023-04-06 16:38:08,509:INFO:Initializing create_model()
2023-04-06 16:38:08,509:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:38:08,509:INFO:Checking exceptions
2023-04-06 16:38:08,509:INFO:Importing libraries
2023-04-06 16:38:08,509:INFO:Copying training dataset
2023-04-06 16:38:08,511:INFO:Defining folds
2023-04-06 16:38:08,511:INFO:Declaring metric variables
2023-04-06 16:38:08,512:INFO:Importing untrained model
2023-04-06 16:38:08,515:INFO:CatBoost Regressor Imported successfully
2023-04-06 16:38:08,518:INFO:Starting cross validation
2023-04-06 16:38:08,518:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:38:13,900:INFO:Calculating mean and std
2023-04-06 16:38:13,900:INFO:Creating metrics dataframe
2023-04-06 16:38:14,292:INFO:Uploading results into container
2023-04-06 16:38:14,293:INFO:Uploading model into container now
2023-04-06 16:38:14,294:INFO:_master_model_container: 19
2023-04-06 16:38:14,294:INFO:_display_container: 2
2023-04-06 16:38:14,294:INFO:<catboost.core.CatBoostRegressor object at 0x177019f40>
2023-04-06 16:38:14,294:INFO:create_model() successfully completed......................................
2023-04-06 16:38:14,368:INFO:SubProcess create_model() end ==================================
2023-04-06 16:38:14,368:INFO:Creating metrics dataframe
2023-04-06 16:38:14,373:INFO:Initializing Dummy Regressor
2023-04-06 16:38:14,373:INFO:Total runtime is 1.4826469699541727 minutes
2023-04-06 16:38:14,374:INFO:SubProcess create_model() called ==================================
2023-04-06 16:38:14,374:INFO:Initializing create_model()
2023-04-06 16:38:14,374:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:38:14,374:INFO:Checking exceptions
2023-04-06 16:38:14,374:INFO:Importing libraries
2023-04-06 16:38:14,374:INFO:Copying training dataset
2023-04-06 16:38:14,377:INFO:Defining folds
2023-04-06 16:38:14,377:INFO:Declaring metric variables
2023-04-06 16:38:14,378:INFO:Importing untrained model
2023-04-06 16:38:14,379:INFO:Dummy Regressor Imported successfully
2023-04-06 16:38:14,381:INFO:Starting cross validation
2023-04-06 16:38:14,382:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:38:18,250:INFO:Calculating mean and std
2023-04-06 16:38:18,251:INFO:Creating metrics dataframe
2023-04-06 16:38:18,643:INFO:Uploading results into container
2023-04-06 16:38:18,644:INFO:Uploading model into container now
2023-04-06 16:38:18,644:INFO:_master_model_container: 20
2023-04-06 16:38:18,645:INFO:_display_container: 2
2023-04-06 16:38:18,645:INFO:DummyRegressor()
2023-04-06 16:38:18,645:INFO:create_model() successfully completed......................................
2023-04-06 16:38:18,721:INFO:SubProcess create_model() end ==================================
2023-04-06 16:38:18,721:INFO:Creating metrics dataframe
2023-04-06 16:38:18,731:INFO:Initializing create_model()
2023-04-06 16:38:18,732:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=<catboost.core.CatBoostRegressor object at 0x177019f40>, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:38:18,732:INFO:Checking exceptions
2023-04-06 16:38:18,733:INFO:Importing libraries
2023-04-06 16:38:18,733:INFO:Copying training dataset
2023-04-06 16:38:18,738:INFO:Defining folds
2023-04-06 16:38:18,738:INFO:Declaring metric variables
2023-04-06 16:38:18,739:INFO:Importing untrained model
2023-04-06 16:38:18,739:INFO:Declaring custom model
2023-04-06 16:38:18,739:INFO:CatBoost Regressor Imported successfully
2023-04-06 16:38:18,744:INFO:Cross validation set to False
2023-04-06 16:38:18,744:INFO:Fitting Model
2023-04-06 16:38:20,121:INFO:<catboost.core.CatBoostRegressor object at 0x176baee20>
2023-04-06 16:38:20,121:INFO:create_model() successfully completed......................................
2023-04-06 16:38:20,210:INFO:_master_model_container: 20
2023-04-06 16:38:20,210:INFO:_display_container: 2
2023-04-06 16:38:20,210:INFO:<catboost.core.CatBoostRegressor object at 0x176baee20>
2023-04-06 16:38:20,210:INFO:compare_models() successfully completed......................................
2023-04-06 16:38:58,855:INFO:Initializing create_model()
2023-04-06 16:38:58,856:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=ada, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:38:58,856:INFO:Checking exceptions
2023-04-06 16:38:58,878:INFO:Importing libraries
2023-04-06 16:38:58,878:INFO:Copying training dataset
2023-04-06 16:38:58,883:INFO:Defining folds
2023-04-06 16:38:58,883:INFO:Declaring metric variables
2023-04-06 16:38:58,885:INFO:Importing untrained model
2023-04-06 16:38:58,886:INFO:AdaBoost Regressor Imported successfully
2023-04-06 16:38:58,890:INFO:Starting cross validation
2023-04-06 16:38:58,891:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:39:02,604:INFO:Calculating mean and std
2023-04-06 16:39:02,604:INFO:Creating metrics dataframe
2023-04-06 16:39:02,607:INFO:Finalizing model
2023-04-06 16:39:03,196:INFO:Uploading results into container
2023-04-06 16:39:03,197:INFO:Uploading model into container now
2023-04-06 16:39:03,200:INFO:_master_model_container: 21
2023-04-06 16:39:03,200:INFO:_display_container: 3
2023-04-06 16:39:03,200:INFO:AdaBoostRegressor(random_state=123)
2023-04-06 16:39:03,200:INFO:create_model() successfully completed......................................
2023-04-06 16:39:03,285:INFO:Initializing create_model()
2023-04-06 16:39:03,286:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:39:03,286:INFO:Checking exceptions
2023-04-06 16:39:03,293:INFO:Importing libraries
2023-04-06 16:39:03,293:INFO:Copying training dataset
2023-04-06 16:39:03,297:INFO:Defining folds
2023-04-06 16:39:03,297:INFO:Declaring metric variables
2023-04-06 16:39:03,298:INFO:Importing untrained model
2023-04-06 16:39:03,299:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-06 16:39:03,302:INFO:Starting cross validation
2023-04-06 16:39:03,303:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:39:07,055:INFO:Calculating mean and std
2023-04-06 16:39:07,056:INFO:Creating metrics dataframe
2023-04-06 16:39:07,058:INFO:Finalizing model
2023-04-06 16:39:07,526:INFO:Uploading results into container
2023-04-06 16:39:07,527:INFO:Uploading model into container now
2023-04-06 16:39:07,530:INFO:_master_model_container: 22
2023-04-06 16:39:07,530:INFO:_display_container: 4
2023-04-06 16:39:07,530:INFO:LGBMRegressor(random_state=123)
2023-04-06 16:39:07,530:INFO:create_model() successfully completed......................................
2023-04-06 16:39:07,608:INFO:Initializing create_model()
2023-04-06 16:39:07,608:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:39:07,608:INFO:Checking exceptions
2023-04-06 16:39:07,615:INFO:Importing libraries
2023-04-06 16:39:07,615:INFO:Copying training dataset
2023-04-06 16:39:07,619:INFO:Defining folds
2023-04-06 16:39:07,620:INFO:Declaring metric variables
2023-04-06 16:39:07,621:INFO:Importing untrained model
2023-04-06 16:39:07,623:INFO:Decision Tree Regressor Imported successfully
2023-04-06 16:39:07,626:INFO:Starting cross validation
2023-04-06 16:39:07,627:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:39:11,458:INFO:Calculating mean and std
2023-04-06 16:39:11,460:INFO:Creating metrics dataframe
2023-04-06 16:39:11,462:INFO:Finalizing model
2023-04-06 16:39:11,926:INFO:Uploading results into container
2023-04-06 16:39:11,926:INFO:Uploading model into container now
2023-04-06 16:39:11,931:INFO:_master_model_container: 23
2023-04-06 16:39:11,931:INFO:_display_container: 5
2023-04-06 16:39:11,931:INFO:DecisionTreeRegressor(random_state=123)
2023-04-06 16:39:11,931:INFO:create_model() successfully completed......................................
2023-04-06 16:39:12,012:INFO:Initializing tune_model()
2023-04-06 16:39:12,012:INFO:tune_model(estimator=ada, fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>)
2023-04-06 16:39:12,012:INFO:Checking exceptions
2023-04-06 16:40:21,117:INFO:Initializing tune_model()
2023-04-06 16:40:21,118:INFO:tune_model(estimator=lightgbm, fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>)
2023-04-06 16:40:21,119:INFO:Checking exceptions
2023-04-06 16:40:28,849:INFO:Initializing tune_model()
2023-04-06 16:40:28,850:INFO:tune_model(estimator=dt, fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>)
2023-04-06 16:40:28,850:INFO:Checking exceptions
2023-04-06 16:43:27,395:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-06 16:43:27,396:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-06 16:43:27,396:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-06 16:43:27,396:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-06 16:43:27,990:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-06 16:43:28,617:INFO:PyCaret RegressionExperiment
2023-04-06 16:43:28,617:INFO:Logging name: reg-default-name
2023-04-06 16:43:28,617:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-06 16:43:28,617:INFO:version 3.0.0
2023-04-06 16:43:28,617:INFO:Initializing setup()
2023-04-06 16:43:28,617:INFO:self.USI: a2b4
2023-04-06 16:43:28,617:INFO:self._variable_keys: {'X_test', 'USI', 'fold_groups_param', 'X_train', 'transform_target_param', 'n_jobs_param', 'y_test', 'exp_name_log', 'y_train', 'exp_id', '_available_plots', 'idx', 'logging_param', 'fold_generator', 'target_param', 'data', 'log_plots_param', 'gpu_n_jobs_param', 'seed', 'pipeline', 'X', '_ml_usecase', 'html_param', 'gpu_param', 'fold_shuffle_param', 'y', 'memory'}
2023-04-06 16:43:28,617:INFO:Checking environment
2023-04-06 16:43:28,617:INFO:python_version: 3.9.15
2023-04-06 16:43:28,617:INFO:python_build: ('main', 'Nov 24 2022 08:28:41')
2023-04-06 16:43:28,617:INFO:machine: arm64
2023-04-06 16:43:28,617:INFO:platform: macOS-13.2-arm64-arm-64bit
2023-04-06 16:43:28,617:INFO:Memory: svmem(total=17179869184, available=4853432320, percent=71.7, used=6362988544, free=803487744, active=4054876160, inactive=3897278464, wired=2308112384)
2023-04-06 16:43:28,617:INFO:Physical Core: 10
2023-04-06 16:43:28,617:INFO:Logical Core: 10
2023-04-06 16:43:28,617:INFO:Checking libraries
2023-04-06 16:43:28,617:INFO:System:
2023-04-06 16:43:28,617:INFO:    python: 3.9.15 (main, Nov 24 2022, 08:28:41)  [Clang 14.0.6 ]
2023-04-06 16:43:28,617:INFO:executable: /Users/a06411/opt/anaconda3/bin/python
2023-04-06 16:43:28,617:INFO:   machine: macOS-13.2-arm64-arm-64bit
2023-04-06 16:43:28,617:INFO:PyCaret required dependencies:
2023-04-06 16:43:28,617:INFO:                 pip: 22.3.1
2023-04-06 16:43:28,617:INFO:          setuptools: 65.5.0
2023-04-06 16:43:28,617:INFO:             pycaret: 3.0.0
2023-04-06 16:43:28,617:INFO:             IPython: 8.7.0
2023-04-06 16:43:28,617:INFO:          ipywidgets: 7.6.5
2023-04-06 16:43:28,617:INFO:                tqdm: 4.64.1
2023-04-06 16:43:28,617:INFO:               numpy: 1.21.5
2023-04-06 16:43:28,617:INFO:              pandas: 1.4.4
2023-04-06 16:43:28,617:INFO:              jinja2: 2.11.3
2023-04-06 16:43:28,617:INFO:               scipy: 1.9.3
2023-04-06 16:43:28,617:INFO:              joblib: 1.2.0
2023-04-06 16:43:28,617:INFO:             sklearn: 1.1.3
2023-04-06 16:43:28,617:INFO:                pyod: 1.0.9
2023-04-06 16:43:28,617:INFO:            imblearn: 0.10.1
2023-04-06 16:43:28,617:INFO:   category_encoders: 2.6.0
2023-04-06 16:43:28,617:INFO:            lightgbm: 3.3.5
2023-04-06 16:43:28,617:INFO:               numba: 0.56.4
2023-04-06 16:43:28,617:INFO:            requests: 2.28.1
2023-04-06 16:43:28,617:INFO:          matplotlib: 3.6.2
2023-04-06 16:43:28,617:INFO:          scikitplot: 0.3.7
2023-04-06 16:43:28,617:INFO:         yellowbrick: 1.5
2023-04-06 16:43:28,617:INFO:              plotly: 5.9.0
2023-04-06 16:43:28,617:INFO:             kaleido: 0.2.1
2023-04-06 16:43:28,617:INFO:         statsmodels: 0.13.2
2023-04-06 16:43:28,617:INFO:              sktime: 0.16.1
2023-04-06 16:43:28,617:INFO:               tbats: 1.1.2
2023-04-06 16:43:28,617:INFO:            pmdarima: 2.0.3
2023-04-06 16:43:28,617:INFO:              psutil: 5.9.0
2023-04-06 16:43:28,617:INFO:PyCaret optional dependencies:
2023-04-06 16:43:28,622:INFO:                shap: 0.41.0
2023-04-06 16:43:28,622:INFO:           interpret: Not installed
2023-04-06 16:43:28,622:INFO:                umap: 0.5.3
2023-04-06 16:43:28,622:INFO:    pandas_profiling: Not installed
2023-04-06 16:43:28,622:INFO:  explainerdashboard: 0.4.2.1
2023-04-06 16:43:28,622:INFO:             autoviz: Not installed
2023-04-06 16:43:28,622:INFO:           fairlearn: Not installed
2023-04-06 16:43:28,622:INFO:             xgboost: 1.7.2
2023-04-06 16:43:28,622:INFO:            catboost: 1.1.1
2023-04-06 16:43:28,622:INFO:              kmodes: Not installed
2023-04-06 16:43:28,622:INFO:             mlxtend: Not installed
2023-04-06 16:43:28,622:INFO:       statsforecast: Not installed
2023-04-06 16:43:28,622:INFO:        tune_sklearn: Not installed
2023-04-06 16:43:28,622:INFO:                 ray: Not installed
2023-04-06 16:43:28,622:INFO:            hyperopt: 0.2.7
2023-04-06 16:43:28,622:INFO:              optuna: 3.1.0
2023-04-06 16:43:28,622:INFO:               skopt: 0.9.0
2023-04-06 16:43:28,622:INFO:              mlflow: 2.2.2
2023-04-06 16:43:28,622:INFO:              gradio: Not installed
2023-04-06 16:43:28,622:INFO:             fastapi: Not installed
2023-04-06 16:43:28,622:INFO:             uvicorn: Not installed
2023-04-06 16:43:28,622:INFO:              m2cgen: Not installed
2023-04-06 16:43:28,622:INFO:           evidently: Not installed
2023-04-06 16:43:28,622:INFO:               fugue: Not installed
2023-04-06 16:43:28,622:INFO:           streamlit: Not installed
2023-04-06 16:43:28,622:INFO:             prophet: Not installed
2023-04-06 16:43:28,622:INFO:None
2023-04-06 16:43:28,622:INFO:Set up data.
2023-04-06 16:43:28,626:INFO:Set up train/test split.
2023-04-06 16:43:28,627:INFO:Set up index.
2023-04-06 16:43:28,627:INFO:Set up folding strategy.
2023-04-06 16:43:28,627:INFO:Assigning column types.
2023-04-06 16:43:28,628:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-06 16:43:28,629:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,630:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,632:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,655:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,673:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,673:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:43:28,806:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:43:28,818:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,820:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,822:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,846:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,864:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,864:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:43:28,865:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:43:28,866:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-06 16:43:28,867:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,869:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,893:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,911:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,911:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:43:28,912:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:43:28,914:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,916:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,939:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,956:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,957:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:43:28,958:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:43:28,958:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-06 16:43:28,961:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,984:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:43:29,002:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 16:43:29,002:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:43:29,003:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:43:29,007:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 16:43:29,030:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:43:29,048:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 16:43:29,048:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:43:29,049:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:43:29,050:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-06 16:43:29,078:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:43:29,096:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 16:43:29,096:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:43:29,097:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:43:29,123:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:43:29,142:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 16:43:29,142:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:43:29,143:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:43:29,143:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-06 16:43:29,170:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:43:29,188:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:43:29,189:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:43:29,215:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:43:29,233:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:43:29,234:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:43:29,235:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-06 16:43:29,279:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:43:29,280:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:43:29,325:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:43:29,326:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:43:29,328:INFO:Preparing preprocessing pipeline...
2023-04-06 16:43:29,328:INFO:Set up simple imputation.
2023-04-06 16:43:29,330:INFO:Set up encoding of ordinal features.
2023-04-06 16:43:29,330:INFO:Set up encoding of categorical features.
2023-04-06 16:43:29,331:INFO:Set up column name cleaning.
2023-04-06 16:43:29,389:INFO:Finished creating preprocessing pipeline.
2023-04-06 16:43:29,400:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry', 'Report'],
                                    transformer=SimpleImputer(strategy='most_frequent')...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': AGSL    0
GIA     1
NaN    -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry'],
                                    transformer=OneHotEncoder(cols=['Cut',
                                                                    'Color',
                                                                    'Clarity',
                                                                    'Polish',
                                                                    'Symmetry'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-06 16:43:29,400:INFO:Creating final display dataframe.
2023-04-06 16:43:29,533:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             Price
2                   Target type        Regression
3           Original data shape         (5400, 8)
4        Transformed data shape        (5400, 29)
5   Transformed train set shape        (3779, 29)
6    Transformed test set shape        (1621, 29)
7              Ordinal features                 1
8              Numeric features                 1
9          Categorical features                 6
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              a2b4
2023-04-06 16:43:29,583:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:43:29,584:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:43:29,630:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:43:29,631:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:43:29,631:INFO:setup() successfully completed in 1.46s...............
2023-04-06 16:43:29,634:INFO:Initializing compare_models()
2023-04-06 16:43:29,634:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-06 16:43:29,634:INFO:Checking exceptions
2023-04-06 16:43:29,635:INFO:Preparing display monitor
2023-04-06 16:43:29,659:INFO:Initializing Linear Regression
2023-04-06 16:43:29,659:INFO:Total runtime is 3.417332967122396e-06 minutes
2023-04-06 16:43:29,661:INFO:SubProcess create_model() called ==================================
2023-04-06 16:43:29,662:INFO:Initializing create_model()
2023-04-06 16:43:29,662:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:43:29,662:INFO:Checking exceptions
2023-04-06 16:43:29,662:INFO:Importing libraries
2023-04-06 16:43:29,662:INFO:Copying training dataset
2023-04-06 16:43:29,666:INFO:Defining folds
2023-04-06 16:43:29,666:INFO:Declaring metric variables
2023-04-06 16:43:29,667:INFO:Importing untrained model
2023-04-06 16:43:29,669:INFO:Linear Regression Imported successfully
2023-04-06 16:43:29,672:INFO:Starting cross validation
2023-04-06 16:43:29,677:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:43:35,991:INFO:Calculating mean and std
2023-04-06 16:43:35,992:INFO:Creating metrics dataframe
2023-04-06 16:43:36,373:INFO:Uploading results into container
2023-04-06 16:43:36,374:INFO:Uploading model into container now
2023-04-06 16:43:36,374:INFO:_master_model_container: 1
2023-04-06 16:43:36,374:INFO:_display_container: 2
2023-04-06 16:43:36,374:INFO:LinearRegression(n_jobs=-1)
2023-04-06 16:43:36,375:INFO:create_model() successfully completed......................................
2023-04-06 16:43:36,442:INFO:SubProcess create_model() end ==================================
2023-04-06 16:43:36,442:INFO:Creating metrics dataframe
2023-04-06 16:43:36,445:INFO:Initializing Lasso Regression
2023-04-06 16:43:36,445:INFO:Total runtime is 0.11309589942296346 minutes
2023-04-06 16:43:36,446:INFO:SubProcess create_model() called ==================================
2023-04-06 16:43:36,447:INFO:Initializing create_model()
2023-04-06 16:43:36,447:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:43:36,447:INFO:Checking exceptions
2023-04-06 16:43:36,447:INFO:Importing libraries
2023-04-06 16:43:36,447:INFO:Copying training dataset
2023-04-06 16:43:36,449:INFO:Defining folds
2023-04-06 16:43:36,449:INFO:Declaring metric variables
2023-04-06 16:43:36,450:INFO:Importing untrained model
2023-04-06 16:43:36,451:INFO:Lasso Regression Imported successfully
2023-04-06 16:43:36,454:INFO:Starting cross validation
2023-04-06 16:43:36,455:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:43:40,174:INFO:Calculating mean and std
2023-04-06 16:43:40,174:INFO:Creating metrics dataframe
2023-04-06 16:43:40,565:INFO:Uploading results into container
2023-04-06 16:43:40,566:INFO:Uploading model into container now
2023-04-06 16:43:40,566:INFO:_master_model_container: 2
2023-04-06 16:43:40,566:INFO:_display_container: 2
2023-04-06 16:43:40,566:INFO:Lasso(random_state=123)
2023-04-06 16:43:40,566:INFO:create_model() successfully completed......................................
2023-04-06 16:43:40,621:INFO:SubProcess create_model() end ==================================
2023-04-06 16:43:40,621:INFO:Creating metrics dataframe
2023-04-06 16:43:40,624:INFO:Initializing Ridge Regression
2023-04-06 16:43:40,624:INFO:Total runtime is 0.18275176684061686 minutes
2023-04-06 16:43:40,626:INFO:SubProcess create_model() called ==================================
2023-04-06 16:43:40,626:INFO:Initializing create_model()
2023-04-06 16:43:40,626:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:43:40,626:INFO:Checking exceptions
2023-04-06 16:43:40,626:INFO:Importing libraries
2023-04-06 16:43:40,626:INFO:Copying training dataset
2023-04-06 16:43:40,628:INFO:Defining folds
2023-04-06 16:43:40,628:INFO:Declaring metric variables
2023-04-06 16:43:40,629:INFO:Importing untrained model
2023-04-06 16:43:40,630:INFO:Ridge Regression Imported successfully
2023-04-06 16:43:40,632:INFO:Starting cross validation
2023-04-06 16:43:40,633:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:43:44,334:INFO:Calculating mean and std
2023-04-06 16:43:44,335:INFO:Creating metrics dataframe
2023-04-06 16:43:44,720:INFO:Uploading results into container
2023-04-06 16:43:44,720:INFO:Uploading model into container now
2023-04-06 16:43:44,721:INFO:_master_model_container: 3
2023-04-06 16:43:44,721:INFO:_display_container: 2
2023-04-06 16:43:44,721:INFO:Ridge(random_state=123)
2023-04-06 16:43:44,721:INFO:create_model() successfully completed......................................
2023-04-06 16:43:44,777:INFO:SubProcess create_model() end ==================================
2023-04-06 16:43:44,777:INFO:Creating metrics dataframe
2023-04-06 16:43:44,781:INFO:Initializing Elastic Net
2023-04-06 16:43:44,781:INFO:Total runtime is 0.25202696720759077 minutes
2023-04-06 16:43:44,782:INFO:SubProcess create_model() called ==================================
2023-04-06 16:43:44,782:INFO:Initializing create_model()
2023-04-06 16:43:44,782:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:43:44,782:INFO:Checking exceptions
2023-04-06 16:43:44,782:INFO:Importing libraries
2023-04-06 16:43:44,782:INFO:Copying training dataset
2023-04-06 16:43:44,784:INFO:Defining folds
2023-04-06 16:43:44,784:INFO:Declaring metric variables
2023-04-06 16:43:44,785:INFO:Importing untrained model
2023-04-06 16:43:44,787:INFO:Elastic Net Imported successfully
2023-04-06 16:43:44,789:INFO:Starting cross validation
2023-04-06 16:43:44,790:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:43:48,617:INFO:Calculating mean and std
2023-04-06 16:43:48,618:INFO:Creating metrics dataframe
2023-04-06 16:43:48,988:INFO:Uploading results into container
2023-04-06 16:43:48,989:INFO:Uploading model into container now
2023-04-06 16:43:48,989:INFO:_master_model_container: 4
2023-04-06 16:43:48,989:INFO:_display_container: 2
2023-04-06 16:43:48,989:INFO:ElasticNet(random_state=123)
2023-04-06 16:43:48,989:INFO:create_model() successfully completed......................................
2023-04-06 16:43:49,046:INFO:SubProcess create_model() end ==================================
2023-04-06 16:43:49,046:INFO:Creating metrics dataframe
2023-04-06 16:43:49,050:INFO:Initializing Least Angle Regression
2023-04-06 16:43:49,050:INFO:Total runtime is 0.32318618297576907 minutes
2023-04-06 16:43:49,052:INFO:SubProcess create_model() called ==================================
2023-04-06 16:43:49,052:INFO:Initializing create_model()
2023-04-06 16:43:49,052:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:43:49,052:INFO:Checking exceptions
2023-04-06 16:43:49,052:INFO:Importing libraries
2023-04-06 16:43:49,052:INFO:Copying training dataset
2023-04-06 16:43:49,054:INFO:Defining folds
2023-04-06 16:43:49,054:INFO:Declaring metric variables
2023-04-06 16:43:49,055:INFO:Importing untrained model
2023-04-06 16:43:49,057:INFO:Least Angle Regression Imported successfully
2023-04-06 16:43:49,060:INFO:Starting cross validation
2023-04-06 16:43:49,061:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:43:49,144:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:49,149:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:49,157:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:49,162:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:49,173:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:49,175:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:49,176:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=6.036e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 16:43:49,176:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=4.789e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 16:43:49,176:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.582e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 16:43:49,176:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.117e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 16:43:49,176:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.036e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 16:43:49,180:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:49,194:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:49,207:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:49,231:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:52,873:INFO:Calculating mean and std
2023-04-06 16:43:52,874:INFO:Creating metrics dataframe
2023-04-06 16:43:53,278:INFO:Uploading results into container
2023-04-06 16:43:53,278:INFO:Uploading model into container now
2023-04-06 16:43:53,278:INFO:_master_model_container: 5
2023-04-06 16:43:53,278:INFO:_display_container: 2
2023-04-06 16:43:53,279:INFO:Lars(random_state=123)
2023-04-06 16:43:53,279:INFO:create_model() successfully completed......................................
2023-04-06 16:43:53,333:INFO:SubProcess create_model() end ==================================
2023-04-06 16:43:53,333:INFO:Creating metrics dataframe
2023-04-06 16:43:53,337:INFO:Initializing Lasso Least Angle Regression
2023-04-06 16:43:53,337:INFO:Total runtime is 0.39463286399841313 minutes
2023-04-06 16:43:53,338:INFO:SubProcess create_model() called ==================================
2023-04-06 16:43:53,339:INFO:Initializing create_model()
2023-04-06 16:43:53,339:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:43:53,339:INFO:Checking exceptions
2023-04-06 16:43:53,339:INFO:Importing libraries
2023-04-06 16:43:53,339:INFO:Copying training dataset
2023-04-06 16:43:53,341:INFO:Defining folds
2023-04-06 16:43:53,341:INFO:Declaring metric variables
2023-04-06 16:43:53,342:INFO:Importing untrained model
2023-04-06 16:43:53,344:INFO:Lasso Least Angle Regression Imported successfully
2023-04-06 16:43:53,346:INFO:Starting cross validation
2023-04-06 16:43:53,347:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:43:53,427:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:43:53,434:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:43:53,443:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:43:53,443:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:43:53,450:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:43:53,457:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:43:53,461:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:43:53,466:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:43:53,488:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:43:53,492:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:43:57,046:INFO:Calculating mean and std
2023-04-06 16:43:57,047:INFO:Creating metrics dataframe
2023-04-06 16:43:57,435:INFO:Uploading results into container
2023-04-06 16:43:57,436:INFO:Uploading model into container now
2023-04-06 16:43:57,436:INFO:_master_model_container: 6
2023-04-06 16:43:57,436:INFO:_display_container: 2
2023-04-06 16:43:57,436:INFO:LassoLars(random_state=123)
2023-04-06 16:43:57,436:INFO:create_model() successfully completed......................................
2023-04-06 16:43:57,493:INFO:SubProcess create_model() end ==================================
2023-04-06 16:43:57,493:INFO:Creating metrics dataframe
2023-04-06 16:43:57,498:INFO:Initializing Orthogonal Matching Pursuit
2023-04-06 16:43:57,498:INFO:Total runtime is 0.46398140192031867 minutes
2023-04-06 16:43:57,500:INFO:SubProcess create_model() called ==================================
2023-04-06 16:43:57,500:INFO:Initializing create_model()
2023-04-06 16:43:57,500:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:43:57,500:INFO:Checking exceptions
2023-04-06 16:43:57,500:INFO:Importing libraries
2023-04-06 16:43:57,500:INFO:Copying training dataset
2023-04-06 16:43:57,503:INFO:Defining folds
2023-04-06 16:43:57,503:INFO:Declaring metric variables
2023-04-06 16:43:57,504:INFO:Importing untrained model
2023-04-06 16:43:57,505:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-06 16:43:57,508:INFO:Starting cross validation
2023-04-06 16:43:57,508:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:43:57,589:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:57,598:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:57,601:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:57,601:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:57,612:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:57,624:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:57,625:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:57,636:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:57,648:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:57,649:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:44:01,286:INFO:Calculating mean and std
2023-04-06 16:44:01,286:INFO:Creating metrics dataframe
2023-04-06 16:44:01,676:INFO:Uploading results into container
2023-04-06 16:44:01,676:INFO:Uploading model into container now
2023-04-06 16:44:01,677:INFO:_master_model_container: 7
2023-04-06 16:44:01,677:INFO:_display_container: 2
2023-04-06 16:44:01,677:INFO:OrthogonalMatchingPursuit()
2023-04-06 16:44:01,677:INFO:create_model() successfully completed......................................
2023-04-06 16:44:01,735:INFO:SubProcess create_model() end ==================================
2023-04-06 16:44:01,736:INFO:Creating metrics dataframe
2023-04-06 16:44:01,740:INFO:Initializing Bayesian Ridge
2023-04-06 16:44:01,740:INFO:Total runtime is 0.5346790154774984 minutes
2023-04-06 16:44:01,742:INFO:SubProcess create_model() called ==================================
2023-04-06 16:44:01,742:INFO:Initializing create_model()
2023-04-06 16:44:01,742:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:44:01,742:INFO:Checking exceptions
2023-04-06 16:44:01,742:INFO:Importing libraries
2023-04-06 16:44:01,742:INFO:Copying training dataset
2023-04-06 16:44:01,744:INFO:Defining folds
2023-04-06 16:44:01,744:INFO:Declaring metric variables
2023-04-06 16:44:01,745:INFO:Importing untrained model
2023-04-06 16:44:01,747:INFO:Bayesian Ridge Imported successfully
2023-04-06 16:44:01,750:INFO:Starting cross validation
2023-04-06 16:44:01,751:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:44:05,764:INFO:Calculating mean and std
2023-04-06 16:44:05,765:INFO:Creating metrics dataframe
2023-04-06 16:44:06,165:INFO:Uploading results into container
2023-04-06 16:44:06,165:INFO:Uploading model into container now
2023-04-06 16:44:06,166:INFO:_master_model_container: 8
2023-04-06 16:44:06,166:INFO:_display_container: 2
2023-04-06 16:44:06,166:INFO:BayesianRidge()
2023-04-06 16:44:06,166:INFO:create_model() successfully completed......................................
2023-04-06 16:44:06,222:INFO:SubProcess create_model() end ==================================
2023-04-06 16:44:06,222:INFO:Creating metrics dataframe
2023-04-06 16:44:06,227:INFO:Initializing Passive Aggressive Regressor
2023-04-06 16:44:06,227:INFO:Total runtime is 0.6094612836837769 minutes
2023-04-06 16:44:06,228:INFO:SubProcess create_model() called ==================================
2023-04-06 16:44:06,228:INFO:Initializing create_model()
2023-04-06 16:44:06,228:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:44:06,229:INFO:Checking exceptions
2023-04-06 16:44:06,229:INFO:Importing libraries
2023-04-06 16:44:06,229:INFO:Copying training dataset
2023-04-06 16:44:06,231:INFO:Defining folds
2023-04-06 16:44:06,231:INFO:Declaring metric variables
2023-04-06 16:44:06,232:INFO:Importing untrained model
2023-04-06 16:44:06,234:INFO:Passive Aggressive Regressor Imported successfully
2023-04-06 16:44:06,236:INFO:Starting cross validation
2023-04-06 16:44:06,237:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:44:10,069:INFO:Calculating mean and std
2023-04-06 16:44:10,070:INFO:Creating metrics dataframe
2023-04-06 16:44:10,462:INFO:Uploading results into container
2023-04-06 16:44:10,462:INFO:Uploading model into container now
2023-04-06 16:44:10,462:INFO:_master_model_container: 9
2023-04-06 16:44:10,462:INFO:_display_container: 2
2023-04-06 16:44:10,462:INFO:PassiveAggressiveRegressor(random_state=123)
2023-04-06 16:44:10,462:INFO:create_model() successfully completed......................................
2023-04-06 16:44:10,517:INFO:SubProcess create_model() end ==================================
2023-04-06 16:44:10,518:INFO:Creating metrics dataframe
2023-04-06 16:44:10,522:INFO:Initializing Huber Regressor
2023-04-06 16:44:10,522:INFO:Total runtime is 0.681045432885488 minutes
2023-04-06 16:44:10,523:INFO:SubProcess create_model() called ==================================
2023-04-06 16:44:10,524:INFO:Initializing create_model()
2023-04-06 16:44:10,524:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:44:10,524:INFO:Checking exceptions
2023-04-06 16:44:10,524:INFO:Importing libraries
2023-04-06 16:44:10,524:INFO:Copying training dataset
2023-04-06 16:44:10,527:INFO:Defining folds
2023-04-06 16:44:10,527:INFO:Declaring metric variables
2023-04-06 16:44:10,528:INFO:Importing untrained model
2023-04-06 16:44:10,529:INFO:Huber Regressor Imported successfully
2023-04-06 16:44:10,532:INFO:Starting cross validation
2023-04-06 16:44:10,533:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:44:10,667:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 16:44:10,669:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 16:44:10,671:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 16:44:10,676:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 16:44:10,690:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 16:44:10,691:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 16:44:10,698:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 16:44:10,714:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 16:44:14,313:INFO:Calculating mean and std
2023-04-06 16:44:14,313:INFO:Creating metrics dataframe
2023-04-06 16:44:14,695:INFO:Uploading results into container
2023-04-06 16:44:14,695:INFO:Uploading model into container now
2023-04-06 16:44:14,696:INFO:_master_model_container: 10
2023-04-06 16:44:14,696:INFO:_display_container: 2
2023-04-06 16:44:14,696:INFO:HuberRegressor()
2023-04-06 16:44:14,696:INFO:create_model() successfully completed......................................
2023-04-06 16:44:14,754:INFO:SubProcess create_model() end ==================================
2023-04-06 16:44:14,754:INFO:Creating metrics dataframe
2023-04-06 16:44:14,759:INFO:Initializing K Neighbors Regressor
2023-04-06 16:44:14,759:INFO:Total runtime is 0.75166658560435 minutes
2023-04-06 16:44:14,761:INFO:SubProcess create_model() called ==================================
2023-04-06 16:44:14,761:INFO:Initializing create_model()
2023-04-06 16:44:14,761:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:44:14,761:INFO:Checking exceptions
2023-04-06 16:44:14,761:INFO:Importing libraries
2023-04-06 16:44:14,761:INFO:Copying training dataset
2023-04-06 16:44:14,764:INFO:Defining folds
2023-04-06 16:44:14,764:INFO:Declaring metric variables
2023-04-06 16:44:14,765:INFO:Importing untrained model
2023-04-06 16:44:14,767:INFO:K Neighbors Regressor Imported successfully
2023-04-06 16:44:14,770:INFO:Starting cross validation
2023-04-06 16:44:14,770:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:44:18,550:INFO:Calculating mean and std
2023-04-06 16:44:18,550:INFO:Creating metrics dataframe
2023-04-06 16:44:18,936:INFO:Uploading results into container
2023-04-06 16:44:18,936:INFO:Uploading model into container now
2023-04-06 16:44:18,936:INFO:_master_model_container: 11
2023-04-06 16:44:18,936:INFO:_display_container: 2
2023-04-06 16:44:18,937:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-06 16:44:18,937:INFO:create_model() successfully completed......................................
2023-04-06 16:44:18,993:INFO:SubProcess create_model() end ==================================
2023-04-06 16:44:18,994:INFO:Creating metrics dataframe
2023-04-06 16:44:18,998:INFO:Initializing Decision Tree Regressor
2023-04-06 16:44:18,998:INFO:Total runtime is 0.8223115324974062 minutes
2023-04-06 16:44:18,999:INFO:SubProcess create_model() called ==================================
2023-04-06 16:44:18,999:INFO:Initializing create_model()
2023-04-06 16:44:18,999:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:44:18,999:INFO:Checking exceptions
2023-04-06 16:44:18,999:INFO:Importing libraries
2023-04-06 16:44:18,999:INFO:Copying training dataset
2023-04-06 16:44:19,001:INFO:Defining folds
2023-04-06 16:44:19,001:INFO:Declaring metric variables
2023-04-06 16:44:19,003:INFO:Importing untrained model
2023-04-06 16:44:19,004:INFO:Decision Tree Regressor Imported successfully
2023-04-06 16:44:19,006:INFO:Starting cross validation
2023-04-06 16:44:19,007:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:44:22,807:INFO:Calculating mean and std
2023-04-06 16:44:22,807:INFO:Creating metrics dataframe
2023-04-06 16:44:23,193:INFO:Uploading results into container
2023-04-06 16:44:23,194:INFO:Uploading model into container now
2023-04-06 16:44:23,194:INFO:_master_model_container: 12
2023-04-06 16:44:23,194:INFO:_display_container: 2
2023-04-06 16:44:23,194:INFO:DecisionTreeRegressor(random_state=123)
2023-04-06 16:44:23,194:INFO:create_model() successfully completed......................................
2023-04-06 16:44:23,252:INFO:SubProcess create_model() end ==================================
2023-04-06 16:44:23,253:INFO:Creating metrics dataframe
2023-04-06 16:44:23,258:INFO:Initializing Random Forest Regressor
2023-04-06 16:44:23,258:INFO:Total runtime is 0.8933154503504437 minutes
2023-04-06 16:44:23,260:INFO:SubProcess create_model() called ==================================
2023-04-06 16:44:23,260:INFO:Initializing create_model()
2023-04-06 16:44:23,260:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:44:23,260:INFO:Checking exceptions
2023-04-06 16:44:23,260:INFO:Importing libraries
2023-04-06 16:44:23,260:INFO:Copying training dataset
2023-04-06 16:44:23,263:INFO:Defining folds
2023-04-06 16:44:23,263:INFO:Declaring metric variables
2023-04-06 16:44:23,264:INFO:Importing untrained model
2023-04-06 16:44:23,266:INFO:Random Forest Regressor Imported successfully
2023-04-06 16:44:23,268:INFO:Starting cross validation
2023-04-06 16:44:23,269:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:44:27,142:INFO:Calculating mean and std
2023-04-06 16:44:27,143:INFO:Creating metrics dataframe
2023-04-06 16:44:27,532:INFO:Uploading results into container
2023-04-06 16:44:27,533:INFO:Uploading model into container now
2023-04-06 16:44:27,533:INFO:_master_model_container: 13
2023-04-06 16:44:27,533:INFO:_display_container: 2
2023-04-06 16:44:27,533:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-04-06 16:44:27,533:INFO:create_model() successfully completed......................................
2023-04-06 16:44:27,593:INFO:SubProcess create_model() end ==================================
2023-04-06 16:44:27,594:INFO:Creating metrics dataframe
2023-04-06 16:44:27,599:INFO:Initializing Extra Trees Regressor
2023-04-06 16:44:27,599:INFO:Total runtime is 0.9656657814979555 minutes
2023-04-06 16:44:27,601:INFO:SubProcess create_model() called ==================================
2023-04-06 16:44:27,601:INFO:Initializing create_model()
2023-04-06 16:44:27,601:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:44:27,601:INFO:Checking exceptions
2023-04-06 16:44:27,601:INFO:Importing libraries
2023-04-06 16:44:27,601:INFO:Copying training dataset
2023-04-06 16:44:27,603:INFO:Defining folds
2023-04-06 16:44:27,603:INFO:Declaring metric variables
2023-04-06 16:44:27,605:INFO:Importing untrained model
2023-04-06 16:44:27,606:INFO:Extra Trees Regressor Imported successfully
2023-04-06 16:44:27,609:INFO:Starting cross validation
2023-04-06 16:44:27,610:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:44:31,637:INFO:Calculating mean and std
2023-04-06 16:44:31,638:INFO:Creating metrics dataframe
2023-04-06 16:44:32,044:INFO:Uploading results into container
2023-04-06 16:44:32,046:INFO:Uploading model into container now
2023-04-06 16:44:32,047:INFO:_master_model_container: 14
2023-04-06 16:44:32,047:INFO:_display_container: 2
2023-04-06 16:44:32,047:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-04-06 16:44:32,047:INFO:create_model() successfully completed......................................
2023-04-06 16:44:32,147:INFO:SubProcess create_model() end ==================================
2023-04-06 16:44:32,147:INFO:Creating metrics dataframe
2023-04-06 16:44:32,152:INFO:Initializing AdaBoost Regressor
2023-04-06 16:44:32,152:INFO:Total runtime is 1.0415479501088463 minutes
2023-04-06 16:44:32,153:INFO:SubProcess create_model() called ==================================
2023-04-06 16:44:32,154:INFO:Initializing create_model()
2023-04-06 16:44:32,154:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:44:32,154:INFO:Checking exceptions
2023-04-06 16:44:32,154:INFO:Importing libraries
2023-04-06 16:44:32,154:INFO:Copying training dataset
2023-04-06 16:44:32,156:INFO:Defining folds
2023-04-06 16:44:32,156:INFO:Declaring metric variables
2023-04-06 16:44:32,158:INFO:Importing untrained model
2023-04-06 16:44:32,160:INFO:AdaBoost Regressor Imported successfully
2023-04-06 16:44:32,163:INFO:Starting cross validation
2023-04-06 16:44:32,164:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:44:35,924:INFO:Calculating mean and std
2023-04-06 16:44:35,925:INFO:Creating metrics dataframe
2023-04-06 16:44:36,311:INFO:Uploading results into container
2023-04-06 16:44:36,311:INFO:Uploading model into container now
2023-04-06 16:44:36,312:INFO:_master_model_container: 15
2023-04-06 16:44:36,312:INFO:_display_container: 2
2023-04-06 16:44:36,312:INFO:AdaBoostRegressor(random_state=123)
2023-04-06 16:44:36,312:INFO:create_model() successfully completed......................................
2023-04-06 16:44:36,369:INFO:SubProcess create_model() end ==================================
2023-04-06 16:44:36,369:INFO:Creating metrics dataframe
2023-04-06 16:44:36,374:INFO:Initializing Gradient Boosting Regressor
2023-04-06 16:44:36,374:INFO:Total runtime is 1.1119085669517519 minutes
2023-04-06 16:44:36,375:INFO:SubProcess create_model() called ==================================
2023-04-06 16:44:36,375:INFO:Initializing create_model()
2023-04-06 16:44:36,375:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:44:36,375:INFO:Checking exceptions
2023-04-06 16:44:36,375:INFO:Importing libraries
2023-04-06 16:44:36,375:INFO:Copying training dataset
2023-04-06 16:44:36,377:INFO:Defining folds
2023-04-06 16:44:36,377:INFO:Declaring metric variables
2023-04-06 16:44:36,378:INFO:Importing untrained model
2023-04-06 16:44:36,380:INFO:Gradient Boosting Regressor Imported successfully
2023-04-06 16:44:36,382:INFO:Starting cross validation
2023-04-06 16:44:36,383:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:44:40,184:INFO:Calculating mean and std
2023-04-06 16:44:40,184:INFO:Creating metrics dataframe
2023-04-06 16:44:40,574:INFO:Uploading results into container
2023-04-06 16:44:40,574:INFO:Uploading model into container now
2023-04-06 16:44:40,575:INFO:_master_model_container: 16
2023-04-06 16:44:40,575:INFO:_display_container: 2
2023-04-06 16:44:40,575:INFO:GradientBoostingRegressor(random_state=123)
2023-04-06 16:44:40,575:INFO:create_model() successfully completed......................................
2023-04-06 16:44:40,629:INFO:SubProcess create_model() end ==================================
2023-04-06 16:44:40,630:INFO:Creating metrics dataframe
2023-04-06 16:44:40,635:INFO:Initializing Extreme Gradient Boosting
2023-04-06 16:44:40,635:INFO:Total runtime is 1.1829238017400108 minutes
2023-04-06 16:44:40,636:INFO:SubProcess create_model() called ==================================
2023-04-06 16:44:40,636:INFO:Initializing create_model()
2023-04-06 16:44:40,636:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:44:40,636:INFO:Checking exceptions
2023-04-06 16:44:40,636:INFO:Importing libraries
2023-04-06 16:44:40,636:INFO:Copying training dataset
2023-04-06 16:44:40,638:INFO:Defining folds
2023-04-06 16:44:40,639:INFO:Declaring metric variables
2023-04-06 16:44:40,640:INFO:Importing untrained model
2023-04-06 16:44:40,641:INFO:Extreme Gradient Boosting Imported successfully
2023-04-06 16:44:40,643:INFO:Starting cross validation
2023-04-06 16:44:40,644:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:44:44,415:INFO:Calculating mean and std
2023-04-06 16:44:44,415:INFO:Creating metrics dataframe
2023-04-06 16:44:44,802:INFO:Uploading results into container
2023-04-06 16:44:44,803:INFO:Uploading model into container now
2023-04-06 16:44:44,803:INFO:_master_model_container: 17
2023-04-06 16:44:44,803:INFO:_display_container: 2
2023-04-06 16:44:44,804:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=123, ...)
2023-04-06 16:44:44,804:INFO:create_model() successfully completed......................................
2023-04-06 16:44:44,862:INFO:SubProcess create_model() end ==================================
2023-04-06 16:44:44,862:INFO:Creating metrics dataframe
2023-04-06 16:44:44,867:INFO:Initializing Light Gradient Boosting Machine
2023-04-06 16:44:44,867:INFO:Total runtime is 1.2534611304601035 minutes
2023-04-06 16:44:44,868:INFO:SubProcess create_model() called ==================================
2023-04-06 16:44:44,868:INFO:Initializing create_model()
2023-04-06 16:44:44,868:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:44:44,868:INFO:Checking exceptions
2023-04-06 16:44:44,869:INFO:Importing libraries
2023-04-06 16:44:44,869:INFO:Copying training dataset
2023-04-06 16:44:44,870:INFO:Defining folds
2023-04-06 16:44:44,870:INFO:Declaring metric variables
2023-04-06 16:44:44,871:INFO:Importing untrained model
2023-04-06 16:44:44,873:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-06 16:44:44,875:INFO:Starting cross validation
2023-04-06 16:44:44,876:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:44:49,406:INFO:Calculating mean and std
2023-04-06 16:44:49,407:INFO:Creating metrics dataframe
2023-04-06 16:44:49,803:INFO:Uploading results into container
2023-04-06 16:44:49,803:INFO:Uploading model into container now
2023-04-06 16:44:49,803:INFO:_master_model_container: 18
2023-04-06 16:44:49,803:INFO:_display_container: 2
2023-04-06 16:44:49,804:INFO:LGBMRegressor(random_state=123)
2023-04-06 16:44:49,804:INFO:create_model() successfully completed......................................
2023-04-06 16:44:49,863:INFO:SubProcess create_model() end ==================================
2023-04-06 16:44:49,864:INFO:Creating metrics dataframe
2023-04-06 16:44:49,869:INFO:Initializing CatBoost Regressor
2023-04-06 16:44:49,869:INFO:Total runtime is 1.3368359684944155 minutes
2023-04-06 16:44:49,871:INFO:SubProcess create_model() called ==================================
2023-04-06 16:44:49,872:INFO:Initializing create_model()
2023-04-06 16:44:49,872:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:44:49,872:INFO:Checking exceptions
2023-04-06 16:44:49,872:INFO:Importing libraries
2023-04-06 16:44:49,872:INFO:Copying training dataset
2023-04-06 16:44:49,874:INFO:Defining folds
2023-04-06 16:44:49,874:INFO:Declaring metric variables
2023-04-06 16:44:49,875:INFO:Importing untrained model
2023-04-06 16:44:49,880:INFO:CatBoost Regressor Imported successfully
2023-04-06 16:44:49,883:INFO:Starting cross validation
2023-04-06 16:44:49,884:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:44:54,247:INFO:Calculating mean and std
2023-04-06 16:44:54,248:INFO:Creating metrics dataframe
2023-04-06 16:44:54,642:INFO:Uploading results into container
2023-04-06 16:44:54,642:INFO:Uploading model into container now
2023-04-06 16:44:54,642:INFO:_master_model_container: 19
2023-04-06 16:44:54,642:INFO:_display_container: 2
2023-04-06 16:44:54,642:INFO:<catboost.core.CatBoostRegressor object at 0x16b5790d0>
2023-04-06 16:44:54,642:INFO:create_model() successfully completed......................................
2023-04-06 16:44:54,698:INFO:SubProcess create_model() end ==================================
2023-04-06 16:44:54,698:INFO:Creating metrics dataframe
2023-04-06 16:44:54,704:INFO:Initializing Dummy Regressor
2023-04-06 16:44:54,704:INFO:Total runtime is 1.4174164017041526 minutes
2023-04-06 16:44:54,706:INFO:SubProcess create_model() called ==================================
2023-04-06 16:44:54,706:INFO:Initializing create_model()
2023-04-06 16:44:54,706:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:44:54,706:INFO:Checking exceptions
2023-04-06 16:44:54,706:INFO:Importing libraries
2023-04-06 16:44:54,706:INFO:Copying training dataset
2023-04-06 16:44:54,708:INFO:Defining folds
2023-04-06 16:44:54,708:INFO:Declaring metric variables
2023-04-06 16:44:54,709:INFO:Importing untrained model
2023-04-06 16:44:54,711:INFO:Dummy Regressor Imported successfully
2023-04-06 16:44:54,713:INFO:Starting cross validation
2023-04-06 16:44:54,714:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:44:58,515:INFO:Calculating mean and std
2023-04-06 16:44:58,516:INFO:Creating metrics dataframe
2023-04-06 16:44:58,934:INFO:Uploading results into container
2023-04-06 16:44:58,935:INFO:Uploading model into container now
2023-04-06 16:44:58,935:INFO:_master_model_container: 20
2023-04-06 16:44:58,935:INFO:_display_container: 2
2023-04-06 16:44:58,935:INFO:DummyRegressor()
2023-04-06 16:44:58,935:INFO:create_model() successfully completed......................................
2023-04-06 16:44:58,991:INFO:SubProcess create_model() end ==================================
2023-04-06 16:44:58,991:INFO:Creating metrics dataframe
2023-04-06 16:44:58,999:INFO:Initializing create_model()
2023-04-06 16:44:59,000:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=<catboost.core.CatBoostRegressor object at 0x16b5790d0>, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:44:59,000:INFO:Checking exceptions
2023-04-06 16:44:59,001:INFO:Importing libraries
2023-04-06 16:44:59,001:INFO:Copying training dataset
2023-04-06 16:44:59,003:INFO:Defining folds
2023-04-06 16:44:59,003:INFO:Declaring metric variables
2023-04-06 16:44:59,003:INFO:Importing untrained model
2023-04-06 16:44:59,003:INFO:Declaring custom model
2023-04-06 16:44:59,004:INFO:CatBoost Regressor Imported successfully
2023-04-06 16:44:59,004:INFO:Cross validation set to False
2023-04-06 16:44:59,004:INFO:Fitting Model
2023-04-06 16:44:59,391:INFO:<catboost.core.CatBoostRegressor object at 0x16b579b80>
2023-04-06 16:44:59,391:INFO:create_model() successfully completed......................................
2023-04-06 16:44:59,459:INFO:_master_model_container: 20
2023-04-06 16:44:59,459:INFO:_display_container: 2
2023-04-06 16:44:59,459:INFO:<catboost.core.CatBoostRegressor object at 0x16b579b80>
2023-04-06 16:44:59,459:INFO:compare_models() successfully completed......................................
2023-04-06 16:44:59,463:INFO:Initializing create_model()
2023-04-06 16:44:59,463:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=ada, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:44:59,463:INFO:Checking exceptions
2023-04-06 16:44:59,470:INFO:Importing libraries
2023-04-06 16:44:59,470:INFO:Copying training dataset
2023-04-06 16:44:59,476:INFO:Defining folds
2023-04-06 16:44:59,476:INFO:Declaring metric variables
2023-04-06 16:44:59,477:INFO:Importing untrained model
2023-04-06 16:44:59,479:INFO:AdaBoost Regressor Imported successfully
2023-04-06 16:44:59,482:INFO:Starting cross validation
2023-04-06 16:44:59,483:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:45:03,213:INFO:Calculating mean and std
2023-04-06 16:45:03,214:INFO:Creating metrics dataframe
2023-04-06 16:45:03,216:INFO:Finalizing model
2023-04-06 16:45:03,693:INFO:Uploading results into container
2023-04-06 16:45:03,694:INFO:Uploading model into container now
2023-04-06 16:45:03,698:INFO:_master_model_container: 21
2023-04-06 16:45:03,698:INFO:_display_container: 3
2023-04-06 16:45:03,698:INFO:AdaBoostRegressor(random_state=123)
2023-04-06 16:45:03,698:INFO:create_model() successfully completed......................................
2023-04-06 16:45:03,764:INFO:Initializing create_model()
2023-04-06 16:45:03,764:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:45:03,764:INFO:Checking exceptions
2023-04-06 16:45:03,771:INFO:Importing libraries
2023-04-06 16:45:03,771:INFO:Copying training dataset
2023-04-06 16:45:03,775:INFO:Defining folds
2023-04-06 16:45:03,775:INFO:Declaring metric variables
2023-04-06 16:45:03,777:INFO:Importing untrained model
2023-04-06 16:45:03,778:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-06 16:45:03,781:INFO:Starting cross validation
2023-04-06 16:45:03,782:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:45:07,575:INFO:Calculating mean and std
2023-04-06 16:45:07,576:INFO:Creating metrics dataframe
2023-04-06 16:45:07,578:INFO:Finalizing model
2023-04-06 16:45:08,054:INFO:Uploading results into container
2023-04-06 16:45:08,054:INFO:Uploading model into container now
2023-04-06 16:45:08,058:INFO:_master_model_container: 22
2023-04-06 16:45:08,058:INFO:_display_container: 4
2023-04-06 16:45:08,058:INFO:LGBMRegressor(random_state=123)
2023-04-06 16:45:08,059:INFO:create_model() successfully completed......................................
2023-04-06 16:45:08,125:INFO:Initializing create_model()
2023-04-06 16:45:08,125:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:45:08,125:INFO:Checking exceptions
2023-04-06 16:45:08,132:INFO:Importing libraries
2023-04-06 16:45:08,132:INFO:Copying training dataset
2023-04-06 16:45:08,137:INFO:Defining folds
2023-04-06 16:45:08,137:INFO:Declaring metric variables
2023-04-06 16:45:08,139:INFO:Importing untrained model
2023-04-06 16:45:08,140:INFO:Decision Tree Regressor Imported successfully
2023-04-06 16:45:08,143:INFO:Starting cross validation
2023-04-06 16:45:08,144:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:45:11,950:INFO:Calculating mean and std
2023-04-06 16:45:11,951:INFO:Creating metrics dataframe
2023-04-06 16:45:11,953:INFO:Finalizing model
2023-04-06 16:45:12,403:INFO:Uploading results into container
2023-04-06 16:45:12,404:INFO:Uploading model into container now
2023-04-06 16:45:12,407:INFO:_master_model_container: 23
2023-04-06 16:45:12,407:INFO:_display_container: 5
2023-04-06 16:45:12,407:INFO:DecisionTreeRegressor(random_state=123)
2023-04-06 16:45:12,407:INFO:create_model() successfully completed......................................
2023-04-06 16:45:12,468:INFO:Initializing tune_model()
2023-04-06 16:45:12,468:INFO:tune_model(estimator=ada, fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>)
2023-04-06 16:45:12,468:INFO:Checking exceptions
2023-04-06 16:45:37,311:INFO:Initializing tune_model()
2023-04-06 16:45:37,312:INFO:tune_model(estimator=LGBMRegressor(random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>)
2023-04-06 16:45:37,313:INFO:Checking exceptions
2023-04-06 16:45:37,332:INFO:Copying training dataset
2023-04-06 16:45:37,336:INFO:Checking base model
2023-04-06 16:45:37,336:INFO:Base model : Light Gradient Boosting Machine
2023-04-06 16:45:37,338:INFO:Declaring metric variables
2023-04-06 16:45:37,340:INFO:Defining Hyperparameters
2023-04-06 16:45:37,426:INFO:Tuning with n_jobs=-1
2023-04-06 16:45:37,426:INFO:Initializing RandomizedSearchCV
2023-04-06 16:46:14,438:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-04-06 16:46:14,439:INFO:Hyperparameter search completed
2023-04-06 16:46:14,439:INFO:SubProcess create_model() called ==================================
2023-04-06 16:46:14,440:INFO:Initializing create_model()
2023-04-06 16:46:14,440:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=LGBMRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1758acb50>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-04-06 16:46:14,440:INFO:Checking exceptions
2023-04-06 16:46:14,440:INFO:Importing libraries
2023-04-06 16:46:14,440:INFO:Copying training dataset
2023-04-06 16:46:14,442:INFO:Defining folds
2023-04-06 16:46:14,442:INFO:Declaring metric variables
2023-04-06 16:46:14,443:INFO:Importing untrained model
2023-04-06 16:46:14,443:INFO:Declaring custom model
2023-04-06 16:46:14,445:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-06 16:46:14,447:INFO:Starting cross validation
2023-04-06 16:46:14,448:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:46:18,117:INFO:Calculating mean and std
2023-04-06 16:46:18,118:INFO:Creating metrics dataframe
2023-04-06 16:46:18,120:INFO:Finalizing model
2023-04-06 16:46:18,710:INFO:Uploading results into container
2023-04-06 16:46:18,710:INFO:Uploading model into container now
2023-04-06 16:46:18,711:INFO:_master_model_container: 24
2023-04-06 16:46:18,711:INFO:_display_container: 6
2023-04-06 16:46:18,711:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              num_leaves=70, random_state=123, reg_alpha=2, reg_lambda=3)
2023-04-06 16:46:18,711:INFO:create_model() successfully completed......................................
2023-04-06 16:46:18,788:INFO:SubProcess create_model() end ==================================
2023-04-06 16:46:18,788:INFO:choose_better activated
2023-04-06 16:46:18,790:INFO:SubProcess create_model() called ==================================
2023-04-06 16:46:18,790:INFO:Initializing create_model()
2023-04-06 16:46:18,790:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=LGBMRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:46:18,790:INFO:Checking exceptions
2023-04-06 16:46:18,790:INFO:Importing libraries
2023-04-06 16:46:18,790:INFO:Copying training dataset
2023-04-06 16:46:18,793:INFO:Defining folds
2023-04-06 16:46:18,793:INFO:Declaring metric variables
2023-04-06 16:46:18,793:INFO:Importing untrained model
2023-04-06 16:46:18,793:INFO:Declaring custom model
2023-04-06 16:46:18,793:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-06 16:46:18,793:INFO:Starting cross validation
2023-04-06 16:46:18,794:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:46:22,566:INFO:Calculating mean and std
2023-04-06 16:46:22,566:INFO:Creating metrics dataframe
2023-04-06 16:46:22,567:INFO:Finalizing model
2023-04-06 16:46:23,029:INFO:Uploading results into container
2023-04-06 16:46:23,030:INFO:Uploading model into container now
2023-04-06 16:46:23,030:INFO:_master_model_container: 25
2023-04-06 16:46:23,030:INFO:_display_container: 7
2023-04-06 16:46:23,030:INFO:LGBMRegressor(random_state=123)
2023-04-06 16:46:23,030:INFO:create_model() successfully completed......................................
2023-04-06 16:46:23,108:INFO:SubProcess create_model() end ==================================
2023-04-06 16:46:23,109:INFO:LGBMRegressor(random_state=123) result for R2 is 0.9711
2023-04-06 16:46:23,109:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              num_leaves=70, random_state=123, reg_alpha=2, reg_lambda=3) result for R2 is 0.9651
2023-04-06 16:46:23,109:INFO:LGBMRegressor(random_state=123) is best model
2023-04-06 16:46:23,109:INFO:choose_better completed
2023-04-06 16:46:23,109:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-04-06 16:46:23,113:INFO:_master_model_container: 25
2023-04-06 16:46:23,113:INFO:_display_container: 6
2023-04-06 16:46:23,114:INFO:LGBMRegressor(random_state=123)
2023-04-06 16:46:23,114:INFO:tune_model() successfully completed......................................
2023-04-06 16:46:23,559:INFO:Initializing create_model()
2023-04-06 16:46:23,560:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=catboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:46:23,560:INFO:Checking exceptions
2023-04-06 16:46:23,566:INFO:Importing libraries
2023-04-06 16:46:23,567:INFO:Copying training dataset
2023-04-06 16:46:23,571:INFO:Defining folds
2023-04-06 16:46:23,571:INFO:Declaring metric variables
2023-04-06 16:46:23,573:INFO:Importing untrained model
2023-04-06 16:46:23,574:INFO:CatBoost Regressor Imported successfully
2023-04-06 16:46:23,577:INFO:Starting cross validation
2023-04-06 16:46:23,578:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:46:27,326:INFO:Calculating mean and std
2023-04-06 16:46:27,328:INFO:Creating metrics dataframe
2023-04-06 16:46:27,331:INFO:Finalizing model
2023-04-06 16:46:27,790:INFO:Uploading results into container
2023-04-06 16:46:27,790:INFO:Uploading model into container now
2023-04-06 16:46:27,794:INFO:_master_model_container: 26
2023-04-06 16:46:27,794:INFO:_display_container: 7
2023-04-06 16:46:27,794:INFO:<catboost.core.CatBoostRegressor object at 0x177e598b0>
2023-04-06 16:46:27,794:INFO:create_model() successfully completed......................................
2023-04-06 16:46:32,965:INFO:Initializing tune_model()
2023-04-06 16:46:32,966:INFO:tune_model(estimator=DecisionTreeRegressor(random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>)
2023-04-06 16:46:32,966:INFO:Checking exceptions
2023-04-06 16:46:32,986:INFO:Copying training dataset
2023-04-06 16:46:32,990:INFO:Checking base model
2023-04-06 16:46:32,990:INFO:Base model : Decision Tree Regressor
2023-04-06 16:46:32,992:INFO:Declaring metric variables
2023-04-06 16:46:32,994:INFO:Defining Hyperparameters
2023-04-06 16:46:33,076:INFO:Tuning with n_jobs=-1
2023-04-06 16:46:33,076:INFO:Initializing RandomizedSearchCV
2023-04-06 16:47:10,448:INFO:best_params: {'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.01, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 10, 'actual_estimator__criterion': 'friedman_mse'}
2023-04-06 16:47:10,449:INFO:Hyperparameter search completed
2023-04-06 16:47:10,449:INFO:SubProcess create_model() called ==================================
2023-04-06 16:47:10,449:INFO:Initializing create_model()
2023-04-06 16:47:10,449:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=DecisionTreeRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17b00afd0>, model_only=True, return_train_score=False, kwargs={'min_samples_split': 9, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.01, 'max_features': 1.0, 'max_depth': 10, 'criterion': 'friedman_mse'})
2023-04-06 16:47:10,449:INFO:Checking exceptions
2023-04-06 16:47:10,450:INFO:Importing libraries
2023-04-06 16:47:10,450:INFO:Copying training dataset
2023-04-06 16:47:10,452:INFO:Defining folds
2023-04-06 16:47:10,452:INFO:Declaring metric variables
2023-04-06 16:47:10,453:INFO:Importing untrained model
2023-04-06 16:47:10,453:INFO:Declaring custom model
2023-04-06 16:47:10,454:INFO:Decision Tree Regressor Imported successfully
2023-04-06 16:47:10,457:INFO:Starting cross validation
2023-04-06 16:47:10,458:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:47:14,262:INFO:Calculating mean and std
2023-04-06 16:47:14,263:INFO:Creating metrics dataframe
2023-04-06 16:47:14,265:INFO:Finalizing model
2023-04-06 16:47:14,717:INFO:Uploading results into container
2023-04-06 16:47:14,717:INFO:Uploading model into container now
2023-04-06 16:47:14,717:INFO:_master_model_container: 27
2023-04-06 16:47:14,717:INFO:_display_container: 8
2023-04-06 16:47:14,718:INFO:DecisionTreeRegressor(criterion='friedman_mse', max_depth=10, max_features=1.0,
                      min_impurity_decrease=0.01, min_samples_leaf=2,
                      min_samples_split=9, random_state=123)
2023-04-06 16:47:14,718:INFO:create_model() successfully completed......................................
2023-04-06 16:47:14,796:INFO:SubProcess create_model() end ==================================
2023-04-06 16:47:14,796:INFO:choose_better activated
2023-04-06 16:47:14,798:INFO:SubProcess create_model() called ==================================
2023-04-06 16:47:14,798:INFO:Initializing create_model()
2023-04-06 16:47:14,798:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=DecisionTreeRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:47:14,798:INFO:Checking exceptions
2023-04-06 16:47:14,798:INFO:Importing libraries
2023-04-06 16:47:14,799:INFO:Copying training dataset
2023-04-06 16:47:14,801:INFO:Defining folds
2023-04-06 16:47:14,801:INFO:Declaring metric variables
2023-04-06 16:47:14,801:INFO:Importing untrained model
2023-04-06 16:47:14,801:INFO:Declaring custom model
2023-04-06 16:47:14,801:INFO:Decision Tree Regressor Imported successfully
2023-04-06 16:47:14,801:INFO:Starting cross validation
2023-04-06 16:47:14,802:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:47:18,582:INFO:Calculating mean and std
2023-04-06 16:47:18,583:INFO:Creating metrics dataframe
2023-04-06 16:47:18,584:INFO:Finalizing model
2023-04-06 16:47:19,034:INFO:Uploading results into container
2023-04-06 16:47:19,035:INFO:Uploading model into container now
2023-04-06 16:47:19,035:INFO:_master_model_container: 28
2023-04-06 16:47:19,035:INFO:_display_container: 9
2023-04-06 16:47:19,035:INFO:DecisionTreeRegressor(random_state=123)
2023-04-06 16:47:19,035:INFO:create_model() successfully completed......................................
2023-04-06 16:47:19,110:INFO:SubProcess create_model() end ==================================
2023-04-06 16:47:19,111:INFO:DecisionTreeRegressor(random_state=123) result for R2 is 0.9465
2023-04-06 16:47:19,111:INFO:DecisionTreeRegressor(criterion='friedman_mse', max_depth=10, max_features=1.0,
                      min_impurity_decrease=0.01, min_samples_leaf=2,
                      min_samples_split=9, random_state=123) result for R2 is 0.9473
2023-04-06 16:47:19,111:INFO:DecisionTreeRegressor(criterion='friedman_mse', max_depth=10, max_features=1.0,
                      min_impurity_decrease=0.01, min_samples_leaf=2,
                      min_samples_split=9, random_state=123) is best model
2023-04-06 16:47:19,111:INFO:choose_better completed
2023-04-06 16:47:19,114:INFO:_master_model_container: 28
2023-04-06 16:47:19,115:INFO:_display_container: 8
2023-04-06 16:47:19,115:INFO:DecisionTreeRegressor(criterion='friedman_mse', max_depth=10, max_features=1.0,
                      min_impurity_decrease=0.01, min_samples_leaf=2,
                      min_samples_split=9, random_state=123)
2023-04-06 16:47:19,115:INFO:tune_model() successfully completed......................................
2023-04-06 16:48:11,885:INFO:Initializing tune_model()
2023-04-06 16:48:11,887:INFO:tune_model(estimator=<catboost.core.CatBoostRegressor object at 0x177e598b0>, fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>)
2023-04-06 16:48:11,887:INFO:Checking exceptions
2023-04-06 16:48:11,904:INFO:Copying training dataset
2023-04-06 16:48:11,909:INFO:Checking base model
2023-04-06 16:48:11,909:INFO:Base model : CatBoost Regressor
2023-04-06 16:48:11,911:INFO:Declaring metric variables
2023-04-06 16:48:11,913:INFO:Defining Hyperparameters
2023-04-06 16:48:12,000:INFO:Tuning with n_jobs=-1
2023-04-06 16:48:12,000:INFO:Initializing RandomizedSearchCV
2023-04-06 16:48:51,739:INFO:best_params: {'actual_estimator__random_strength': 0.2, 'actual_estimator__n_estimators': 180, 'actual_estimator__l2_leaf_reg': 30, 'actual_estimator__eta': 0.4, 'actual_estimator__depth': 8}
2023-04-06 16:48:51,740:INFO:Hyperparameter search completed
2023-04-06 16:48:51,740:INFO:SubProcess create_model() called ==================================
2023-04-06 16:48:51,741:INFO:Initializing create_model()
2023-04-06 16:48:51,741:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=<catboost.core.CatBoostRegressor object at 0x17b091fd0>, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x175b7cd30>, model_only=True, return_train_score=False, kwargs={'random_strength': 0.2, 'n_estimators': 180, 'l2_leaf_reg': 30, 'eta': 0.4, 'depth': 8})
2023-04-06 16:48:51,741:INFO:Checking exceptions
2023-04-06 16:48:51,741:INFO:Importing libraries
2023-04-06 16:48:51,741:INFO:Copying training dataset
2023-04-06 16:48:51,743:INFO:Defining folds
2023-04-06 16:48:51,743:INFO:Declaring metric variables
2023-04-06 16:48:51,745:INFO:Importing untrained model
2023-04-06 16:48:51,745:INFO:Declaring custom model
2023-04-06 16:48:51,747:INFO:CatBoost Regressor Imported successfully
2023-04-06 16:48:51,750:INFO:Starting cross validation
2023-04-06 16:48:51,751:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:48:55,879:INFO:Calculating mean and std
2023-04-06 16:48:55,880:INFO:Creating metrics dataframe
2023-04-06 16:48:55,883:INFO:Finalizing model
2023-04-06 16:48:56,680:INFO:Uploading results into container
2023-04-06 16:48:56,681:INFO:Uploading model into container now
2023-04-06 16:48:56,681:INFO:_master_model_container: 29
2023-04-06 16:48:56,681:INFO:_display_container: 9
2023-04-06 16:48:56,681:INFO:<catboost.core.CatBoostRegressor object at 0x17afb8e80>
2023-04-06 16:48:56,681:INFO:create_model() successfully completed......................................
2023-04-06 16:48:56,768:INFO:SubProcess create_model() end ==================================
2023-04-06 16:48:56,768:INFO:choose_better activated
2023-04-06 16:48:56,770:INFO:SubProcess create_model() called ==================================
2023-04-06 16:48:56,770:INFO:Initializing create_model()
2023-04-06 16:48:56,770:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=<catboost.core.CatBoostRegressor object at 0x177e598b0>, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:48:56,770:INFO:Checking exceptions
2023-04-06 16:48:56,771:INFO:Importing libraries
2023-04-06 16:48:56,771:INFO:Copying training dataset
2023-04-06 16:48:56,774:INFO:Defining folds
2023-04-06 16:48:56,774:INFO:Declaring metric variables
2023-04-06 16:48:56,774:INFO:Importing untrained model
2023-04-06 16:48:56,774:INFO:Declaring custom model
2023-04-06 16:48:56,774:INFO:CatBoost Regressor Imported successfully
2023-04-06 16:48:56,774:INFO:Starting cross validation
2023-04-06 16:48:56,775:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:49:00,739:INFO:Calculating mean and std
2023-04-06 16:49:00,740:INFO:Creating metrics dataframe
2023-04-06 16:49:00,741:INFO:Finalizing model
2023-04-06 16:49:01,200:INFO:Uploading results into container
2023-04-06 16:49:01,200:INFO:Uploading model into container now
2023-04-06 16:49:01,201:INFO:_master_model_container: 30
2023-04-06 16:49:01,201:INFO:_display_container: 10
2023-04-06 16:49:01,201:INFO:<catboost.core.CatBoostRegressor object at 0x17afd4d90>
2023-04-06 16:49:01,201:INFO:create_model() successfully completed......................................
2023-04-06 16:49:01,279:INFO:SubProcess create_model() end ==================================
2023-04-06 16:49:01,279:INFO:<catboost.core.CatBoostRegressor object at 0x17afd4d90> result for R2 is 0.9807
2023-04-06 16:49:01,279:INFO:<catboost.core.CatBoostRegressor object at 0x17afb8e80> result for R2 is 0.9769
2023-04-06 16:49:01,279:INFO:<catboost.core.CatBoostRegressor object at 0x17afd4d90> is best model
2023-04-06 16:49:01,279:INFO:choose_better completed
2023-04-06 16:49:01,280:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-04-06 16:49:01,284:INFO:_master_model_container: 30
2023-04-06 16:49:01,284:INFO:_display_container: 9
2023-04-06 16:49:01,284:INFO:<catboost.core.CatBoostRegressor object at 0x17afd4d90>
2023-04-06 16:49:01,284:INFO:tune_model() successfully completed......................................
2023-04-06 16:49:01,723:INFO:Initializing plot_model()
2023-04-06 16:49:01,723:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, system=True)
2023-04-06 16:49:01,723:INFO:Checking exceptions
2023-04-06 16:49:01,725:INFO:Preloading libraries
2023-04-06 16:49:01,731:INFO:Copying training dataset
2023-04-06 16:49:01,732:INFO:Plot type: residuals
2023-04-06 16:49:01,876:INFO:Fitting Model
2023-04-06 16:49:01,949:INFO:Scoring test/hold-out set
2023-04-06 16:49:02,281:INFO:Visual Rendered Successfully
2023-04-06 16:49:02,365:INFO:plot_model() successfully completed......................................
2023-04-06 16:49:02,370:INFO:Initializing plot_model()
2023-04-06 16:49:02,370:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, system=True)
2023-04-06 16:49:02,370:INFO:Checking exceptions
2023-04-06 16:49:02,372:INFO:Preloading libraries
2023-04-06 16:49:02,379:INFO:Copying training dataset
2023-04-06 16:49:02,379:INFO:Plot type: feature
2023-04-06 16:49:02,379:WARNING:No coef_ found. Trying feature_importances_
2023-04-06 16:49:02,472:INFO:Visual Rendered Successfully
2023-04-06 16:49:02,552:INFO:plot_model() successfully completed......................................
2023-04-06 16:49:02,556:INFO:Initializing plot_model()
2023-04-06 16:49:02,556:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, system=True)
2023-04-06 16:49:02,556:INFO:Checking exceptions
2023-04-06 16:49:02,558:INFO:Preloading libraries
2023-04-06 16:49:02,565:INFO:Copying training dataset
2023-04-06 16:49:02,565:INFO:Plot type: error
2023-04-06 16:49:02,729:INFO:Fitting Model
2023-04-06 16:49:02,729:INFO:Scoring test/hold-out set
2023-04-06 16:49:02,848:INFO:Visual Rendered Successfully
2023-04-06 16:49:02,928:INFO:plot_model() successfully completed......................................
2023-04-06 16:49:19,536:INFO:Initializing predict_model()
2023-04-06 16:49:19,537:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=LGBMRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x17afe09d0>)
2023-04-06 16:49:19,537:INFO:Checking exceptions
2023-04-06 16:49:19,538:INFO:Preloading libraries
2023-04-06 16:49:37,311:INFO:Initializing finalize_model()
2023-04-06 16:49:37,311:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=LGBMRegressor(random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-04-06 16:49:37,312:INFO:Finalizing LGBMRegressor(random_state=123)
2023-04-06 16:49:37,317:INFO:Initializing create_model()
2023-04-06 16:49:37,317:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=LGBMRegressor(random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-04-06 16:49:37,317:INFO:Checking exceptions
2023-04-06 16:49:37,321:INFO:Importing libraries
2023-04-06 16:49:37,321:INFO:Copying training dataset
2023-04-06 16:49:37,321:INFO:Defining folds
2023-04-06 16:49:37,321:INFO:Declaring metric variables
2023-04-06 16:49:37,321:INFO:Importing untrained model
2023-04-06 16:49:37,322:INFO:Declaring custom model
2023-04-06 16:49:37,323:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-06 16:49:37,325:INFO:Cross validation set to False
2023-04-06 16:49:37,325:INFO:Fitting Model
2023-04-06 16:49:37,450:INFO:Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry', 'Report'],
                                    transformer=SimpleImputer(strategy='most_frequent')...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry'],
                                    transformer=OneHotEncoder(cols=['Cut',
                                                                    'Color',
                                                                    'Clarity',
                                                                    'Polish',
                                                                    'Symmetry'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', LGBMRegressor(random_state=123))])
2023-04-06 16:49:37,450:INFO:create_model() successfully completed......................................
2023-04-06 16:49:37,528:INFO:_master_model_container: 30
2023-04-06 16:49:37,528:INFO:_display_container: 10
2023-04-06 16:49:37,537:INFO:Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry', 'Report'],
                                    transformer=SimpleImputer(strategy='most_frequent')...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry'],
                                    transformer=OneHotEncoder(cols=['Cut',
                                                                    'Color',
                                                                    'Clarity',
                                                                    'Polish',
                                                                    'Symmetry'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', LGBMRegressor(random_state=123))])
2023-04-06 16:49:37,537:INFO:finalize_model() successfully completed......................................
2023-04-06 16:50:01,724:INFO:Initializing predict_model()
2023-04-06 16:50:01,725:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry', 'Report'],
                                    transformer=SimpleImputer(strategy='most_frequent')...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry'],
                                    transformer=OneHotEncoder(cols=['Cut',
                                                                    'Color',
                                                                    'Clarity',
                                                                    'Polish',
                                                                    'Symmetry'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', LGBMRegressor(random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x17afe0820>)
2023-04-06 16:50:01,725:INFO:Checking exceptions
2023-04-06 16:50:01,725:INFO:Preloading libraries
2023-04-06 16:50:13,236:INFO:Initializing predict_model()
2023-04-06 16:50:13,236:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry', 'Report'],
                                    transformer=SimpleImputer(strategy='most_frequent')...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry'],
                                    transformer=OneHotEncoder(cols=['Cut',
                                                                    'Color',
                                                                    'Clarity',
                                                                    'Polish',
                                                                    'Symmetry'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', LGBMRegressor(random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x17afe00d0>)
2023-04-06 16:50:13,236:INFO:Checking exceptions
2023-04-06 16:50:13,237:INFO:Preloading libraries
2023-04-06 16:50:13,238:INFO:Set up data.
2023-04-06 16:50:13,242:INFO:Set up index.
2023-04-06 16:50:27,773:INFO:Initializing save_model()
2023-04-06 16:50:27,773:INFO:save_model(model=Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry', 'Report'],
                                    transformer=SimpleImputer(strategy='most_frequent')...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry'],
                                    transformer=OneHotEncoder(cols=['Cut',
                                                                    'Color',
                                                                    'Clarity',
                                                                    'Polish',
                                                                    'Symmetry'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', LGBMRegressor(random_state=123))]), model_name=Final Lightgbm Model 08Feb2020, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry', 'Report'],
                                    transformer=SimpleImputer(strategy='most_frequent')...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': AGSL    0
GIA     1
NaN    -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry'],
                                    transformer=OneHotEncoder(cols=['Cut',
                                                                    'Color',
                                                                    'Clarity',
                                                                    'Polish',
                                                                    'Symmetry'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-04-06 16:50:27,773:INFO:Adding model into prep_pipe
2023-04-06 16:50:27,784:WARNING:Only Model saved as it was a pipeline.
2023-04-06 16:50:27,798:INFO:Final Lightgbm Model 08Feb2020.pkl saved in current working directory
2023-04-06 16:50:27,809:INFO:Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry', 'Report'],
                                    transformer=SimpleImputer(strategy='most_frequent')...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry'],
                                    transformer=OneHotEncoder(cols=['Cut',
                                                                    'Color',
                                                                    'Clarity',
                                                                    'Polish',
                                                                    'Symmetry'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', LGBMRegressor(random_state=123))])
2023-04-06 16:50:27,809:INFO:save_model() successfully completed......................................
2023-04-06 16:51:33,177:INFO:Initializing load_model()
2023-04-06 16:51:33,179:INFO:load_model(model_name=Final Lightgbm Model 08Feb2020, platform=None, authentication=None, verbose=True)
2023-04-06 16:51:33,863:INFO:Initializing predict_model()
2023-04-06 16:51:33,863:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry', 'Report'],
                                    transformer=SimpleImputer(strategy='most_frequent')...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry'],
                                    transformer=OneHotEncoder(cols=['Cut',
                                                                    'Color',
                                                                    'Clarity',
                                                                    'Polish',
                                                                    'Symmetry'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', LGBMRegressor(random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x17afe0ca0>)
2023-04-06 16:51:33,863:INFO:Checking exceptions
2023-04-06 16:51:33,863:INFO:Preloading libraries
2023-04-06 16:51:33,864:INFO:Set up data.
2023-04-06 16:51:33,868:INFO:Set up index.
2023-04-06 17:03:48,745:INFO:Initializing create_model()
2023-04-06 17:03:48,747:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=catboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:03:48,747:INFO:Checking exceptions
2023-04-06 17:03:48,767:INFO:Importing libraries
2023-04-06 17:03:48,768:INFO:Copying training dataset
2023-04-06 17:03:48,772:INFO:Defining folds
2023-04-06 17:03:48,772:INFO:Declaring metric variables
2023-04-06 17:03:48,774:INFO:Importing untrained model
2023-04-06 17:03:48,776:INFO:CatBoost Regressor Imported successfully
2023-04-06 17:03:48,779:INFO:Starting cross validation
2023-04-06 17:03:48,781:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:03:56,366:INFO:Calculating mean and std
2023-04-06 17:03:56,368:INFO:Creating metrics dataframe
2023-04-06 17:03:56,371:INFO:Finalizing model
2023-04-06 17:03:56,850:INFO:Uploading results into container
2023-04-06 17:03:56,850:INFO:Uploading model into container now
2023-04-06 17:03:56,855:INFO:_master_model_container: 31
2023-04-06 17:03:56,855:INFO:_display_container: 14
2023-04-06 17:03:56,855:INFO:<catboost.core.CatBoostRegressor object at 0x17af98e80>
2023-04-06 17:03:56,855:INFO:create_model() successfully completed......................................
2023-04-06 17:04:06,139:INFO:Initializing tune_model()
2023-04-06 17:04:06,140:INFO:tune_model(estimator=<catboost.core.CatBoostRegressor object at 0x17af98e80>, fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>)
2023-04-06 17:04:06,141:INFO:Checking exceptions
2023-04-06 17:04:06,161:INFO:Copying training dataset
2023-04-06 17:04:06,165:INFO:Checking base model
2023-04-06 17:04:06,165:INFO:Base model : CatBoost Regressor
2023-04-06 17:04:06,167:INFO:Declaring metric variables
2023-04-06 17:04:06,169:INFO:Defining Hyperparameters
2023-04-06 17:04:06,254:INFO:Tuning with n_jobs=-1
2023-04-06 17:04:06,254:INFO:Initializing RandomizedSearchCV
2023-04-06 17:04:46,187:INFO:best_params: {'actual_estimator__random_strength': 0.2, 'actual_estimator__n_estimators': 180, 'actual_estimator__l2_leaf_reg': 30, 'actual_estimator__eta': 0.4, 'actual_estimator__depth': 8}
2023-04-06 17:04:46,189:INFO:Hyperparameter search completed
2023-04-06 17:04:46,189:INFO:SubProcess create_model() called ==================================
2023-04-06 17:04:46,189:INFO:Initializing create_model()
2023-04-06 17:04:46,189:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=<catboost.core.CatBoostRegressor object at 0x17ffb9280>, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x16b574a90>, model_only=True, return_train_score=False, kwargs={'random_strength': 0.2, 'n_estimators': 180, 'l2_leaf_reg': 30, 'eta': 0.4, 'depth': 8})
2023-04-06 17:04:46,189:INFO:Checking exceptions
2023-04-06 17:04:46,189:INFO:Importing libraries
2023-04-06 17:04:46,189:INFO:Copying training dataset
2023-04-06 17:04:46,193:INFO:Defining folds
2023-04-06 17:04:46,193:INFO:Declaring metric variables
2023-04-06 17:04:46,196:INFO:Importing untrained model
2023-04-06 17:04:46,196:INFO:Declaring custom model
2023-04-06 17:04:46,197:INFO:CatBoost Regressor Imported successfully
2023-04-06 17:04:46,200:INFO:Starting cross validation
2023-04-06 17:04:46,201:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:04:50,142:INFO:Calculating mean and std
2023-04-06 17:04:50,143:INFO:Creating metrics dataframe
2023-04-06 17:04:50,145:INFO:Finalizing model
2023-04-06 17:04:50,618:INFO:Uploading results into container
2023-04-06 17:04:50,618:INFO:Uploading model into container now
2023-04-06 17:04:50,619:INFO:_master_model_container: 32
2023-04-06 17:04:50,619:INFO:_display_container: 15
2023-04-06 17:04:50,619:INFO:<catboost.core.CatBoostRegressor object at 0x17b0cb640>
2023-04-06 17:04:50,619:INFO:create_model() successfully completed......................................
2023-04-06 17:04:50,707:INFO:SubProcess create_model() end ==================================
2023-04-06 17:04:50,707:INFO:choose_better activated
2023-04-06 17:04:50,709:INFO:SubProcess create_model() called ==================================
2023-04-06 17:04:50,709:INFO:Initializing create_model()
2023-04-06 17:04:50,709:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=<catboost.core.CatBoostRegressor object at 0x17af98e80>, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:04:50,709:INFO:Checking exceptions
2023-04-06 17:04:50,709:INFO:Importing libraries
2023-04-06 17:04:50,710:INFO:Copying training dataset
2023-04-06 17:04:50,712:INFO:Defining folds
2023-04-06 17:04:50,712:INFO:Declaring metric variables
2023-04-06 17:04:50,712:INFO:Importing untrained model
2023-04-06 17:04:50,712:INFO:Declaring custom model
2023-04-06 17:04:50,712:INFO:CatBoost Regressor Imported successfully
2023-04-06 17:04:50,712:INFO:Starting cross validation
2023-04-06 17:04:50,713:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:04:54,574:INFO:Calculating mean and std
2023-04-06 17:04:54,574:INFO:Creating metrics dataframe
2023-04-06 17:04:54,575:INFO:Finalizing model
2023-04-06 17:04:55,036:INFO:Uploading results into container
2023-04-06 17:04:55,037:INFO:Uploading model into container now
2023-04-06 17:04:55,037:INFO:_master_model_container: 33
2023-04-06 17:04:55,037:INFO:_display_container: 16
2023-04-06 17:04:55,037:INFO:<catboost.core.CatBoostRegressor object at 0x1789ea970>
2023-04-06 17:04:55,037:INFO:create_model() successfully completed......................................
2023-04-06 17:04:55,119:INFO:SubProcess create_model() end ==================================
2023-04-06 17:04:55,119:INFO:<catboost.core.CatBoostRegressor object at 0x1789ea970> result for R2 is 0.9807
2023-04-06 17:04:55,119:INFO:<catboost.core.CatBoostRegressor object at 0x17b0cb640> result for R2 is 0.9769
2023-04-06 17:04:55,119:INFO:<catboost.core.CatBoostRegressor object at 0x1789ea970> is best model
2023-04-06 17:04:55,119:INFO:choose_better completed
2023-04-06 17:04:55,119:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-04-06 17:04:55,123:INFO:_master_model_container: 33
2023-04-06 17:04:55,124:INFO:_display_container: 15
2023-04-06 17:04:55,124:INFO:<catboost.core.CatBoostRegressor object at 0x1789ea970>
2023-04-06 17:04:55,124:INFO:tune_model() successfully completed......................................
2023-04-06 17:05:27,075:INFO:Initializing plot_model()
2023-04-06 17:05:27,077:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=<catboost.core.CatBoostRegressor object at 0x1789ea970>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, system=True)
2023-04-06 17:05:27,077:INFO:Checking exceptions
2023-04-06 17:05:27,086:INFO:Preloading libraries
2023-04-06 17:05:27,091:INFO:Copying training dataset
2023-04-06 17:05:27,091:INFO:Plot type: residuals
2023-04-06 17:05:27,252:INFO:Fitting Model
2023-04-06 17:05:27,272:INFO:Scoring test/hold-out set
2023-04-06 17:05:27,461:INFO:Visual Rendered Successfully
2023-04-06 17:05:27,579:INFO:plot_model() successfully completed......................................
2023-04-06 17:05:40,611:INFO:Initializing plot_model()
2023-04-06 17:05:40,611:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=<catboost.core.CatBoostRegressor object at 0x1789ea970>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, system=True)
2023-04-06 17:05:40,611:INFO:Checking exceptions
2023-04-06 17:05:40,621:INFO:Preloading libraries
2023-04-06 17:05:40,623:INFO:Copying training dataset
2023-04-06 17:05:40,623:INFO:Plot type: error
2023-04-06 17:05:40,781:INFO:Fitting Model
2023-04-06 17:05:40,781:INFO:Scoring test/hold-out set
2023-04-06 17:05:40,872:INFO:Visual Rendered Successfully
2023-04-06 17:05:40,952:INFO:plot_model() successfully completed......................................
2023-04-06 17:05:53,227:INFO:Initializing plot_model()
2023-04-06 17:05:53,229:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=<catboost.core.CatBoostRegressor object at 0x1789ea970>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, system=True)
2023-04-06 17:05:53,229:INFO:Checking exceptions
2023-04-06 17:05:53,237:INFO:Preloading libraries
2023-04-06 17:05:53,238:INFO:Copying training dataset
2023-04-06 17:05:53,239:INFO:Plot type: feature
2023-04-06 17:05:53,244:WARNING:No coef_ found. Trying feature_importances_
2023-04-06 17:05:53,353:INFO:Visual Rendered Successfully
2023-04-06 17:05:53,434:INFO:plot_model() successfully completed......................................
2023-04-06 17:06:26,646:INFO:Initializing interpret_model()
2023-04-06 17:06:26,648:INFO:interpret_model(estimator=DecisionTreeRegressor(criterion='friedman_mse', max_depth=10, max_features=1.0,
                      min_impurity_decrease=0.01, min_samples_leaf=2,
                      min_samples_split=9, random_state=123), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>)
2023-04-06 17:06:26,648:INFO:Checking exceptions
2023-04-06 17:06:26,648:INFO:Soft dependency imported: shap: 0.41.0
2023-04-06 17:06:27,340:INFO:plot type: summary
2023-04-06 17:06:27,340:INFO:Creating TreeExplainer
2023-04-06 17:06:27,341:INFO:Compiling shap values
2023-04-06 17:06:27,400:WARNING:No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored

2023-04-06 17:06:27,662:INFO:Visual Rendered Successfully
2023-04-06 17:06:27,663:INFO:interpret_model() successfully completed......................................
2023-04-06 17:06:46,054:INFO:Initializing interpret_model()
2023-04-06 17:06:46,056:INFO:interpret_model(estimator=<catboost.core.CatBoostRegressor object at 0x1789ea970>, use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>)
2023-04-06 17:06:46,056:INFO:Checking exceptions
2023-04-06 17:06:46,056:INFO:Soft dependency imported: shap: 0.41.0
2023-04-06 17:06:46,117:INFO:plot type: summary
2023-04-06 17:06:46,117:INFO:Creating TreeExplainer
2023-04-06 17:06:46,117:INFO:Compiling shap values
2023-04-06 17:06:46,360:WARNING:No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored

2023-04-06 17:06:46,621:INFO:Visual Rendered Successfully
2023-04-06 17:06:46,621:INFO:interpret_model() successfully completed......................................
2023-04-06 17:07:11,058:INFO:Initializing plot_model()
2023-04-06 17:07:11,060:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=DecisionTreeRegressor(criterion='friedman_mse', max_depth=10, max_features=1.0,
                      min_impurity_decrease=0.01, min_samples_leaf=2,
                      min_samples_split=9, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, system=True)
2023-04-06 17:07:11,060:INFO:Checking exceptions
2023-04-06 17:07:11,073:INFO:Preloading libraries
2023-04-06 17:07:11,074:INFO:Copying training dataset
2023-04-06 17:07:11,074:INFO:Plot type: feature
2023-04-06 17:07:11,076:WARNING:No coef_ found. Trying feature_importances_
2023-04-06 17:07:11,200:INFO:Visual Rendered Successfully
2023-04-06 17:07:11,287:INFO:plot_model() successfully completed......................................
2023-04-06 17:15:08,174:ERROR:
'pandas_profiling' is a soft dependency and not included in the pycaret installation. Please run: `pip install pandas-profiling` to install.
Alternately, you can install this by running `pip install pycaret[analysis]`
NoneType: None
2023-04-06 17:15:41,105:ERROR:
'pandas_profiling' is a soft dependency and not included in the pycaret installation. Please run: `pip install pandas-profiling` to install.
Alternately, you can install this by running `pip install pycaret[analysis]`
NoneType: None
2023-04-06 17:15:51,241:ERROR:
'pandas_profiling' is a soft dependency and not included in the pycaret installation. Please run: `pip install pandas-profiling` to install.
Alternately, you can install this by running `pip install pycaret[analysis]`
NoneType: None
2023-04-06 17:17:33,796:INFO:Soft dependency imported: pandas_profiling: 4.1.2
2023-04-06 17:21:49,730:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-06 17:21:49,730:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-06 17:21:49,731:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-06 17:21:49,731:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-06 17:21:50,269:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-06 17:22:35,718:INFO:PyCaret RegressionExperiment
2023-04-06 17:22:35,718:INFO:Logging name: reg-default-name
2023-04-06 17:22:35,718:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-06 17:22:35,718:INFO:version 3.0.0
2023-04-06 17:22:35,718:INFO:Initializing setup()
2023-04-06 17:22:35,718:INFO:self.USI: 187f
2023-04-06 17:22:35,718:INFO:self._variable_keys: {'y', 'X', 'exp_name_log', 'logging_param', 'gpu_param', 'gpu_n_jobs_param', 'log_plots_param', 'X_train', 'X_test', 'n_jobs_param', 'y_test', 'y_train', 'idx', 'USI', 'seed', 'data', 'pipeline', '_available_plots', 'exp_id', '_ml_usecase', 'fold_groups_param', 'fold_generator', 'fold_shuffle_param', 'html_param', 'target_param', 'transform_target_param', 'memory'}
2023-04-06 17:22:35,718:INFO:Checking environment
2023-04-06 17:22:35,718:INFO:python_version: 3.9.15
2023-04-06 17:22:35,718:INFO:python_build: ('main', 'Nov 24 2022 08:28:41')
2023-04-06 17:22:35,718:INFO:machine: arm64
2023-04-06 17:22:35,718:INFO:platform: macOS-13.2-arm64-arm-64bit
2023-04-06 17:22:35,718:INFO:Memory: svmem(total=17179869184, available=4919017472, percent=71.4, used=6899171328, free=133545984, active=4807901184, inactive=4749688832, wired=2091270144)
2023-04-06 17:22:35,718:INFO:Physical Core: 10
2023-04-06 17:22:35,718:INFO:Logical Core: 10
2023-04-06 17:22:35,718:INFO:Checking libraries
2023-04-06 17:22:35,718:INFO:System:
2023-04-06 17:22:35,718:INFO:    python: 3.9.15 (main, Nov 24 2022, 08:28:41)  [Clang 14.0.6 ]
2023-04-06 17:22:35,718:INFO:executable: /Users/a06411/opt/anaconda3/bin/python
2023-04-06 17:22:35,718:INFO:   machine: macOS-13.2-arm64-arm-64bit
2023-04-06 17:22:35,718:INFO:PyCaret required dependencies:
2023-04-06 17:22:35,718:INFO:                 pip: 22.3.1
2023-04-06 17:22:35,718:INFO:          setuptools: 65.5.0
2023-04-06 17:22:35,718:INFO:             pycaret: 3.0.0
2023-04-06 17:22:35,718:INFO:             IPython: 8.7.0
2023-04-06 17:22:35,718:INFO:          ipywidgets: 7.6.5
2023-04-06 17:22:35,718:INFO:                tqdm: 4.64.1
2023-04-06 17:22:35,718:INFO:               numpy: 1.21.5
2023-04-06 17:22:35,718:INFO:              pandas: 1.4.4
2023-04-06 17:22:35,718:INFO:              jinja2: 2.11.3
2023-04-06 17:22:35,719:INFO:               scipy: 1.9.3
2023-04-06 17:22:35,719:INFO:              joblib: 1.2.0
2023-04-06 17:22:35,719:INFO:             sklearn: 1.1.3
2023-04-06 17:22:35,719:INFO:                pyod: 1.0.9
2023-04-06 17:22:35,719:INFO:            imblearn: 0.10.1
2023-04-06 17:22:35,719:INFO:   category_encoders: 2.6.0
2023-04-06 17:22:35,719:INFO:            lightgbm: 3.3.5
2023-04-06 17:22:35,719:INFO:               numba: 0.56.4
2023-04-06 17:22:35,719:INFO:            requests: 2.28.1
2023-04-06 17:22:35,719:INFO:          matplotlib: 3.6.2
2023-04-06 17:22:35,719:INFO:          scikitplot: 0.3.7
2023-04-06 17:22:35,719:INFO:         yellowbrick: 1.5
2023-04-06 17:22:35,719:INFO:              plotly: 5.9.0
2023-04-06 17:22:35,719:INFO:             kaleido: 0.2.1
2023-04-06 17:22:35,719:INFO:         statsmodels: 0.13.2
2023-04-06 17:22:35,719:INFO:              sktime: 0.16.1
2023-04-06 17:22:35,719:INFO:               tbats: 1.1.2
2023-04-06 17:22:35,719:INFO:            pmdarima: 2.0.3
2023-04-06 17:22:35,719:INFO:              psutil: 5.9.0
2023-04-06 17:22:35,719:INFO:PyCaret optional dependencies:
2023-04-06 17:22:35,723:INFO:                shap: 0.41.0
2023-04-06 17:22:35,723:INFO:           interpret: Not installed
2023-04-06 17:22:35,723:INFO:                umap: 0.5.3
2023-04-06 17:22:35,723:INFO:    pandas_profiling: 4.1.2
2023-04-06 17:22:35,723:INFO:  explainerdashboard: 0.4.2.1
2023-04-06 17:22:35,723:INFO:             autoviz: Not installed
2023-04-06 17:22:35,723:INFO:           fairlearn: Not installed
2023-04-06 17:22:35,723:INFO:             xgboost: 1.7.2
2023-04-06 17:22:35,723:INFO:            catboost: 1.1.1
2023-04-06 17:22:35,723:INFO:              kmodes: Not installed
2023-04-06 17:22:35,723:INFO:             mlxtend: Not installed
2023-04-06 17:22:35,723:INFO:       statsforecast: Not installed
2023-04-06 17:22:35,723:INFO:        tune_sklearn: Not installed
2023-04-06 17:22:35,723:INFO:                 ray: Not installed
2023-04-06 17:22:35,723:INFO:            hyperopt: 0.2.7
2023-04-06 17:22:35,723:INFO:              optuna: 3.1.0
2023-04-06 17:22:35,723:INFO:               skopt: 0.9.0
2023-04-06 17:22:35,723:INFO:              mlflow: 2.2.2
2023-04-06 17:22:35,723:INFO:              gradio: Not installed
2023-04-06 17:22:35,723:INFO:             fastapi: Not installed
2023-04-06 17:22:35,723:INFO:             uvicorn: Not installed
2023-04-06 17:22:35,723:INFO:              m2cgen: Not installed
2023-04-06 17:22:35,723:INFO:           evidently: Not installed
2023-04-06 17:22:35,723:INFO:               fugue: Not installed
2023-04-06 17:22:35,723:INFO:           streamlit: Not installed
2023-04-06 17:22:35,723:INFO:             prophet: Not installed
2023-04-06 17:22:35,723:INFO:None
2023-04-06 17:22:35,723:INFO:Set up data.
2023-04-06 17:22:35,727:INFO:Set up train/test split.
2023-04-06 17:22:35,729:INFO:Set up index.
2023-04-06 17:22:35,729:INFO:Set up folding strategy.
2023-04-06 17:22:35,729:INFO:Assigning column types.
2023-04-06 17:22:35,730:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-06 17:22:35,730:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-06 17:22:35,732:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-06 17:22:35,734:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 17:22:35,757:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 17:22:35,776:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 17:22:35,776:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:22:35,900:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:22:35,912:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-06 17:22:35,914:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-06 17:22:35,916:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 17:22:35,939:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 17:22:35,957:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 17:22:35,957:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:22:35,958:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:22:35,959:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-06 17:22:35,960:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-06 17:22:35,962:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 17:22:35,985:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 17:22:36,004:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 17:22:36,004:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:22:36,005:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:22:36,007:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-06 17:22:36,009:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 17:22:36,033:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 17:22:36,051:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 17:22:36,051:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:22:36,052:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:22:36,052:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-06 17:22:36,056:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 17:22:36,079:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 17:22:36,097:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 17:22:36,097:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:22:36,098:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:22:36,102:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 17:22:36,125:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 17:22:36,143:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 17:22:36,143:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:22:36,145:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:22:36,145:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-06 17:22:36,171:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 17:22:36,189:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 17:22:36,190:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:22:36,191:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:22:36,217:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 17:22:36,235:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 17:22:36,235:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:22:36,236:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:22:36,236:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-06 17:22:36,263:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 17:22:36,281:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:22:36,282:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:22:36,309:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 17:22:36,328:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:22:36,331:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:22:36,331:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-06 17:22:36,376:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:22:36,377:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:22:36,423:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:22:36,424:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:22:36,426:INFO:Preparing preprocessing pipeline...
2023-04-06 17:22:36,426:INFO:Set up target transformation.
2023-04-06 17:22:36,426:INFO:Set up simple imputation.
2023-04-06 17:22:36,428:INFO:Set up encoding of ordinal features.
2023-04-06 17:22:36,428:INFO:Set up encoding of categorical features.
2023-04-06 17:22:36,428:INFO:Set up removing multicollinearity.
2023-04-06 17:22:36,428:INFO:Set up binning of numerical features.
2023-04-06 17:22:36,428:INFO:Set up column transformation.
2023-04-06 17:22:36,428:INFO:Set up feature normalization.
2023-04-06 17:22:36,429:INFO:Set up column name cleaning.
2023-04-06 17:22:36,566:INFO:Finished creating preprocessing pipeline.
2023-04-06 17:22:36,577:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer'...
                ('bin_numeric_features',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=KBinsDiscretizer(encode='ordinal',
                                                                 strategy='kmeans'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-06 17:22:36,577:INFO:Creating final display dataframe.
2023-04-06 17:22:36,748:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             Price
2                   Target type        Regression
3           Original data shape         (5400, 8)
4        Transformed data shape        (5400, 28)
5   Transformed train set shape        (3779, 28)
6    Transformed test set shape        (1621, 28)
7              Ordinal features                 1
8              Numeric features                 1
9          Categorical features                 6
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16     Remove multicollinearity              True
17  Multicollinearity threshold              0.95
18               Transformation              True
19        Transformation method       yeo-johnson
20                    Normalize              True
21             Normalize method            zscore
22             Transform target              True
23      Transform target method       yeo-johnson
24               Fold Generator             KFold
25                  Fold Number                10
26                     CPU Jobs                -1
27                      Use GPU             False
28               Log Experiment             False
29              Experiment Name  reg-default-name
30                          USI              187f
2023-04-06 17:22:36,798:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:22:36,799:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:22:36,845:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:22:36,846:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:22:36,846:INFO:setup() successfully completed in 1.58s...............
2023-04-06 17:22:58,621:INFO:Initializing compare_models()
2023-04-06 17:22:58,622:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-06 17:22:58,622:INFO:Checking exceptions
2023-04-06 17:22:58,631:INFO:Preparing display monitor
2023-04-06 17:22:58,652:INFO:Initializing Linear Regression
2023-04-06 17:22:58,652:INFO:Total runtime is 2.6305516560872396e-06 minutes
2023-04-06 17:22:58,655:INFO:SubProcess create_model() called ==================================
2023-04-06 17:22:58,655:INFO:Initializing create_model()
2023-04-06 17:22:58,655:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103dc2130>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:22:58,655:INFO:Checking exceptions
2023-04-06 17:22:58,655:INFO:Importing libraries
2023-04-06 17:22:58,655:INFO:Copying training dataset
2023-04-06 17:22:58,660:INFO:Defining folds
2023-04-06 17:22:58,660:INFO:Declaring metric variables
2023-04-06 17:22:58,662:INFO:Importing untrained model
2023-04-06 17:22:58,664:INFO:Linear Regression Imported successfully
2023-04-06 17:22:58,668:INFO:Starting cross validation
2023-04-06 17:22:58,674:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:23:06,080:INFO:Calculating mean and std
2023-04-06 17:23:06,082:INFO:Creating metrics dataframe
2023-04-06 17:23:06,481:INFO:Uploading results into container
2023-04-06 17:23:06,482:INFO:Uploading model into container now
2023-04-06 17:23:06,482:INFO:_master_model_container: 1
2023-04-06 17:23:06,482:INFO:_display_container: 2
2023-04-06 17:23:06,482:INFO:LinearRegression(n_jobs=-1)
2023-04-06 17:23:06,482:INFO:create_model() successfully completed......................................
2023-04-06 17:23:06,587:INFO:SubProcess create_model() end ==================================
2023-04-06 17:23:06,587:INFO:Creating metrics dataframe
2023-04-06 17:23:06,590:INFO:Initializing Lasso Regression
2023-04-06 17:23:06,591:INFO:Total runtime is 0.13230396509170533 minutes
2023-04-06 17:23:06,592:INFO:SubProcess create_model() called ==================================
2023-04-06 17:23:06,592:INFO:Initializing create_model()
2023-04-06 17:23:06,592:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103dc2130>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:23:06,592:INFO:Checking exceptions
2023-04-06 17:23:06,592:INFO:Importing libraries
2023-04-06 17:23:06,592:INFO:Copying training dataset
2023-04-06 17:23:06,594:INFO:Defining folds
2023-04-06 17:23:06,594:INFO:Declaring metric variables
2023-04-06 17:23:06,596:INFO:Importing untrained model
2023-04-06 17:23:06,597:INFO:Lasso Regression Imported successfully
2023-04-06 17:23:06,599:INFO:Starting cross validation
2023-04-06 17:23:06,600:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:23:10,835:INFO:Calculating mean and std
2023-04-06 17:23:10,836:INFO:Creating metrics dataframe
2023-04-06 17:23:11,239:INFO:Uploading results into container
2023-04-06 17:23:11,240:INFO:Uploading model into container now
2023-04-06 17:23:11,240:INFO:_master_model_container: 2
2023-04-06 17:23:11,240:INFO:_display_container: 2
2023-04-06 17:23:11,240:INFO:Lasso(random_state=123)
2023-04-06 17:23:11,240:INFO:create_model() successfully completed......................................
2023-04-06 17:23:11,329:INFO:SubProcess create_model() end ==================================
2023-04-06 17:23:11,329:INFO:Creating metrics dataframe
2023-04-06 17:23:11,333:INFO:Initializing Ridge Regression
2023-04-06 17:23:11,333:INFO:Total runtime is 0.2113534172375997 minutes
2023-04-06 17:23:11,335:INFO:SubProcess create_model() called ==================================
2023-04-06 17:23:11,335:INFO:Initializing create_model()
2023-04-06 17:23:11,335:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103dc2130>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:23:11,335:INFO:Checking exceptions
2023-04-06 17:23:11,335:INFO:Importing libraries
2023-04-06 17:23:11,335:INFO:Copying training dataset
2023-04-06 17:23:11,337:INFO:Defining folds
2023-04-06 17:23:11,337:INFO:Declaring metric variables
2023-04-06 17:23:11,339:INFO:Importing untrained model
2023-04-06 17:23:11,340:INFO:Ridge Regression Imported successfully
2023-04-06 17:23:11,343:INFO:Starting cross validation
2023-04-06 17:23:11,344:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:23:15,376:INFO:Calculating mean and std
2023-04-06 17:23:15,377:INFO:Creating metrics dataframe
2023-04-06 17:23:15,787:INFO:Uploading results into container
2023-04-06 17:23:15,787:INFO:Uploading model into container now
2023-04-06 17:23:15,787:INFO:_master_model_container: 3
2023-04-06 17:23:15,787:INFO:_display_container: 2
2023-04-06 17:23:15,788:INFO:Ridge(random_state=123)
2023-04-06 17:23:15,788:INFO:create_model() successfully completed......................................
2023-04-06 17:23:15,879:INFO:SubProcess create_model() end ==================================
2023-04-06 17:23:15,879:INFO:Creating metrics dataframe
2023-04-06 17:23:15,883:INFO:Initializing Elastic Net
2023-04-06 17:23:15,884:INFO:Total runtime is 0.28718894720077515 minutes
2023-04-06 17:23:15,885:INFO:SubProcess create_model() called ==================================
2023-04-06 17:23:15,885:INFO:Initializing create_model()
2023-04-06 17:23:15,885:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103dc2130>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:23:15,885:INFO:Checking exceptions
2023-04-06 17:23:15,885:INFO:Importing libraries
2023-04-06 17:23:15,885:INFO:Copying training dataset
2023-04-06 17:23:15,888:INFO:Defining folds
2023-04-06 17:23:15,888:INFO:Declaring metric variables
2023-04-06 17:23:15,889:INFO:Importing untrained model
2023-04-06 17:23:15,890:INFO:Elastic Net Imported successfully
2023-04-06 17:23:15,893:INFO:Starting cross validation
2023-04-06 17:23:15,894:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:23:19,985:INFO:Calculating mean and std
2023-04-06 17:23:19,986:INFO:Creating metrics dataframe
2023-04-06 17:23:20,397:INFO:Uploading results into container
2023-04-06 17:23:20,397:INFO:Uploading model into container now
2023-04-06 17:23:20,397:INFO:_master_model_container: 4
2023-04-06 17:23:20,397:INFO:_display_container: 2
2023-04-06 17:23:20,398:INFO:ElasticNet(random_state=123)
2023-04-06 17:23:20,398:INFO:create_model() successfully completed......................................
2023-04-06 17:23:20,497:INFO:SubProcess create_model() end ==================================
2023-04-06 17:23:20,497:INFO:Creating metrics dataframe
2023-04-06 17:23:20,501:INFO:Initializing Least Angle Regression
2023-04-06 17:23:20,501:INFO:Total runtime is 0.36414484977722167 minutes
2023-04-06 17:23:20,502:INFO:SubProcess create_model() called ==================================
2023-04-06 17:23:20,502:INFO:Initializing create_model()
2023-04-06 17:23:20,502:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103dc2130>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:23:20,503:INFO:Checking exceptions
2023-04-06 17:23:20,503:INFO:Importing libraries
2023-04-06 17:23:20,503:INFO:Copying training dataset
2023-04-06 17:23:20,505:INFO:Defining folds
2023-04-06 17:23:20,505:INFO:Declaring metric variables
2023-04-06 17:23:20,506:INFO:Importing untrained model
2023-04-06 17:23:20,507:INFO:Least Angle Regression Imported successfully
2023-04-06 17:23:20,510:INFO:Starting cross validation
2023-04-06 17:23:20,511:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:23:20,682:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 17:23:20,685:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=5.022e-07, with an active set of 23 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,685:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.599e-07, with an active set of 23 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,685:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.264e-07, with an active set of 23 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,685:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.221e-07, with an active set of 23 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,695:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 17:23:20,697:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=7.522e-07, with an active set of 22 regressors, and the smallest cholesky pivot element being 8.752e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,698:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=2.079e-07, with an active set of 22 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,698:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.626e-07, with an active set of 22 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,698:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.612e-07, with an active set of 22 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,698:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 17:23:20,698:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 17:23:20,700:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.172e-06, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,700:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=3.093e-06, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,700:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=3.157e-07, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,701:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=2.754e-07, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,701:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.089e-06, with an active set of 22 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,701:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=2.588e-07, with an active set of 23 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,701:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.534e-06, with an active set of 23 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,701:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=3.535e-07, with an active set of 23 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,701:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.639e-07, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,701:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.387e-07, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,709:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 17:23:20,713:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=3.439e-07, with an active set of 24 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,713:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=3.177e-07, with an active set of 24 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,723:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 17:23:20,723:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 17:23:20,726:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=4.304e-07, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,726:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.088e-06, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,740:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 17:23:20,741:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 17:23:20,743:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.207e-06, with an active set of 22 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,743:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=4.443e-07, with an active set of 23 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,743:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.590e-07, with an active set of 23 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,743:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.505e-07, with an active set of 23 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,744:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.610e-06, with an active set of 23 regressors, and the smallest cholesky pivot element being 9.940e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:20,752:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 17:23:20,754:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=3.418e-07, with an active set of 22 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 17:23:24,687:INFO:Calculating mean and std
2023-04-06 17:23:24,688:INFO:Creating metrics dataframe
2023-04-06 17:23:25,061:INFO:Uploading results into container
2023-04-06 17:23:25,061:INFO:Uploading model into container now
2023-04-06 17:23:25,062:INFO:_master_model_container: 5
2023-04-06 17:23:25,062:INFO:_display_container: 2
2023-04-06 17:23:25,062:INFO:Lars(random_state=123)
2023-04-06 17:23:25,062:INFO:create_model() successfully completed......................................
2023-04-06 17:23:25,154:INFO:SubProcess create_model() end ==================================
2023-04-06 17:23:25,154:INFO:Creating metrics dataframe
2023-04-06 17:23:25,158:INFO:Initializing Lasso Least Angle Regression
2023-04-06 17:23:25,158:INFO:Total runtime is 0.44176859458287554 minutes
2023-04-06 17:23:25,160:INFO:SubProcess create_model() called ==================================
2023-04-06 17:23:25,160:INFO:Initializing create_model()
2023-04-06 17:23:25,160:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103dc2130>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:23:25,160:INFO:Checking exceptions
2023-04-06 17:23:25,160:INFO:Importing libraries
2023-04-06 17:23:25,160:INFO:Copying training dataset
2023-04-06 17:23:25,163:INFO:Defining folds
2023-04-06 17:23:25,163:INFO:Declaring metric variables
2023-04-06 17:23:25,164:INFO:Importing untrained model
2023-04-06 17:23:25,166:INFO:Lasso Least Angle Regression Imported successfully
2023-04-06 17:23:25,169:INFO:Starting cross validation
2023-04-06 17:23:25,170:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:23:25,342:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 17:23:25,343:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 17:23:25,349:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 17:23:25,369:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 17:23:25,376:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 17:23:25,391:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 17:23:25,392:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 17:23:25,398:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 17:23:25,430:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 17:23:25,430:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 17:23:29,330:INFO:Calculating mean and std
2023-04-06 17:23:29,331:INFO:Creating metrics dataframe
2023-04-06 17:23:29,760:INFO:Uploading results into container
2023-04-06 17:23:29,761:INFO:Uploading model into container now
2023-04-06 17:23:29,761:INFO:_master_model_container: 6
2023-04-06 17:23:29,761:INFO:_display_container: 2
2023-04-06 17:23:29,761:INFO:LassoLars(random_state=123)
2023-04-06 17:23:29,761:INFO:create_model() successfully completed......................................
2023-04-06 17:23:29,850:INFO:SubProcess create_model() end ==================================
2023-04-06 17:23:29,850:INFO:Creating metrics dataframe
2023-04-06 17:23:29,854:INFO:Initializing Orthogonal Matching Pursuit
2023-04-06 17:23:29,854:INFO:Total runtime is 0.5200272003809611 minutes
2023-04-06 17:23:29,855:INFO:SubProcess create_model() called ==================================
2023-04-06 17:23:29,855:INFO:Initializing create_model()
2023-04-06 17:23:29,855:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103dc2130>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:23:29,855:INFO:Checking exceptions
2023-04-06 17:23:29,855:INFO:Importing libraries
2023-04-06 17:23:29,855:INFO:Copying training dataset
2023-04-06 17:23:29,858:INFO:Defining folds
2023-04-06 17:23:29,858:INFO:Declaring metric variables
2023-04-06 17:23:29,859:INFO:Importing untrained model
2023-04-06 17:23:29,861:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-06 17:23:29,864:INFO:Starting cross validation
2023-04-06 17:23:29,865:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:23:30,067:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 17:23:30,067:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 17:23:30,068:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 17:23:30,074:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 17:23:30,079:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 17:23:30,082:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 17:23:30,093:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 17:23:30,119:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 17:23:30,121:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 17:23:30,138:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 17:23:34,012:INFO:Calculating mean and std
2023-04-06 17:23:34,013:INFO:Creating metrics dataframe
2023-04-06 17:23:34,419:INFO:Uploading results into container
2023-04-06 17:23:34,419:INFO:Uploading model into container now
2023-04-06 17:23:34,420:INFO:_master_model_container: 7
2023-04-06 17:23:34,420:INFO:_display_container: 2
2023-04-06 17:23:34,420:INFO:OrthogonalMatchingPursuit()
2023-04-06 17:23:34,420:INFO:create_model() successfully completed......................................
2023-04-06 17:23:34,508:INFO:SubProcess create_model() end ==================================
2023-04-06 17:23:34,508:INFO:Creating metrics dataframe
2023-04-06 17:23:34,513:INFO:Initializing Bayesian Ridge
2023-04-06 17:23:34,513:INFO:Total runtime is 0.5976743141810099 minutes
2023-04-06 17:23:34,514:INFO:SubProcess create_model() called ==================================
2023-04-06 17:23:34,514:INFO:Initializing create_model()
2023-04-06 17:23:34,514:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103dc2130>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:23:34,514:INFO:Checking exceptions
2023-04-06 17:23:34,514:INFO:Importing libraries
2023-04-06 17:23:34,514:INFO:Copying training dataset
2023-04-06 17:23:34,517:INFO:Defining folds
2023-04-06 17:23:34,517:INFO:Declaring metric variables
2023-04-06 17:23:34,518:INFO:Importing untrained model
2023-04-06 17:23:34,519:INFO:Bayesian Ridge Imported successfully
2023-04-06 17:23:34,523:INFO:Starting cross validation
2023-04-06 17:23:34,524:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:23:38,714:INFO:Calculating mean and std
2023-04-06 17:23:38,716:INFO:Creating metrics dataframe
2023-04-06 17:23:39,137:INFO:Uploading results into container
2023-04-06 17:23:39,137:INFO:Uploading model into container now
2023-04-06 17:23:39,137:INFO:_master_model_container: 8
2023-04-06 17:23:39,138:INFO:_display_container: 2
2023-04-06 17:23:39,138:INFO:BayesianRidge()
2023-04-06 17:23:39,138:INFO:create_model() successfully completed......................................
2023-04-06 17:23:39,222:INFO:SubProcess create_model() end ==================================
2023-04-06 17:23:39,222:INFO:Creating metrics dataframe
2023-04-06 17:23:39,226:INFO:Initializing Passive Aggressive Regressor
2023-04-06 17:23:39,227:INFO:Total runtime is 0.6762371778488159 minutes
2023-04-06 17:23:39,228:INFO:SubProcess create_model() called ==================================
2023-04-06 17:23:39,228:INFO:Initializing create_model()
2023-04-06 17:23:39,228:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103dc2130>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:23:39,228:INFO:Checking exceptions
2023-04-06 17:23:39,228:INFO:Importing libraries
2023-04-06 17:23:39,228:INFO:Copying training dataset
2023-04-06 17:23:39,231:INFO:Defining folds
2023-04-06 17:23:39,231:INFO:Declaring metric variables
2023-04-06 17:23:39,232:INFO:Importing untrained model
2023-04-06 17:23:39,234:INFO:Passive Aggressive Regressor Imported successfully
2023-04-06 17:23:39,237:INFO:Starting cross validation
2023-04-06 17:23:39,238:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:23:39,488:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 267, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 899, in check_array
    _assert_all_finite(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 146, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-06 17:23:39,489:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 267, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 899, in check_array
    _assert_all_finite(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 146, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-06 17:23:39,506:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 267, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 899, in check_array
    _assert_all_finite(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 146, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-06 17:23:39,517:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 267, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 899, in check_array
    _assert_all_finite(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 146, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-06 17:23:39,543:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 267, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 899, in check_array
    _assert_all_finite(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 146, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-06 17:23:39,548:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 267, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 899, in check_array
    _assert_all_finite(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 146, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-06 17:23:43,527:INFO:Calculating mean and std
2023-04-06 17:23:43,528:INFO:Creating metrics dataframe
2023-04-06 17:23:43,937:INFO:Uploading results into container
2023-04-06 17:23:43,938:INFO:Uploading model into container now
2023-04-06 17:23:43,938:INFO:_master_model_container: 9
2023-04-06 17:23:43,938:INFO:_display_container: 2
2023-04-06 17:23:43,938:INFO:PassiveAggressiveRegressor(random_state=123)
2023-04-06 17:23:43,938:INFO:create_model() successfully completed......................................
2023-04-06 17:23:44,026:WARNING:create_model() for PassiveAggressiveRegressor(random_state=123) raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-06 17:23:44,029:WARNING:Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 796, in compare_models
    assert (
AssertionError

2023-04-06 17:23:44,029:INFO:Initializing create_model()
2023-04-06 17:23:44,029:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103dc2130>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:23:44,029:INFO:Checking exceptions
2023-04-06 17:23:44,029:INFO:Importing libraries
2023-04-06 17:23:44,029:INFO:Copying training dataset
2023-04-06 17:23:44,030:INFO:Defining folds
2023-04-06 17:23:44,030:INFO:Declaring metric variables
2023-04-06 17:23:44,032:INFO:Importing untrained model
2023-04-06 17:23:44,033:INFO:Passive Aggressive Regressor Imported successfully
2023-04-06 17:23:44,036:INFO:Starting cross validation
2023-04-06 17:23:44,037:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:23:44,265:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 267, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 899, in check_array
    _assert_all_finite(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 146, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-06 17:23:44,286:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 267, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 899, in check_array
    _assert_all_finite(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 146, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-06 17:23:44,297:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 267, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 899, in check_array
    _assert_all_finite(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 146, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-06 17:23:44,305:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 267, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 899, in check_array
    _assert_all_finite(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 146, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-06 17:23:44,308:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 267, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 899, in check_array
    _assert_all_finite(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 146, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-06 17:23:44,318:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 267, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 899, in check_array
    _assert_all_finite(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 146, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-06 17:23:48,087:INFO:Calculating mean and std
2023-04-06 17:23:48,088:INFO:Creating metrics dataframe
2023-04-06 17:23:48,496:INFO:Uploading results into container
2023-04-06 17:23:48,497:INFO:Uploading model into container now
2023-04-06 17:23:48,497:INFO:_master_model_container: 10
2023-04-06 17:23:48,497:INFO:_display_container: 2
2023-04-06 17:23:48,497:INFO:PassiveAggressiveRegressor(random_state=123)
2023-04-06 17:23:48,497:INFO:create_model() successfully completed......................................
2023-04-06 17:23:48,584:ERROR:create_model() for PassiveAggressiveRegressor(random_state=123) raised an exception or returned all 0.0:
2023-04-06 17:23:48,584:ERROR:Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 796, in compare_models
    assert (
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 812, in compare_models
    assert (
AssertionError

2023-04-06 17:23:48,584:INFO:Initializing Huber Regressor
2023-04-06 17:23:48,584:INFO:Total runtime is 0.832192595799764 minutes
2023-04-06 17:23:48,585:INFO:SubProcess create_model() called ==================================
2023-04-06 17:23:48,585:INFO:Initializing create_model()
2023-04-06 17:23:48,585:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103dc2130>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:23:48,585:INFO:Checking exceptions
2023-04-06 17:23:48,586:INFO:Importing libraries
2023-04-06 17:23:48,586:INFO:Copying training dataset
2023-04-06 17:23:48,587:INFO:Defining folds
2023-04-06 17:23:48,587:INFO:Declaring metric variables
2023-04-06 17:23:48,589:INFO:Importing untrained model
2023-04-06 17:23:48,590:INFO:Huber Regressor Imported successfully
2023-04-06 17:23:48,592:INFO:Starting cross validation
2023-04-06 17:23:48,593:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:23:52,631:INFO:Calculating mean and std
2023-04-06 17:23:52,632:INFO:Creating metrics dataframe
2023-04-06 17:23:53,026:INFO:Uploading results into container
2023-04-06 17:23:53,026:INFO:Uploading model into container now
2023-04-06 17:23:53,026:INFO:_master_model_container: 11
2023-04-06 17:23:53,026:INFO:_display_container: 2
2023-04-06 17:23:53,026:INFO:HuberRegressor()
2023-04-06 17:23:53,026:INFO:create_model() successfully completed......................................
2023-04-06 17:23:53,112:INFO:SubProcess create_model() end ==================================
2023-04-06 17:23:53,112:INFO:Creating metrics dataframe
2023-04-06 17:23:53,117:INFO:Initializing K Neighbors Regressor
2023-04-06 17:23:53,117:INFO:Total runtime is 0.9077428301175435 minutes
2023-04-06 17:23:53,118:INFO:SubProcess create_model() called ==================================
2023-04-06 17:23:53,118:INFO:Initializing create_model()
2023-04-06 17:23:53,118:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103dc2130>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:23:53,118:INFO:Checking exceptions
2023-04-06 17:23:53,118:INFO:Importing libraries
2023-04-06 17:23:53,118:INFO:Copying training dataset
2023-04-06 17:23:53,120:INFO:Defining folds
2023-04-06 17:23:53,121:INFO:Declaring metric variables
2023-04-06 17:23:53,122:INFO:Importing untrained model
2023-04-06 17:23:53,123:INFO:K Neighbors Regressor Imported successfully
2023-04-06 17:23:53,125:INFO:Starting cross validation
2023-04-06 17:23:53,126:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:23:57,049:INFO:Calculating mean and std
2023-04-06 17:23:57,050:INFO:Creating metrics dataframe
2023-04-06 17:23:57,453:INFO:Uploading results into container
2023-04-06 17:23:57,454:INFO:Uploading model into container now
2023-04-06 17:23:57,454:INFO:_master_model_container: 12
2023-04-06 17:23:57,454:INFO:_display_container: 2
2023-04-06 17:23:57,454:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-06 17:23:57,454:INFO:create_model() successfully completed......................................
2023-04-06 17:23:57,539:INFO:SubProcess create_model() end ==================================
2023-04-06 17:23:57,540:INFO:Creating metrics dataframe
2023-04-06 17:23:57,544:INFO:Initializing Decision Tree Regressor
2023-04-06 17:23:57,544:INFO:Total runtime is 0.981529446442922 minutes
2023-04-06 17:23:57,545:INFO:SubProcess create_model() called ==================================
2023-04-06 17:23:57,545:INFO:Initializing create_model()
2023-04-06 17:23:57,545:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103dc2130>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:23:57,545:INFO:Checking exceptions
2023-04-06 17:23:57,545:INFO:Importing libraries
2023-04-06 17:23:57,546:INFO:Copying training dataset
2023-04-06 17:23:57,548:INFO:Defining folds
2023-04-06 17:23:57,548:INFO:Declaring metric variables
2023-04-06 17:23:57,549:INFO:Importing untrained model
2023-04-06 17:23:57,550:INFO:Decision Tree Regressor Imported successfully
2023-04-06 17:23:57,552:INFO:Starting cross validation
2023-04-06 17:23:57,553:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:24:01,722:INFO:Calculating mean and std
2023-04-06 17:24:01,723:INFO:Creating metrics dataframe
2023-04-06 17:24:02,129:INFO:Uploading results into container
2023-04-06 17:24:02,130:INFO:Uploading model into container now
2023-04-06 17:24:02,130:INFO:_master_model_container: 13
2023-04-06 17:24:02,130:INFO:_display_container: 2
2023-04-06 17:24:02,130:INFO:DecisionTreeRegressor(random_state=123)
2023-04-06 17:24:02,130:INFO:create_model() successfully completed......................................
2023-04-06 17:24:02,219:INFO:SubProcess create_model() end ==================================
2023-04-06 17:24:02,219:INFO:Creating metrics dataframe
2023-04-06 17:24:02,223:INFO:Initializing Random Forest Regressor
2023-04-06 17:24:02,223:INFO:Total runtime is 1.0595136443773905 minutes
2023-04-06 17:24:02,224:INFO:SubProcess create_model() called ==================================
2023-04-06 17:24:02,224:INFO:Initializing create_model()
2023-04-06 17:24:02,224:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103dc2130>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:24:02,225:INFO:Checking exceptions
2023-04-06 17:24:02,225:INFO:Importing libraries
2023-04-06 17:24:02,225:INFO:Copying training dataset
2023-04-06 17:24:02,227:INFO:Defining folds
2023-04-06 17:24:02,227:INFO:Declaring metric variables
2023-04-06 17:24:02,228:INFO:Importing untrained model
2023-04-06 17:24:02,230:INFO:Random Forest Regressor Imported successfully
2023-04-06 17:24:02,233:INFO:Starting cross validation
2023-04-06 17:24:02,235:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:24:07,063:INFO:Calculating mean and std
2023-04-06 17:24:07,064:INFO:Creating metrics dataframe
2023-04-06 17:24:07,478:INFO:Uploading results into container
2023-04-06 17:24:07,479:INFO:Uploading model into container now
2023-04-06 17:24:07,479:INFO:_master_model_container: 14
2023-04-06 17:24:07,479:INFO:_display_container: 2
2023-04-06 17:24:07,479:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-04-06 17:24:07,479:INFO:create_model() successfully completed......................................
2023-04-06 17:24:07,567:INFO:SubProcess create_model() end ==================================
2023-04-06 17:24:07,567:INFO:Creating metrics dataframe
2023-04-06 17:24:07,572:INFO:Initializing Extra Trees Regressor
2023-04-06 17:24:07,572:INFO:Total runtime is 1.1486610968907673 minutes
2023-04-06 17:24:07,573:INFO:SubProcess create_model() called ==================================
2023-04-06 17:24:07,573:INFO:Initializing create_model()
2023-04-06 17:24:07,574:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103dc2130>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:24:07,574:INFO:Checking exceptions
2023-04-06 17:24:07,574:INFO:Importing libraries
2023-04-06 17:24:07,574:INFO:Copying training dataset
2023-04-06 17:24:07,577:INFO:Defining folds
2023-04-06 17:24:07,577:INFO:Declaring metric variables
2023-04-06 17:24:07,578:INFO:Importing untrained model
2023-04-06 17:24:07,580:INFO:Extra Trees Regressor Imported successfully
2023-04-06 17:24:07,582:INFO:Starting cross validation
2023-04-06 17:24:07,583:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:24:12,502:INFO:Calculating mean and std
2023-04-06 17:24:12,503:INFO:Creating metrics dataframe
2023-04-06 17:24:12,912:INFO:Uploading results into container
2023-04-06 17:24:12,912:INFO:Uploading model into container now
2023-04-06 17:24:12,913:INFO:_master_model_container: 15
2023-04-06 17:24:12,913:INFO:_display_container: 2
2023-04-06 17:24:12,913:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-04-06 17:24:12,913:INFO:create_model() successfully completed......................................
2023-04-06 17:24:13,000:INFO:SubProcess create_model() end ==================================
2023-04-06 17:24:13,001:INFO:Creating metrics dataframe
2023-04-06 17:24:13,005:INFO:Initializing AdaBoost Regressor
2023-04-06 17:24:13,005:INFO:Total runtime is 1.2392182826995848 minutes
2023-04-06 17:24:13,007:INFO:SubProcess create_model() called ==================================
2023-04-06 17:24:13,007:INFO:Initializing create_model()
2023-04-06 17:24:13,007:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103dc2130>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:24:13,007:INFO:Checking exceptions
2023-04-06 17:24:13,007:INFO:Importing libraries
2023-04-06 17:24:13,007:INFO:Copying training dataset
2023-04-06 17:24:13,010:INFO:Defining folds
2023-04-06 17:24:13,010:INFO:Declaring metric variables
2023-04-06 17:24:13,011:INFO:Importing untrained model
2023-04-06 17:24:13,013:INFO:AdaBoost Regressor Imported successfully
2023-04-06 17:24:13,016:INFO:Starting cross validation
2023-04-06 17:24:13,017:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:24:17,531:INFO:Calculating mean and std
2023-04-06 17:24:17,531:INFO:Creating metrics dataframe
2023-04-06 17:24:17,937:INFO:Uploading results into container
2023-04-06 17:24:17,937:INFO:Uploading model into container now
2023-04-06 17:24:17,938:INFO:_master_model_container: 16
2023-04-06 17:24:17,938:INFO:_display_container: 2
2023-04-06 17:24:17,938:INFO:AdaBoostRegressor(random_state=123)
2023-04-06 17:24:17,938:INFO:create_model() successfully completed......................................
2023-04-06 17:24:18,028:INFO:SubProcess create_model() end ==================================
2023-04-06 17:24:18,028:INFO:Creating metrics dataframe
2023-04-06 17:24:18,034:INFO:Initializing Gradient Boosting Regressor
2023-04-06 17:24:18,034:INFO:Total runtime is 1.32302801211675 minutes
2023-04-06 17:24:18,036:INFO:SubProcess create_model() called ==================================
2023-04-06 17:24:18,036:INFO:Initializing create_model()
2023-04-06 17:24:18,036:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103dc2130>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:24:18,036:INFO:Checking exceptions
2023-04-06 17:24:18,036:INFO:Importing libraries
2023-04-06 17:24:18,036:INFO:Copying training dataset
2023-04-06 17:24:18,039:INFO:Defining folds
2023-04-06 17:24:18,039:INFO:Declaring metric variables
2023-04-06 17:24:18,040:INFO:Importing untrained model
2023-04-06 17:24:18,042:INFO:Gradient Boosting Regressor Imported successfully
2023-04-06 17:24:18,045:INFO:Starting cross validation
2023-04-06 17:24:18,046:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:24:22,503:INFO:Calculating mean and std
2023-04-06 17:24:22,504:INFO:Creating metrics dataframe
2023-04-06 17:24:22,926:INFO:Uploading results into container
2023-04-06 17:24:22,926:INFO:Uploading model into container now
2023-04-06 17:24:22,927:INFO:_master_model_container: 17
2023-04-06 17:24:22,927:INFO:_display_container: 2
2023-04-06 17:24:22,927:INFO:GradientBoostingRegressor(random_state=123)
2023-04-06 17:24:22,927:INFO:create_model() successfully completed......................................
2023-04-06 17:24:23,013:INFO:SubProcess create_model() end ==================================
2023-04-06 17:24:23,013:INFO:Creating metrics dataframe
2023-04-06 17:24:23,018:INFO:Initializing Extreme Gradient Boosting
2023-04-06 17:24:23,018:INFO:Total runtime is 1.406098131338755 minutes
2023-04-06 17:24:23,020:INFO:SubProcess create_model() called ==================================
2023-04-06 17:24:23,020:INFO:Initializing create_model()
2023-04-06 17:24:23,020:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103dc2130>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:24:23,020:INFO:Checking exceptions
2023-04-06 17:24:23,020:INFO:Importing libraries
2023-04-06 17:24:23,020:INFO:Copying training dataset
2023-04-06 17:24:23,022:INFO:Defining folds
2023-04-06 17:24:23,023:INFO:Declaring metric variables
2023-04-06 17:24:23,024:INFO:Importing untrained model
2023-04-06 17:24:23,026:INFO:Extreme Gradient Boosting Imported successfully
2023-04-06 17:24:23,028:INFO:Starting cross validation
2023-04-06 17:24:23,029:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:24:27,515:INFO:Calculating mean and std
2023-04-06 17:24:27,515:INFO:Creating metrics dataframe
2023-04-06 17:24:27,936:INFO:Uploading results into container
2023-04-06 17:24:27,936:INFO:Uploading model into container now
2023-04-06 17:24:27,937:INFO:_master_model_container: 18
2023-04-06 17:24:27,937:INFO:_display_container: 2
2023-04-06 17:24:27,937:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=123, ...)
2023-04-06 17:24:27,937:INFO:create_model() successfully completed......................................
2023-04-06 17:24:28,025:INFO:SubProcess create_model() end ==================================
2023-04-06 17:24:28,025:INFO:Creating metrics dataframe
2023-04-06 17:24:28,030:INFO:Initializing Light Gradient Boosting Machine
2023-04-06 17:24:28,030:INFO:Total runtime is 1.4896260301272073 minutes
2023-04-06 17:24:28,031:INFO:SubProcess create_model() called ==================================
2023-04-06 17:24:28,031:INFO:Initializing create_model()
2023-04-06 17:24:28,031:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103dc2130>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:24:28,031:INFO:Checking exceptions
2023-04-06 17:24:28,031:INFO:Importing libraries
2023-04-06 17:24:28,031:INFO:Copying training dataset
2023-04-06 17:24:28,034:INFO:Defining folds
2023-04-06 17:24:28,034:INFO:Declaring metric variables
2023-04-06 17:24:28,035:INFO:Importing untrained model
2023-04-06 17:24:28,036:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-06 17:24:28,039:INFO:Starting cross validation
2023-04-06 17:24:28,040:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:24:32,813:INFO:Calculating mean and std
2023-04-06 17:24:32,814:INFO:Creating metrics dataframe
2023-04-06 17:24:33,220:INFO:Uploading results into container
2023-04-06 17:24:33,221:INFO:Uploading model into container now
2023-04-06 17:24:33,221:INFO:_master_model_container: 19
2023-04-06 17:24:33,222:INFO:_display_container: 2
2023-04-06 17:24:33,222:INFO:LGBMRegressor(random_state=123)
2023-04-06 17:24:33,222:INFO:create_model() successfully completed......................................
2023-04-06 17:24:33,310:INFO:SubProcess create_model() end ==================================
2023-04-06 17:24:33,310:INFO:Creating metrics dataframe
2023-04-06 17:24:33,315:INFO:Initializing CatBoost Regressor
2023-04-06 17:24:33,315:INFO:Total runtime is 1.5777198950449625 minutes
2023-04-06 17:24:33,317:INFO:SubProcess create_model() called ==================================
2023-04-06 17:24:33,317:INFO:Initializing create_model()
2023-04-06 17:24:33,317:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103dc2130>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:24:33,317:INFO:Checking exceptions
2023-04-06 17:24:33,317:INFO:Importing libraries
2023-04-06 17:24:33,317:INFO:Copying training dataset
2023-04-06 17:24:33,319:INFO:Defining folds
2023-04-06 17:24:33,319:INFO:Declaring metric variables
2023-04-06 17:24:33,321:INFO:Importing untrained model
2023-04-06 17:24:33,322:INFO:CatBoost Regressor Imported successfully
2023-04-06 17:24:33,325:INFO:Starting cross validation
2023-04-06 17:24:33,326:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:24:39,034:INFO:Calculating mean and std
2023-04-06 17:24:39,034:INFO:Creating metrics dataframe
2023-04-06 17:24:39,470:INFO:Uploading results into container
2023-04-06 17:24:39,471:INFO:Uploading model into container now
2023-04-06 17:24:39,471:INFO:_master_model_container: 20
2023-04-06 17:24:39,471:INFO:_display_container: 2
2023-04-06 17:24:39,472:INFO:<catboost.core.CatBoostRegressor object at 0x283db4760>
2023-04-06 17:24:39,472:INFO:create_model() successfully completed......................................
2023-04-06 17:24:39,565:INFO:SubProcess create_model() end ==================================
2023-04-06 17:24:39,565:INFO:Creating metrics dataframe
2023-04-06 17:24:39,571:INFO:Initializing Dummy Regressor
2023-04-06 17:24:39,571:INFO:Total runtime is 1.681976815064748 minutes
2023-04-06 17:24:39,572:INFO:SubProcess create_model() called ==================================
2023-04-06 17:24:39,573:INFO:Initializing create_model()
2023-04-06 17:24:39,573:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x103dc2130>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:24:39,573:INFO:Checking exceptions
2023-04-06 17:24:39,573:INFO:Importing libraries
2023-04-06 17:24:39,573:INFO:Copying training dataset
2023-04-06 17:24:39,576:INFO:Defining folds
2023-04-06 17:24:39,576:INFO:Declaring metric variables
2023-04-06 17:24:39,578:INFO:Importing untrained model
2023-04-06 17:24:39,580:INFO:Dummy Regressor Imported successfully
2023-04-06 17:24:39,582:INFO:Starting cross validation
2023-04-06 17:24:39,583:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:24:43,897:INFO:Calculating mean and std
2023-04-06 17:24:43,900:INFO:Creating metrics dataframe
2023-04-06 17:24:44,321:INFO:Uploading results into container
2023-04-06 17:24:44,322:INFO:Uploading model into container now
2023-04-06 17:24:44,322:INFO:_master_model_container: 21
2023-04-06 17:24:44,322:INFO:_display_container: 2
2023-04-06 17:24:44,322:INFO:DummyRegressor()
2023-04-06 17:24:44,322:INFO:create_model() successfully completed......................................
2023-04-06 17:24:44,411:INFO:SubProcess create_model() end ==================================
2023-04-06 17:24:44,411:INFO:Creating metrics dataframe
2023-04-06 17:24:44,420:INFO:Initializing create_model()
2023-04-06 17:24:44,420:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:24:44,420:INFO:Checking exceptions
2023-04-06 17:24:44,421:INFO:Importing libraries
2023-04-06 17:24:44,421:INFO:Copying training dataset
2023-04-06 17:24:44,423:INFO:Defining folds
2023-04-06 17:24:44,423:INFO:Declaring metric variables
2023-04-06 17:24:44,423:INFO:Importing untrained model
2023-04-06 17:24:44,423:INFO:Declaring custom model
2023-04-06 17:24:44,423:INFO:Gradient Boosting Regressor Imported successfully
2023-04-06 17:24:44,424:INFO:Cross validation set to False
2023-04-06 17:24:44,424:INFO:Fitting Model
2023-04-06 17:24:45,189:INFO:GradientBoostingRegressor(random_state=123)
2023-04-06 17:24:45,189:INFO:create_model() successfully completed......................................
2023-04-06 17:24:45,287:INFO:_master_model_container: 21
2023-04-06 17:24:45,287:INFO:_display_container: 2
2023-04-06 17:24:45,287:INFO:GradientBoostingRegressor(random_state=123)
2023-04-06 17:24:45,287:INFO:compare_models() successfully completed......................................
2023-04-06 17:24:45,291:INFO:Initializing create_model()
2023-04-06 17:24:45,291:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=dt, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:24:45,291:INFO:Checking exceptions
2023-04-06 17:24:45,299:INFO:Importing libraries
2023-04-06 17:24:45,301:INFO:Copying training dataset
2023-04-06 17:24:45,307:INFO:Defining folds
2023-04-06 17:24:45,307:INFO:Declaring metric variables
2023-04-06 17:24:45,309:INFO:Importing untrained model
2023-04-06 17:24:45,311:INFO:Decision Tree Regressor Imported successfully
2023-04-06 17:24:45,315:INFO:Starting cross validation
2023-04-06 17:24:45,316:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:24:47,234:INFO:Calculating mean and std
2023-04-06 17:24:47,235:INFO:Creating metrics dataframe
2023-04-06 17:24:47,237:INFO:Finalizing model
2023-04-06 17:24:47,844:INFO:Uploading results into container
2023-04-06 17:24:47,844:INFO:Uploading model into container now
2023-04-06 17:24:47,848:INFO:_master_model_container: 22
2023-04-06 17:24:47,848:INFO:_display_container: 3
2023-04-06 17:24:47,848:INFO:DecisionTreeRegressor(random_state=123)
2023-04-06 17:24:47,848:INFO:create_model() successfully completed......................................
2023-04-06 17:24:47,939:INFO:Initializing create_model()
2023-04-06 17:24:47,939:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=dt, fold=5, round=2, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:24:47,940:INFO:Checking exceptions
2023-04-06 17:24:47,946:INFO:Importing libraries
2023-04-06 17:24:47,946:INFO:Copying training dataset
2023-04-06 17:24:47,949:INFO:Defining folds
2023-04-06 17:24:47,949:INFO:Declaring metric variables
2023-04-06 17:24:47,951:INFO:Importing untrained model
2023-04-06 17:24:47,952:INFO:Decision Tree Regressor Imported successfully
2023-04-06 17:24:47,955:INFO:Starting cross validation
2023-04-06 17:24:47,956:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:24:49,905:INFO:Calculating mean and std
2023-04-06 17:24:49,906:INFO:Creating metrics dataframe
2023-04-06 17:24:49,908:INFO:Finalizing model
2023-04-06 17:24:50,488:INFO:Uploading results into container
2023-04-06 17:24:50,489:INFO:Uploading model into container now
2023-04-06 17:24:50,493:INFO:_master_model_container: 23
2023-04-06 17:24:50,493:INFO:_display_container: 4
2023-04-06 17:24:50,493:INFO:DecisionTreeRegressor(random_state=123)
2023-04-06 17:24:50,493:INFO:create_model() successfully completed......................................
2023-04-06 17:24:50,587:INFO:Initializing tune_model()
2023-04-06 17:24:50,587:INFO:tune_model(estimator=knn, fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>)
2023-04-06 17:24:50,587:INFO:Checking exceptions
2023-04-06 17:25:43,763:INFO:Initializing create_model()
2023-04-06 17:25:43,766:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=knn, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:25:43,767:INFO:Checking exceptions
2023-04-06 17:25:43,783:INFO:Importing libraries
2023-04-06 17:25:43,784:INFO:Copying training dataset
2023-04-06 17:25:43,789:INFO:Defining folds
2023-04-06 17:25:43,789:INFO:Declaring metric variables
2023-04-06 17:25:43,791:INFO:Importing untrained model
2023-04-06 17:25:43,793:INFO:K Neighbors Regressor Imported successfully
2023-04-06 17:25:43,796:INFO:Starting cross validation
2023-04-06 17:25:43,798:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:25:45,748:INFO:Calculating mean and std
2023-04-06 17:25:45,749:INFO:Creating metrics dataframe
2023-04-06 17:25:45,752:INFO:Finalizing model
2023-04-06 17:25:46,312:INFO:Uploading results into container
2023-04-06 17:25:46,313:INFO:Uploading model into container now
2023-04-06 17:25:46,316:INFO:_master_model_container: 24
2023-04-06 17:25:46,316:INFO:_display_container: 5
2023-04-06 17:25:46,317:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-06 17:25:46,317:INFO:create_model() successfully completed......................................
2023-04-06 17:25:52,104:INFO:Initializing tune_model()
2023-04-06 17:25:52,105:INFO:tune_model(estimator=KNeighborsRegressor(n_jobs=-1), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>)
2023-04-06 17:25:52,105:INFO:Checking exceptions
2023-04-06 17:25:52,122:INFO:Copying training dataset
2023-04-06 17:25:52,126:INFO:Checking base model
2023-04-06 17:25:52,126:INFO:Base model : K Neighbors Regressor
2023-04-06 17:25:52,128:INFO:Declaring metric variables
2023-04-06 17:25:52,130:INFO:Defining Hyperparameters
2023-04-06 17:25:52,246:INFO:Tuning with n_jobs=-1
2023-04-06 17:25:52,246:INFO:Initializing RandomizedSearchCV
2023-04-06 17:26:32,297:INFO:best_params: {'actual_estimator__weights': 'distance', 'actual_estimator__n_neighbors': 13, 'actual_estimator__metric': 'manhattan'}
2023-04-06 17:26:32,298:INFO:Hyperparameter search completed
2023-04-06 17:26:32,298:INFO:SubProcess create_model() called ==================================
2023-04-06 17:26:32,298:INFO:Initializing create_model()
2023-04-06 17:26:32,298:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=KNeighborsRegressor(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x283d9af70>, model_only=True, return_train_score=False, kwargs={'weights': 'distance', 'n_neighbors': 13, 'metric': 'manhattan'})
2023-04-06 17:26:32,298:INFO:Checking exceptions
2023-04-06 17:26:32,298:INFO:Importing libraries
2023-04-06 17:26:32,298:INFO:Copying training dataset
2023-04-06 17:26:32,301:INFO:Defining folds
2023-04-06 17:26:32,301:INFO:Declaring metric variables
2023-04-06 17:26:32,303:INFO:Importing untrained model
2023-04-06 17:26:32,303:INFO:Declaring custom model
2023-04-06 17:26:32,304:INFO:K Neighbors Regressor Imported successfully
2023-04-06 17:26:32,307:INFO:Starting cross validation
2023-04-06 17:26:32,309:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:26:36,899:INFO:Calculating mean and std
2023-04-06 17:26:36,900:INFO:Creating metrics dataframe
2023-04-06 17:26:36,902:INFO:Finalizing model
2023-04-06 17:26:37,508:INFO:Uploading results into container
2023-04-06 17:26:37,508:INFO:Uploading model into container now
2023-04-06 17:26:37,509:INFO:_master_model_container: 25
2023-04-06 17:26:37,509:INFO:_display_container: 6
2023-04-06 17:26:37,509:INFO:KNeighborsRegressor(metric='manhattan', n_jobs=-1, n_neighbors=13,
                    weights='distance')
2023-04-06 17:26:37,509:INFO:create_model() successfully completed......................................
2023-04-06 17:26:37,617:INFO:SubProcess create_model() end ==================================
2023-04-06 17:26:37,618:INFO:choose_better activated
2023-04-06 17:26:37,619:INFO:SubProcess create_model() called ==================================
2023-04-06 17:26:37,620:INFO:Initializing create_model()
2023-04-06 17:26:37,620:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=KNeighborsRegressor(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:26:37,620:INFO:Checking exceptions
2023-04-06 17:26:37,621:INFO:Importing libraries
2023-04-06 17:26:37,621:INFO:Copying training dataset
2023-04-06 17:26:37,623:INFO:Defining folds
2023-04-06 17:26:37,623:INFO:Declaring metric variables
2023-04-06 17:26:37,623:INFO:Importing untrained model
2023-04-06 17:26:37,624:INFO:Declaring custom model
2023-04-06 17:26:37,624:INFO:K Neighbors Regressor Imported successfully
2023-04-06 17:26:37,624:INFO:Starting cross validation
2023-04-06 17:26:37,625:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:26:41,995:INFO:Calculating mean and std
2023-04-06 17:26:41,996:INFO:Creating metrics dataframe
2023-04-06 17:26:41,996:INFO:Finalizing model
2023-04-06 17:26:42,606:INFO:Uploading results into container
2023-04-06 17:26:42,607:INFO:Uploading model into container now
2023-04-06 17:26:42,607:INFO:_master_model_container: 26
2023-04-06 17:26:42,607:INFO:_display_container: 7
2023-04-06 17:26:42,607:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-06 17:26:42,607:INFO:create_model() successfully completed......................................
2023-04-06 17:26:42,712:INFO:SubProcess create_model() end ==================================
2023-04-06 17:26:42,713:INFO:KNeighborsRegressor(n_jobs=-1) result for R2 is 0.4787
2023-04-06 17:26:42,713:INFO:KNeighborsRegressor(metric='manhattan', n_jobs=-1, n_neighbors=13,
                    weights='distance') result for R2 is 0.6353
2023-04-06 17:26:42,713:INFO:KNeighborsRegressor(metric='manhattan', n_jobs=-1, n_neighbors=13,
                    weights='distance') is best model
2023-04-06 17:26:42,713:INFO:choose_better completed
2023-04-06 17:26:42,717:INFO:_master_model_container: 26
2023-04-06 17:26:42,717:INFO:_display_container: 6
2023-04-06 17:26:42,717:INFO:KNeighborsRegressor(metric='manhattan', n_jobs=-1, n_neighbors=13,
                    weights='distance')
2023-04-06 17:26:42,717:INFO:tune_model() successfully completed......................................
2023-04-06 17:26:43,214:INFO:Initializing tune_model()
2023-04-06 17:26:43,215:INFO:tune_model(estimator=KNeighborsRegressor(n_jobs=-1), fold=None, round=4, n_iter=25, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>)
2023-04-06 17:26:43,215:INFO:Checking exceptions
2023-04-06 17:26:43,222:INFO:Copying training dataset
2023-04-06 17:26:43,225:INFO:Checking base model
2023-04-06 17:26:43,225:INFO:Base model : K Neighbors Regressor
2023-04-06 17:26:43,227:INFO:Declaring metric variables
2023-04-06 17:26:43,229:INFO:Defining Hyperparameters
2023-04-06 17:26:43,337:INFO:Tuning with n_jobs=-1
2023-04-06 17:26:43,337:INFO:Initializing RandomizedSearchCV
2023-04-06 17:28:21,377:INFO:best_params: {'actual_estimator__weights': 'distance', 'actual_estimator__n_neighbors': 6, 'actual_estimator__metric': 'euclidean'}
2023-04-06 17:28:21,378:INFO:Hyperparameter search completed
2023-04-06 17:28:21,378:INFO:SubProcess create_model() called ==================================
2023-04-06 17:28:21,378:INFO:Initializing create_model()
2023-04-06 17:28:21,379:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=KNeighborsRegressor(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x2817afac0>, model_only=True, return_train_score=False, kwargs={'weights': 'distance', 'n_neighbors': 6, 'metric': 'euclidean'})
2023-04-06 17:28:21,379:INFO:Checking exceptions
2023-04-06 17:28:21,379:INFO:Importing libraries
2023-04-06 17:28:21,379:INFO:Copying training dataset
2023-04-06 17:28:21,381:INFO:Defining folds
2023-04-06 17:28:21,381:INFO:Declaring metric variables
2023-04-06 17:28:21,383:INFO:Importing untrained model
2023-04-06 17:28:21,383:INFO:Declaring custom model
2023-04-06 17:28:21,385:INFO:K Neighbors Regressor Imported successfully
2023-04-06 17:28:21,388:INFO:Starting cross validation
2023-04-06 17:28:21,389:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:28:25,691:INFO:Calculating mean and std
2023-04-06 17:28:25,691:INFO:Creating metrics dataframe
2023-04-06 17:28:25,694:INFO:Finalizing model
2023-04-06 17:28:26,299:INFO:Uploading results into container
2023-04-06 17:28:26,299:INFO:Uploading model into container now
2023-04-06 17:28:26,299:INFO:_master_model_container: 27
2023-04-06 17:28:26,299:INFO:_display_container: 7
2023-04-06 17:28:26,300:INFO:KNeighborsRegressor(metric='euclidean', n_jobs=-1, n_neighbors=6,
                    weights='distance')
2023-04-06 17:28:26,300:INFO:create_model() successfully completed......................................
2023-04-06 17:28:26,402:INFO:SubProcess create_model() end ==================================
2023-04-06 17:28:26,403:INFO:choose_better activated
2023-04-06 17:28:26,404:INFO:SubProcess create_model() called ==================================
2023-04-06 17:28:26,404:INFO:Initializing create_model()
2023-04-06 17:28:26,404:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=KNeighborsRegressor(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:28:26,404:INFO:Checking exceptions
2023-04-06 17:28:26,405:INFO:Importing libraries
2023-04-06 17:28:26,405:INFO:Copying training dataset
2023-04-06 17:28:26,407:INFO:Defining folds
2023-04-06 17:28:26,407:INFO:Declaring metric variables
2023-04-06 17:28:26,408:INFO:Importing untrained model
2023-04-06 17:28:26,408:INFO:Declaring custom model
2023-04-06 17:28:26,408:INFO:K Neighbors Regressor Imported successfully
2023-04-06 17:28:26,408:INFO:Starting cross validation
2023-04-06 17:28:26,409:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:28:30,692:INFO:Calculating mean and std
2023-04-06 17:28:30,692:INFO:Creating metrics dataframe
2023-04-06 17:28:30,693:INFO:Finalizing model
2023-04-06 17:28:31,275:INFO:Uploading results into container
2023-04-06 17:28:31,276:INFO:Uploading model into container now
2023-04-06 17:28:31,276:INFO:_master_model_container: 28
2023-04-06 17:28:31,276:INFO:_display_container: 8
2023-04-06 17:28:31,276:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-06 17:28:31,276:INFO:create_model() successfully completed......................................
2023-04-06 17:28:31,387:INFO:SubProcess create_model() end ==================================
2023-04-06 17:28:31,387:INFO:KNeighborsRegressor(n_jobs=-1) result for R2 is 0.4787
2023-04-06 17:28:31,387:INFO:KNeighborsRegressor(metric='euclidean', n_jobs=-1, n_neighbors=6,
                    weights='distance') result for R2 is 0.6419
2023-04-06 17:28:31,388:INFO:KNeighborsRegressor(metric='euclidean', n_jobs=-1, n_neighbors=6,
                    weights='distance') is best model
2023-04-06 17:28:31,388:INFO:choose_better completed
2023-04-06 17:28:31,392:INFO:_master_model_container: 28
2023-04-06 17:28:31,392:INFO:_display_container: 7
2023-04-06 17:28:31,392:INFO:KNeighborsRegressor(metric='euclidean', n_jobs=-1, n_neighbors=6,
                    weights='distance')
2023-04-06 17:28:31,392:INFO:tune_model() successfully completed......................................
2023-04-06 17:28:31,907:INFO:Initializing plot_model()
2023-04-06 17:28:31,907:INFO:plot_model(plot=parameter, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=KNeighborsRegressor(metric='manhattan', n_jobs=-1, n_neighbors=13,
                    weights='distance'), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, system=True)
2023-04-06 17:28:31,907:INFO:Checking exceptions
2023-04-06 17:28:31,910:INFO:Preloading libraries
2023-04-06 17:28:31,910:INFO:Copying training dataset
2023-04-06 17:28:31,910:INFO:Plot type: parameter
2023-04-06 17:28:31,912:INFO:Visual Rendered Successfully
2023-04-06 17:28:32,016:INFO:plot_model() successfully completed......................................
2023-04-06 17:28:32,020:INFO:Initializing plot_model()
2023-04-06 17:28:32,021:INFO:plot_model(plot=parameter, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=KNeighborsRegressor(metric='euclidean', n_jobs=-1, n_neighbors=6,
                    weights='distance'), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, system=True)
2023-04-06 17:28:32,021:INFO:Checking exceptions
2023-04-06 17:28:32,023:INFO:Preloading libraries
2023-04-06 17:28:32,026:INFO:Copying training dataset
2023-04-06 17:28:32,026:INFO:Plot type: parameter
2023-04-06 17:28:32,028:INFO:Visual Rendered Successfully
2023-04-06 17:28:32,138:INFO:plot_model() successfully completed......................................
2023-04-06 17:28:32,141:INFO:Initializing ensemble_model()
2023-04-06 17:28:32,141:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=DecisionTreeRegressor(random_state=123), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-04-06 17:28:32,141:INFO:Checking exceptions
2023-04-06 17:28:32,149:INFO:Importing libraries
2023-04-06 17:28:32,149:INFO:Copying training dataset
2023-04-06 17:28:32,149:INFO:Checking base model
2023-04-06 17:28:32,150:INFO:Base model : Decision Tree Regressor
2023-04-06 17:28:32,153:INFO:Importing untrained ensembler
2023-04-06 17:28:32,153:INFO:Ensemble method set to Bagging
2023-04-06 17:28:32,153:INFO:SubProcess create_model() called ==================================
2023-04-06 17:28:32,154:INFO:Initializing create_model()
2023-04-06 17:28:32,154:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=BaggingRegressor(base_estimator=DecisionTreeRegressor(random_state=123),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x2817d86d0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:28:32,154:INFO:Checking exceptions
2023-04-06 17:28:32,154:INFO:Importing libraries
2023-04-06 17:28:32,154:INFO:Copying training dataset
2023-04-06 17:28:32,158:INFO:Defining folds
2023-04-06 17:28:32,158:INFO:Declaring metric variables
2023-04-06 17:28:32,159:INFO:Importing untrained model
2023-04-06 17:28:32,159:INFO:Declaring custom model
2023-04-06 17:28:32,161:INFO:Decision Tree Regressor Imported successfully
2023-04-06 17:28:32,164:INFO:Starting cross validation
2023-04-06 17:28:32,165:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:28:36,556:INFO:Calculating mean and std
2023-04-06 17:28:36,556:INFO:Creating metrics dataframe
2023-04-06 17:28:36,559:INFO:Finalizing model
2023-04-06 17:28:37,192:INFO:Uploading results into container
2023-04-06 17:28:37,192:INFO:Uploading model into container now
2023-04-06 17:28:37,192:INFO:_master_model_container: 29
2023-04-06 17:28:37,192:INFO:_display_container: 8
2023-04-06 17:28:37,193:INFO:BaggingRegressor(base_estimator=DecisionTreeRegressor(random_state=123),
                 random_state=123)
2023-04-06 17:28:37,193:INFO:create_model() successfully completed......................................
2023-04-06 17:28:37,298:INFO:SubProcess create_model() end ==================================
2023-04-06 17:28:37,302:INFO:_master_model_container: 29
2023-04-06 17:28:37,302:INFO:_display_container: 8
2023-04-06 17:28:37,302:INFO:BaggingRegressor(base_estimator=DecisionTreeRegressor(random_state=123),
                 random_state=123)
2023-04-06 17:28:37,302:INFO:ensemble_model() successfully completed......................................
2023-04-06 17:28:37,415:INFO:Initializing ensemble_model()
2023-04-06 17:28:37,415:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=DecisionTreeRegressor(random_state=123), method=Boosting, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-04-06 17:28:37,416:INFO:Checking exceptions
2023-04-06 17:28:37,585:INFO:Importing libraries
2023-04-06 17:28:37,585:INFO:Copying training dataset
2023-04-06 17:28:37,589:INFO:Checking base model
2023-04-06 17:28:37,589:INFO:Base model : Decision Tree Regressor
2023-04-06 17:28:37,592:INFO:Importing untrained ensembler
2023-04-06 17:28:37,593:INFO:Ensemble method set to Boosting
2023-04-06 17:28:37,593:INFO:SubProcess create_model() called ==================================
2023-04-06 17:28:37,593:INFO:Initializing create_model()
2023-04-06 17:28:37,593:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=AdaBoostRegressor(base_estimator=DecisionTreeRegressor(random_state=123),
                  n_estimators=10, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x28149cf70>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:28:37,593:INFO:Checking exceptions
2023-04-06 17:28:37,593:INFO:Importing libraries
2023-04-06 17:28:37,593:INFO:Copying training dataset
2023-04-06 17:28:37,598:INFO:Defining folds
2023-04-06 17:28:37,598:INFO:Declaring metric variables
2023-04-06 17:28:37,600:INFO:Importing untrained model
2023-04-06 17:28:37,600:INFO:Declaring custom model
2023-04-06 17:28:37,602:INFO:Decision Tree Regressor Imported successfully
2023-04-06 17:28:37,605:INFO:Starting cross validation
2023-04-06 17:28:37,607:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:28:42,024:INFO:Calculating mean and std
2023-04-06 17:28:42,025:INFO:Creating metrics dataframe
2023-04-06 17:28:42,027:INFO:Finalizing model
2023-04-06 17:28:42,660:INFO:Uploading results into container
2023-04-06 17:28:42,661:INFO:Uploading model into container now
2023-04-06 17:28:42,661:INFO:_master_model_container: 30
2023-04-06 17:28:42,661:INFO:_display_container: 9
2023-04-06 17:28:42,662:INFO:AdaBoostRegressor(base_estimator=DecisionTreeRegressor(random_state=123),
                  n_estimators=10, random_state=123)
2023-04-06 17:28:42,662:INFO:create_model() successfully completed......................................
2023-04-06 17:28:42,765:INFO:SubProcess create_model() end ==================================
2023-04-06 17:28:42,769:INFO:_master_model_container: 30
2023-04-06 17:28:42,769:INFO:_display_container: 9
2023-04-06 17:28:42,769:INFO:AdaBoostRegressor(base_estimator=DecisionTreeRegressor(random_state=123),
                  n_estimators=10, random_state=123)
2023-04-06 17:28:42,769:INFO:ensemble_model() successfully completed......................................
2023-04-06 17:28:42,875:INFO:Initializing ensemble_model()
2023-04-06 17:28:42,875:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=DecisionTreeRegressor(random_state=123), method=Bagging, fold=None, n_estimators=50, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-04-06 17:28:42,876:INFO:Checking exceptions
2023-04-06 17:28:42,884:INFO:Importing libraries
2023-04-06 17:28:42,884:INFO:Copying training dataset
2023-04-06 17:28:42,884:INFO:Checking base model
2023-04-06 17:28:42,884:INFO:Base model : Decision Tree Regressor
2023-04-06 17:28:42,887:INFO:Importing untrained ensembler
2023-04-06 17:28:42,887:INFO:Ensemble method set to Bagging
2023-04-06 17:28:42,887:INFO:SubProcess create_model() called ==================================
2023-04-06 17:28:42,888:INFO:Initializing create_model()
2023-04-06 17:28:42,888:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=BaggingRegressor(base_estimator=DecisionTreeRegressor(random_state=123),
                 n_estimators=50, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x2817ee1c0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:28:42,888:INFO:Checking exceptions
2023-04-06 17:28:42,888:INFO:Importing libraries
2023-04-06 17:28:42,888:INFO:Copying training dataset
2023-04-06 17:28:42,892:INFO:Defining folds
2023-04-06 17:28:42,892:INFO:Declaring metric variables
2023-04-06 17:28:42,893:INFO:Importing untrained model
2023-04-06 17:28:42,894:INFO:Declaring custom model
2023-04-06 17:28:42,896:INFO:Decision Tree Regressor Imported successfully
2023-04-06 17:28:42,899:INFO:Starting cross validation
2023-04-06 17:28:42,900:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:28:47,588:INFO:Calculating mean and std
2023-04-06 17:28:47,588:INFO:Creating metrics dataframe
2023-04-06 17:28:47,591:INFO:Finalizing model
2023-04-06 17:28:48,430:INFO:Uploading results into container
2023-04-06 17:28:48,431:INFO:Uploading model into container now
2023-04-06 17:28:48,431:INFO:_master_model_container: 31
2023-04-06 17:28:48,431:INFO:_display_container: 10
2023-04-06 17:28:48,431:INFO:BaggingRegressor(base_estimator=DecisionTreeRegressor(random_state=123),
                 n_estimators=50, random_state=123)
2023-04-06 17:28:48,431:INFO:create_model() successfully completed......................................
2023-04-06 17:28:48,536:INFO:SubProcess create_model() end ==================================
2023-04-06 17:28:48,541:INFO:_master_model_container: 31
2023-04-06 17:28:48,541:INFO:_display_container: 10
2023-04-06 17:28:48,541:INFO:BaggingRegressor(base_estimator=DecisionTreeRegressor(random_state=123),
                 n_estimators=50, random_state=123)
2023-04-06 17:28:48,541:INFO:ensemble_model() successfully completed......................................
2023-04-06 17:28:48,646:INFO:Initializing tune_model()
2023-04-06 17:28:48,646:INFO:tune_model(estimator=dt, fold=None, round=4, n_iter=100, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={'ensemble': True, 'method': 'Bagging'}, self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>)
2023-04-06 17:28:48,646:INFO:Checking exceptions
2023-04-06 17:28:58,379:INFO:Initializing tune_model()
2023-04-06 17:28:58,380:INFO:tune_model(estimator=DecisionTreeRegressor(random_state=123), fold=None, round=4, n_iter=100, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={'ensemble': True, 'method': 'Bagging'}, self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>)
2023-04-06 17:28:58,380:INFO:Checking exceptions
2023-04-06 17:28:58,395:INFO:Copying training dataset
2023-04-06 17:28:58,399:INFO:Checking base model
2023-04-06 17:28:58,399:INFO:Base model : Decision Tree Regressor
2023-04-06 17:28:58,401:INFO:Declaring metric variables
2023-04-06 17:28:58,402:INFO:Defining Hyperparameters
2023-04-06 17:28:58,514:INFO:Tuning with n_jobs=-1
2023-04-06 17:28:58,514:INFO:Initializing RandomizedSearchCV
2023-04-06 17:29:22,182:INFO:Initializing tune_model()
2023-04-06 17:29:22,183:INFO:tune_model(estimator=DecisionTreeRegressor(random_state=123), fold=None, round=4, n_iter=100, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={'method': 'Bagging'}, self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>)
2023-04-06 17:29:22,184:INFO:Checking exceptions
2023-04-06 17:29:22,199:INFO:Copying training dataset
2023-04-06 17:29:22,203:INFO:Checking base model
2023-04-06 17:29:22,203:INFO:Base model : Decision Tree Regressor
2023-04-06 17:29:22,205:INFO:Declaring metric variables
2023-04-06 17:29:22,207:INFO:Defining Hyperparameters
2023-04-06 17:29:22,317:INFO:Tuning with n_jobs=-1
2023-04-06 17:29:22,317:INFO:Initializing RandomizedSearchCV
2023-04-06 17:31:19,847:INFO:Initializing blend_models()
2023-04-06 17:31:19,849:INFO:blend_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator_list=['dt', 'catboost'], fold=None, round=4, choose_better=False, optimize=R2, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-04-06 17:31:19,849:INFO:Checking exceptions
2023-04-06 17:32:35,910:INFO:Initializing blend_models()
2023-04-06 17:32:35,911:INFO:blend_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator_list=[DecisionTreeRegressor(random_state=123), KNeighborsRegressor(n_jobs=-1)], fold=None, round=4, choose_better=False, optimize=R2, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-04-06 17:32:35,911:INFO:Checking exceptions
2023-04-06 17:32:35,932:INFO:Importing libraries
2023-04-06 17:32:35,932:INFO:Copying training dataset
2023-04-06 17:32:35,935:INFO:Getting model names
2023-04-06 17:32:35,937:INFO:SubProcess create_model() called ==================================
2023-04-06 17:32:35,938:INFO:Initializing create_model()
2023-04-06 17:32:35,938:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=VotingRegressor(estimators=[('Decision Tree Regressor',
                             DecisionTreeRegressor(random_state=123)),
                            ('K Neighbors Regressor',
                             KNeighborsRegressor(n_jobs=-1))],
                n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x2816db4f0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:32:35,938:INFO:Checking exceptions
2023-04-06 17:32:35,938:INFO:Importing libraries
2023-04-06 17:32:35,938:INFO:Copying training dataset
2023-04-06 17:32:35,943:INFO:Defining folds
2023-04-06 17:32:35,943:INFO:Declaring metric variables
2023-04-06 17:32:35,945:INFO:Importing untrained model
2023-04-06 17:32:35,945:INFO:Declaring custom model
2023-04-06 17:32:35,948:INFO:Voting Regressor Imported successfully
2023-04-06 17:32:35,951:INFO:Starting cross validation
2023-04-06 17:32:35,953:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:32:40,202:INFO:Calculating mean and std
2023-04-06 17:32:40,203:INFO:Creating metrics dataframe
2023-04-06 17:32:40,205:INFO:Finalizing model
2023-04-06 17:32:41,093:INFO:Uploading results into container
2023-04-06 17:32:41,093:INFO:Uploading model into container now
2023-04-06 17:32:41,093:INFO:_master_model_container: 32
2023-04-06 17:32:41,093:INFO:_display_container: 11
2023-04-06 17:32:41,094:INFO:VotingRegressor(estimators=[('Decision Tree Regressor',
                             DecisionTreeRegressor(random_state=123)),
                            ('K Neighbors Regressor',
                             KNeighborsRegressor(n_jobs=-1))],
                n_jobs=-1)
2023-04-06 17:32:41,094:INFO:create_model() successfully completed......................................
2023-04-06 17:32:41,959:INFO:SubProcess create_model() end ==================================
2023-04-06 17:32:41,963:INFO:_master_model_container: 32
2023-04-06 17:32:41,963:INFO:_display_container: 11
2023-04-06 17:32:41,964:INFO:VotingRegressor(estimators=[('Decision Tree Regressor',
                             DecisionTreeRegressor(random_state=123)),
                            ('K Neighbors Regressor',
                             KNeighborsRegressor(n_jobs=-1))],
                n_jobs=-1)
2023-04-06 17:32:41,964:INFO:blend_models() successfully completed......................................
2023-04-06 17:33:55,666:INFO:Initializing stack_models()
2023-04-06 17:33:55,669:INFO:stack_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator_list=[DecisionTreeRegressor(random_state=123), KNeighborsRegressor(n_jobs=-1)], meta_model=None, meta_model_fold=5, fold=None, round=4, method=auto, restack=True, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-04-06 17:33:55,669:INFO:Checking exceptions
2023-04-06 17:33:55,680:INFO:Defining meta model
2023-04-06 17:33:55,696:INFO:Getting model names
2023-04-06 17:33:55,696:INFO:[('Decision Tree Regressor', DecisionTreeRegressor(random_state=123)), ('K Neighbors Regressor', KNeighborsRegressor(n_jobs=-1))]
2023-04-06 17:33:55,698:INFO:SubProcess create_model() called ==================================
2023-04-06 17:33:55,700:INFO:Initializing create_model()
2023-04-06 17:33:55,700:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=StackingRegressor(cv=5,
                  estimators=[('Decision Tree Regressor',
                               DecisionTreeRegressor(random_state=123)),
                              ('K Neighbors Regressor',
                               KNeighborsRegressor(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x283dedaf0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:33:55,700:INFO:Checking exceptions
2023-04-06 17:33:55,700:INFO:Importing libraries
2023-04-06 17:33:55,700:INFO:Copying training dataset
2023-04-06 17:33:55,705:INFO:Defining folds
2023-04-06 17:33:55,706:INFO:Declaring metric variables
2023-04-06 17:33:55,708:INFO:Importing untrained model
2023-04-06 17:33:55,708:INFO:Declaring custom model
2023-04-06 17:33:55,711:INFO:Stacking Regressor Imported successfully
2023-04-06 17:33:55,716:INFO:Starting cross validation
2023-04-06 17:33:55,717:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:34:00,118:INFO:Calculating mean and std
2023-04-06 17:34:00,118:INFO:Creating metrics dataframe
2023-04-06 17:34:00,121:INFO:Finalizing model
2023-04-06 17:34:01,037:INFO:Uploading results into container
2023-04-06 17:34:01,038:INFO:Uploading model into container now
2023-04-06 17:34:01,038:INFO:_master_model_container: 33
2023-04-06 17:34:01,038:INFO:_display_container: 12
2023-04-06 17:34:01,039:INFO:StackingRegressor(cv=5,
                  estimators=[('Decision Tree Regressor',
                               DecisionTreeRegressor(random_state=123)),
                              ('K Neighbors Regressor',
                               KNeighborsRegressor(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True)
2023-04-06 17:34:01,039:INFO:create_model() successfully completed......................................
2023-04-06 17:34:01,149:INFO:SubProcess create_model() end ==================================
2023-04-06 17:34:01,153:INFO:_master_model_container: 33
2023-04-06 17:34:01,153:INFO:_display_container: 12
2023-04-06 17:34:01,153:INFO:StackingRegressor(cv=5,
                  estimators=[('Decision Tree Regressor',
                               DecisionTreeRegressor(random_state=123)),
                              ('K Neighbors Regressor',
                               KNeighborsRegressor(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True)
2023-04-06 17:34:01,154:INFO:stack_models() successfully completed......................................
2023-04-06 17:34:30,461:INFO:Initializing stack_models()
2023-04-06 17:34:30,463:INFO:stack_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator_list=[DecisionTreeRegressor(random_state=123), KNeighborsRegressor(n_jobs=-1)], meta_model=DecisionTreeRegressor(random_state=123), meta_model_fold=5, fold=None, round=4, method=auto, restack=True, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-04-06 17:34:30,464:INFO:Checking exceptions
2023-04-06 17:34:30,469:INFO:Defining meta model
2023-04-06 17:34:30,485:INFO:Getting model names
2023-04-06 17:34:30,486:INFO:[('Decision Tree Regressor', DecisionTreeRegressor(random_state=123)), ('K Neighbors Regressor', KNeighborsRegressor(n_jobs=-1))]
2023-04-06 17:34:30,488:INFO:SubProcess create_model() called ==================================
2023-04-06 17:34:30,489:INFO:Initializing create_model()
2023-04-06 17:34:30,489:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=StackingRegressor(cv=5,
                  estimators=[('Decision Tree Regressor',
                               DecisionTreeRegressor(random_state=123)),
                              ('K Neighbors Regressor',
                               KNeighborsRegressor(n_jobs=-1))],
                  final_estimator=DecisionTreeRegressor(random_state=123),
                  n_jobs=-1, passthrough=True), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x283dedaf0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:34:30,489:INFO:Checking exceptions
2023-04-06 17:34:30,489:INFO:Importing libraries
2023-04-06 17:34:30,489:INFO:Copying training dataset
2023-04-06 17:34:30,494:INFO:Defining folds
2023-04-06 17:34:30,495:INFO:Declaring metric variables
2023-04-06 17:34:30,497:INFO:Importing untrained model
2023-04-06 17:34:30,497:INFO:Declaring custom model
2023-04-06 17:34:30,499:INFO:Stacking Regressor Imported successfully
2023-04-06 17:34:30,503:INFO:Starting cross validation
2023-04-06 17:34:30,504:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:34:34,919:INFO:Calculating mean and std
2023-04-06 17:34:34,920:INFO:Creating metrics dataframe
2023-04-06 17:34:34,923:INFO:Finalizing model
2023-04-06 17:34:35,832:INFO:Uploading results into container
2023-04-06 17:34:35,832:INFO:Uploading model into container now
2023-04-06 17:34:35,833:INFO:_master_model_container: 34
2023-04-06 17:34:35,833:INFO:_display_container: 13
2023-04-06 17:34:35,833:INFO:StackingRegressor(cv=5,
                  estimators=[('Decision Tree Regressor',
                               DecisionTreeRegressor(random_state=123)),
                              ('K Neighbors Regressor',
                               KNeighborsRegressor(n_jobs=-1))],
                  final_estimator=DecisionTreeRegressor(random_state=123),
                  n_jobs=-1, passthrough=True)
2023-04-06 17:34:35,834:INFO:create_model() successfully completed......................................
2023-04-06 17:34:35,937:INFO:SubProcess create_model() end ==================================
2023-04-06 17:34:35,940:INFO:_master_model_container: 34
2023-04-06 17:34:35,941:INFO:_display_container: 13
2023-04-06 17:34:35,941:INFO:StackingRegressor(cv=5,
                  estimators=[('Decision Tree Regressor',
                               DecisionTreeRegressor(random_state=123)),
                              ('K Neighbors Regressor',
                               KNeighborsRegressor(n_jobs=-1))],
                  final_estimator=DecisionTreeRegressor(random_state=123),
                  n_jobs=-1, passthrough=True)
2023-04-06 17:34:35,941:INFO:stack_models() successfully completed......................................
2023-04-06 17:35:02,140:INFO:Initializing stack_models()
2023-04-06 17:35:02,142:INFO:stack_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator_list=[DecisionTreeRegressor(random_state=123), KNeighborsRegressor(n_jobs=-1)], meta_model=None, meta_model_fold=5, fold=None, round=4, method=auto, restack=False, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-04-06 17:35:02,143:INFO:Checking exceptions
2023-04-06 17:35:02,147:INFO:Defining meta model
2023-04-06 17:35:02,159:INFO:Getting model names
2023-04-06 17:35:02,160:INFO:[('Decision Tree Regressor', DecisionTreeRegressor(random_state=123)), ('K Neighbors Regressor', KNeighborsRegressor(n_jobs=-1))]
2023-04-06 17:35:02,162:INFO:SubProcess create_model() called ==================================
2023-04-06 17:35:02,163:INFO:Initializing create_model()
2023-04-06 17:35:02,163:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=StackingRegressor(cv=5,
                  estimators=[('Decision Tree Regressor',
                               DecisionTreeRegressor(random_state=123)),
                              ('K Neighbors Regressor',
                               KNeighborsRegressor(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x2979b8880>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:35:02,164:INFO:Checking exceptions
2023-04-06 17:35:02,164:INFO:Importing libraries
2023-04-06 17:35:02,164:INFO:Copying training dataset
2023-04-06 17:35:02,168:INFO:Defining folds
2023-04-06 17:35:02,168:INFO:Declaring metric variables
2023-04-06 17:35:02,170:INFO:Importing untrained model
2023-04-06 17:35:02,170:INFO:Declaring custom model
2023-04-06 17:35:02,172:INFO:Stacking Regressor Imported successfully
2023-04-06 17:35:02,176:INFO:Starting cross validation
2023-04-06 17:35:02,177:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:35:06,634:INFO:Calculating mean and std
2023-04-06 17:35:06,634:INFO:Creating metrics dataframe
2023-04-06 17:35:06,637:INFO:Finalizing model
2023-04-06 17:35:07,536:INFO:Uploading results into container
2023-04-06 17:35:07,537:INFO:Uploading model into container now
2023-04-06 17:35:07,537:INFO:_master_model_container: 35
2023-04-06 17:35:07,537:INFO:_display_container: 14
2023-04-06 17:35:07,538:INFO:StackingRegressor(cv=5,
                  estimators=[('Decision Tree Regressor',
                               DecisionTreeRegressor(random_state=123)),
                              ('K Neighbors Regressor',
                               KNeighborsRegressor(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1)
2023-04-06 17:35:07,538:INFO:create_model() successfully completed......................................
2023-04-06 17:35:07,643:INFO:SubProcess create_model() end ==================================
2023-04-06 17:35:07,647:INFO:_master_model_container: 35
2023-04-06 17:35:07,647:INFO:_display_container: 14
2023-04-06 17:35:07,648:INFO:StackingRegressor(cv=5,
                  estimators=[('Decision Tree Regressor',
                               DecisionTreeRegressor(random_state=123)),
                              ('K Neighbors Regressor',
                               KNeighborsRegressor(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1)
2023-04-06 17:35:07,648:INFO:stack_models() successfully completed......................................
2023-04-06 17:35:36,054:INFO:Initializing predict_model()
2023-04-06 17:35:36,056:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=StackingRegressor(cv=5,
                  estimators=[('Decision Tree Regressor',
                               DecisionTreeRegressor(random_state=123)),
                              ('K Neighbors Regressor',
                               KNeighborsRegressor(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x2b491b940>)
2023-04-06 17:35:36,056:INFO:Checking exceptions
2023-04-06 17:35:36,056:INFO:Preloading libraries
2023-04-06 17:35:50,567:INFO:Initializing finalize_model()
2023-04-06 17:35:50,569:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=StackingRegressor(cv=5,
                  estimators=[('Decision Tree Regressor',
                               DecisionTreeRegressor(random_state=123)),
                              ('K Neighbors Regressor',
                               KNeighborsRegressor(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-04-06 17:35:50,574:INFO:Finalizing StackingRegressor(cv=5,
                  estimators=[('Decision Tree Regressor',
                               DecisionTreeRegressor(random_state=123)),
                              ('K Neighbors Regressor',
                               KNeighborsRegressor(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True)
2023-04-06 17:35:50,580:INFO:Initializing create_model()
2023-04-06 17:35:50,581:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=StackingRegressor(cv=5,
                  estimators=[('Decision Tree Regressor',
                               DecisionTreeRegressor(random_state=123)),
                              ('K Neighbors Regressor',
                               KNeighborsRegressor(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-04-06 17:35:50,581:INFO:Checking exceptions
2023-04-06 17:35:50,582:INFO:Importing libraries
2023-04-06 17:35:50,583:INFO:Copying training dataset
2023-04-06 17:35:50,583:INFO:Defining folds
2023-04-06 17:35:50,583:INFO:Declaring metric variables
2023-04-06 17:35:50,583:INFO:Importing untrained model
2023-04-06 17:35:50,583:INFO:Declaring custom model
2023-04-06 17:35:50,584:INFO:Stacking Regressor Imported successfully
2023-04-06 17:35:50,585:INFO:Cross validation set to False
2023-04-06 17:35:50,585:INFO:Fitting Model
2023-04-06 17:35:51,072:INFO:Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer'...
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 StackingRegressor(cv=5,
                                   estimators=[('Decision Tree Regressor',
                                                DecisionTreeRegressor(random_state=123)),
                                               ('K Neighbors Regressor',
                                                KNeighborsRegressor(n_jobs=-1))],
                                   final_estimator=LinearRegression(n_jobs=-1),
                                   n_jobs=-1, passthrough=True))])
2023-04-06 17:35:51,072:INFO:create_model() successfully completed......................................
2023-04-06 17:35:51,176:INFO:_master_model_container: 35
2023-04-06 17:35:51,176:INFO:_display_container: 15
2023-04-06 17:35:51,189:INFO:Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer'...
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 StackingRegressor(cv=5,
                                   estimators=[('Decision Tree Regressor',
                                                DecisionTreeRegressor(random_state=123)),
                                               ('K Neighbors Regressor',
                                                KNeighborsRegressor(n_jobs=-1))],
                                   final_estimator=LinearRegression(n_jobs=-1),
                                   n_jobs=-1, passthrough=True))])
2023-04-06 17:35:51,189:INFO:finalize_model() successfully completed......................................
2023-04-06 17:36:38,063:INFO:Initializing predict_model()
2023-04-06 17:36:38,063:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28149cf40>, estimator=Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer'...
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 StackingRegressor(cv=5,
                                   estimators=[('Decision Tree Regressor',
                                                DecisionTreeRegressor(random_state=123)),
                                               ('K Neighbors Regressor',
                                                KNeighborsRegressor(n_jobs=-1))],
                                   final_estimator=LinearRegression(n_jobs=-1),
                                   n_jobs=-1, passthrough=True))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=0, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x2b491ba60>)
2023-04-06 17:36:38,063:INFO:Checking exceptions
2023-04-06 17:36:38,063:INFO:Preloading libraries
2023-04-06 17:36:38,064:INFO:Set up data.
2023-04-06 17:36:38,068:INFO:Set up index.
2023-04-06 17:39:47,943:INFO:PyCaret RegressionExperiment
2023-04-06 17:39:47,943:INFO:Logging name: reg-default-name
2023-04-06 17:39:47,943:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-06 17:39:47,943:INFO:version 3.0.0
2023-04-06 17:39:47,943:INFO:Initializing setup()
2023-04-06 17:39:47,943:INFO:self.USI: 6603
2023-04-06 17:39:47,943:INFO:self._variable_keys: {'logging_param', 'gpu_param', 'X_train', 'X_test', 'y_train', 'pipeline', '_available_plots', 'exp_id', '_ml_usecase', 'html_param', 'transform_target_param', 'n_jobs_param', 'memory', 'y', 'X', 'exp_name_log', 'gpu_n_jobs_param', 'log_plots_param', 'y_test', 'USI', 'idx', 'seed', 'data', 'fold_groups_param', 'fold_generator', 'fold_shuffle_param', 'target_param'}
2023-04-06 17:39:47,943:INFO:Checking environment
2023-04-06 17:39:47,943:INFO:python_version: 3.9.15
2023-04-06 17:39:47,943:INFO:python_build: ('main', 'Nov 24 2022 08:28:41')
2023-04-06 17:39:47,943:INFO:machine: arm64
2023-04-06 17:39:47,943:INFO:platform: macOS-13.2-arm64-arm-64bit
2023-04-06 17:39:47,943:INFO:Memory: svmem(total=17179869184, available=4056104960, percent=76.4, used=6179979264, free=68419584, active=3999858688, inactive=3984556032, wired=2180120576)
2023-04-06 17:39:47,943:INFO:Physical Core: 10
2023-04-06 17:39:47,943:INFO:Logical Core: 10
2023-04-06 17:39:47,943:INFO:Checking libraries
2023-04-06 17:39:47,943:INFO:System:
2023-04-06 17:39:47,943:INFO:    python: 3.9.15 (main, Nov 24 2022, 08:28:41)  [Clang 14.0.6 ]
2023-04-06 17:39:47,943:INFO:executable: /Users/a06411/opt/anaconda3/bin/python
2023-04-06 17:39:47,943:INFO:   machine: macOS-13.2-arm64-arm-64bit
2023-04-06 17:39:47,943:INFO:PyCaret required dependencies:
2023-04-06 17:39:47,943:INFO:                 pip: 22.3.1
2023-04-06 17:39:47,943:INFO:          setuptools: 65.5.0
2023-04-06 17:39:47,943:INFO:             pycaret: 3.0.0
2023-04-06 17:39:47,943:INFO:             IPython: 8.7.0
2023-04-06 17:39:47,943:INFO:          ipywidgets: 7.6.5
2023-04-06 17:39:47,943:INFO:                tqdm: 4.64.1
2023-04-06 17:39:47,944:INFO:               numpy: 1.21.5
2023-04-06 17:39:47,944:INFO:              pandas: 1.4.4
2023-04-06 17:39:47,944:INFO:              jinja2: 2.11.3
2023-04-06 17:39:47,944:INFO:               scipy: 1.9.3
2023-04-06 17:39:47,944:INFO:              joblib: 1.2.0
2023-04-06 17:39:47,944:INFO:             sklearn: 1.1.3
2023-04-06 17:39:47,944:INFO:                pyod: 1.0.9
2023-04-06 17:39:47,944:INFO:            imblearn: 0.10.1
2023-04-06 17:39:47,944:INFO:   category_encoders: 2.6.0
2023-04-06 17:39:47,944:INFO:            lightgbm: 3.3.5
2023-04-06 17:39:47,944:INFO:               numba: 0.56.4
2023-04-06 17:39:47,944:INFO:            requests: 2.28.1
2023-04-06 17:39:47,944:INFO:          matplotlib: 3.6.2
2023-04-06 17:39:47,944:INFO:          scikitplot: 0.3.7
2023-04-06 17:39:47,944:INFO:         yellowbrick: 1.5
2023-04-06 17:39:47,944:INFO:              plotly: 5.9.0
2023-04-06 17:39:47,944:INFO:             kaleido: 0.2.1
2023-04-06 17:39:47,944:INFO:         statsmodels: 0.13.2
2023-04-06 17:39:47,944:INFO:              sktime: 0.16.1
2023-04-06 17:39:47,944:INFO:               tbats: 1.1.2
2023-04-06 17:39:47,944:INFO:            pmdarima: 2.0.3
2023-04-06 17:39:47,944:INFO:              psutil: 5.9.0
2023-04-06 17:39:47,944:INFO:PyCaret optional dependencies:
2023-04-06 17:39:47,944:INFO:                shap: 0.41.0
2023-04-06 17:39:47,944:INFO:           interpret: Not installed
2023-04-06 17:39:47,944:INFO:                umap: 0.5.3
2023-04-06 17:39:47,944:INFO:    pandas_profiling: 4.1.2
2023-04-06 17:39:47,944:INFO:  explainerdashboard: 0.4.2.1
2023-04-06 17:39:47,944:INFO:             autoviz: Not installed
2023-04-06 17:39:47,944:INFO:           fairlearn: Not installed
2023-04-06 17:39:47,944:INFO:             xgboost: 1.7.2
2023-04-06 17:39:47,944:INFO:            catboost: 1.1.1
2023-04-06 17:39:47,944:INFO:              kmodes: Not installed
2023-04-06 17:39:47,944:INFO:             mlxtend: Not installed
2023-04-06 17:39:47,944:INFO:       statsforecast: Not installed
2023-04-06 17:39:47,944:INFO:        tune_sklearn: Not installed
2023-04-06 17:39:47,944:INFO:                 ray: Not installed
2023-04-06 17:39:47,944:INFO:            hyperopt: 0.2.7
2023-04-06 17:39:47,944:INFO:              optuna: 3.1.0
2023-04-06 17:39:47,944:INFO:               skopt: 0.9.0
2023-04-06 17:39:47,944:INFO:              mlflow: 2.2.2
2023-04-06 17:39:47,944:INFO:              gradio: Not installed
2023-04-06 17:39:47,944:INFO:             fastapi: Not installed
2023-04-06 17:39:47,944:INFO:             uvicorn: Not installed
2023-04-06 17:39:47,944:INFO:              m2cgen: Not installed
2023-04-06 17:39:47,944:INFO:           evidently: Not installed
2023-04-06 17:39:47,944:INFO:               fugue: Not installed
2023-04-06 17:39:47,944:INFO:           streamlit: Not installed
2023-04-06 17:39:47,944:INFO:             prophet: Not installed
2023-04-06 17:39:47,944:INFO:None
2023-04-06 17:39:47,944:INFO:Set up data.
2023-04-06 17:39:47,947:INFO:Set up train/test split.
2023-04-06 17:39:47,949:INFO:Set up index.
2023-04-06 17:39:47,949:INFO:Set up folding strategy.
2023-04-06 17:39:47,949:INFO:Assigning column types.
2023-04-06 17:39:47,950:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-06 17:39:47,995:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:39:47,996:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:39:48,041:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:39:48,042:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:39:48,042:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-06 17:39:48,087:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:39:48,088:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:39:48,136:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:39:48,138:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:39:48,138:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-06 17:39:48,186:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:39:48,187:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:39:48,235:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:39:48,236:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:39:48,236:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-06 17:39:48,283:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:39:48,285:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:39:48,332:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:39:48,333:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:39:48,334:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-06 17:39:48,380:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:39:48,382:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:39:48,428:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:39:48,429:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:39:48,430:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-06 17:39:48,477:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:39:48,478:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:39:48,527:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:39:48,528:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:39:48,528:INFO:Preparing preprocessing pipeline...
2023-04-06 17:39:48,528:INFO:Set up target transformation.
2023-04-06 17:39:48,528:INFO:Set up simple imputation.
2023-04-06 17:39:48,530:INFO:Set up encoding of ordinal features.
2023-04-06 17:39:48,530:INFO:Set up encoding of categorical features.
2023-04-06 17:39:48,530:INFO:Set up removing multicollinearity.
2023-04-06 17:39:48,530:INFO:Set up binning of numerical features.
2023-04-06 17:39:48,530:INFO:Set up column transformation.
2023-04-06 17:39:48,530:INFO:Set up feature normalization.
2023-04-06 17:39:48,531:INFO:Set up column name cleaning.
2023-04-06 17:39:48,630:INFO:Finished creating preprocessing pipeline.
2023-04-06 17:39:48,641:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer'...
                ('bin_numeric_features',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=KBinsDiscretizer(encode='ordinal',
                                                                 strategy='kmeans'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-06 17:39:48,641:INFO:Creating final display dataframe.
2023-04-06 17:39:48,817:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             Price
2                   Target type        Regression
3           Original data shape          (600, 8)
4        Transformed data shape         (600, 27)
5   Transformed train set shape         (420, 27)
6    Transformed test set shape         (180, 27)
7              Ordinal features                 1
8              Numeric features                 1
9          Categorical features                 6
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16     Remove multicollinearity              True
17  Multicollinearity threshold              0.95
18               Transformation              True
19        Transformation method       yeo-johnson
20                    Normalize              True
21             Normalize method            zscore
22             Transform target              True
23      Transform target method       yeo-johnson
24               Fold Generator             KFold
25                  Fold Number                10
26                     CPU Jobs                -1
27                      Use GPU             False
28               Log Experiment             False
29              Experiment Name  reg-default-name
30                          USI              6603
2023-04-06 17:39:48,869:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:39:48,870:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:39:48,916:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:39:48,918:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:39:48,918:INFO:setup() successfully completed in 1.49s...............
2023-04-06 17:41:27,537:INFO:gpu_param set to False
2023-04-06 17:44:46,915:INFO:Initializing save_model()
2023-04-06 17:44:46,915:INFO:save_model(model=Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer'...
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 StackingRegressor(cv=5,
                                   estimators=[('Decision Tree Regressor',
                                                DecisionTreeRegressor(random_state=123)),
                                               ('K Neighbors Regressor',
                                                KNeighborsRegressor(n_jobs=-1))],
                                   final_estimator=LinearRegression(n_jobs=-1),
                                   n_jobs=-1, passthrough=True))]), model_name=Experiment_123 08Feb2020, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer'...
                ('bin_numeric_features',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=KBinsDiscretizer(encode='ordinal',
                                                                 strategy='kmeans'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-04-06 17:44:46,915:INFO:Adding model into prep_pipe
2023-04-06 17:44:46,917:WARNING:Only Model saved as it was a pipeline.
2023-04-06 17:44:46,925:INFO:Experiment_123 08Feb2020.pkl saved in current working directory
2023-04-06 17:44:46,941:INFO:Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer'...
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 StackingRegressor(cv=5,
                                   estimators=[('Decision Tree Regressor',
                                                DecisionTreeRegressor(random_state=123)),
                                               ('K Neighbors Regressor',
                                                KNeighborsRegressor(n_jobs=-1))],
                                   final_estimator=LinearRegression(n_jobs=-1),
                                   n_jobs=-1, passthrough=True))])
2023-04-06 17:44:46,941:INFO:save_model() successfully completed......................................
2023-04-06 17:44:59,837:INFO:PyCaret RegressionExperiment
2023-04-06 17:44:59,837:INFO:Logging name: reg-default-name
2023-04-06 17:44:59,837:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-06 17:44:59,837:INFO:version 3.0.0
2023-04-06 17:44:59,837:INFO:Initializing setup()
2023-04-06 17:44:59,837:INFO:self.USI: 2e64
2023-04-06 17:44:59,837:INFO:self._variable_keys: {'logging_param', 'gpu_param', 'X_train', 'X_test', 'y_train', 'pipeline', '_available_plots', 'exp_id', '_ml_usecase', 'html_param', 'transform_target_param', 'n_jobs_param', 'memory', 'y', 'X', 'exp_name_log', 'gpu_n_jobs_param', 'log_plots_param', 'y_test', 'USI', 'idx', 'seed', 'data', 'fold_groups_param', 'fold_generator', 'fold_shuffle_param', 'target_param'}
2023-04-06 17:44:59,837:INFO:Checking environment
2023-04-06 17:44:59,837:INFO:python_version: 3.9.15
2023-04-06 17:44:59,837:INFO:python_build: ('main', 'Nov 24 2022 08:28:41')
2023-04-06 17:44:59,837:INFO:machine: arm64
2023-04-06 17:44:59,837:INFO:platform: macOS-13.2-arm64-arm-64bit
2023-04-06 17:44:59,837:INFO:Memory: svmem(total=17179869184, available=4911153152, percent=71.4, used=6863699968, free=220528640, active=4707581952, inactive=4584292352, wired=2156118016)
2023-04-06 17:44:59,838:INFO:Physical Core: 10
2023-04-06 17:44:59,838:INFO:Logical Core: 10
2023-04-06 17:44:59,838:INFO:Checking libraries
2023-04-06 17:44:59,838:INFO:System:
2023-04-06 17:44:59,838:INFO:    python: 3.9.15 (main, Nov 24 2022, 08:28:41)  [Clang 14.0.6 ]
2023-04-06 17:44:59,838:INFO:executable: /Users/a06411/opt/anaconda3/bin/python
2023-04-06 17:44:59,838:INFO:   machine: macOS-13.2-arm64-arm-64bit
2023-04-06 17:44:59,838:INFO:PyCaret required dependencies:
2023-04-06 17:44:59,838:INFO:                 pip: 22.3.1
2023-04-06 17:44:59,838:INFO:          setuptools: 65.5.0
2023-04-06 17:44:59,838:INFO:             pycaret: 3.0.0
2023-04-06 17:44:59,838:INFO:             IPython: 8.7.0
2023-04-06 17:44:59,838:INFO:          ipywidgets: 7.6.5
2023-04-06 17:44:59,838:INFO:                tqdm: 4.64.1
2023-04-06 17:44:59,838:INFO:               numpy: 1.21.5
2023-04-06 17:44:59,838:INFO:              pandas: 1.4.4
2023-04-06 17:44:59,838:INFO:              jinja2: 2.11.3
2023-04-06 17:44:59,838:INFO:               scipy: 1.9.3
2023-04-06 17:44:59,838:INFO:              joblib: 1.2.0
2023-04-06 17:44:59,838:INFO:             sklearn: 1.1.3
2023-04-06 17:44:59,838:INFO:                pyod: 1.0.9
2023-04-06 17:44:59,838:INFO:            imblearn: 0.10.1
2023-04-06 17:44:59,838:INFO:   category_encoders: 2.6.0
2023-04-06 17:44:59,838:INFO:            lightgbm: 3.3.5
2023-04-06 17:44:59,838:INFO:               numba: 0.56.4
2023-04-06 17:44:59,838:INFO:            requests: 2.28.1
2023-04-06 17:44:59,838:INFO:          matplotlib: 3.6.2
2023-04-06 17:44:59,838:INFO:          scikitplot: 0.3.7
2023-04-06 17:44:59,838:INFO:         yellowbrick: 1.5
2023-04-06 17:44:59,838:INFO:              plotly: 5.9.0
2023-04-06 17:44:59,838:INFO:             kaleido: 0.2.1
2023-04-06 17:44:59,838:INFO:         statsmodels: 0.13.2
2023-04-06 17:44:59,838:INFO:              sktime: 0.16.1
2023-04-06 17:44:59,838:INFO:               tbats: 1.1.2
2023-04-06 17:44:59,838:INFO:            pmdarima: 2.0.3
2023-04-06 17:44:59,838:INFO:              psutil: 5.9.0
2023-04-06 17:44:59,838:INFO:PyCaret optional dependencies:
2023-04-06 17:44:59,838:INFO:                shap: 0.41.0
2023-04-06 17:44:59,838:INFO:           interpret: Not installed
2023-04-06 17:44:59,838:INFO:                umap: 0.5.3
2023-04-06 17:44:59,838:INFO:    pandas_profiling: 4.1.2
2023-04-06 17:44:59,838:INFO:  explainerdashboard: 0.4.2.1
2023-04-06 17:44:59,838:INFO:             autoviz: Not installed
2023-04-06 17:44:59,838:INFO:           fairlearn: Not installed
2023-04-06 17:44:59,838:INFO:             xgboost: 1.7.2
2023-04-06 17:44:59,838:INFO:            catboost: 1.1.1
2023-04-06 17:44:59,838:INFO:              kmodes: Not installed
2023-04-06 17:44:59,838:INFO:             mlxtend: Not installed
2023-04-06 17:44:59,838:INFO:       statsforecast: Not installed
2023-04-06 17:44:59,838:INFO:        tune_sklearn: Not installed
2023-04-06 17:44:59,838:INFO:                 ray: Not installed
2023-04-06 17:44:59,838:INFO:            hyperopt: 0.2.7
2023-04-06 17:44:59,838:INFO:              optuna: 3.1.0
2023-04-06 17:44:59,838:INFO:               skopt: 0.9.0
2023-04-06 17:44:59,838:INFO:              mlflow: 2.2.2
2023-04-06 17:44:59,838:INFO:              gradio: Not installed
2023-04-06 17:44:59,838:INFO:             fastapi: Not installed
2023-04-06 17:44:59,838:INFO:             uvicorn: Not installed
2023-04-06 17:44:59,838:INFO:              m2cgen: Not installed
2023-04-06 17:44:59,838:INFO:           evidently: Not installed
2023-04-06 17:44:59,838:INFO:               fugue: Not installed
2023-04-06 17:44:59,838:INFO:           streamlit: Not installed
2023-04-06 17:44:59,838:INFO:             prophet: Not installed
2023-04-06 17:44:59,838:INFO:None
2023-04-06 17:44:59,838:INFO:Set up data.
2023-04-06 17:44:59,840:INFO:Set up train/test split.
2023-04-06 17:44:59,842:INFO:Set up index.
2023-04-06 17:44:59,842:INFO:Set up folding strategy.
2023-04-06 17:44:59,842:INFO:Assigning column types.
2023-04-06 17:44:59,843:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-06 17:44:59,888:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:44:59,889:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:44:59,935:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:44:59,936:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:44:59,936:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-06 17:44:59,980:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:44:59,981:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:45:00,026:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:45:00,027:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:45:00,027:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-06 17:45:00,071:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:45:00,072:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:45:00,116:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:45:00,117:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:45:00,118:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-06 17:45:00,161:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:45:00,162:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:45:00,207:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:45:00,208:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:45:00,209:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-06 17:45:00,252:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:45:00,254:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:45:00,297:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:45:00,298:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:45:00,298:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-06 17:45:00,342:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:45:00,345:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:45:00,389:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:45:00,390:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:45:00,391:INFO:Preparing preprocessing pipeline...
2023-04-06 17:45:00,391:INFO:Set up target transformation.
2023-04-06 17:45:00,391:INFO:Set up simple imputation.
2023-04-06 17:45:00,392:INFO:Set up encoding of ordinal features.
2023-04-06 17:45:00,392:INFO:Set up encoding of categorical features.
2023-04-06 17:45:00,392:INFO:Set up removing multicollinearity.
2023-04-06 17:45:00,392:INFO:Set up binning of numerical features.
2023-04-06 17:45:00,393:INFO:Set up column transformation.
2023-04-06 17:45:00,393:INFO:Set up feature normalization.
2023-04-06 17:45:00,393:INFO:Set up column name cleaning.
2023-04-06 17:45:00,483:INFO:Finished creating preprocessing pipeline.
2023-04-06 17:45:00,494:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer'...
                ('bin_numeric_features',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=KBinsDiscretizer(encode='ordinal',
                                                                 strategy='kmeans'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-06 17:45:00,494:INFO:Creating final display dataframe.
2023-04-06 17:45:00,645:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             Price
2                   Target type        Regression
3           Original data shape          (600, 8)
4        Transformed data shape         (600, 27)
5   Transformed train set shape         (420, 27)
6    Transformed test set shape         (180, 27)
7              Ordinal features                 1
8              Numeric features                 1
9          Categorical features                 6
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16     Remove multicollinearity              True
17  Multicollinearity threshold              0.95
18               Transformation              True
19        Transformation method       yeo-johnson
20                    Normalize              True
21             Normalize method            zscore
22             Transform target              True
23      Transform target method       yeo-johnson
24               Fold Generator             KFold
25                  Fold Number                10
26                     CPU Jobs                -1
27                      Use GPU             False
28               Log Experiment             False
29              Experiment Name  reg-default-name
30                          USI              2e64
2023-04-06 17:45:00,695:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:45:00,696:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:45:00,742:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 17:45:00,743:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 17:45:00,744:INFO:setup() successfully completed in 1.26s...............
2023-04-06 17:45:12,940:INFO:gpu_param set to False
2023-04-06 18:02:33,056:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-06 18:02:33,057:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-06 18:02:33,057:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-06 18:02:33,057:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-06 18:02:33,642:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-06 18:02:34,332:INFO:PyCaret RegressionExperiment
2023-04-06 18:02:34,332:INFO:Logging name: reg-default-name
2023-04-06 18:02:34,332:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-06 18:02:34,332:INFO:version 3.0.0
2023-04-06 18:02:34,332:INFO:Initializing setup()
2023-04-06 18:02:34,332:INFO:self.USI: f294
2023-04-06 18:02:34,332:INFO:self._variable_keys: {'idx', 'fold_generator', 'fold_groups_param', 'y_train', 'html_param', 'memory', 'logging_param', 'X_test', 'exp_name_log', 'USI', 'y', 'target_param', 'transform_target_param', '_available_plots', 'n_jobs_param', 'gpu_n_jobs_param', 'gpu_param', 'data', 'y_test', '_ml_usecase', 'log_plots_param', 'X', 'seed', 'exp_id', 'X_train', 'pipeline', 'fold_shuffle_param'}
2023-04-06 18:02:34,332:INFO:Checking environment
2023-04-06 18:02:34,332:INFO:python_version: 3.9.15
2023-04-06 18:02:34,332:INFO:python_build: ('main', 'Nov 24 2022 08:28:41')
2023-04-06 18:02:34,332:INFO:machine: arm64
2023-04-06 18:02:34,332:INFO:platform: macOS-13.2-arm64-arm-64bit
2023-04-06 18:02:34,332:INFO:Memory: svmem(total=17179869184, available=4234379264, percent=75.4, used=6453788672, free=40206336, active=4255268864, inactive=4136976384, wired=2198519808)
2023-04-06 18:02:34,332:INFO:Physical Core: 10
2023-04-06 18:02:34,332:INFO:Logical Core: 10
2023-04-06 18:02:34,332:INFO:Checking libraries
2023-04-06 18:02:34,333:INFO:System:
2023-04-06 18:02:34,333:INFO:    python: 3.9.15 (main, Nov 24 2022, 08:28:41)  [Clang 14.0.6 ]
2023-04-06 18:02:34,333:INFO:executable: /Users/a06411/opt/anaconda3/bin/python
2023-04-06 18:02:34,333:INFO:   machine: macOS-13.2-arm64-arm-64bit
2023-04-06 18:02:34,333:INFO:PyCaret required dependencies:
2023-04-06 18:02:34,333:INFO:                 pip: 22.3.1
2023-04-06 18:02:34,333:INFO:          setuptools: 65.5.0
2023-04-06 18:02:34,333:INFO:             pycaret: 3.0.0
2023-04-06 18:02:34,333:INFO:             IPython: 8.7.0
2023-04-06 18:02:34,333:INFO:          ipywidgets: 7.6.5
2023-04-06 18:02:34,333:INFO:                tqdm: 4.64.1
2023-04-06 18:02:34,333:INFO:               numpy: 1.21.5
2023-04-06 18:02:34,333:INFO:              pandas: 1.4.4
2023-04-06 18:02:34,333:INFO:              jinja2: 2.11.3
2023-04-06 18:02:34,333:INFO:               scipy: 1.9.3
2023-04-06 18:02:34,333:INFO:              joblib: 1.2.0
2023-04-06 18:02:34,333:INFO:             sklearn: 1.1.3
2023-04-06 18:02:34,333:INFO:                pyod: 1.0.9
2023-04-06 18:02:34,333:INFO:            imblearn: 0.10.1
2023-04-06 18:02:34,333:INFO:   category_encoders: 2.6.0
2023-04-06 18:02:34,333:INFO:            lightgbm: 3.3.5
2023-04-06 18:02:34,333:INFO:               numba: 0.56.4
2023-04-06 18:02:34,333:INFO:            requests: 2.28.1
2023-04-06 18:02:34,333:INFO:          matplotlib: 3.6.2
2023-04-06 18:02:34,333:INFO:          scikitplot: 0.3.7
2023-04-06 18:02:34,333:INFO:         yellowbrick: 1.5
2023-04-06 18:02:34,333:INFO:              plotly: 5.9.0
2023-04-06 18:02:34,333:INFO:             kaleido: 0.2.1
2023-04-06 18:02:34,333:INFO:         statsmodels: 0.13.2
2023-04-06 18:02:34,333:INFO:              sktime: 0.16.1
2023-04-06 18:02:34,333:INFO:               tbats: 1.1.2
2023-04-06 18:02:34,333:INFO:            pmdarima: 2.0.3
2023-04-06 18:02:34,333:INFO:              psutil: 5.9.0
2023-04-06 18:02:34,333:INFO:PyCaret optional dependencies:
2023-04-06 18:02:34,337:INFO:                shap: 0.41.0
2023-04-06 18:02:34,337:INFO:           interpret: Not installed
2023-04-06 18:02:34,337:INFO:                umap: 0.5.3
2023-04-06 18:02:34,337:INFO:    pandas_profiling: 4.1.2
2023-04-06 18:02:34,337:INFO:  explainerdashboard: 0.4.2.1
2023-04-06 18:02:34,337:INFO:             autoviz: Not installed
2023-04-06 18:02:34,337:INFO:           fairlearn: Not installed
2023-04-06 18:02:34,337:INFO:             xgboost: 1.7.2
2023-04-06 18:02:34,337:INFO:            catboost: 1.1.1
2023-04-06 18:02:34,337:INFO:              kmodes: Not installed
2023-04-06 18:02:34,337:INFO:             mlxtend: Not installed
2023-04-06 18:02:34,337:INFO:       statsforecast: Not installed
2023-04-06 18:02:34,337:INFO:        tune_sklearn: Not installed
2023-04-06 18:02:34,337:INFO:                 ray: Not installed
2023-04-06 18:02:34,337:INFO:            hyperopt: 0.2.7
2023-04-06 18:02:34,337:INFO:              optuna: 3.1.0
2023-04-06 18:02:34,337:INFO:               skopt: 0.9.0
2023-04-06 18:02:34,337:INFO:              mlflow: 2.2.2
2023-04-06 18:02:34,337:INFO:              gradio: Not installed
2023-04-06 18:02:34,337:INFO:             fastapi: Not installed
2023-04-06 18:02:34,337:INFO:             uvicorn: Not installed
2023-04-06 18:02:34,337:INFO:              m2cgen: Not installed
2023-04-06 18:02:34,338:INFO:           evidently: Not installed
2023-04-06 18:02:34,338:INFO:               fugue: Not installed
2023-04-06 18:02:34,338:INFO:           streamlit: Not installed
2023-04-06 18:02:34,338:INFO:             prophet: Not installed
2023-04-06 18:02:34,338:INFO:None
2023-04-06 18:02:34,338:INFO:Set up data.
2023-04-06 18:02:34,340:INFO:Set up train/test split.
2023-04-06 18:02:34,341:INFO:Set up index.
2023-04-06 18:02:34,341:INFO:Set up folding strategy.
2023-04-06 18:02:34,341:INFO:Assigning column types.
2023-04-06 18:02:34,342:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-06 18:02:34,343:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-06 18:02:34,344:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-06 18:02:34,346:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 18:02:34,369:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 18:02:34,387:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 18:02:34,388:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:02:34,532:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:02:34,542:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-06 18:02:34,544:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-06 18:02:34,546:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 18:02:34,569:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 18:02:34,587:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 18:02:34,587:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:02:34,588:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:02:34,589:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-06 18:02:34,590:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-06 18:02:34,592:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 18:02:34,615:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 18:02:34,633:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 18:02:34,633:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:02:34,634:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:02:34,636:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-06 18:02:34,638:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 18:02:34,660:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 18:02:34,678:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 18:02:34,678:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:02:34,679:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:02:34,679:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-06 18:02:34,683:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 18:02:34,706:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 18:02:34,724:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 18:02:34,724:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:02:34,725:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:02:34,729:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 18:02:34,753:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 18:02:34,772:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 18:02:34,772:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:02:34,773:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:02:34,773:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-06 18:02:34,801:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 18:02:34,819:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 18:02:34,820:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:02:34,821:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:02:34,849:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 18:02:34,867:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 18:02:34,868:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:02:34,869:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:02:34,869:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-06 18:02:34,896:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 18:02:34,915:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:02:34,917:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:02:34,945:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 18:02:34,963:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:02:34,964:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:02:34,965:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-06 18:02:35,011:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:02:35,012:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:02:35,058:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:02:35,059:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:02:35,061:INFO:Preparing preprocessing pipeline...
2023-04-06 18:02:35,061:INFO:Set up simple imputation.
2023-04-06 18:02:35,062:INFO:Set up encoding of ordinal features.
2023-04-06 18:02:35,063:INFO:Set up encoding of categorical features.
2023-04-06 18:02:35,092:INFO:Finished creating preprocessing pipeline.
2023-04-06 18:02:35,103:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encodin...
                                                                     'smoker'],
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64},
                                                                        {'col': 'smoker',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['region'],
                                    transformer=OneHotEncoder(cols=['region'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2023-04-06 18:02:35,103:INFO:Creating final display dataframe.
2023-04-06 18:02:35,189:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           charges
2                   Target type        Regression
3           Original data shape         (1338, 7)
4        Transformed data shape        (1338, 10)
5   Transformed train set shape         (936, 10)
6    Transformed test set shape         (402, 10)
7              Ordinal features                 2
8              Numeric features                 3
9          Categorical features                 3
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              f294
2023-04-06 18:02:35,240:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:02:35,241:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:02:35,291:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:02:35,292:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:02:35,293:INFO:setup() successfully completed in 1.48s...............
2023-04-06 18:03:39,717:INFO:PyCaret RegressionExperiment
2023-04-06 18:03:39,717:INFO:Logging name: reg-default-name
2023-04-06 18:03:39,717:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-06 18:03:39,717:INFO:version 3.0.0
2023-04-06 18:03:39,717:INFO:Initializing setup()
2023-04-06 18:03:39,717:INFO:self.USI: c4ed
2023-04-06 18:03:39,717:INFO:self._variable_keys: {'idx', 'fold_generator', 'fold_groups_param', 'y_train', 'html_param', 'memory', 'logging_param', 'X_test', 'exp_name_log', 'USI', 'y', 'target_param', 'transform_target_param', '_available_plots', 'n_jobs_param', 'gpu_n_jobs_param', 'gpu_param', 'data', 'y_test', '_ml_usecase', 'log_plots_param', 'X', 'seed', 'exp_id', 'X_train', 'pipeline', 'fold_shuffle_param'}
2023-04-06 18:03:39,717:INFO:Checking environment
2023-04-06 18:03:39,717:INFO:python_version: 3.9.15
2023-04-06 18:03:39,717:INFO:python_build: ('main', 'Nov 24 2022 08:28:41')
2023-04-06 18:03:39,717:INFO:machine: arm64
2023-04-06 18:03:39,717:INFO:platform: macOS-13.2-arm64-arm-64bit
2023-04-06 18:03:39,717:INFO:Memory: svmem(total=17179869184, available=4254646272, percent=75.2, used=6331219968, free=203571200, active=4092018688, inactive=4039884800, wired=2239201280)
2023-04-06 18:03:39,717:INFO:Physical Core: 10
2023-04-06 18:03:39,717:INFO:Logical Core: 10
2023-04-06 18:03:39,717:INFO:Checking libraries
2023-04-06 18:03:39,717:INFO:System:
2023-04-06 18:03:39,717:INFO:    python: 3.9.15 (main, Nov 24 2022, 08:28:41)  [Clang 14.0.6 ]
2023-04-06 18:03:39,717:INFO:executable: /Users/a06411/opt/anaconda3/bin/python
2023-04-06 18:03:39,717:INFO:   machine: macOS-13.2-arm64-arm-64bit
2023-04-06 18:03:39,717:INFO:PyCaret required dependencies:
2023-04-06 18:03:39,717:INFO:                 pip: 22.3.1
2023-04-06 18:03:39,717:INFO:          setuptools: 65.5.0
2023-04-06 18:03:39,717:INFO:             pycaret: 3.0.0
2023-04-06 18:03:39,717:INFO:             IPython: 8.7.0
2023-04-06 18:03:39,717:INFO:          ipywidgets: 7.6.5
2023-04-06 18:03:39,717:INFO:                tqdm: 4.64.1
2023-04-06 18:03:39,717:INFO:               numpy: 1.21.5
2023-04-06 18:03:39,717:INFO:              pandas: 1.4.4
2023-04-06 18:03:39,717:INFO:              jinja2: 2.11.3
2023-04-06 18:03:39,717:INFO:               scipy: 1.9.3
2023-04-06 18:03:39,717:INFO:              joblib: 1.2.0
2023-04-06 18:03:39,718:INFO:             sklearn: 1.1.3
2023-04-06 18:03:39,718:INFO:                pyod: 1.0.9
2023-04-06 18:03:39,718:INFO:            imblearn: 0.10.1
2023-04-06 18:03:39,718:INFO:   category_encoders: 2.6.0
2023-04-06 18:03:39,718:INFO:            lightgbm: 3.3.5
2023-04-06 18:03:39,718:INFO:               numba: 0.56.4
2023-04-06 18:03:39,718:INFO:            requests: 2.28.1
2023-04-06 18:03:39,718:INFO:          matplotlib: 3.6.2
2023-04-06 18:03:39,718:INFO:          scikitplot: 0.3.7
2023-04-06 18:03:39,718:INFO:         yellowbrick: 1.5
2023-04-06 18:03:39,718:INFO:              plotly: 5.9.0
2023-04-06 18:03:39,718:INFO:             kaleido: 0.2.1
2023-04-06 18:03:39,718:INFO:         statsmodels: 0.13.2
2023-04-06 18:03:39,718:INFO:              sktime: 0.16.1
2023-04-06 18:03:39,718:INFO:               tbats: 1.1.2
2023-04-06 18:03:39,718:INFO:            pmdarima: 2.0.3
2023-04-06 18:03:39,718:INFO:              psutil: 5.9.0
2023-04-06 18:03:39,718:INFO:PyCaret optional dependencies:
2023-04-06 18:03:39,718:INFO:                shap: 0.41.0
2023-04-06 18:03:39,718:INFO:           interpret: Not installed
2023-04-06 18:03:39,718:INFO:                umap: 0.5.3
2023-04-06 18:03:39,718:INFO:    pandas_profiling: 4.1.2
2023-04-06 18:03:39,718:INFO:  explainerdashboard: 0.4.2.1
2023-04-06 18:03:39,718:INFO:             autoviz: Not installed
2023-04-06 18:03:39,718:INFO:           fairlearn: Not installed
2023-04-06 18:03:39,718:INFO:             xgboost: 1.7.2
2023-04-06 18:03:39,718:INFO:            catboost: 1.1.1
2023-04-06 18:03:39,718:INFO:              kmodes: Not installed
2023-04-06 18:03:39,718:INFO:             mlxtend: Not installed
2023-04-06 18:03:39,718:INFO:       statsforecast: Not installed
2023-04-06 18:03:39,718:INFO:        tune_sklearn: Not installed
2023-04-06 18:03:39,718:INFO:                 ray: Not installed
2023-04-06 18:03:39,718:INFO:            hyperopt: 0.2.7
2023-04-06 18:03:39,718:INFO:              optuna: 3.1.0
2023-04-06 18:03:39,718:INFO:               skopt: 0.9.0
2023-04-06 18:03:39,718:INFO:              mlflow: 2.2.2
2023-04-06 18:03:39,718:INFO:              gradio: Not installed
2023-04-06 18:03:39,718:INFO:             fastapi: Not installed
2023-04-06 18:03:39,718:INFO:             uvicorn: Not installed
2023-04-06 18:03:39,718:INFO:              m2cgen: Not installed
2023-04-06 18:03:39,718:INFO:           evidently: Not installed
2023-04-06 18:03:39,718:INFO:               fugue: Not installed
2023-04-06 18:03:39,718:INFO:           streamlit: Not installed
2023-04-06 18:03:39,718:INFO:             prophet: Not installed
2023-04-06 18:03:39,718:INFO:None
2023-04-06 18:03:39,718:INFO:Set up data.
2023-04-06 18:03:39,720:INFO:Set up train/test split.
2023-04-06 18:03:39,722:INFO:Set up index.
2023-04-06 18:03:39,722:INFO:Set up folding strategy.
2023-04-06 18:03:39,722:INFO:Assigning column types.
2023-04-06 18:03:39,723:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-06 18:03:39,723:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-06 18:03:39,725:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-06 18:03:39,726:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 18:03:39,749:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 18:03:39,767:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 18:03:39,767:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:03:39,768:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:03:39,769:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-06 18:03:39,770:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-06 18:03:39,772:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 18:03:39,795:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 18:03:39,813:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 18:03:39,813:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:03:39,814:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:03:39,814:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-06 18:03:39,816:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-06 18:03:39,818:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 18:03:39,841:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 18:03:39,859:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 18:03:39,859:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:03:39,860:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:03:39,862:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-06 18:03:39,864:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 18:03:39,887:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 18:03:39,905:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 18:03:39,905:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:03:39,906:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:03:39,906:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-06 18:03:39,910:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 18:03:39,933:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 18:03:39,951:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 18:03:39,952:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:03:39,953:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:03:39,957:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 18:03:39,980:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 18:03:39,998:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 18:03:39,998:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:03:39,999:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:03:39,999:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-06 18:03:40,027:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 18:03:40,045:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 18:03:40,046:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:03:40,047:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:03:40,073:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 18:03:40,091:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 18:03:40,092:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:03:40,093:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:03:40,093:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-06 18:03:40,119:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 18:03:40,137:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:03:40,138:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:03:40,165:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 18:03:40,183:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:03:40,184:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:03:40,184:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-06 18:03:40,229:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:03:40,230:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:03:40,274:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:03:40,275:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:03:40,276:INFO:Preparing preprocessing pipeline...
2023-04-06 18:03:40,276:INFO:Set up simple imputation.
2023-04-06 18:03:40,277:INFO:Set up encoding of ordinal features.
2023-04-06 18:03:40,278:INFO:Set up encoding of categorical features.
2023-04-06 18:03:40,308:INFO:Finished creating preprocessing pipeline.
2023-04-06 18:03:40,319:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encodin...
                                                                     'smoker'],
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64},
                                                                        {'col': 'smoker',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['region'],
                                    transformer=OneHotEncoder(cols=['region'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2023-04-06 18:03:40,319:INFO:Creating final display dataframe.
2023-04-06 18:03:40,397:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           charges
2                   Target type        Regression
3           Original data shape         (1338, 7)
4        Transformed data shape        (1338, 10)
5   Transformed train set shape         (936, 10)
6    Transformed test set shape         (402, 10)
7              Ordinal features                 2
8              Numeric features                 3
9          Categorical features                 3
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              c4ed
2023-04-06 18:03:40,447:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:03:40,448:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:03:40,494:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:03:40,495:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:03:40,496:INFO:setup() successfully completed in 1.16s...............
2023-04-06 18:06:09,712:INFO:Initializing compare_models()
2023-04-06 18:06:09,713:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x106cb92b0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x106cb92b0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-06 18:06:09,713:INFO:Checking exceptions
2023-04-06 18:06:09,719:INFO:Preparing display monitor
2023-04-06 18:06:09,764:INFO:Initializing Linear Regression
2023-04-06 18:06:09,764:INFO:Total runtime is 5.018711090087891e-06 minutes
2023-04-06 18:06:09,766:INFO:SubProcess create_model() called ==================================
2023-04-06 18:06:09,766:INFO:Initializing create_model()
2023-04-06 18:06:09,766:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x106cb92b0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x177092280>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:06:09,766:INFO:Checking exceptions
2023-04-06 18:06:09,767:INFO:Importing libraries
2023-04-06 18:06:09,767:INFO:Copying training dataset
2023-04-06 18:06:09,770:INFO:Defining folds
2023-04-06 18:06:09,770:INFO:Declaring metric variables
2023-04-06 18:06:09,772:INFO:Importing untrained model
2023-04-06 18:06:09,774:INFO:Linear Regression Imported successfully
2023-04-06 18:06:09,777:INFO:Starting cross validation
2023-04-06 18:06:09,782:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:06:16,964:INFO:Calculating mean and std
2023-04-06 18:06:16,966:INFO:Creating metrics dataframe
2023-04-06 18:06:17,454:INFO:Uploading results into container
2023-04-06 18:06:17,455:INFO:Uploading model into container now
2023-04-06 18:06:17,455:INFO:_master_model_container: 1
2023-04-06 18:06:17,455:INFO:_display_container: 2
2023-04-06 18:06:17,456:INFO:LinearRegression(n_jobs=-1)
2023-04-06 18:06:17,456:INFO:create_model() successfully completed......................................
2023-04-06 18:06:17,538:INFO:SubProcess create_model() end ==================================
2023-04-06 18:06:17,538:INFO:Creating metrics dataframe
2023-04-06 18:06:17,542:INFO:Initializing Lasso Regression
2023-04-06 18:06:17,542:INFO:Total runtime is 0.12963514725367228 minutes
2023-04-06 18:06:17,543:INFO:SubProcess create_model() called ==================================
2023-04-06 18:06:17,543:INFO:Initializing create_model()
2023-04-06 18:06:17,543:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x106cb92b0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x177092280>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:06:17,543:INFO:Checking exceptions
2023-04-06 18:06:17,543:INFO:Importing libraries
2023-04-06 18:06:17,543:INFO:Copying training dataset
2023-04-06 18:06:17,545:INFO:Defining folds
2023-04-06 18:06:17,545:INFO:Declaring metric variables
2023-04-06 18:06:17,547:INFO:Importing untrained model
2023-04-06 18:06:17,549:INFO:Lasso Regression Imported successfully
2023-04-06 18:06:17,553:INFO:Starting cross validation
2023-04-06 18:06:17,553:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:06:21,840:INFO:Calculating mean and std
2023-04-06 18:06:21,841:INFO:Creating metrics dataframe
2023-04-06 18:06:22,270:INFO:Uploading results into container
2023-04-06 18:06:22,270:INFO:Uploading model into container now
2023-04-06 18:06:22,270:INFO:_master_model_container: 2
2023-04-06 18:06:22,270:INFO:_display_container: 2
2023-04-06 18:06:22,270:INFO:Lasso(random_state=123)
2023-04-06 18:06:22,270:INFO:create_model() successfully completed......................................
2023-04-06 18:06:22,326:INFO:SubProcess create_model() end ==================================
2023-04-06 18:06:22,327:INFO:Creating metrics dataframe
2023-04-06 18:06:22,331:INFO:Initializing Ridge Regression
2023-04-06 18:06:22,331:INFO:Total runtime is 0.20945476690928141 minutes
2023-04-06 18:06:22,332:INFO:SubProcess create_model() called ==================================
2023-04-06 18:06:22,332:INFO:Initializing create_model()
2023-04-06 18:06:22,332:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x106cb92b0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x177092280>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:06:22,332:INFO:Checking exceptions
2023-04-06 18:06:22,332:INFO:Importing libraries
2023-04-06 18:06:22,333:INFO:Copying training dataset
2023-04-06 18:06:22,334:INFO:Defining folds
2023-04-06 18:06:22,334:INFO:Declaring metric variables
2023-04-06 18:06:22,336:INFO:Importing untrained model
2023-04-06 18:06:22,337:INFO:Ridge Regression Imported successfully
2023-04-06 18:06:22,339:INFO:Starting cross validation
2023-04-06 18:06:22,340:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:06:26,550:INFO:Calculating mean and std
2023-04-06 18:06:26,550:INFO:Creating metrics dataframe
2023-04-06 18:06:26,983:INFO:Uploading results into container
2023-04-06 18:06:26,983:INFO:Uploading model into container now
2023-04-06 18:06:26,984:INFO:_master_model_container: 3
2023-04-06 18:06:26,984:INFO:_display_container: 2
2023-04-06 18:06:26,984:INFO:Ridge(random_state=123)
2023-04-06 18:06:26,984:INFO:create_model() successfully completed......................................
2023-04-06 18:06:27,039:INFO:SubProcess create_model() end ==================================
2023-04-06 18:06:27,039:INFO:Creating metrics dataframe
2023-04-06 18:06:27,043:INFO:Initializing Elastic Net
2023-04-06 18:06:27,043:INFO:Total runtime is 0.2879870335261027 minutes
2023-04-06 18:06:27,044:INFO:SubProcess create_model() called ==================================
2023-04-06 18:06:27,044:INFO:Initializing create_model()
2023-04-06 18:06:27,044:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x106cb92b0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x177092280>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:06:27,044:INFO:Checking exceptions
2023-04-06 18:06:27,044:INFO:Importing libraries
2023-04-06 18:06:27,045:INFO:Copying training dataset
2023-04-06 18:06:27,046:INFO:Defining folds
2023-04-06 18:06:27,046:INFO:Declaring metric variables
2023-04-06 18:06:27,047:INFO:Importing untrained model
2023-04-06 18:06:27,048:INFO:Elastic Net Imported successfully
2023-04-06 18:06:27,050:INFO:Starting cross validation
2023-04-06 18:06:27,051:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:06:31,310:INFO:Calculating mean and std
2023-04-06 18:06:31,311:INFO:Creating metrics dataframe
2023-04-06 18:06:31,743:INFO:Uploading results into container
2023-04-06 18:06:31,743:INFO:Uploading model into container now
2023-04-06 18:06:31,743:INFO:_master_model_container: 4
2023-04-06 18:06:31,743:INFO:_display_container: 2
2023-04-06 18:06:31,744:INFO:ElasticNet(random_state=123)
2023-04-06 18:06:31,744:INFO:create_model() successfully completed......................................
2023-04-06 18:06:31,800:INFO:SubProcess create_model() end ==================================
2023-04-06 18:06:31,800:INFO:Creating metrics dataframe
2023-04-06 18:06:31,803:INFO:Initializing Least Angle Regression
2023-04-06 18:06:31,803:INFO:Total runtime is 0.36732933521270755 minutes
2023-04-06 18:06:31,805:INFO:SubProcess create_model() called ==================================
2023-04-06 18:06:31,805:INFO:Initializing create_model()
2023-04-06 18:06:31,805:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x106cb92b0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x177092280>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:06:31,805:INFO:Checking exceptions
2023-04-06 18:06:31,805:INFO:Importing libraries
2023-04-06 18:06:31,805:INFO:Copying training dataset
2023-04-06 18:06:31,807:INFO:Defining folds
2023-04-06 18:06:31,807:INFO:Declaring metric variables
2023-04-06 18:06:31,808:INFO:Importing untrained model
2023-04-06 18:06:31,809:INFO:Least Angle Regression Imported successfully
2023-04-06 18:06:31,811:INFO:Starting cross validation
2023-04-06 18:06:31,812:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:06:31,858:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:06:31,860:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:06:31,862:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:06:31,873:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:06:31,878:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:06:31,882:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:06:31,882:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:06:31,883:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:06:31,897:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:06:31,905:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:06:36,045:INFO:Calculating mean and std
2023-04-06 18:06:36,045:INFO:Creating metrics dataframe
2023-04-06 18:06:36,485:INFO:Uploading results into container
2023-04-06 18:06:36,486:INFO:Uploading model into container now
2023-04-06 18:06:36,486:INFO:_master_model_container: 5
2023-04-06 18:06:36,486:INFO:_display_container: 2
2023-04-06 18:06:36,486:INFO:Lars(random_state=123)
2023-04-06 18:06:36,486:INFO:create_model() successfully completed......................................
2023-04-06 18:06:36,542:INFO:SubProcess create_model() end ==================================
2023-04-06 18:06:36,542:INFO:Creating metrics dataframe
2023-04-06 18:06:36,546:INFO:Initializing Lasso Least Angle Regression
2023-04-06 18:06:36,546:INFO:Total runtime is 0.44637548526128135 minutes
2023-04-06 18:06:36,547:INFO:SubProcess create_model() called ==================================
2023-04-06 18:06:36,548:INFO:Initializing create_model()
2023-04-06 18:06:36,548:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x106cb92b0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x177092280>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:06:36,548:INFO:Checking exceptions
2023-04-06 18:06:36,548:INFO:Importing libraries
2023-04-06 18:06:36,548:INFO:Copying training dataset
2023-04-06 18:06:36,549:INFO:Defining folds
2023-04-06 18:06:36,549:INFO:Declaring metric variables
2023-04-06 18:06:36,550:INFO:Importing untrained model
2023-04-06 18:06:36,551:INFO:Lasso Least Angle Regression Imported successfully
2023-04-06 18:06:36,554:INFO:Starting cross validation
2023-04-06 18:06:36,554:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:06:36,605:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 18:06:36,610:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 18:06:36,610:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 18:06:36,615:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 18:06:36,626:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 18:06:36,628:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 18:06:36,640:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 18:06:36,643:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 18:06:36,659:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 18:06:36,667:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 18:06:40,684:INFO:Calculating mean and std
2023-04-06 18:06:40,685:INFO:Creating metrics dataframe
2023-04-06 18:06:41,114:INFO:Uploading results into container
2023-04-06 18:06:41,114:INFO:Uploading model into container now
2023-04-06 18:06:41,115:INFO:_master_model_container: 6
2023-04-06 18:06:41,115:INFO:_display_container: 2
2023-04-06 18:06:41,115:INFO:LassoLars(random_state=123)
2023-04-06 18:06:41,115:INFO:create_model() successfully completed......................................
2023-04-06 18:06:41,171:INFO:SubProcess create_model() end ==================================
2023-04-06 18:06:41,171:INFO:Creating metrics dataframe
2023-04-06 18:06:41,175:INFO:Initializing Orthogonal Matching Pursuit
2023-04-06 18:06:41,175:INFO:Total runtime is 0.5235148827234904 minutes
2023-04-06 18:06:41,176:INFO:SubProcess create_model() called ==================================
2023-04-06 18:06:41,176:INFO:Initializing create_model()
2023-04-06 18:06:41,176:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x106cb92b0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x177092280>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:06:41,176:INFO:Checking exceptions
2023-04-06 18:06:41,176:INFO:Importing libraries
2023-04-06 18:06:41,176:INFO:Copying training dataset
2023-04-06 18:06:41,177:INFO:Defining folds
2023-04-06 18:06:41,178:INFO:Declaring metric variables
2023-04-06 18:06:41,179:INFO:Importing untrained model
2023-04-06 18:06:41,180:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-06 18:06:41,182:INFO:Starting cross validation
2023-04-06 18:06:41,183:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:06:41,228:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:06:41,233:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:06:41,244:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:06:41,246:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:06:41,248:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:06:41,249:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:06:41,255:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:06:41,257:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:06:41,272:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:06:41,278:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:06:45,341:INFO:Calculating mean and std
2023-04-06 18:06:45,342:INFO:Creating metrics dataframe
2023-04-06 18:06:45,767:INFO:Uploading results into container
2023-04-06 18:06:45,767:INFO:Uploading model into container now
2023-04-06 18:06:45,768:INFO:_master_model_container: 7
2023-04-06 18:06:45,768:INFO:_display_container: 2
2023-04-06 18:06:45,768:INFO:OrthogonalMatchingPursuit()
2023-04-06 18:06:45,768:INFO:create_model() successfully completed......................................
2023-04-06 18:06:45,826:INFO:SubProcess create_model() end ==================================
2023-04-06 18:06:45,826:INFO:Creating metrics dataframe
2023-04-06 18:06:45,830:INFO:Initializing Bayesian Ridge
2023-04-06 18:06:45,830:INFO:Total runtime is 0.6010987003644308 minutes
2023-04-06 18:06:45,831:INFO:SubProcess create_model() called ==================================
2023-04-06 18:06:45,831:INFO:Initializing create_model()
2023-04-06 18:06:45,831:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x106cb92b0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x177092280>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:06:45,831:INFO:Checking exceptions
2023-04-06 18:06:45,831:INFO:Importing libraries
2023-04-06 18:06:45,831:INFO:Copying training dataset
2023-04-06 18:06:45,833:INFO:Defining folds
2023-04-06 18:06:45,833:INFO:Declaring metric variables
2023-04-06 18:06:45,834:INFO:Importing untrained model
2023-04-06 18:06:45,835:INFO:Bayesian Ridge Imported successfully
2023-04-06 18:06:45,838:INFO:Starting cross validation
2023-04-06 18:06:45,839:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:06:49,855:INFO:Calculating mean and std
2023-04-06 18:06:49,855:INFO:Creating metrics dataframe
2023-04-06 18:06:50,282:INFO:Uploading results into container
2023-04-06 18:06:50,282:INFO:Uploading model into container now
2023-04-06 18:06:50,282:INFO:_master_model_container: 8
2023-04-06 18:06:50,283:INFO:_display_container: 2
2023-04-06 18:06:50,283:INFO:BayesianRidge()
2023-04-06 18:06:50,283:INFO:create_model() successfully completed......................................
2023-04-06 18:06:50,340:INFO:SubProcess create_model() end ==================================
2023-04-06 18:06:50,341:INFO:Creating metrics dataframe
2023-04-06 18:06:50,345:INFO:Initializing Passive Aggressive Regressor
2023-04-06 18:06:50,346:INFO:Total runtime is 0.6763654192288717 minutes
2023-04-06 18:06:50,347:INFO:SubProcess create_model() called ==================================
2023-04-06 18:06:50,347:INFO:Initializing create_model()
2023-04-06 18:06:50,347:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x106cb92b0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x177092280>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:06:50,347:INFO:Checking exceptions
2023-04-06 18:06:50,348:INFO:Importing libraries
2023-04-06 18:06:50,348:INFO:Copying training dataset
2023-04-06 18:06:50,349:INFO:Defining folds
2023-04-06 18:06:50,349:INFO:Declaring metric variables
2023-04-06 18:06:50,351:INFO:Importing untrained model
2023-04-06 18:06:50,352:INFO:Passive Aggressive Regressor Imported successfully
2023-04-06 18:06:50,355:INFO:Starting cross validation
2023-04-06 18:06:50,356:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:06:54,453:INFO:Calculating mean and std
2023-04-06 18:06:54,454:INFO:Creating metrics dataframe
2023-04-06 18:06:54,913:INFO:Uploading results into container
2023-04-06 18:06:54,914:INFO:Uploading model into container now
2023-04-06 18:06:54,914:INFO:_master_model_container: 9
2023-04-06 18:06:54,914:INFO:_display_container: 2
2023-04-06 18:06:54,914:INFO:PassiveAggressiveRegressor(random_state=123)
2023-04-06 18:06:54,914:INFO:create_model() successfully completed......................................
2023-04-06 18:06:54,970:INFO:SubProcess create_model() end ==================================
2023-04-06 18:06:54,970:INFO:Creating metrics dataframe
2023-04-06 18:06:54,974:INFO:Initializing Huber Regressor
2023-04-06 18:06:54,974:INFO:Total runtime is 0.7535132328669231 minutes
2023-04-06 18:06:54,976:INFO:SubProcess create_model() called ==================================
2023-04-06 18:06:54,976:INFO:Initializing create_model()
2023-04-06 18:06:54,976:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x106cb92b0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x177092280>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:06:54,976:INFO:Checking exceptions
2023-04-06 18:06:54,976:INFO:Importing libraries
2023-04-06 18:06:54,976:INFO:Copying training dataset
2023-04-06 18:06:54,978:INFO:Defining folds
2023-04-06 18:06:54,978:INFO:Declaring metric variables
2023-04-06 18:06:54,980:INFO:Importing untrained model
2023-04-06 18:06:54,981:INFO:Huber Regressor Imported successfully
2023-04-06 18:06:54,983:INFO:Starting cross validation
2023-04-06 18:06:54,984:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:06:55,046:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 18:06:55,047:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 18:06:55,053:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 18:06:55,056:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 18:06:55,059:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 18:06:55,065:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 18:06:55,070:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 18:06:55,072:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 18:06:55,086:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 18:06:55,105:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 18:06:59,197:INFO:Calculating mean and std
2023-04-06 18:06:59,198:INFO:Creating metrics dataframe
2023-04-06 18:06:59,612:INFO:Uploading results into container
2023-04-06 18:06:59,613:INFO:Uploading model into container now
2023-04-06 18:06:59,613:INFO:_master_model_container: 10
2023-04-06 18:06:59,613:INFO:_display_container: 2
2023-04-06 18:06:59,614:INFO:HuberRegressor()
2023-04-06 18:06:59,614:INFO:create_model() successfully completed......................................
2023-04-06 18:06:59,673:INFO:SubProcess create_model() end ==================================
2023-04-06 18:06:59,673:INFO:Creating metrics dataframe
2023-04-06 18:06:59,677:INFO:Initializing K Neighbors Regressor
2023-04-06 18:06:59,677:INFO:Total runtime is 0.8318922837575278 minutes
2023-04-06 18:06:59,678:INFO:SubProcess create_model() called ==================================
2023-04-06 18:06:59,679:INFO:Initializing create_model()
2023-04-06 18:06:59,679:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x106cb92b0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x177092280>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:06:59,679:INFO:Checking exceptions
2023-04-06 18:06:59,679:INFO:Importing libraries
2023-04-06 18:06:59,679:INFO:Copying training dataset
2023-04-06 18:06:59,680:INFO:Defining folds
2023-04-06 18:06:59,680:INFO:Declaring metric variables
2023-04-06 18:06:59,682:INFO:Importing untrained model
2023-04-06 18:06:59,683:INFO:K Neighbors Regressor Imported successfully
2023-04-06 18:06:59,686:INFO:Starting cross validation
2023-04-06 18:06:59,686:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:07:03,716:INFO:Calculating mean and std
2023-04-06 18:07:03,716:INFO:Creating metrics dataframe
2023-04-06 18:07:04,140:INFO:Uploading results into container
2023-04-06 18:07:04,141:INFO:Uploading model into container now
2023-04-06 18:07:04,141:INFO:_master_model_container: 11
2023-04-06 18:07:04,141:INFO:_display_container: 2
2023-04-06 18:07:04,141:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-06 18:07:04,141:INFO:create_model() successfully completed......................................
2023-04-06 18:07:04,196:INFO:SubProcess create_model() end ==================================
2023-04-06 18:07:04,196:INFO:Creating metrics dataframe
2023-04-06 18:07:04,200:INFO:Initializing Decision Tree Regressor
2023-04-06 18:07:04,200:INFO:Total runtime is 0.9072782317797344 minutes
2023-04-06 18:07:04,202:INFO:SubProcess create_model() called ==================================
2023-04-06 18:07:04,202:INFO:Initializing create_model()
2023-04-06 18:07:04,202:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x106cb92b0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x177092280>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:07:04,202:INFO:Checking exceptions
2023-04-06 18:07:04,202:INFO:Importing libraries
2023-04-06 18:07:04,202:INFO:Copying training dataset
2023-04-06 18:07:04,205:INFO:Defining folds
2023-04-06 18:07:04,205:INFO:Declaring metric variables
2023-04-06 18:07:04,206:INFO:Importing untrained model
2023-04-06 18:07:04,208:INFO:Decision Tree Regressor Imported successfully
2023-04-06 18:07:04,210:INFO:Starting cross validation
2023-04-06 18:07:04,211:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:07:08,436:INFO:Calculating mean and std
2023-04-06 18:07:08,437:INFO:Creating metrics dataframe
2023-04-06 18:07:08,889:INFO:Uploading results into container
2023-04-06 18:07:08,889:INFO:Uploading model into container now
2023-04-06 18:07:08,890:INFO:_master_model_container: 12
2023-04-06 18:07:08,890:INFO:_display_container: 2
2023-04-06 18:07:08,890:INFO:DecisionTreeRegressor(random_state=123)
2023-04-06 18:07:08,890:INFO:create_model() successfully completed......................................
2023-04-06 18:07:08,945:INFO:SubProcess create_model() end ==================================
2023-04-06 18:07:08,945:INFO:Creating metrics dataframe
2023-04-06 18:07:08,950:INFO:Initializing Random Forest Regressor
2023-04-06 18:07:08,950:INFO:Total runtime is 0.9864381670951845 minutes
2023-04-06 18:07:08,951:INFO:SubProcess create_model() called ==================================
2023-04-06 18:07:08,951:INFO:Initializing create_model()
2023-04-06 18:07:08,951:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x106cb92b0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x177092280>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:07:08,951:INFO:Checking exceptions
2023-04-06 18:07:08,951:INFO:Importing libraries
2023-04-06 18:07:08,951:INFO:Copying training dataset
2023-04-06 18:07:08,953:INFO:Defining folds
2023-04-06 18:07:08,953:INFO:Declaring metric variables
2023-04-06 18:07:08,954:INFO:Importing untrained model
2023-04-06 18:07:08,955:INFO:Random Forest Regressor Imported successfully
2023-04-06 18:07:08,957:INFO:Starting cross validation
2023-04-06 18:07:08,958:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:07:13,527:INFO:Calculating mean and std
2023-04-06 18:07:13,528:INFO:Creating metrics dataframe
2023-04-06 18:07:13,957:INFO:Uploading results into container
2023-04-06 18:07:13,957:INFO:Uploading model into container now
2023-04-06 18:07:13,957:INFO:_master_model_container: 13
2023-04-06 18:07:13,957:INFO:_display_container: 2
2023-04-06 18:07:13,957:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-04-06 18:07:13,957:INFO:create_model() successfully completed......................................
2023-04-06 18:07:14,014:INFO:SubProcess create_model() end ==================================
2023-04-06 18:07:14,014:INFO:Creating metrics dataframe
2023-04-06 18:07:14,019:INFO:Initializing Extra Trees Regressor
2023-04-06 18:07:14,019:INFO:Total runtime is 1.070920769373576 minutes
2023-04-06 18:07:14,020:INFO:SubProcess create_model() called ==================================
2023-04-06 18:07:14,020:INFO:Initializing create_model()
2023-04-06 18:07:14,020:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x106cb92b0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x177092280>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:07:14,020:INFO:Checking exceptions
2023-04-06 18:07:14,020:INFO:Importing libraries
2023-04-06 18:07:14,021:INFO:Copying training dataset
2023-04-06 18:07:14,022:INFO:Defining folds
2023-04-06 18:07:14,022:INFO:Declaring metric variables
2023-04-06 18:07:14,023:INFO:Importing untrained model
2023-04-06 18:07:14,025:INFO:Extra Trees Regressor Imported successfully
2023-04-06 18:07:14,028:INFO:Starting cross validation
2023-04-06 18:07:14,028:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:07:18,479:INFO:Calculating mean and std
2023-04-06 18:07:18,480:INFO:Creating metrics dataframe
2023-04-06 18:07:18,906:INFO:Uploading results into container
2023-04-06 18:07:18,906:INFO:Uploading model into container now
2023-04-06 18:07:18,907:INFO:_master_model_container: 14
2023-04-06 18:07:18,907:INFO:_display_container: 2
2023-04-06 18:07:18,907:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-04-06 18:07:18,907:INFO:create_model() successfully completed......................................
2023-04-06 18:07:18,964:INFO:SubProcess create_model() end ==================================
2023-04-06 18:07:18,964:INFO:Creating metrics dataframe
2023-04-06 18:07:18,969:INFO:Initializing AdaBoost Regressor
2023-04-06 18:07:18,969:INFO:Total runtime is 1.1534205993016562 minutes
2023-04-06 18:07:18,970:INFO:SubProcess create_model() called ==================================
2023-04-06 18:07:18,970:INFO:Initializing create_model()
2023-04-06 18:07:18,970:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x106cb92b0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x177092280>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:07:18,970:INFO:Checking exceptions
2023-04-06 18:07:18,971:INFO:Importing libraries
2023-04-06 18:07:18,971:INFO:Copying training dataset
2023-04-06 18:07:18,972:INFO:Defining folds
2023-04-06 18:07:18,972:INFO:Declaring metric variables
2023-04-06 18:07:18,973:INFO:Importing untrained model
2023-04-06 18:07:18,975:INFO:AdaBoost Regressor Imported successfully
2023-04-06 18:07:18,977:INFO:Starting cross validation
2023-04-06 18:07:18,978:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:07:23,195:INFO:Calculating mean and std
2023-04-06 18:07:23,196:INFO:Creating metrics dataframe
2023-04-06 18:07:23,625:INFO:Uploading results into container
2023-04-06 18:07:23,625:INFO:Uploading model into container now
2023-04-06 18:07:23,626:INFO:_master_model_container: 15
2023-04-06 18:07:23,626:INFO:_display_container: 2
2023-04-06 18:07:23,626:INFO:AdaBoostRegressor(random_state=123)
2023-04-06 18:07:23,626:INFO:create_model() successfully completed......................................
2023-04-06 18:07:23,683:INFO:SubProcess create_model() end ==================================
2023-04-06 18:07:23,684:INFO:Creating metrics dataframe
2023-04-06 18:07:23,689:INFO:Initializing Gradient Boosting Regressor
2023-04-06 18:07:23,689:INFO:Total runtime is 1.232093401749929 minutes
2023-04-06 18:07:23,691:INFO:SubProcess create_model() called ==================================
2023-04-06 18:07:23,691:INFO:Initializing create_model()
2023-04-06 18:07:23,691:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x106cb92b0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x177092280>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:07:23,691:INFO:Checking exceptions
2023-04-06 18:07:23,691:INFO:Importing libraries
2023-04-06 18:07:23,692:INFO:Copying training dataset
2023-04-06 18:07:23,694:INFO:Defining folds
2023-04-06 18:07:23,694:INFO:Declaring metric variables
2023-04-06 18:07:23,695:INFO:Importing untrained model
2023-04-06 18:07:23,696:INFO:Gradient Boosting Regressor Imported successfully
2023-04-06 18:07:23,699:INFO:Starting cross validation
2023-04-06 18:07:23,699:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:07:27,971:INFO:Calculating mean and std
2023-04-06 18:07:27,972:INFO:Creating metrics dataframe
2023-04-06 18:07:28,412:INFO:Uploading results into container
2023-04-06 18:07:28,413:INFO:Uploading model into container now
2023-04-06 18:07:28,413:INFO:_master_model_container: 16
2023-04-06 18:07:28,413:INFO:_display_container: 2
2023-04-06 18:07:28,413:INFO:GradientBoostingRegressor(random_state=123)
2023-04-06 18:07:28,413:INFO:create_model() successfully completed......................................
2023-04-06 18:07:28,468:INFO:SubProcess create_model() end ==================================
2023-04-06 18:07:28,468:INFO:Creating metrics dataframe
2023-04-06 18:07:28,473:INFO:Initializing Extreme Gradient Boosting
2023-04-06 18:07:28,473:INFO:Total runtime is 1.3118285695711773 minutes
2023-04-06 18:07:28,475:INFO:SubProcess create_model() called ==================================
2023-04-06 18:07:28,475:INFO:Initializing create_model()
2023-04-06 18:07:28,475:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x106cb92b0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x177092280>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:07:28,475:INFO:Checking exceptions
2023-04-06 18:07:28,475:INFO:Importing libraries
2023-04-06 18:07:28,475:INFO:Copying training dataset
2023-04-06 18:07:28,477:INFO:Defining folds
2023-04-06 18:07:28,477:INFO:Declaring metric variables
2023-04-06 18:07:28,478:INFO:Importing untrained model
2023-04-06 18:07:28,480:INFO:Extreme Gradient Boosting Imported successfully
2023-04-06 18:07:28,482:INFO:Starting cross validation
2023-04-06 18:07:28,483:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:07:32,668:INFO:Calculating mean and std
2023-04-06 18:07:32,669:INFO:Creating metrics dataframe
2023-04-06 18:07:33,110:INFO:Uploading results into container
2023-04-06 18:07:33,111:INFO:Uploading model into container now
2023-04-06 18:07:33,111:INFO:_master_model_container: 17
2023-04-06 18:07:33,111:INFO:_display_container: 2
2023-04-06 18:07:33,111:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=123, ...)
2023-04-06 18:07:33,111:INFO:create_model() successfully completed......................................
2023-04-06 18:07:33,167:INFO:SubProcess create_model() end ==================================
2023-04-06 18:07:33,167:INFO:Creating metrics dataframe
2023-04-06 18:07:33,172:INFO:Initializing Light Gradient Boosting Machine
2023-04-06 18:07:33,172:INFO:Total runtime is 1.3901419679323834 minutes
2023-04-06 18:07:33,173:INFO:SubProcess create_model() called ==================================
2023-04-06 18:07:33,174:INFO:Initializing create_model()
2023-04-06 18:07:33,174:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x106cb92b0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x177092280>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:07:33,174:INFO:Checking exceptions
2023-04-06 18:07:33,174:INFO:Importing libraries
2023-04-06 18:07:33,174:INFO:Copying training dataset
2023-04-06 18:07:33,175:INFO:Defining folds
2023-04-06 18:07:33,176:INFO:Declaring metric variables
2023-04-06 18:07:33,177:INFO:Importing untrained model
2023-04-06 18:07:33,178:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-06 18:07:33,180:INFO:Starting cross validation
2023-04-06 18:07:33,181:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:07:37,945:INFO:Calculating mean and std
2023-04-06 18:07:37,946:INFO:Creating metrics dataframe
2023-04-06 18:07:38,363:INFO:Uploading results into container
2023-04-06 18:07:38,363:INFO:Uploading model into container now
2023-04-06 18:07:38,364:INFO:_master_model_container: 18
2023-04-06 18:07:38,364:INFO:_display_container: 2
2023-04-06 18:07:38,364:INFO:LGBMRegressor(random_state=123)
2023-04-06 18:07:38,364:INFO:create_model() successfully completed......................................
2023-04-06 18:07:38,421:INFO:SubProcess create_model() end ==================================
2023-04-06 18:07:38,421:INFO:Creating metrics dataframe
2023-04-06 18:07:38,426:INFO:Initializing CatBoost Regressor
2023-04-06 18:07:38,426:INFO:Total runtime is 1.4777085185050967 minutes
2023-04-06 18:07:38,428:INFO:SubProcess create_model() called ==================================
2023-04-06 18:07:38,428:INFO:Initializing create_model()
2023-04-06 18:07:38,428:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x106cb92b0>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x177092280>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:07:38,428:INFO:Checking exceptions
2023-04-06 18:07:38,428:INFO:Importing libraries
2023-04-06 18:07:38,428:INFO:Copying training dataset
2023-04-06 18:07:38,430:INFO:Defining folds
2023-04-06 18:07:38,430:INFO:Declaring metric variables
2023-04-06 18:07:38,431:INFO:Importing untrained model
2023-04-06 18:07:38,432:INFO:CatBoost Regressor Imported successfully
2023-04-06 18:07:38,435:INFO:Starting cross validation
2023-04-06 18:07:38,436:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:07:43,827:INFO:Calculating mean and std
2023-04-06 18:07:43,829:INFO:Creating metrics dataframe
2023-04-06 18:07:44,317:INFO:Uploading results into container
2023-04-06 18:07:44,318:INFO:Uploading model into container now
2023-04-06 18:07:44,318:INFO:_master_model_container: 19
2023-04-06 18:07:44,318:INFO:_display_container: 2
2023-04-06 18:07:44,318:INFO:<catboost.core.CatBoostRegressor object at 0x16bfd4250>
2023-04-06 18:07:44,318:INFO:create_model() successfully completed......................................
2023-04-06 18:07:44,396:INFO:SubProcess create_model() end ==================================
2023-04-06 18:07:44,396:INFO:Creating metrics dataframe
2023-04-06 18:07:44,402:INFO:Initializing Dummy Regressor
2023-04-06 18:07:44,402:INFO:Total runtime is 1.577308034896851 minutes
2023-04-06 18:07:44,404:INFO:SubProcess create_model() called ==================================
2023-04-06 18:07:44,404:INFO:Initializing create_model()
2023-04-06 18:07:44,404:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x106cb92b0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x177092280>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:07:44,404:INFO:Checking exceptions
2023-04-06 18:07:44,404:INFO:Importing libraries
2023-04-06 18:07:44,404:INFO:Copying training dataset
2023-04-06 18:07:44,406:INFO:Defining folds
2023-04-06 18:07:44,406:INFO:Declaring metric variables
2023-04-06 18:07:44,408:INFO:Importing untrained model
2023-04-06 18:07:44,410:INFO:Dummy Regressor Imported successfully
2023-04-06 18:07:44,413:INFO:Starting cross validation
2023-04-06 18:07:44,413:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:07:48,743:INFO:Calculating mean and std
2023-04-06 18:07:48,744:INFO:Creating metrics dataframe
2023-04-06 18:07:49,175:INFO:Uploading results into container
2023-04-06 18:07:49,175:INFO:Uploading model into container now
2023-04-06 18:07:49,176:INFO:_master_model_container: 20
2023-04-06 18:07:49,176:INFO:_display_container: 2
2023-04-06 18:07:49,176:INFO:DummyRegressor()
2023-04-06 18:07:49,176:INFO:create_model() successfully completed......................................
2023-04-06 18:07:49,231:INFO:SubProcess create_model() end ==================================
2023-04-06 18:07:49,231:INFO:Creating metrics dataframe
2023-04-06 18:07:49,239:INFO:Initializing create_model()
2023-04-06 18:07:49,239:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x106cb92b0>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:07:49,240:INFO:Checking exceptions
2023-04-06 18:07:49,240:INFO:Importing libraries
2023-04-06 18:07:49,240:INFO:Copying training dataset
2023-04-06 18:07:49,241:INFO:Defining folds
2023-04-06 18:07:49,241:INFO:Declaring metric variables
2023-04-06 18:07:49,241:INFO:Importing untrained model
2023-04-06 18:07:49,242:INFO:Declaring custom model
2023-04-06 18:07:49,242:INFO:Gradient Boosting Regressor Imported successfully
2023-04-06 18:07:49,242:INFO:Cross validation set to False
2023-04-06 18:07:49,242:INFO:Fitting Model
2023-04-06 18:07:49,677:INFO:GradientBoostingRegressor(random_state=123)
2023-04-06 18:07:49,677:INFO:create_model() successfully completed......................................
2023-04-06 18:07:49,746:INFO:_master_model_container: 20
2023-04-06 18:07:49,746:INFO:_display_container: 2
2023-04-06 18:07:49,747:INFO:GradientBoostingRegressor(random_state=123)
2023-04-06 18:07:49,747:INFO:compare_models() successfully completed......................................
2023-04-06 18:07:49,750:INFO:Initializing compare_models()
2023-04-06 18:07:49,750:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x17728d880>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x17728d880>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-06 18:07:49,750:INFO:Checking exceptions
2023-04-06 18:07:49,751:INFO:Preparing display monitor
2023-04-06 18:07:49,760:INFO:Initializing Linear Regression
2023-04-06 18:07:49,760:INFO:Total runtime is 1.5298525492350261e-06 minutes
2023-04-06 18:07:49,762:INFO:SubProcess create_model() called ==================================
2023-04-06 18:07:49,762:INFO:Initializing create_model()
2023-04-06 18:07:49,762:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x17728d880>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x13c3bf2e0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:07:49,762:INFO:Checking exceptions
2023-04-06 18:07:49,762:INFO:Importing libraries
2023-04-06 18:07:49,762:INFO:Copying training dataset
2023-04-06 18:07:49,764:INFO:Defining folds
2023-04-06 18:07:49,764:INFO:Declaring metric variables
2023-04-06 18:07:49,766:INFO:Importing untrained model
2023-04-06 18:07:49,767:INFO:Linear Regression Imported successfully
2023-04-06 18:07:49,769:INFO:Starting cross validation
2023-04-06 18:07:49,770:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:07:54,080:INFO:Calculating mean and std
2023-04-06 18:07:54,081:INFO:Creating metrics dataframe
2023-04-06 18:07:54,512:INFO:Uploading results into container
2023-04-06 18:07:54,512:INFO:Uploading model into container now
2023-04-06 18:07:54,512:INFO:_master_model_container: 1
2023-04-06 18:07:54,512:INFO:_display_container: 2
2023-04-06 18:07:54,513:INFO:LinearRegression(n_jobs=-1)
2023-04-06 18:07:54,513:INFO:create_model() successfully completed......................................
2023-04-06 18:07:54,571:INFO:SubProcess create_model() end ==================================
2023-04-06 18:07:54,571:INFO:Creating metrics dataframe
2023-04-06 18:07:54,574:INFO:Initializing Lasso Regression
2023-04-06 18:07:54,574:INFO:Total runtime is 0.08022942940394084 minutes
2023-04-06 18:07:54,575:INFO:SubProcess create_model() called ==================================
2023-04-06 18:07:54,575:INFO:Initializing create_model()
2023-04-06 18:07:54,575:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x17728d880>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x13c3bf2e0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:07:54,576:INFO:Checking exceptions
2023-04-06 18:07:54,576:INFO:Importing libraries
2023-04-06 18:07:54,576:INFO:Copying training dataset
2023-04-06 18:07:54,577:INFO:Defining folds
2023-04-06 18:07:54,577:INFO:Declaring metric variables
2023-04-06 18:07:54,578:INFO:Importing untrained model
2023-04-06 18:07:54,579:INFO:Lasso Regression Imported successfully
2023-04-06 18:07:54,582:INFO:Starting cross validation
2023-04-06 18:07:54,582:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:07:58,788:INFO:Calculating mean and std
2023-04-06 18:07:58,788:INFO:Creating metrics dataframe
2023-04-06 18:07:59,239:INFO:Uploading results into container
2023-04-06 18:07:59,240:INFO:Uploading model into container now
2023-04-06 18:07:59,240:INFO:_master_model_container: 2
2023-04-06 18:07:59,240:INFO:_display_container: 2
2023-04-06 18:07:59,240:INFO:Lasso(random_state=123)
2023-04-06 18:07:59,240:INFO:create_model() successfully completed......................................
2023-04-06 18:07:59,298:INFO:SubProcess create_model() end ==================================
2023-04-06 18:07:59,298:INFO:Creating metrics dataframe
2023-04-06 18:07:59,303:INFO:Initializing Ridge Regression
2023-04-06 18:07:59,303:INFO:Total runtime is 0.15904146432876587 minutes
2023-04-06 18:07:59,304:INFO:SubProcess create_model() called ==================================
2023-04-06 18:07:59,304:INFO:Initializing create_model()
2023-04-06 18:07:59,304:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x17728d880>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x13c3bf2e0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:07:59,305:INFO:Checking exceptions
2023-04-06 18:07:59,305:INFO:Importing libraries
2023-04-06 18:07:59,305:INFO:Copying training dataset
2023-04-06 18:07:59,306:INFO:Defining folds
2023-04-06 18:07:59,306:INFO:Declaring metric variables
2023-04-06 18:07:59,308:INFO:Importing untrained model
2023-04-06 18:07:59,309:INFO:Ridge Regression Imported successfully
2023-04-06 18:07:59,311:INFO:Starting cross validation
2023-04-06 18:07:59,312:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:08:03,669:INFO:Calculating mean and std
2023-04-06 18:08:03,670:INFO:Creating metrics dataframe
2023-04-06 18:08:04,109:INFO:Uploading results into container
2023-04-06 18:08:04,109:INFO:Uploading model into container now
2023-04-06 18:08:04,109:INFO:_master_model_container: 3
2023-04-06 18:08:04,109:INFO:_display_container: 2
2023-04-06 18:08:04,110:INFO:Ridge(random_state=123)
2023-04-06 18:08:04,110:INFO:create_model() successfully completed......................................
2023-04-06 18:08:04,167:INFO:SubProcess create_model() end ==================================
2023-04-06 18:08:04,167:INFO:Creating metrics dataframe
2023-04-06 18:08:04,171:INFO:Initializing Elastic Net
2023-04-06 18:08:04,172:INFO:Total runtime is 0.2401870330174764 minutes
2023-04-06 18:08:04,173:INFO:SubProcess create_model() called ==================================
2023-04-06 18:08:04,173:INFO:Initializing create_model()
2023-04-06 18:08:04,173:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x17728d880>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x13c3bf2e0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:08:04,173:INFO:Checking exceptions
2023-04-06 18:08:04,173:INFO:Importing libraries
2023-04-06 18:08:04,173:INFO:Copying training dataset
2023-04-06 18:08:04,175:INFO:Defining folds
2023-04-06 18:08:04,175:INFO:Declaring metric variables
2023-04-06 18:08:04,176:INFO:Importing untrained model
2023-04-06 18:08:04,177:INFO:Elastic Net Imported successfully
2023-04-06 18:08:04,180:INFO:Starting cross validation
2023-04-06 18:08:04,181:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:08:08,394:INFO:Calculating mean and std
2023-04-06 18:08:08,395:INFO:Creating metrics dataframe
2023-04-06 18:08:08,834:INFO:Uploading results into container
2023-04-06 18:08:08,834:INFO:Uploading model into container now
2023-04-06 18:08:08,834:INFO:_master_model_container: 4
2023-04-06 18:08:08,834:INFO:_display_container: 2
2023-04-06 18:08:08,835:INFO:ElasticNet(random_state=123)
2023-04-06 18:08:08,835:INFO:create_model() successfully completed......................................
2023-04-06 18:08:08,893:INFO:SubProcess create_model() end ==================================
2023-04-06 18:08:08,893:INFO:Creating metrics dataframe
2023-04-06 18:08:08,898:INFO:Initializing Least Angle Regression
2023-04-06 18:08:08,898:INFO:Total runtime is 0.31896201769510907 minutes
2023-04-06 18:08:08,900:INFO:SubProcess create_model() called ==================================
2023-04-06 18:08:08,900:INFO:Initializing create_model()
2023-04-06 18:08:08,900:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x17728d880>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x13c3bf2e0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:08:08,900:INFO:Checking exceptions
2023-04-06 18:08:08,900:INFO:Importing libraries
2023-04-06 18:08:08,900:INFO:Copying training dataset
2023-04-06 18:08:08,901:INFO:Defining folds
2023-04-06 18:08:08,902:INFO:Declaring metric variables
2023-04-06 18:08:08,903:INFO:Importing untrained model
2023-04-06 18:08:08,904:INFO:Least Angle Regression Imported successfully
2023-04-06 18:08:08,906:INFO:Starting cross validation
2023-04-06 18:08:08,907:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:08:08,954:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:08:08,957:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:08:08,962:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:08:08,967:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:08:08,973:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:08:08,978:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:08:08,985:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:08:08,985:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:08:08,990:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:08:08,998:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:08:13,228:INFO:Calculating mean and std
2023-04-06 18:08:13,230:INFO:Creating metrics dataframe
2023-04-06 18:08:13,670:INFO:Uploading results into container
2023-04-06 18:08:13,671:INFO:Uploading model into container now
2023-04-06 18:08:13,671:INFO:_master_model_container: 5
2023-04-06 18:08:13,671:INFO:_display_container: 2
2023-04-06 18:08:13,671:INFO:Lars(random_state=123)
2023-04-06 18:08:13,671:INFO:create_model() successfully completed......................................
2023-04-06 18:08:13,730:INFO:SubProcess create_model() end ==================================
2023-04-06 18:08:13,730:INFO:Creating metrics dataframe
2023-04-06 18:08:13,734:INFO:Initializing Lasso Least Angle Regression
2023-04-06 18:08:13,734:INFO:Total runtime is 0.399569300810496 minutes
2023-04-06 18:08:13,736:INFO:SubProcess create_model() called ==================================
2023-04-06 18:08:13,736:INFO:Initializing create_model()
2023-04-06 18:08:13,736:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x17728d880>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x13c3bf2e0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:08:13,736:INFO:Checking exceptions
2023-04-06 18:08:13,736:INFO:Importing libraries
2023-04-06 18:08:13,736:INFO:Copying training dataset
2023-04-06 18:08:13,738:INFO:Defining folds
2023-04-06 18:08:13,738:INFO:Declaring metric variables
2023-04-06 18:08:13,739:INFO:Importing untrained model
2023-04-06 18:08:13,741:INFO:Lasso Least Angle Regression Imported successfully
2023-04-06 18:08:13,743:INFO:Starting cross validation
2023-04-06 18:08:13,744:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:08:13,796:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 18:08:13,797:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 18:08:13,799:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 18:08:13,805:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 18:08:13,815:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 18:08:13,825:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 18:08:13,833:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 18:08:13,833:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 18:08:13,854:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 18:08:13,857:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 18:08:18,071:INFO:Calculating mean and std
2023-04-06 18:08:18,072:INFO:Creating metrics dataframe
2023-04-06 18:08:18,506:INFO:Uploading results into container
2023-04-06 18:08:18,507:INFO:Uploading model into container now
2023-04-06 18:08:18,507:INFO:_master_model_container: 6
2023-04-06 18:08:18,507:INFO:_display_container: 2
2023-04-06 18:08:18,507:INFO:LassoLars(random_state=123)
2023-04-06 18:08:18,507:INFO:create_model() successfully completed......................................
2023-04-06 18:08:18,565:INFO:SubProcess create_model() end ==================================
2023-04-06 18:08:18,565:INFO:Creating metrics dataframe
2023-04-06 18:08:18,570:INFO:Initializing Orthogonal Matching Pursuit
2023-04-06 18:08:18,570:INFO:Total runtime is 0.4801565011342367 minutes
2023-04-06 18:08:18,571:INFO:SubProcess create_model() called ==================================
2023-04-06 18:08:18,571:INFO:Initializing create_model()
2023-04-06 18:08:18,571:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x17728d880>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x13c3bf2e0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:08:18,571:INFO:Checking exceptions
2023-04-06 18:08:18,571:INFO:Importing libraries
2023-04-06 18:08:18,572:INFO:Copying training dataset
2023-04-06 18:08:18,573:INFO:Defining folds
2023-04-06 18:08:18,573:INFO:Declaring metric variables
2023-04-06 18:08:18,574:INFO:Importing untrained model
2023-04-06 18:08:18,575:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-06 18:08:18,578:INFO:Starting cross validation
2023-04-06 18:08:18,578:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:08:18,625:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:08:18,626:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:08:18,632:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:08:18,632:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:08:18,636:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:08:18,642:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:08:18,652:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:08:18,657:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:08:18,665:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:08:18,680:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:08:22,850:INFO:Calculating mean and std
2023-04-06 18:08:22,851:INFO:Creating metrics dataframe
2023-04-06 18:08:23,284:INFO:Uploading results into container
2023-04-06 18:08:23,284:INFO:Uploading model into container now
2023-04-06 18:08:23,285:INFO:_master_model_container: 7
2023-04-06 18:08:23,285:INFO:_display_container: 2
2023-04-06 18:08:23,285:INFO:OrthogonalMatchingPursuit()
2023-04-06 18:08:23,285:INFO:create_model() successfully completed......................................
2023-04-06 18:08:23,340:INFO:SubProcess create_model() end ==================================
2023-04-06 18:08:23,340:INFO:Creating metrics dataframe
2023-04-06 18:08:23,344:INFO:Initializing Bayesian Ridge
2023-04-06 18:08:23,344:INFO:Total runtime is 0.5597365498542786 minutes
2023-04-06 18:08:23,346:INFO:SubProcess create_model() called ==================================
2023-04-06 18:08:23,346:INFO:Initializing create_model()
2023-04-06 18:08:23,346:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x17728d880>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x13c3bf2e0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:08:23,346:INFO:Checking exceptions
2023-04-06 18:08:23,346:INFO:Importing libraries
2023-04-06 18:08:23,346:INFO:Copying training dataset
2023-04-06 18:08:23,348:INFO:Defining folds
2023-04-06 18:08:23,348:INFO:Declaring metric variables
2023-04-06 18:08:23,349:INFO:Importing untrained model
2023-04-06 18:08:23,350:INFO:Bayesian Ridge Imported successfully
2023-04-06 18:08:23,353:INFO:Starting cross validation
2023-04-06 18:08:23,353:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:08:27,573:INFO:Calculating mean and std
2023-04-06 18:08:27,574:INFO:Creating metrics dataframe
2023-04-06 18:08:28,016:INFO:Uploading results into container
2023-04-06 18:08:28,016:INFO:Uploading model into container now
2023-04-06 18:08:28,017:INFO:_master_model_container: 8
2023-04-06 18:08:28,017:INFO:_display_container: 2
2023-04-06 18:08:28,017:INFO:BayesianRidge()
2023-04-06 18:08:28,017:INFO:create_model() successfully completed......................................
2023-04-06 18:08:28,076:INFO:SubProcess create_model() end ==================================
2023-04-06 18:08:28,076:INFO:Creating metrics dataframe
2023-04-06 18:08:28,081:INFO:Initializing Passive Aggressive Regressor
2023-04-06 18:08:28,081:INFO:Total runtime is 0.6386755665143331 minutes
2023-04-06 18:08:28,082:INFO:SubProcess create_model() called ==================================
2023-04-06 18:08:28,083:INFO:Initializing create_model()
2023-04-06 18:08:28,083:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x17728d880>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x13c3bf2e0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:08:28,083:INFO:Checking exceptions
2023-04-06 18:08:28,083:INFO:Importing libraries
2023-04-06 18:08:28,083:INFO:Copying training dataset
2023-04-06 18:08:28,085:INFO:Defining folds
2023-04-06 18:08:28,085:INFO:Declaring metric variables
2023-04-06 18:08:28,086:INFO:Importing untrained model
2023-04-06 18:08:28,088:INFO:Passive Aggressive Regressor Imported successfully
2023-04-06 18:08:28,091:INFO:Starting cross validation
2023-04-06 18:08:28,091:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:08:32,310:INFO:Calculating mean and std
2023-04-06 18:08:32,311:INFO:Creating metrics dataframe
2023-04-06 18:08:32,746:INFO:Uploading results into container
2023-04-06 18:08:32,747:INFO:Uploading model into container now
2023-04-06 18:08:32,747:INFO:_master_model_container: 9
2023-04-06 18:08:32,747:INFO:_display_container: 2
2023-04-06 18:08:32,747:INFO:PassiveAggressiveRegressor(random_state=123)
2023-04-06 18:08:32,747:INFO:create_model() successfully completed......................................
2023-04-06 18:08:32,804:INFO:SubProcess create_model() end ==================================
2023-04-06 18:08:32,804:INFO:Creating metrics dataframe
2023-04-06 18:08:32,809:INFO:Initializing Huber Regressor
2023-04-06 18:08:32,809:INFO:Total runtime is 0.7174819310506185 minutes
2023-04-06 18:08:32,811:INFO:SubProcess create_model() called ==================================
2023-04-06 18:08:32,811:INFO:Initializing create_model()
2023-04-06 18:08:32,811:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x17728d880>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x13c3bf2e0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:08:32,811:INFO:Checking exceptions
2023-04-06 18:08:32,811:INFO:Importing libraries
2023-04-06 18:08:32,811:INFO:Copying training dataset
2023-04-06 18:08:32,813:INFO:Defining folds
2023-04-06 18:08:32,814:INFO:Declaring metric variables
2023-04-06 18:08:32,815:INFO:Importing untrained model
2023-04-06 18:08:32,816:INFO:Huber Regressor Imported successfully
2023-04-06 18:08:32,819:INFO:Starting cross validation
2023-04-06 18:08:32,820:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:08:32,877:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 18:08:32,883:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 18:08:32,885:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 18:08:32,895:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 18:08:32,898:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 18:08:32,903:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 18:08:32,917:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 18:08:32,918:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 18:08:32,918:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 18:08:32,930:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 18:08:37,229:INFO:Calculating mean and std
2023-04-06 18:08:37,229:INFO:Creating metrics dataframe
2023-04-06 18:08:37,694:INFO:Uploading results into container
2023-04-06 18:08:37,694:INFO:Uploading model into container now
2023-04-06 18:08:37,695:INFO:_master_model_container: 10
2023-04-06 18:08:37,695:INFO:_display_container: 2
2023-04-06 18:08:37,695:INFO:HuberRegressor()
2023-04-06 18:08:37,695:INFO:create_model() successfully completed......................................
2023-04-06 18:08:37,762:INFO:SubProcess create_model() end ==================================
2023-04-06 18:08:37,762:INFO:Creating metrics dataframe
2023-04-06 18:08:37,767:INFO:Initializing K Neighbors Regressor
2023-04-06 18:08:37,767:INFO:Total runtime is 0.8001171469688416 minutes
2023-04-06 18:08:37,769:INFO:SubProcess create_model() called ==================================
2023-04-06 18:08:37,769:INFO:Initializing create_model()
2023-04-06 18:08:37,769:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x17728d880>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x13c3bf2e0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:08:37,769:INFO:Checking exceptions
2023-04-06 18:08:37,769:INFO:Importing libraries
2023-04-06 18:08:37,769:INFO:Copying training dataset
2023-04-06 18:08:37,771:INFO:Defining folds
2023-04-06 18:08:37,771:INFO:Declaring metric variables
2023-04-06 18:08:37,773:INFO:Importing untrained model
2023-04-06 18:08:37,774:INFO:K Neighbors Regressor Imported successfully
2023-04-06 18:08:37,777:INFO:Starting cross validation
2023-04-06 18:08:37,778:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:08:41,940:INFO:Calculating mean and std
2023-04-06 18:08:41,941:INFO:Creating metrics dataframe
2023-04-06 18:08:42,371:INFO:Uploading results into container
2023-04-06 18:08:42,372:INFO:Uploading model into container now
2023-04-06 18:08:42,372:INFO:_master_model_container: 11
2023-04-06 18:08:42,372:INFO:_display_container: 2
2023-04-06 18:08:42,372:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-06 18:08:42,372:INFO:create_model() successfully completed......................................
2023-04-06 18:08:42,432:INFO:SubProcess create_model() end ==================================
2023-04-06 18:08:42,432:INFO:Creating metrics dataframe
2023-04-06 18:08:42,436:INFO:Initializing Decision Tree Regressor
2023-04-06 18:08:42,437:INFO:Total runtime is 0.8779384970664978 minutes
2023-04-06 18:08:42,438:INFO:SubProcess create_model() called ==================================
2023-04-06 18:08:42,438:INFO:Initializing create_model()
2023-04-06 18:08:42,438:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x17728d880>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x13c3bf2e0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:08:42,438:INFO:Checking exceptions
2023-04-06 18:08:42,438:INFO:Importing libraries
2023-04-06 18:08:42,438:INFO:Copying training dataset
2023-04-06 18:08:42,440:INFO:Defining folds
2023-04-06 18:08:42,440:INFO:Declaring metric variables
2023-04-06 18:08:42,441:INFO:Importing untrained model
2023-04-06 18:08:42,442:INFO:Decision Tree Regressor Imported successfully
2023-04-06 18:08:42,445:INFO:Starting cross validation
2023-04-06 18:08:42,445:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:08:46,692:INFO:Calculating mean and std
2023-04-06 18:08:46,692:INFO:Creating metrics dataframe
2023-04-06 18:08:47,130:INFO:Uploading results into container
2023-04-06 18:08:47,130:INFO:Uploading model into container now
2023-04-06 18:08:47,130:INFO:_master_model_container: 12
2023-04-06 18:08:47,130:INFO:_display_container: 2
2023-04-06 18:08:47,131:INFO:DecisionTreeRegressor(random_state=123)
2023-04-06 18:08:47,131:INFO:create_model() successfully completed......................................
2023-04-06 18:08:47,187:INFO:SubProcess create_model() end ==================================
2023-04-06 18:08:47,188:INFO:Creating metrics dataframe
2023-04-06 18:08:47,192:INFO:Initializing Random Forest Regressor
2023-04-06 18:08:47,192:INFO:Total runtime is 0.957196048895518 minutes
2023-04-06 18:08:47,193:INFO:SubProcess create_model() called ==================================
2023-04-06 18:08:47,193:INFO:Initializing create_model()
2023-04-06 18:08:47,193:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x17728d880>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x13c3bf2e0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:08:47,193:INFO:Checking exceptions
2023-04-06 18:08:47,194:INFO:Importing libraries
2023-04-06 18:08:47,194:INFO:Copying training dataset
2023-04-06 18:08:47,196:INFO:Defining folds
2023-04-06 18:08:47,196:INFO:Declaring metric variables
2023-04-06 18:08:47,197:INFO:Importing untrained model
2023-04-06 18:08:47,198:INFO:Random Forest Regressor Imported successfully
2023-04-06 18:08:47,201:INFO:Starting cross validation
2023-04-06 18:08:47,201:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:08:51,624:INFO:Calculating mean and std
2023-04-06 18:08:51,626:INFO:Creating metrics dataframe
2023-04-06 18:08:52,067:INFO:Uploading results into container
2023-04-06 18:08:52,067:INFO:Uploading model into container now
2023-04-06 18:08:52,068:INFO:_master_model_container: 13
2023-04-06 18:08:52,068:INFO:_display_container: 2
2023-04-06 18:08:52,068:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-04-06 18:08:52,068:INFO:create_model() successfully completed......................................
2023-04-06 18:08:52,127:INFO:SubProcess create_model() end ==================================
2023-04-06 18:08:52,127:INFO:Creating metrics dataframe
2023-04-06 18:08:52,133:INFO:Initializing Extra Trees Regressor
2023-04-06 18:08:52,133:INFO:Total runtime is 1.0395405968030293 minutes
2023-04-06 18:08:52,135:INFO:SubProcess create_model() called ==================================
2023-04-06 18:08:52,135:INFO:Initializing create_model()
2023-04-06 18:08:52,135:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x17728d880>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x13c3bf2e0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:08:52,135:INFO:Checking exceptions
2023-04-06 18:08:52,135:INFO:Importing libraries
2023-04-06 18:08:52,135:INFO:Copying training dataset
2023-04-06 18:08:52,137:INFO:Defining folds
2023-04-06 18:08:52,137:INFO:Declaring metric variables
2023-04-06 18:08:52,139:INFO:Importing untrained model
2023-04-06 18:08:52,140:INFO:Extra Trees Regressor Imported successfully
2023-04-06 18:08:52,144:INFO:Starting cross validation
2023-04-06 18:08:52,144:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:08:56,651:INFO:Calculating mean and std
2023-04-06 18:08:56,652:INFO:Creating metrics dataframe
2023-04-06 18:08:57,093:INFO:Uploading results into container
2023-04-06 18:08:57,093:INFO:Uploading model into container now
2023-04-06 18:08:57,094:INFO:_master_model_container: 14
2023-04-06 18:08:57,094:INFO:_display_container: 2
2023-04-06 18:08:57,094:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-04-06 18:08:57,094:INFO:create_model() successfully completed......................................
2023-04-06 18:08:57,152:INFO:SubProcess create_model() end ==================================
2023-04-06 18:08:57,152:INFO:Creating metrics dataframe
2023-04-06 18:08:57,157:INFO:Initializing AdaBoost Regressor
2023-04-06 18:08:57,157:INFO:Total runtime is 1.123283847173055 minutes
2023-04-06 18:08:57,159:INFO:SubProcess create_model() called ==================================
2023-04-06 18:08:57,159:INFO:Initializing create_model()
2023-04-06 18:08:57,159:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x17728d880>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x13c3bf2e0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:08:57,159:INFO:Checking exceptions
2023-04-06 18:08:57,159:INFO:Importing libraries
2023-04-06 18:08:57,159:INFO:Copying training dataset
2023-04-06 18:08:57,161:INFO:Defining folds
2023-04-06 18:08:57,161:INFO:Declaring metric variables
2023-04-06 18:08:57,162:INFO:Importing untrained model
2023-04-06 18:08:57,164:INFO:AdaBoost Regressor Imported successfully
2023-04-06 18:08:57,167:INFO:Starting cross validation
2023-04-06 18:08:57,168:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:09:01,713:INFO:Calculating mean and std
2023-04-06 18:09:01,714:INFO:Creating metrics dataframe
2023-04-06 18:09:02,164:INFO:Uploading results into container
2023-04-06 18:09:02,164:INFO:Uploading model into container now
2023-04-06 18:09:02,165:INFO:_master_model_container: 15
2023-04-06 18:09:02,165:INFO:_display_container: 2
2023-04-06 18:09:02,165:INFO:AdaBoostRegressor(random_state=123)
2023-04-06 18:09:02,165:INFO:create_model() successfully completed......................................
2023-04-06 18:09:02,225:INFO:SubProcess create_model() end ==================================
2023-04-06 18:09:02,226:INFO:Creating metrics dataframe
2023-04-06 18:09:02,231:INFO:Initializing Gradient Boosting Regressor
2023-04-06 18:09:02,231:INFO:Total runtime is 1.2078481634457907 minutes
2023-04-06 18:09:02,233:INFO:SubProcess create_model() called ==================================
2023-04-06 18:09:02,233:INFO:Initializing create_model()
2023-04-06 18:09:02,233:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x17728d880>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x13c3bf2e0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:09:02,233:INFO:Checking exceptions
2023-04-06 18:09:02,234:INFO:Importing libraries
2023-04-06 18:09:02,234:INFO:Copying training dataset
2023-04-06 18:09:02,235:INFO:Defining folds
2023-04-06 18:09:02,235:INFO:Declaring metric variables
2023-04-06 18:09:02,236:INFO:Importing untrained model
2023-04-06 18:09:02,238:INFO:Gradient Boosting Regressor Imported successfully
2023-04-06 18:09:02,240:INFO:Starting cross validation
2023-04-06 18:09:02,241:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:09:06,785:INFO:Calculating mean and std
2023-04-06 18:09:06,785:INFO:Creating metrics dataframe
2023-04-06 18:09:07,240:INFO:Uploading results into container
2023-04-06 18:09:07,240:INFO:Uploading model into container now
2023-04-06 18:09:07,241:INFO:_master_model_container: 16
2023-04-06 18:09:07,241:INFO:_display_container: 2
2023-04-06 18:09:07,241:INFO:GradientBoostingRegressor(random_state=123)
2023-04-06 18:09:07,241:INFO:create_model() successfully completed......................................
2023-04-06 18:09:07,299:INFO:SubProcess create_model() end ==================================
2023-04-06 18:09:07,299:INFO:Creating metrics dataframe
2023-04-06 18:09:07,304:INFO:Initializing Extreme Gradient Boosting
2023-04-06 18:09:07,305:INFO:Total runtime is 1.2924042304356893 minutes
2023-04-06 18:09:07,306:INFO:SubProcess create_model() called ==================================
2023-04-06 18:09:07,306:INFO:Initializing create_model()
2023-04-06 18:09:07,306:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x17728d880>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x13c3bf2e0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:09:07,306:INFO:Checking exceptions
2023-04-06 18:09:07,306:INFO:Importing libraries
2023-04-06 18:09:07,306:INFO:Copying training dataset
2023-04-06 18:09:07,308:INFO:Defining folds
2023-04-06 18:09:07,308:INFO:Declaring metric variables
2023-04-06 18:09:07,309:INFO:Importing untrained model
2023-04-06 18:09:07,311:INFO:Extreme Gradient Boosting Imported successfully
2023-04-06 18:09:07,313:INFO:Starting cross validation
2023-04-06 18:09:07,314:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:09:11,686:INFO:Calculating mean and std
2023-04-06 18:09:11,687:INFO:Creating metrics dataframe
2023-04-06 18:09:12,128:INFO:Uploading results into container
2023-04-06 18:09:12,129:INFO:Uploading model into container now
2023-04-06 18:09:12,129:INFO:_master_model_container: 17
2023-04-06 18:09:12,129:INFO:_display_container: 2
2023-04-06 18:09:12,129:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=123, ...)
2023-04-06 18:09:12,129:INFO:create_model() successfully completed......................................
2023-04-06 18:09:12,187:INFO:SubProcess create_model() end ==================================
2023-04-06 18:09:12,187:INFO:Creating metrics dataframe
2023-04-06 18:09:12,193:INFO:Initializing Light Gradient Boosting Machine
2023-04-06 18:09:12,193:INFO:Total runtime is 1.3738746484120687 minutes
2023-04-06 18:09:12,194:INFO:SubProcess create_model() called ==================================
2023-04-06 18:09:12,194:INFO:Initializing create_model()
2023-04-06 18:09:12,194:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x17728d880>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x13c3bf2e0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:09:12,195:INFO:Checking exceptions
2023-04-06 18:09:12,195:INFO:Importing libraries
2023-04-06 18:09:12,195:INFO:Copying training dataset
2023-04-06 18:09:12,197:INFO:Defining folds
2023-04-06 18:09:12,197:INFO:Declaring metric variables
2023-04-06 18:09:12,198:INFO:Importing untrained model
2023-04-06 18:09:12,199:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-06 18:09:12,202:INFO:Starting cross validation
2023-04-06 18:09:12,203:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:09:16,570:INFO:Calculating mean and std
2023-04-06 18:09:16,571:INFO:Creating metrics dataframe
2023-04-06 18:09:17,001:INFO:Uploading results into container
2023-04-06 18:09:17,001:INFO:Uploading model into container now
2023-04-06 18:09:17,002:INFO:_master_model_container: 18
2023-04-06 18:09:17,002:INFO:_display_container: 2
2023-04-06 18:09:17,002:INFO:LGBMRegressor(random_state=123)
2023-04-06 18:09:17,002:INFO:create_model() successfully completed......................................
2023-04-06 18:09:17,059:INFO:SubProcess create_model() end ==================================
2023-04-06 18:09:17,059:INFO:Creating metrics dataframe
2023-04-06 18:09:17,064:INFO:Initializing CatBoost Regressor
2023-04-06 18:09:17,064:INFO:Total runtime is 1.4550654848416646 minutes
2023-04-06 18:09:17,066:INFO:SubProcess create_model() called ==================================
2023-04-06 18:09:17,066:INFO:Initializing create_model()
2023-04-06 18:09:17,066:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x17728d880>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x13c3bf2e0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:09:17,066:INFO:Checking exceptions
2023-04-06 18:09:17,066:INFO:Importing libraries
2023-04-06 18:09:17,066:INFO:Copying training dataset
2023-04-06 18:09:17,067:INFO:Defining folds
2023-04-06 18:09:17,067:INFO:Declaring metric variables
2023-04-06 18:09:17,069:INFO:Importing untrained model
2023-04-06 18:09:17,070:INFO:CatBoost Regressor Imported successfully
2023-04-06 18:09:17,073:INFO:Starting cross validation
2023-04-06 18:09:17,073:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:09:21,204:INFO:Calculating mean and std
2023-04-06 18:09:21,205:INFO:Creating metrics dataframe
2023-04-06 18:09:21,632:INFO:Uploading results into container
2023-04-06 18:09:21,633:INFO:Uploading model into container now
2023-04-06 18:09:21,633:INFO:_master_model_container: 19
2023-04-06 18:09:21,633:INFO:_display_container: 2
2023-04-06 18:09:21,634:INFO:<catboost.core.CatBoostRegressor object at 0x17728dee0>
2023-04-06 18:09:21,634:INFO:create_model() successfully completed......................................
2023-04-06 18:09:21,689:INFO:SubProcess create_model() end ==================================
2023-04-06 18:09:21,689:INFO:Creating metrics dataframe
2023-04-06 18:09:21,694:INFO:Initializing Dummy Regressor
2023-04-06 18:09:21,694:INFO:Total runtime is 1.5322335998217265 minutes
2023-04-06 18:09:21,695:INFO:SubProcess create_model() called ==================================
2023-04-06 18:09:21,696:INFO:Initializing create_model()
2023-04-06 18:09:21,696:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x17728d880>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x13c3bf2e0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:09:21,696:INFO:Checking exceptions
2023-04-06 18:09:21,696:INFO:Importing libraries
2023-04-06 18:09:21,696:INFO:Copying training dataset
2023-04-06 18:09:21,697:INFO:Defining folds
2023-04-06 18:09:21,697:INFO:Declaring metric variables
2023-04-06 18:09:21,698:INFO:Importing untrained model
2023-04-06 18:09:21,699:INFO:Dummy Regressor Imported successfully
2023-04-06 18:09:21,702:INFO:Starting cross validation
2023-04-06 18:09:21,702:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:09:26,000:INFO:Calculating mean and std
2023-04-06 18:09:26,001:INFO:Creating metrics dataframe
2023-04-06 18:09:26,447:INFO:Uploading results into container
2023-04-06 18:09:26,448:INFO:Uploading model into container now
2023-04-06 18:09:26,448:INFO:_master_model_container: 20
2023-04-06 18:09:26,448:INFO:_display_container: 2
2023-04-06 18:09:26,448:INFO:DummyRegressor()
2023-04-06 18:09:26,448:INFO:create_model() successfully completed......................................
2023-04-06 18:09:26,507:INFO:SubProcess create_model() end ==================================
2023-04-06 18:09:26,507:INFO:Creating metrics dataframe
2023-04-06 18:09:26,516:INFO:Initializing create_model()
2023-04-06 18:09:26,516:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x17728d880>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:09:26,516:INFO:Checking exceptions
2023-04-06 18:09:26,517:INFO:Importing libraries
2023-04-06 18:09:26,517:INFO:Copying training dataset
2023-04-06 18:09:26,518:INFO:Defining folds
2023-04-06 18:09:26,518:INFO:Declaring metric variables
2023-04-06 18:09:26,518:INFO:Importing untrained model
2023-04-06 18:09:26,518:INFO:Declaring custom model
2023-04-06 18:09:26,519:INFO:Gradient Boosting Regressor Imported successfully
2023-04-06 18:09:26,519:INFO:Cross validation set to False
2023-04-06 18:09:26,519:INFO:Fitting Model
2023-04-06 18:09:26,971:INFO:GradientBoostingRegressor(random_state=123)
2023-04-06 18:09:26,971:INFO:create_model() successfully completed......................................
2023-04-06 18:09:27,040:INFO:_master_model_container: 20
2023-04-06 18:09:27,040:INFO:_display_container: 2
2023-04-06 18:09:27,040:INFO:GradientBoostingRegressor(random_state=123)
2023-04-06 18:09:27,040:INFO:compare_models() successfully completed......................................
2023-04-06 18:09:27,044:INFO:Initializing plot_model()
2023-04-06 18:09:27,045:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x106cb92b0>, system=True)
2023-04-06 18:09:27,045:INFO:Checking exceptions
2023-04-06 18:09:27,048:INFO:Preloading libraries
2023-04-06 18:09:27,051:INFO:Copying training dataset
2023-04-06 18:09:27,051:INFO:Plot type: residuals
2023-04-06 18:09:27,162:INFO:Fitting Model
2023-04-06 18:09:27,166:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names
  warnings.warn(

2023-04-06 18:09:27,182:INFO:Scoring test/hold-out set
2023-04-06 18:09:27,472:INFO:Visual Rendered Successfully
2023-04-06 18:09:27,536:INFO:plot_model() successfully completed......................................
2023-04-06 18:09:27,540:INFO:Initializing plot_model()
2023-04-06 18:09:27,540:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x106cb92b0>, system=True)
2023-04-06 18:09:27,540:INFO:Checking exceptions
2023-04-06 18:09:27,543:INFO:Preloading libraries
2023-04-06 18:09:27,547:INFO:Copying training dataset
2023-04-06 18:09:27,547:INFO:Plot type: error
2023-04-06 18:09:27,633:INFO:Fitting Model
2023-04-06 18:09:27,633:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names
  warnings.warn(

2023-04-06 18:09:27,633:INFO:Scoring test/hold-out set
2023-04-06 18:09:27,721:INFO:Visual Rendered Successfully
2023-04-06 18:09:27,783:INFO:plot_model() successfully completed......................................
2023-04-06 18:09:27,786:INFO:Initializing plot_model()
2023-04-06 18:09:27,786:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x106cb92b0>, system=True)
2023-04-06 18:09:27,786:INFO:Checking exceptions
2023-04-06 18:09:27,789:INFO:Preloading libraries
2023-04-06 18:09:27,792:INFO:Copying training dataset
2023-04-06 18:09:27,792:INFO:Plot type: feature
2023-04-06 18:09:27,793:WARNING:No coef_ found. Trying feature_importances_
2023-04-06 18:09:27,889:INFO:Visual Rendered Successfully
2023-04-06 18:09:27,950:INFO:plot_model() successfully completed......................................
2023-04-06 18:10:01,845:INFO:Initializing evaluate_model()
2023-04-06 18:10:01,847:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x106cb92b0>, estimator=GradientBoostingRegressor(random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-04-06 18:10:01,868:INFO:Initializing plot_model()
2023-04-06 18:10:01,868:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x106cb92b0>, system=True)
2023-04-06 18:10:01,868:INFO:Checking exceptions
2023-04-06 18:10:01,870:INFO:Preloading libraries
2023-04-06 18:10:01,874:INFO:Copying training dataset
2023-04-06 18:10:01,874:INFO:Plot type: pipeline
2023-04-06 18:10:04,491:INFO:Initializing plot_model()
2023-04-06 18:10:04,492:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x106cb92b0>, system=True)
2023-04-06 18:10:04,492:INFO:Checking exceptions
2023-04-06 18:10:04,496:INFO:Preloading libraries
2023-04-06 18:10:04,511:INFO:Copying training dataset
2023-04-06 18:10:04,511:INFO:Plot type: residuals
2023-04-06 18:10:04,623:INFO:Fitting Model
2023-04-06 18:10:04,623:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names
  warnings.warn(

2023-04-06 18:10:04,638:INFO:Scoring test/hold-out set
2023-04-06 18:10:04,773:INFO:Visual Rendered Successfully
2023-04-06 18:10:04,845:INFO:plot_model() successfully completed......................................
2023-04-06 18:10:06,166:INFO:Initializing plot_model()
2023-04-06 18:10:06,166:INFO:plot_model(plot=error, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x106cb92b0>, system=True)
2023-04-06 18:10:06,166:INFO:Checking exceptions
2023-04-06 18:10:06,168:INFO:Preloading libraries
2023-04-06 18:10:06,172:INFO:Copying training dataset
2023-04-06 18:10:06,172:INFO:Plot type: error
2023-04-06 18:10:06,273:INFO:Fitting Model
2023-04-06 18:10:06,273:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names
  warnings.warn(

2023-04-06 18:10:06,273:INFO:Scoring test/hold-out set
2023-04-06 18:10:06,356:INFO:Visual Rendered Successfully
2023-04-06 18:10:06,423:INFO:plot_model() successfully completed......................................
2023-04-06 18:10:07,621:INFO:Initializing plot_model()
2023-04-06 18:10:07,622:INFO:plot_model(plot=cooks, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x106cb92b0>, system=True)
2023-04-06 18:10:07,622:INFO:Checking exceptions
2023-04-06 18:10:07,627:INFO:Preloading libraries
2023-04-06 18:10:07,636:INFO:Copying training dataset
2023-04-06 18:10:07,636:INFO:Plot type: cooks
2023-04-06 18:10:07,736:INFO:Fitting Model
2023-04-06 18:10:07,815:INFO:Visual Rendered Successfully
2023-04-06 18:10:07,883:INFO:plot_model() successfully completed......................................
2023-04-06 18:11:09,140:INFO:Initializing predict_model()
2023-04-06 18:11:09,141:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x106cb92b0>, estimator=GradientBoostingRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x292141790>)
2023-04-06 18:11:09,141:INFO:Checking exceptions
2023-04-06 18:11:09,141:INFO:Preloading libraries
2023-04-06 18:11:55,171:INFO:Initializing predict_model()
2023-04-06 18:11:55,173:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x106cb92b0>, estimator=GradientBoostingRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x292141790>)
2023-04-06 18:11:55,174:INFO:Checking exceptions
2023-04-06 18:11:55,174:INFO:Preloading libraries
2023-04-06 18:11:55,182:INFO:Set up data.
2023-04-06 18:11:55,187:INFO:Set up index.
2023-04-06 18:12:18,904:INFO:Initializing save_model()
2023-04-06 18:12:18,904:INFO:save_model(model=GradientBoostingRegressor(random_state=123), model_name=my_first_pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encodin...
                                                                     'smoker'],
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64},
                                                                        {'col': 'smoker',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['region'],
                                    transformer=OneHotEncoder(cols=['region'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-04-06 18:12:18,904:INFO:Adding model into prep_pipe
2023-04-06 18:12:18,910:INFO:my_first_pipeline.pkl saved in current working directory
2023-04-06 18:12:18,927:INFO:Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encodin...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64},
                                                                        {'col': 'smoker',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['region'],
                                    transformer=OneHotEncoder(cols=['region'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model', GradientBoostingRegressor(random_state=123))])
2023-04-06 18:12:18,927:INFO:save_model() successfully completed......................................
2023-04-06 18:12:32,159:INFO:Initializing load_model()
2023-04-06 18:12:32,160:INFO:load_model(model_name=my_first_pipeline, platform=None, authentication=None, verbose=True)
2023-04-06 18:15:30,088:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-06 18:15:30,088:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-06 18:15:30,088:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-06 18:15:30,088:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-06 18:15:30,712:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-06 18:15:46,279:INFO:PyCaret RegressionExperiment
2023-04-06 18:15:46,280:INFO:Logging name: reg-default-name
2023-04-06 18:15:46,280:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-06 18:15:46,280:INFO:version 3.0.0
2023-04-06 18:15:46,280:INFO:Initializing setup()
2023-04-06 18:15:46,280:INFO:self.USI: 3cbf
2023-04-06 18:15:46,280:INFO:self._variable_keys: {'log_plots_param', '_ml_usecase', 'data', 'y', 'fold_groups_param', 'transform_target_param', 'X_train', 'n_jobs_param', 'seed', '_available_plots', 'USI', 'gpu_n_jobs_param', 'memory', 'fold_generator', 'target_param', 'exp_id', 'y_test', 'X_test', 'idx', 'X', 'exp_name_log', 'html_param', 'gpu_param', 'fold_shuffle_param', 'y_train', 'pipeline', 'logging_param'}
2023-04-06 18:15:46,280:INFO:Checking environment
2023-04-06 18:15:46,280:INFO:python_version: 3.9.15
2023-04-06 18:15:46,280:INFO:python_build: ('main', 'Nov 24 2022 08:28:41')
2023-04-06 18:15:46,280:INFO:machine: arm64
2023-04-06 18:15:46,280:INFO:platform: macOS-13.2-arm64-arm-64bit
2023-04-06 18:15:46,280:INFO:Memory: svmem(total=17179869184, available=4581048320, percent=73.3, used=6141116416, free=639729664, active=3969024000, inactive=3789537280, wired=2172092416)
2023-04-06 18:15:46,280:INFO:Physical Core: 10
2023-04-06 18:15:46,280:INFO:Logical Core: 10
2023-04-06 18:15:46,280:INFO:Checking libraries
2023-04-06 18:15:46,280:INFO:System:
2023-04-06 18:15:46,280:INFO:    python: 3.9.15 (main, Nov 24 2022, 08:28:41)  [Clang 14.0.6 ]
2023-04-06 18:15:46,280:INFO:executable: /Users/a06411/opt/anaconda3/bin/python
2023-04-06 18:15:46,280:INFO:   machine: macOS-13.2-arm64-arm-64bit
2023-04-06 18:15:46,280:INFO:PyCaret required dependencies:
2023-04-06 18:15:46,280:INFO:                 pip: 22.3.1
2023-04-06 18:15:46,280:INFO:          setuptools: 65.5.0
2023-04-06 18:15:46,280:INFO:             pycaret: 3.0.0
2023-04-06 18:15:46,280:INFO:             IPython: 8.7.0
2023-04-06 18:15:46,280:INFO:          ipywidgets: 7.6.5
2023-04-06 18:15:46,280:INFO:                tqdm: 4.64.1
2023-04-06 18:15:46,280:INFO:               numpy: 1.21.5
2023-04-06 18:15:46,280:INFO:              pandas: 1.4.4
2023-04-06 18:15:46,280:INFO:              jinja2: 2.11.3
2023-04-06 18:15:46,280:INFO:               scipy: 1.9.3
2023-04-06 18:15:46,280:INFO:              joblib: 1.2.0
2023-04-06 18:15:46,280:INFO:             sklearn: 1.1.3
2023-04-06 18:15:46,280:INFO:                pyod: 1.0.9
2023-04-06 18:15:46,280:INFO:            imblearn: 0.10.1
2023-04-06 18:15:46,280:INFO:   category_encoders: 2.6.0
2023-04-06 18:15:46,280:INFO:            lightgbm: 3.3.5
2023-04-06 18:15:46,280:INFO:               numba: 0.56.4
2023-04-06 18:15:46,280:INFO:            requests: 2.28.1
2023-04-06 18:15:46,280:INFO:          matplotlib: 3.6.2
2023-04-06 18:15:46,280:INFO:          scikitplot: 0.3.7
2023-04-06 18:15:46,280:INFO:         yellowbrick: 1.5
2023-04-06 18:15:46,280:INFO:              plotly: 5.9.0
2023-04-06 18:15:46,280:INFO:             kaleido: 0.2.1
2023-04-06 18:15:46,280:INFO:         statsmodels: 0.13.2
2023-04-06 18:15:46,280:INFO:              sktime: 0.16.1
2023-04-06 18:15:46,280:INFO:               tbats: 1.1.2
2023-04-06 18:15:46,280:INFO:            pmdarima: 2.0.3
2023-04-06 18:15:46,280:INFO:              psutil: 5.9.0
2023-04-06 18:15:46,280:INFO:PyCaret optional dependencies:
2023-04-06 18:15:46,285:INFO:                shap: 0.41.0
2023-04-06 18:15:46,285:INFO:           interpret: Not installed
2023-04-06 18:15:46,285:INFO:                umap: 0.5.3
2023-04-06 18:15:46,285:INFO:    pandas_profiling: 4.1.2
2023-04-06 18:15:46,285:INFO:  explainerdashboard: 0.4.2.1
2023-04-06 18:15:46,285:INFO:             autoviz: Not installed
2023-04-06 18:15:46,285:INFO:           fairlearn: Not installed
2023-04-06 18:15:46,285:INFO:             xgboost: 1.7.2
2023-04-06 18:15:46,285:INFO:            catboost: 1.1.1
2023-04-06 18:15:46,285:INFO:              kmodes: Not installed
2023-04-06 18:15:46,285:INFO:             mlxtend: Not installed
2023-04-06 18:15:46,285:INFO:       statsforecast: Not installed
2023-04-06 18:15:46,285:INFO:        tune_sklearn: Not installed
2023-04-06 18:15:46,285:INFO:                 ray: Not installed
2023-04-06 18:15:46,285:INFO:            hyperopt: 0.2.7
2023-04-06 18:15:46,285:INFO:              optuna: 3.1.0
2023-04-06 18:15:46,285:INFO:               skopt: 0.9.0
2023-04-06 18:15:46,285:INFO:              mlflow: 2.2.2
2023-04-06 18:15:46,285:INFO:              gradio: Not installed
2023-04-06 18:15:46,285:INFO:             fastapi: Not installed
2023-04-06 18:15:46,285:INFO:             uvicorn: Not installed
2023-04-06 18:15:46,285:INFO:              m2cgen: Not installed
2023-04-06 18:15:46,285:INFO:           evidently: Not installed
2023-04-06 18:15:46,285:INFO:               fugue: Not installed
2023-04-06 18:15:46,285:INFO:           streamlit: Not installed
2023-04-06 18:15:46,285:INFO:             prophet: Not installed
2023-04-06 18:15:46,285:INFO:None
2023-04-06 18:15:46,285:INFO:Set up data.
2023-04-06 18:15:46,287:INFO:Set up train/test split.
2023-04-06 18:15:46,289:INFO:Set up index.
2023-04-06 18:15:46,289:INFO:Set up folding strategy.
2023-04-06 18:15:46,289:INFO:Assigning column types.
2023-04-06 18:15:46,290:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-06 18:15:46,290:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-06 18:15:46,292:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-06 18:15:46,294:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 18:15:46,317:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 18:15:46,335:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 18:15:46,335:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:15:46,464:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:15:46,476:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-06 18:15:46,478:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-06 18:15:46,480:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 18:15:46,503:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 18:15:46,521:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 18:15:46,521:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:15:46,522:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:15:46,523:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-06 18:15:46,524:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-06 18:15:46,526:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 18:15:46,549:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 18:15:46,567:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 18:15:46,567:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:15:46,568:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:15:46,570:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-06 18:15:46,572:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 18:15:46,596:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 18:15:46,614:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 18:15:46,615:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:15:46,616:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:15:46,616:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-06 18:15:46,620:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 18:15:46,643:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 18:15:46,661:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 18:15:46,662:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:15:46,663:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:15:46,667:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 18:15:46,699:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 18:15:46,718:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 18:15:46,718:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:15:46,719:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:15:46,720:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-06 18:15:46,747:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 18:15:46,765:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 18:15:46,765:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:15:46,766:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:15:46,793:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 18:15:46,811:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 18:15:46,812:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:15:46,813:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:15:46,813:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-06 18:15:46,840:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 18:15:46,858:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:15:46,859:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:15:46,886:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 18:15:46,905:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:15:46,906:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:15:46,908:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-06 18:15:46,953:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:15:46,954:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:15:46,999:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:15:47,000:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:15:47,003:INFO:Preparing preprocessing pipeline...
2023-04-06 18:15:47,003:INFO:Set up simple imputation.
2023-04-06 18:15:47,004:INFO:Set up encoding of ordinal features.
2023-04-06 18:15:47,005:INFO:Set up encoding of categorical features.
2023-04-06 18:15:47,033:INFO:Finished creating preprocessing pipeline.
2023-04-06 18:15:47,045:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encodin...
                                                                     'smoker'],
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64},
                                                                        {'col': 'smoker',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['region'],
                                    transformer=OneHotEncoder(cols=['region'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2023-04-06 18:15:47,045:INFO:Creating final display dataframe.
2023-04-06 18:15:47,130:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           charges
2                   Target type        Regression
3           Original data shape         (1338, 7)
4        Transformed data shape        (1338, 10)
5   Transformed train set shape         (936, 10)
6    Transformed test set shape         (402, 10)
7              Ordinal features                 2
8              Numeric features                 3
9          Categorical features                 3
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              3cbf
2023-04-06 18:15:47,180:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:15:47,181:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:15:47,229:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:15:47,230:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:15:47,231:INFO:setup() successfully completed in 1.4s...............
2023-04-06 18:15:55,346:INFO:Initializing get_config()
2023-04-06 18:15:55,346:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x28a930100>, variable=None)
2023-04-06 18:17:01,376:INFO:Initializing get_config()
2023-04-06 18:17:01,376:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x28a930100>, variable=X_train_transformed)
2023-04-06 18:17:01,417:INFO:Variable: X_train returned as        age  sex        bmi  children  smoker  region_northeast  \
300   36.0  1.0  27.549999       3.0     0.0               1.0   
904   60.0  0.0  35.099998       0.0     0.0               0.0   
670   30.0  1.0  31.570000       3.0     0.0               0.0   
617   49.0  1.0  25.600000       2.0     1.0               0.0   
373   26.0  1.0  32.900002       2.0     1.0               0.0   
...    ...  ...        ...       ...     ...               ...   
1238  37.0  1.0  22.705000       3.0     0.0               1.0   
1147  20.0  0.0  31.920000       0.0     0.0               0.0   
106   19.0  0.0  28.400000       1.0     0.0               0.0   
1041  18.0  1.0  23.084999       0.0     0.0               1.0   
1122  53.0  0.0  36.860001       3.0     1.0               0.0   

      region_southwest  region_southeast  region_northwest  
300                0.0               0.0               0.0  
904                1.0               0.0               0.0  
670                0.0               1.0               0.0  
617                1.0               0.0               0.0  
373                1.0               0.0               0.0  
...                ...               ...               ...  
1238               0.0               0.0               0.0  
1147               0.0               0.0               1.0  
106                1.0               0.0               0.0  
1041               0.0               0.0               0.0  
1122               0.0               0.0               1.0  

[936 rows x 9 columns]
2023-04-06 18:17:01,417:INFO:get_config() successfully completed......................................
2023-04-06 18:17:20,439:INFO:Initializing get_config()
2023-04-06 18:17:20,440:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x28a930100>, variable=seed)
2023-04-06 18:17:20,440:INFO:Variable:  returned as 123
2023-04-06 18:17:20,440:INFO:get_config() successfully completed......................................
2023-04-06 18:17:20,441:INFO:Initializing set_config()
2023-04-06 18:17:20,442:INFO:set_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x28a930100>, variable=seed, value=786, kwargs={})
2023-04-06 18:17:20,443:INFO:Global variable: seed updated to 786
2023-04-06 18:17:20,443:INFO:set_config() successfully completed......................................
2023-04-06 18:17:20,443:INFO:Initializing get_config()
2023-04-06 18:17:20,443:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x28a930100>, variable=seed)
2023-04-06 18:17:20,444:INFO:Variable:  returned as 786
2023-04-06 18:17:20,444:INFO:get_config() successfully completed......................................
2023-04-06 18:17:38,599:INFO:PyCaret RegressionExperiment
2023-04-06 18:17:38,600:INFO:Logging name: reg-default-name
2023-04-06 18:17:38,600:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-06 18:17:38,600:INFO:version 3.0.0
2023-04-06 18:17:38,600:INFO:Initializing setup()
2023-04-06 18:17:38,600:INFO:self.USI: bf40
2023-04-06 18:17:38,600:INFO:self._variable_keys: {'log_plots_param', '_ml_usecase', 'data', 'y', 'fold_groups_param', 'transform_target_param', 'X_train', 'n_jobs_param', 'seed', '_available_plots', 'USI', 'gpu_n_jobs_param', 'memory', 'fold_generator', 'target_param', 'exp_id', 'y_test', 'X_test', 'idx', 'X', 'exp_name_log', 'html_param', 'gpu_param', 'fold_shuffle_param', 'y_train', 'pipeline', 'logging_param'}
2023-04-06 18:17:38,600:INFO:Checking environment
2023-04-06 18:17:38,600:INFO:python_version: 3.9.15
2023-04-06 18:17:38,600:INFO:python_build: ('main', 'Nov 24 2022 08:28:41')
2023-04-06 18:17:38,600:INFO:machine: arm64
2023-04-06 18:17:38,600:INFO:platform: macOS-13.2-arm64-arm-64bit
2023-04-06 18:17:38,600:INFO:Memory: svmem(total=17179869184, available=4542889984, percent=73.6, used=6549389312, free=197656576, active=4360650752, inactive=4308533248, wired=2188738560)
2023-04-06 18:17:38,600:INFO:Physical Core: 10
2023-04-06 18:17:38,600:INFO:Logical Core: 10
2023-04-06 18:17:38,600:INFO:Checking libraries
2023-04-06 18:17:38,600:INFO:System:
2023-04-06 18:17:38,600:INFO:    python: 3.9.15 (main, Nov 24 2022, 08:28:41)  [Clang 14.0.6 ]
2023-04-06 18:17:38,600:INFO:executable: /Users/a06411/opt/anaconda3/bin/python
2023-04-06 18:17:38,600:INFO:   machine: macOS-13.2-arm64-arm-64bit
2023-04-06 18:17:38,600:INFO:PyCaret required dependencies:
2023-04-06 18:17:38,600:INFO:                 pip: 22.3.1
2023-04-06 18:17:38,600:INFO:          setuptools: 65.5.0
2023-04-06 18:17:38,600:INFO:             pycaret: 3.0.0
2023-04-06 18:17:38,600:INFO:             IPython: 8.7.0
2023-04-06 18:17:38,600:INFO:          ipywidgets: 7.6.5
2023-04-06 18:17:38,600:INFO:                tqdm: 4.64.1
2023-04-06 18:17:38,600:INFO:               numpy: 1.21.5
2023-04-06 18:17:38,600:INFO:              pandas: 1.4.4
2023-04-06 18:17:38,600:INFO:              jinja2: 2.11.3
2023-04-06 18:17:38,600:INFO:               scipy: 1.9.3
2023-04-06 18:17:38,600:INFO:              joblib: 1.2.0
2023-04-06 18:17:38,600:INFO:             sklearn: 1.1.3
2023-04-06 18:17:38,600:INFO:                pyod: 1.0.9
2023-04-06 18:17:38,600:INFO:            imblearn: 0.10.1
2023-04-06 18:17:38,600:INFO:   category_encoders: 2.6.0
2023-04-06 18:17:38,600:INFO:            lightgbm: 3.3.5
2023-04-06 18:17:38,600:INFO:               numba: 0.56.4
2023-04-06 18:17:38,600:INFO:            requests: 2.28.1
2023-04-06 18:17:38,600:INFO:          matplotlib: 3.6.2
2023-04-06 18:17:38,600:INFO:          scikitplot: 0.3.7
2023-04-06 18:17:38,600:INFO:         yellowbrick: 1.5
2023-04-06 18:17:38,600:INFO:              plotly: 5.9.0
2023-04-06 18:17:38,600:INFO:             kaleido: 0.2.1
2023-04-06 18:17:38,600:INFO:         statsmodels: 0.13.2
2023-04-06 18:17:38,600:INFO:              sktime: 0.16.1
2023-04-06 18:17:38,600:INFO:               tbats: 1.1.2
2023-04-06 18:17:38,600:INFO:            pmdarima: 2.0.3
2023-04-06 18:17:38,600:INFO:              psutil: 5.9.0
2023-04-06 18:17:38,600:INFO:PyCaret optional dependencies:
2023-04-06 18:17:38,600:INFO:                shap: 0.41.0
2023-04-06 18:17:38,600:INFO:           interpret: Not installed
2023-04-06 18:17:38,600:INFO:                umap: 0.5.3
2023-04-06 18:17:38,600:INFO:    pandas_profiling: 4.1.2
2023-04-06 18:17:38,600:INFO:  explainerdashboard: 0.4.2.1
2023-04-06 18:17:38,600:INFO:             autoviz: Not installed
2023-04-06 18:17:38,600:INFO:           fairlearn: Not installed
2023-04-06 18:17:38,600:INFO:             xgboost: 1.7.2
2023-04-06 18:17:38,600:INFO:            catboost: 1.1.1
2023-04-06 18:17:38,600:INFO:              kmodes: Not installed
2023-04-06 18:17:38,600:INFO:             mlxtend: Not installed
2023-04-06 18:17:38,600:INFO:       statsforecast: Not installed
2023-04-06 18:17:38,600:INFO:        tune_sklearn: Not installed
2023-04-06 18:17:38,600:INFO:                 ray: Not installed
2023-04-06 18:17:38,600:INFO:            hyperopt: 0.2.7
2023-04-06 18:17:38,600:INFO:              optuna: 3.1.0
2023-04-06 18:17:38,600:INFO:               skopt: 0.9.0
2023-04-06 18:17:38,600:INFO:              mlflow: 2.2.2
2023-04-06 18:17:38,600:INFO:              gradio: Not installed
2023-04-06 18:17:38,600:INFO:             fastapi: Not installed
2023-04-06 18:17:38,600:INFO:             uvicorn: Not installed
2023-04-06 18:17:38,601:INFO:              m2cgen: Not installed
2023-04-06 18:17:38,601:INFO:           evidently: Not installed
2023-04-06 18:17:38,601:INFO:               fugue: Not installed
2023-04-06 18:17:38,601:INFO:           streamlit: Not installed
2023-04-06 18:17:38,601:INFO:             prophet: Not installed
2023-04-06 18:17:38,601:INFO:None
2023-04-06 18:17:38,601:INFO:Set up data.
2023-04-06 18:17:38,603:INFO:Set up train/test split.
2023-04-06 18:17:38,604:INFO:Set up index.
2023-04-06 18:17:38,604:INFO:Set up folding strategy.
2023-04-06 18:17:38,604:INFO:Assigning column types.
2023-04-06 18:17:38,605:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-06 18:17:38,605:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-06 18:17:38,607:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-06 18:17:38,609:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 18:17:38,632:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 18:17:38,650:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 18:17:38,650:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:17:38,651:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:17:38,652:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-06 18:17:38,653:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-06 18:17:38,655:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 18:17:38,678:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 18:17:38,697:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 18:17:38,698:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:17:38,699:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:17:38,699:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-06 18:17:38,701:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-06 18:17:38,703:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 18:17:38,726:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 18:17:38,745:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 18:17:38,745:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:17:38,746:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:17:38,749:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-06 18:17:38,751:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 18:17:38,776:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 18:17:38,795:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 18:17:38,795:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:17:38,797:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:17:38,797:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-06 18:17:38,801:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 18:17:38,824:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 18:17:38,842:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 18:17:38,843:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:17:38,844:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:17:38,848:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 18:17:38,871:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 18:17:38,889:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 18:17:38,889:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:17:38,891:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:17:38,891:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-06 18:17:38,918:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 18:17:38,936:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 18:17:38,936:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:17:38,937:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:17:38,964:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 18:17:38,982:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 18:17:38,983:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:17:38,984:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:17:38,984:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-06 18:17:39,010:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 18:17:39,028:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:17:39,029:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:17:39,056:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 18:17:39,075:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:17:39,076:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:17:39,076:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-06 18:17:39,121:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:17:39,122:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:17:39,167:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:17:39,168:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:17:39,169:INFO:Preparing preprocessing pipeline...
2023-04-06 18:17:39,169:INFO:Set up simple imputation.
2023-04-06 18:17:39,170:INFO:Set up encoding of ordinal features.
2023-04-06 18:17:39,171:INFO:Set up encoding of categorical features.
2023-04-06 18:17:39,171:INFO:Set up feature normalization.
2023-04-06 18:17:39,210:INFO:Finished creating preprocessing pipeline.
2023-04-06 18:17:39,221:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encodin...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64},
                                                                        {'col': 'smoker',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['region'],
                                    transformer=OneHotEncoder(cols=['region'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler()))])
2023-04-06 18:17:39,221:INFO:Creating final display dataframe.
2023-04-06 18:17:39,318:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           charges
2                   Target type        Regression
3           Original data shape         (1338, 7)
4        Transformed data shape        (1338, 10)
5   Transformed train set shape         (936, 10)
6    Transformed test set shape         (402, 10)
7              Ordinal features                 2
8              Numeric features                 3
9          Categorical features                 3
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                    Normalize              True
17             Normalize method            minmax
18               Fold Generator             KFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  reg-default-name
24                          USI              bf40
2023-04-06 18:17:39,368:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:17:39,370:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:17:39,415:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:17:39,416:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:17:39,416:INFO:setup() successfully completed in 1.28s...............
2023-04-06 18:18:42,844:INFO:Initializing get_config()
2023-04-06 18:18:42,845:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, variable=X_train_transformed)
2023-04-06 18:18:42,894:INFO:Variable: X_train returned as            age  sex       bmi  children  smoker  region_northeast  \
300   0.391304  1.0  0.300154       0.6     0.0               1.0   
904   0.913043  0.0  0.511254       0.0     0.0               0.0   
670   0.260870  1.0  0.412554       0.6     0.0               0.0   
617   0.673913  1.0  0.245631       0.4     1.0               0.0   
373   0.173913  1.0  0.449741       0.4     1.0               0.0   
...        ...  ...       ...       ...     ...               ...   
1238  0.413043  1.0  0.164686       0.6     0.0               1.0   
1147  0.043478  0.0  0.422340       0.0     0.0               0.0   
106   0.021739  0.0  0.323920       0.2     0.0               0.0   
1041  0.000000  1.0  0.175311       0.0     0.0               1.0   
1122  0.760870  0.0  0.560464       0.6     1.0               0.0   

      region_southwest  region_southeast  region_northwest  
300                0.0               0.0               0.0  
904                1.0               0.0               0.0  
670                0.0               1.0               0.0  
617                1.0               0.0               0.0  
373                1.0               0.0               0.0  
...                ...               ...               ...  
1238               0.0               0.0               0.0  
1147               0.0               0.0               1.0  
106                1.0               0.0               0.0  
1041               0.0               0.0               0.0  
1122               0.0               0.0               1.0  

[936 rows x 9 columns]
2023-04-06 18:18:42,894:INFO:get_config() successfully completed......................................
2023-04-06 18:18:56,952:INFO:Initializing get_config()
2023-04-06 18:18:56,954:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, variable=X_train)
2023-04-06 18:18:56,955:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2023-04-06 18:18:56,961:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/pycaret_experiment.py:322: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
  warnings.warn(msg)  # print on screen

2023-04-06 18:18:56,968:INFO:Variable:  returned as       age     sex        bmi  children smoker     region
300    36    male  27.549999         3     no  northeast
904    60  female  35.099998         0     no  southwest
670    30    male  31.570000         3     no  southeast
617    49    male  25.600000         2    yes  southwest
373    26    male  32.900002         2    yes  southwest
...   ...     ...        ...       ...    ...        ...
1238   37    male  22.705000         3     no  northeast
1147   20  female  31.920000         0     no  northwest
106    19  female  28.400000         1     no  southwest
1041   18    male  23.084999         0     no  northeast
1122   53  female  36.860001         3    yes  northwest

[936 rows x 6 columns]
2023-04-06 18:18:56,968:INFO:get_config() successfully completed......................................
2023-04-06 18:20:16,371:INFO:Initializing compare_models()
2023-04-06 18:20:16,372:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-06 18:20:16,372:INFO:Checking exceptions
2023-04-06 18:20:16,378:INFO:Preparing display monitor
2023-04-06 18:20:16,416:INFO:Initializing Linear Regression
2023-04-06 18:20:16,416:INFO:Total runtime is 5.30083974202474e-06 minutes
2023-04-06 18:20:16,418:INFO:SubProcess create_model() called ==================================
2023-04-06 18:20:16,419:INFO:Initializing create_model()
2023-04-06 18:20:16,419:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x28ba3dbb0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:20:16,419:INFO:Checking exceptions
2023-04-06 18:20:16,419:INFO:Importing libraries
2023-04-06 18:20:16,419:INFO:Copying training dataset
2023-04-06 18:20:16,423:INFO:Defining folds
2023-04-06 18:20:16,423:INFO:Declaring metric variables
2023-04-06 18:20:16,425:INFO:Importing untrained model
2023-04-06 18:20:16,427:INFO:Linear Regression Imported successfully
2023-04-06 18:20:16,431:INFO:Starting cross validation
2023-04-06 18:20:16,438:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:20:23,738:INFO:Calculating mean and std
2023-04-06 18:20:23,740:INFO:Creating metrics dataframe
2023-04-06 18:20:24,173:INFO:Uploading results into container
2023-04-06 18:20:24,174:INFO:Uploading model into container now
2023-04-06 18:20:24,174:INFO:_master_model_container: 1
2023-04-06 18:20:24,174:INFO:_display_container: 2
2023-04-06 18:20:24,175:INFO:LinearRegression(n_jobs=-1)
2023-04-06 18:20:24,175:INFO:create_model() successfully completed......................................
2023-04-06 18:20:24,253:INFO:SubProcess create_model() end ==================================
2023-04-06 18:20:24,253:INFO:Creating metrics dataframe
2023-04-06 18:20:24,256:INFO:Initializing Lasso Regression
2023-04-06 18:20:24,257:INFO:Total runtime is 0.1306828498840332 minutes
2023-04-06 18:20:24,258:INFO:SubProcess create_model() called ==================================
2023-04-06 18:20:24,258:INFO:Initializing create_model()
2023-04-06 18:20:24,258:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x28ba3dbb0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:20:24,258:INFO:Checking exceptions
2023-04-06 18:20:24,258:INFO:Importing libraries
2023-04-06 18:20:24,258:INFO:Copying training dataset
2023-04-06 18:20:24,261:INFO:Defining folds
2023-04-06 18:20:24,261:INFO:Declaring metric variables
2023-04-06 18:20:24,262:INFO:Importing untrained model
2023-04-06 18:20:24,263:INFO:Lasso Regression Imported successfully
2023-04-06 18:20:24,266:INFO:Starting cross validation
2023-04-06 18:20:24,267:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:20:28,521:INFO:Calculating mean and std
2023-04-06 18:20:28,522:INFO:Creating metrics dataframe
2023-04-06 18:20:28,993:INFO:Uploading results into container
2023-04-06 18:20:28,993:INFO:Uploading model into container now
2023-04-06 18:20:28,993:INFO:_master_model_container: 2
2023-04-06 18:20:28,993:INFO:_display_container: 2
2023-04-06 18:20:28,994:INFO:Lasso(random_state=123)
2023-04-06 18:20:28,994:INFO:create_model() successfully completed......................................
2023-04-06 18:20:29,064:INFO:SubProcess create_model() end ==================================
2023-04-06 18:20:29,064:INFO:Creating metrics dataframe
2023-04-06 18:20:29,068:INFO:Initializing Ridge Regression
2023-04-06 18:20:29,069:INFO:Total runtime is 0.21088346640268962 minutes
2023-04-06 18:20:29,070:INFO:SubProcess create_model() called ==================================
2023-04-06 18:20:29,071:INFO:Initializing create_model()
2023-04-06 18:20:29,071:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x28ba3dbb0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:20:29,071:INFO:Checking exceptions
2023-04-06 18:20:29,071:INFO:Importing libraries
2023-04-06 18:20:29,071:INFO:Copying training dataset
2023-04-06 18:20:29,073:INFO:Defining folds
2023-04-06 18:20:29,073:INFO:Declaring metric variables
2023-04-06 18:20:29,074:INFO:Importing untrained model
2023-04-06 18:20:29,075:INFO:Ridge Regression Imported successfully
2023-04-06 18:20:29,079:INFO:Starting cross validation
2023-04-06 18:20:29,080:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:20:33,266:INFO:Calculating mean and std
2023-04-06 18:20:33,267:INFO:Creating metrics dataframe
2023-04-06 18:20:33,700:INFO:Uploading results into container
2023-04-06 18:20:33,701:INFO:Uploading model into container now
2023-04-06 18:20:33,701:INFO:_master_model_container: 3
2023-04-06 18:20:33,701:INFO:_display_container: 2
2023-04-06 18:20:33,701:INFO:Ridge(random_state=123)
2023-04-06 18:20:33,701:INFO:create_model() successfully completed......................................
2023-04-06 18:20:33,766:INFO:SubProcess create_model() end ==================================
2023-04-06 18:20:33,767:INFO:Creating metrics dataframe
2023-04-06 18:20:33,771:INFO:Initializing Elastic Net
2023-04-06 18:20:33,771:INFO:Total runtime is 0.2892530004183451 minutes
2023-04-06 18:20:33,772:INFO:SubProcess create_model() called ==================================
2023-04-06 18:20:33,773:INFO:Initializing create_model()
2023-04-06 18:20:33,773:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x28ba3dbb0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:20:33,773:INFO:Checking exceptions
2023-04-06 18:20:33,773:INFO:Importing libraries
2023-04-06 18:20:33,773:INFO:Copying training dataset
2023-04-06 18:20:33,774:INFO:Defining folds
2023-04-06 18:20:33,774:INFO:Declaring metric variables
2023-04-06 18:20:33,776:INFO:Importing untrained model
2023-04-06 18:20:33,777:INFO:Elastic Net Imported successfully
2023-04-06 18:20:33,780:INFO:Starting cross validation
2023-04-06 18:20:33,780:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:20:38,184:INFO:Calculating mean and std
2023-04-06 18:20:38,185:INFO:Creating metrics dataframe
2023-04-06 18:20:38,625:INFO:Uploading results into container
2023-04-06 18:20:38,626:INFO:Uploading model into container now
2023-04-06 18:20:38,626:INFO:_master_model_container: 4
2023-04-06 18:20:38,626:INFO:_display_container: 2
2023-04-06 18:20:38,626:INFO:ElasticNet(random_state=123)
2023-04-06 18:20:38,626:INFO:create_model() successfully completed......................................
2023-04-06 18:20:38,696:INFO:SubProcess create_model() end ==================================
2023-04-06 18:20:38,696:INFO:Creating metrics dataframe
2023-04-06 18:20:38,700:INFO:Initializing Least Angle Regression
2023-04-06 18:20:38,701:INFO:Total runtime is 0.37141691843668617 minutes
2023-04-06 18:20:38,702:INFO:SubProcess create_model() called ==================================
2023-04-06 18:20:38,702:INFO:Initializing create_model()
2023-04-06 18:20:38,702:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x28ba3dbb0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:20:38,702:INFO:Checking exceptions
2023-04-06 18:20:38,702:INFO:Importing libraries
2023-04-06 18:20:38,702:INFO:Copying training dataset
2023-04-06 18:20:38,704:INFO:Defining folds
2023-04-06 18:20:38,704:INFO:Declaring metric variables
2023-04-06 18:20:38,705:INFO:Importing untrained model
2023-04-06 18:20:38,707:INFO:Least Angle Regression Imported successfully
2023-04-06 18:20:38,709:INFO:Starting cross validation
2023-04-06 18:20:38,710:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:20:38,764:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:20:38,768:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:20:38,771:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:20:38,774:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:20:38,778:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:20:38,781:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:20:38,790:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:20:38,796:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:20:38,810:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:20:38,827:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:20:42,897:INFO:Calculating mean and std
2023-04-06 18:20:42,897:INFO:Creating metrics dataframe
2023-04-06 18:20:43,335:INFO:Uploading results into container
2023-04-06 18:20:43,336:INFO:Uploading model into container now
2023-04-06 18:20:43,336:INFO:_master_model_container: 5
2023-04-06 18:20:43,336:INFO:_display_container: 2
2023-04-06 18:20:43,337:INFO:Lars(random_state=123)
2023-04-06 18:20:43,337:INFO:create_model() successfully completed......................................
2023-04-06 18:20:43,402:INFO:SubProcess create_model() end ==================================
2023-04-06 18:20:43,402:INFO:Creating metrics dataframe
2023-04-06 18:20:43,406:INFO:Initializing Lasso Least Angle Regression
2023-04-06 18:20:43,407:INFO:Total runtime is 0.44985059897104895 minutes
2023-04-06 18:20:43,408:INFO:SubProcess create_model() called ==================================
2023-04-06 18:20:43,408:INFO:Initializing create_model()
2023-04-06 18:20:43,408:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x28ba3dbb0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:20:43,408:INFO:Checking exceptions
2023-04-06 18:20:43,408:INFO:Importing libraries
2023-04-06 18:20:43,408:INFO:Copying training dataset
2023-04-06 18:20:43,411:INFO:Defining folds
2023-04-06 18:20:43,411:INFO:Declaring metric variables
2023-04-06 18:20:43,412:INFO:Importing untrained model
2023-04-06 18:20:43,414:INFO:Lasso Least Angle Regression Imported successfully
2023-04-06 18:20:43,417:INFO:Starting cross validation
2023-04-06 18:20:43,418:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:20:43,469:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 18:20:43,472:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 18:20:43,477:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 18:20:43,480:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 18:20:43,489:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 18:20:43,491:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 18:20:43,499:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 18:20:43,502:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 18:20:43,510:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 18:20:43,513:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 18:20:47,794:INFO:Calculating mean and std
2023-04-06 18:20:47,796:INFO:Creating metrics dataframe
2023-04-06 18:20:48,255:INFO:Uploading results into container
2023-04-06 18:20:48,256:INFO:Uploading model into container now
2023-04-06 18:20:48,257:INFO:_master_model_container: 6
2023-04-06 18:20:48,257:INFO:_display_container: 2
2023-04-06 18:20:48,257:INFO:LassoLars(random_state=123)
2023-04-06 18:20:48,257:INFO:create_model() successfully completed......................................
2023-04-06 18:20:48,322:INFO:SubProcess create_model() end ==================================
2023-04-06 18:20:48,322:INFO:Creating metrics dataframe
2023-04-06 18:20:48,326:INFO:Initializing Orthogonal Matching Pursuit
2023-04-06 18:20:48,326:INFO:Total runtime is 0.5318431337674459 minutes
2023-04-06 18:20:48,328:INFO:SubProcess create_model() called ==================================
2023-04-06 18:20:48,328:INFO:Initializing create_model()
2023-04-06 18:20:48,328:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x28ba3dbb0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:20:48,328:INFO:Checking exceptions
2023-04-06 18:20:48,328:INFO:Importing libraries
2023-04-06 18:20:48,328:INFO:Copying training dataset
2023-04-06 18:20:48,330:INFO:Defining folds
2023-04-06 18:20:48,330:INFO:Declaring metric variables
2023-04-06 18:20:48,332:INFO:Importing untrained model
2023-04-06 18:20:48,333:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-06 18:20:48,336:INFO:Starting cross validation
2023-04-06 18:20:48,336:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:20:48,386:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:20:48,388:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:20:48,390:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:20:48,394:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:20:48,398:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:20:48,416:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:20:48,420:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:20:48,423:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:20:48,446:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:20:48,447:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:20:52,619:INFO:Calculating mean and std
2023-04-06 18:20:52,620:INFO:Creating metrics dataframe
2023-04-06 18:20:53,080:INFO:Uploading results into container
2023-04-06 18:20:53,081:INFO:Uploading model into container now
2023-04-06 18:20:53,081:INFO:_master_model_container: 7
2023-04-06 18:20:53,081:INFO:_display_container: 2
2023-04-06 18:20:53,081:INFO:OrthogonalMatchingPursuit()
2023-04-06 18:20:53,081:INFO:create_model() successfully completed......................................
2023-04-06 18:20:53,147:INFO:SubProcess create_model() end ==================================
2023-04-06 18:20:53,147:INFO:Creating metrics dataframe
2023-04-06 18:20:53,152:INFO:Initializing Bayesian Ridge
2023-04-06 18:20:53,152:INFO:Total runtime is 0.6122820814450581 minutes
2023-04-06 18:20:53,154:INFO:SubProcess create_model() called ==================================
2023-04-06 18:20:53,154:INFO:Initializing create_model()
2023-04-06 18:20:53,154:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x28ba3dbb0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:20:53,155:INFO:Checking exceptions
2023-04-06 18:20:53,155:INFO:Importing libraries
2023-04-06 18:20:53,155:INFO:Copying training dataset
2023-04-06 18:20:53,156:INFO:Defining folds
2023-04-06 18:20:53,156:INFO:Declaring metric variables
2023-04-06 18:20:53,158:INFO:Importing untrained model
2023-04-06 18:20:53,159:INFO:Bayesian Ridge Imported successfully
2023-04-06 18:20:53,161:INFO:Starting cross validation
2023-04-06 18:20:53,162:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:20:57,381:INFO:Calculating mean and std
2023-04-06 18:20:57,383:INFO:Creating metrics dataframe
2023-04-06 18:20:57,815:INFO:Uploading results into container
2023-04-06 18:20:57,815:INFO:Uploading model into container now
2023-04-06 18:20:57,815:INFO:_master_model_container: 8
2023-04-06 18:20:57,815:INFO:_display_container: 2
2023-04-06 18:20:57,816:INFO:BayesianRidge()
2023-04-06 18:20:57,816:INFO:create_model() successfully completed......................................
2023-04-06 18:20:57,881:INFO:SubProcess create_model() end ==================================
2023-04-06 18:20:57,881:INFO:Creating metrics dataframe
2023-04-06 18:20:57,886:INFO:Initializing Passive Aggressive Regressor
2023-04-06 18:20:57,886:INFO:Total runtime is 0.6911722501118978 minutes
2023-04-06 18:20:57,887:INFO:SubProcess create_model() called ==================================
2023-04-06 18:20:57,887:INFO:Initializing create_model()
2023-04-06 18:20:57,887:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x28ba3dbb0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:20:57,888:INFO:Checking exceptions
2023-04-06 18:20:57,888:INFO:Importing libraries
2023-04-06 18:20:57,888:INFO:Copying training dataset
2023-04-06 18:20:57,889:INFO:Defining folds
2023-04-06 18:20:57,889:INFO:Declaring metric variables
2023-04-06 18:20:57,891:INFO:Importing untrained model
2023-04-06 18:20:57,892:INFO:Passive Aggressive Regressor Imported successfully
2023-04-06 18:20:57,895:INFO:Starting cross validation
2023-04-06 18:20:57,896:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:20:58,058:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-04-06 18:21:02,172:INFO:Calculating mean and std
2023-04-06 18:21:02,173:INFO:Creating metrics dataframe
2023-04-06 18:21:02,604:INFO:Uploading results into container
2023-04-06 18:21:02,605:INFO:Uploading model into container now
2023-04-06 18:21:02,605:INFO:_master_model_container: 9
2023-04-06 18:21:02,605:INFO:_display_container: 2
2023-04-06 18:21:02,605:INFO:PassiveAggressiveRegressor(random_state=123)
2023-04-06 18:21:02,605:INFO:create_model() successfully completed......................................
2023-04-06 18:21:02,671:INFO:SubProcess create_model() end ==================================
2023-04-06 18:21:02,671:INFO:Creating metrics dataframe
2023-04-06 18:21:02,676:INFO:Initializing Huber Regressor
2023-04-06 18:21:02,676:INFO:Total runtime is 0.7710022489229837 minutes
2023-04-06 18:21:02,677:INFO:SubProcess create_model() called ==================================
2023-04-06 18:21:02,677:INFO:Initializing create_model()
2023-04-06 18:21:02,678:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x28ba3dbb0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:21:02,678:INFO:Checking exceptions
2023-04-06 18:21:02,678:INFO:Importing libraries
2023-04-06 18:21:02,678:INFO:Copying training dataset
2023-04-06 18:21:02,679:INFO:Defining folds
2023-04-06 18:21:02,679:INFO:Declaring metric variables
2023-04-06 18:21:02,681:INFO:Importing untrained model
2023-04-06 18:21:02,682:INFO:Huber Regressor Imported successfully
2023-04-06 18:21:02,685:INFO:Starting cross validation
2023-04-06 18:21:02,686:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:21:07,019:INFO:Calculating mean and std
2023-04-06 18:21:07,020:INFO:Creating metrics dataframe
2023-04-06 18:21:07,438:INFO:Uploading results into container
2023-04-06 18:21:07,439:INFO:Uploading model into container now
2023-04-06 18:21:07,439:INFO:_master_model_container: 10
2023-04-06 18:21:07,439:INFO:_display_container: 2
2023-04-06 18:21:07,439:INFO:HuberRegressor()
2023-04-06 18:21:07,439:INFO:create_model() successfully completed......................................
2023-04-06 18:21:07,506:INFO:SubProcess create_model() end ==================================
2023-04-06 18:21:07,506:INFO:Creating metrics dataframe
2023-04-06 18:21:07,510:INFO:Initializing K Neighbors Regressor
2023-04-06 18:21:07,511:INFO:Total runtime is 0.851583981513977 minutes
2023-04-06 18:21:07,512:INFO:SubProcess create_model() called ==================================
2023-04-06 18:21:07,512:INFO:Initializing create_model()
2023-04-06 18:21:07,512:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x28ba3dbb0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:21:07,512:INFO:Checking exceptions
2023-04-06 18:21:07,512:INFO:Importing libraries
2023-04-06 18:21:07,513:INFO:Copying training dataset
2023-04-06 18:21:07,514:INFO:Defining folds
2023-04-06 18:21:07,514:INFO:Declaring metric variables
2023-04-06 18:21:07,516:INFO:Importing untrained model
2023-04-06 18:21:07,517:INFO:K Neighbors Regressor Imported successfully
2023-04-06 18:21:07,519:INFO:Starting cross validation
2023-04-06 18:21:07,520:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:21:11,711:INFO:Calculating mean and std
2023-04-06 18:21:11,712:INFO:Creating metrics dataframe
2023-04-06 18:21:12,146:INFO:Uploading results into container
2023-04-06 18:21:12,146:INFO:Uploading model into container now
2023-04-06 18:21:12,146:INFO:_master_model_container: 11
2023-04-06 18:21:12,146:INFO:_display_container: 2
2023-04-06 18:21:12,147:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-06 18:21:12,147:INFO:create_model() successfully completed......................................
2023-04-06 18:21:12,210:INFO:SubProcess create_model() end ==================================
2023-04-06 18:21:12,210:INFO:Creating metrics dataframe
2023-04-06 18:21:12,215:INFO:Initializing Decision Tree Regressor
2023-04-06 18:21:12,215:INFO:Total runtime is 0.9299923340479532 minutes
2023-04-06 18:21:12,216:INFO:SubProcess create_model() called ==================================
2023-04-06 18:21:12,216:INFO:Initializing create_model()
2023-04-06 18:21:12,216:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x28ba3dbb0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:21:12,216:INFO:Checking exceptions
2023-04-06 18:21:12,217:INFO:Importing libraries
2023-04-06 18:21:12,217:INFO:Copying training dataset
2023-04-06 18:21:12,219:INFO:Defining folds
2023-04-06 18:21:12,219:INFO:Declaring metric variables
2023-04-06 18:21:12,220:INFO:Importing untrained model
2023-04-06 18:21:12,222:INFO:Decision Tree Regressor Imported successfully
2023-04-06 18:21:12,225:INFO:Starting cross validation
2023-04-06 18:21:12,225:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:21:16,377:INFO:Calculating mean and std
2023-04-06 18:21:16,378:INFO:Creating metrics dataframe
2023-04-06 18:21:16,811:INFO:Uploading results into container
2023-04-06 18:21:16,811:INFO:Uploading model into container now
2023-04-06 18:21:16,812:INFO:_master_model_container: 12
2023-04-06 18:21:16,812:INFO:_display_container: 2
2023-04-06 18:21:16,812:INFO:DecisionTreeRegressor(random_state=123)
2023-04-06 18:21:16,812:INFO:create_model() successfully completed......................................
2023-04-06 18:21:16,881:INFO:SubProcess create_model() end ==================================
2023-04-06 18:21:16,881:INFO:Creating metrics dataframe
2023-04-06 18:21:16,885:INFO:Initializing Random Forest Regressor
2023-04-06 18:21:16,885:INFO:Total runtime is 1.0078313827514649 minutes
2023-04-06 18:21:16,887:INFO:SubProcess create_model() called ==================================
2023-04-06 18:21:16,887:INFO:Initializing create_model()
2023-04-06 18:21:16,887:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x28ba3dbb0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:21:16,887:INFO:Checking exceptions
2023-04-06 18:21:16,887:INFO:Importing libraries
2023-04-06 18:21:16,887:INFO:Copying training dataset
2023-04-06 18:21:16,889:INFO:Defining folds
2023-04-06 18:21:16,889:INFO:Declaring metric variables
2023-04-06 18:21:16,890:INFO:Importing untrained model
2023-04-06 18:21:16,892:INFO:Random Forest Regressor Imported successfully
2023-04-06 18:21:16,895:INFO:Starting cross validation
2023-04-06 18:21:16,896:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:21:21,429:INFO:Calculating mean and std
2023-04-06 18:21:21,430:INFO:Creating metrics dataframe
2023-04-06 18:21:21,884:INFO:Uploading results into container
2023-04-06 18:21:21,884:INFO:Uploading model into container now
2023-04-06 18:21:21,884:INFO:_master_model_container: 13
2023-04-06 18:21:21,885:INFO:_display_container: 2
2023-04-06 18:21:21,885:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-04-06 18:21:21,885:INFO:create_model() successfully completed......................................
2023-04-06 18:21:21,951:INFO:SubProcess create_model() end ==================================
2023-04-06 18:21:21,951:INFO:Creating metrics dataframe
2023-04-06 18:21:21,956:INFO:Initializing Extra Trees Regressor
2023-04-06 18:21:21,956:INFO:Total runtime is 1.0923397858937582 minutes
2023-04-06 18:21:21,957:INFO:SubProcess create_model() called ==================================
2023-04-06 18:21:21,957:INFO:Initializing create_model()
2023-04-06 18:21:21,957:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x28ba3dbb0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:21:21,957:INFO:Checking exceptions
2023-04-06 18:21:21,958:INFO:Importing libraries
2023-04-06 18:21:21,958:INFO:Copying training dataset
2023-04-06 18:21:21,959:INFO:Defining folds
2023-04-06 18:21:21,959:INFO:Declaring metric variables
2023-04-06 18:21:21,961:INFO:Importing untrained model
2023-04-06 18:21:21,962:INFO:Extra Trees Regressor Imported successfully
2023-04-06 18:21:21,965:INFO:Starting cross validation
2023-04-06 18:21:21,965:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:21:26,505:INFO:Calculating mean and std
2023-04-06 18:21:26,507:INFO:Creating metrics dataframe
2023-04-06 18:21:26,942:INFO:Uploading results into container
2023-04-06 18:21:26,943:INFO:Uploading model into container now
2023-04-06 18:21:26,943:INFO:_master_model_container: 14
2023-04-06 18:21:26,943:INFO:_display_container: 2
2023-04-06 18:21:26,944:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-04-06 18:21:26,944:INFO:create_model() successfully completed......................................
2023-04-06 18:21:27,010:INFO:SubProcess create_model() end ==================================
2023-04-06 18:21:27,010:INFO:Creating metrics dataframe
2023-04-06 18:21:27,015:INFO:Initializing AdaBoost Regressor
2023-04-06 18:21:27,015:INFO:Total runtime is 1.1766582846641542 minutes
2023-04-06 18:21:27,017:INFO:SubProcess create_model() called ==================================
2023-04-06 18:21:27,017:INFO:Initializing create_model()
2023-04-06 18:21:27,017:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x28ba3dbb0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:21:27,017:INFO:Checking exceptions
2023-04-06 18:21:27,017:INFO:Importing libraries
2023-04-06 18:21:27,017:INFO:Copying training dataset
2023-04-06 18:21:27,019:INFO:Defining folds
2023-04-06 18:21:27,019:INFO:Declaring metric variables
2023-04-06 18:21:27,020:INFO:Importing untrained model
2023-04-06 18:21:27,022:INFO:AdaBoost Regressor Imported successfully
2023-04-06 18:21:27,025:INFO:Starting cross validation
2023-04-06 18:21:27,026:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:21:31,343:INFO:Calculating mean and std
2023-04-06 18:21:31,343:INFO:Creating metrics dataframe
2023-04-06 18:21:31,789:INFO:Uploading results into container
2023-04-06 18:21:31,789:INFO:Uploading model into container now
2023-04-06 18:21:31,790:INFO:_master_model_container: 15
2023-04-06 18:21:31,790:INFO:_display_container: 2
2023-04-06 18:21:31,790:INFO:AdaBoostRegressor(random_state=123)
2023-04-06 18:21:31,790:INFO:create_model() successfully completed......................................
2023-04-06 18:21:31,854:INFO:SubProcess create_model() end ==================================
2023-04-06 18:21:31,854:INFO:Creating metrics dataframe
2023-04-06 18:21:31,858:INFO:Initializing Gradient Boosting Regressor
2023-04-06 18:21:31,858:INFO:Total runtime is 1.2573817809422814 minutes
2023-04-06 18:21:31,860:INFO:SubProcess create_model() called ==================================
2023-04-06 18:21:31,860:INFO:Initializing create_model()
2023-04-06 18:21:31,860:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x28ba3dbb0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:21:31,860:INFO:Checking exceptions
2023-04-06 18:21:31,860:INFO:Importing libraries
2023-04-06 18:21:31,860:INFO:Copying training dataset
2023-04-06 18:21:31,861:INFO:Defining folds
2023-04-06 18:21:31,861:INFO:Declaring metric variables
2023-04-06 18:21:31,863:INFO:Importing untrained model
2023-04-06 18:21:31,864:INFO:Gradient Boosting Regressor Imported successfully
2023-04-06 18:21:31,866:INFO:Starting cross validation
2023-04-06 18:21:31,867:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:21:36,308:INFO:Calculating mean and std
2023-04-06 18:21:36,308:INFO:Creating metrics dataframe
2023-04-06 18:21:36,755:INFO:Uploading results into container
2023-04-06 18:21:36,755:INFO:Uploading model into container now
2023-04-06 18:21:36,756:INFO:_master_model_container: 16
2023-04-06 18:21:36,756:INFO:_display_container: 2
2023-04-06 18:21:36,756:INFO:GradientBoostingRegressor(random_state=123)
2023-04-06 18:21:36,756:INFO:create_model() successfully completed......................................
2023-04-06 18:21:36,820:INFO:SubProcess create_model() end ==================================
2023-04-06 18:21:36,821:INFO:Creating metrics dataframe
2023-04-06 18:21:36,826:INFO:Initializing Extreme Gradient Boosting
2023-04-06 18:21:36,826:INFO:Total runtime is 1.3401809334754946 minutes
2023-04-06 18:21:36,828:INFO:SubProcess create_model() called ==================================
2023-04-06 18:21:36,828:INFO:Initializing create_model()
2023-04-06 18:21:36,828:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x28ba3dbb0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:21:36,828:INFO:Checking exceptions
2023-04-06 18:21:36,828:INFO:Importing libraries
2023-04-06 18:21:36,828:INFO:Copying training dataset
2023-04-06 18:21:36,830:INFO:Defining folds
2023-04-06 18:21:36,830:INFO:Declaring metric variables
2023-04-06 18:21:36,831:INFO:Importing untrained model
2023-04-06 18:21:36,832:INFO:Extreme Gradient Boosting Imported successfully
2023-04-06 18:21:36,834:INFO:Starting cross validation
2023-04-06 18:21:36,835:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:21:41,399:INFO:Calculating mean and std
2023-04-06 18:21:41,400:INFO:Creating metrics dataframe
2023-04-06 18:21:41,852:INFO:Uploading results into container
2023-04-06 18:21:41,853:INFO:Uploading model into container now
2023-04-06 18:21:41,853:INFO:_master_model_container: 17
2023-04-06 18:21:41,853:INFO:_display_container: 2
2023-04-06 18:21:41,853:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=123, ...)
2023-04-06 18:21:41,854:INFO:create_model() successfully completed......................................
2023-04-06 18:21:41,915:INFO:SubProcess create_model() end ==================================
2023-04-06 18:21:41,916:INFO:Creating metrics dataframe
2023-04-06 18:21:41,921:INFO:Initializing Light Gradient Boosting Machine
2023-04-06 18:21:41,921:INFO:Total runtime is 1.4250848968823753 minutes
2023-04-06 18:21:41,922:INFO:SubProcess create_model() called ==================================
2023-04-06 18:21:41,922:INFO:Initializing create_model()
2023-04-06 18:21:41,922:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x28ba3dbb0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:21:41,922:INFO:Checking exceptions
2023-04-06 18:21:41,922:INFO:Importing libraries
2023-04-06 18:21:41,922:INFO:Copying training dataset
2023-04-06 18:21:41,924:INFO:Defining folds
2023-04-06 18:21:41,924:INFO:Declaring metric variables
2023-04-06 18:21:41,926:INFO:Importing untrained model
2023-04-06 18:21:41,929:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-06 18:21:41,933:INFO:Starting cross validation
2023-04-06 18:21:41,934:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:21:47,060:INFO:Calculating mean and std
2023-04-06 18:21:47,060:INFO:Creating metrics dataframe
2023-04-06 18:21:47,496:INFO:Uploading results into container
2023-04-06 18:21:47,497:INFO:Uploading model into container now
2023-04-06 18:21:47,497:INFO:_master_model_container: 18
2023-04-06 18:21:47,497:INFO:_display_container: 2
2023-04-06 18:21:47,498:INFO:LGBMRegressor(random_state=123)
2023-04-06 18:21:47,498:INFO:create_model() successfully completed......................................
2023-04-06 18:21:47,563:INFO:SubProcess create_model() end ==================================
2023-04-06 18:21:47,563:INFO:Creating metrics dataframe
2023-04-06 18:21:47,568:INFO:Initializing CatBoost Regressor
2023-04-06 18:21:47,568:INFO:Total runtime is 1.5192123651504519 minutes
2023-04-06 18:21:47,570:INFO:SubProcess create_model() called ==================================
2023-04-06 18:21:47,570:INFO:Initializing create_model()
2023-04-06 18:21:47,570:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x28ba3dbb0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:21:47,570:INFO:Checking exceptions
2023-04-06 18:21:47,570:INFO:Importing libraries
2023-04-06 18:21:47,570:INFO:Copying training dataset
2023-04-06 18:21:47,572:INFO:Defining folds
2023-04-06 18:21:47,572:INFO:Declaring metric variables
2023-04-06 18:21:47,573:INFO:Importing untrained model
2023-04-06 18:21:47,574:INFO:CatBoost Regressor Imported successfully
2023-04-06 18:21:47,577:INFO:Starting cross validation
2023-04-06 18:21:47,578:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:21:53,055:INFO:Calculating mean and std
2023-04-06 18:21:53,056:INFO:Creating metrics dataframe
2023-04-06 18:21:53,499:INFO:Uploading results into container
2023-04-06 18:21:53,500:INFO:Uploading model into container now
2023-04-06 18:21:53,500:INFO:_master_model_container: 19
2023-04-06 18:21:53,500:INFO:_display_container: 2
2023-04-06 18:21:53,500:INFO:<catboost.core.CatBoostRegressor object at 0x28c39bc40>
2023-04-06 18:21:53,500:INFO:create_model() successfully completed......................................
2023-04-06 18:21:53,571:INFO:SubProcess create_model() end ==================================
2023-04-06 18:21:53,572:INFO:Creating metrics dataframe
2023-04-06 18:21:53,578:INFO:Initializing Dummy Regressor
2023-04-06 18:21:53,578:INFO:Total runtime is 1.619371330738068 minutes
2023-04-06 18:21:53,580:INFO:SubProcess create_model() called ==================================
2023-04-06 18:21:53,580:INFO:Initializing create_model()
2023-04-06 18:21:53,580:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x28ba3dbb0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:21:53,580:INFO:Checking exceptions
2023-04-06 18:21:53,581:INFO:Importing libraries
2023-04-06 18:21:53,581:INFO:Copying training dataset
2023-04-06 18:21:53,582:INFO:Defining folds
2023-04-06 18:21:53,582:INFO:Declaring metric variables
2023-04-06 18:21:53,584:INFO:Importing untrained model
2023-04-06 18:21:53,585:INFO:Dummy Regressor Imported successfully
2023-04-06 18:21:53,588:INFO:Starting cross validation
2023-04-06 18:21:53,588:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:21:57,952:INFO:Calculating mean and std
2023-04-06 18:21:57,953:INFO:Creating metrics dataframe
2023-04-06 18:21:58,397:INFO:Uploading results into container
2023-04-06 18:21:58,398:INFO:Uploading model into container now
2023-04-06 18:21:58,398:INFO:_master_model_container: 20
2023-04-06 18:21:58,398:INFO:_display_container: 2
2023-04-06 18:21:58,398:INFO:DummyRegressor()
2023-04-06 18:21:58,398:INFO:create_model() successfully completed......................................
2023-04-06 18:21:58,469:INFO:SubProcess create_model() end ==================================
2023-04-06 18:21:58,470:INFO:Creating metrics dataframe
2023-04-06 18:21:58,479:INFO:Initializing create_model()
2023-04-06 18:21:58,479:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:21:58,479:INFO:Checking exceptions
2023-04-06 18:21:58,480:INFO:Importing libraries
2023-04-06 18:21:58,480:INFO:Copying training dataset
2023-04-06 18:21:58,482:INFO:Defining folds
2023-04-06 18:21:58,482:INFO:Declaring metric variables
2023-04-06 18:21:58,482:INFO:Importing untrained model
2023-04-06 18:21:58,482:INFO:Declaring custom model
2023-04-06 18:21:58,482:INFO:Gradient Boosting Regressor Imported successfully
2023-04-06 18:21:58,483:INFO:Cross validation set to False
2023-04-06 18:21:58,483:INFO:Fitting Model
2023-04-06 18:21:58,956:INFO:GradientBoostingRegressor(random_state=123)
2023-04-06 18:21:58,956:INFO:create_model() successfully completed......................................
2023-04-06 18:21:59,037:INFO:_master_model_container: 20
2023-04-06 18:21:59,037:INFO:_display_container: 2
2023-04-06 18:21:59,037:INFO:GradientBoostingRegressor(random_state=123)
2023-04-06 18:21:59,038:INFO:compare_models() successfully completed......................................
2023-04-06 18:21:59,042:INFO:gpu_param set to False
2023-04-06 18:21:59,091:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:21:59,092:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:21:59,140:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:21:59,141:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:21:59,147:INFO:Initializing compare_models()
2023-04-06 18:21:59,147:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, include=['dt', 'rf', 'et', 'gbr', 'xgboost', 'lightgbm', 'catboost'], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, 'include': ['dt', 'rf', 'et', 'gbr', 'xgboost', 'lightgbm', 'catboost'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-06 18:21:59,147:INFO:Checking exceptions
2023-04-06 18:21:59,148:INFO:Preparing display monitor
2023-04-06 18:21:59,159:INFO:Initializing Decision Tree Regressor
2023-04-06 18:21:59,159:INFO:Total runtime is 2.7179718017578126e-06 minutes
2023-04-06 18:21:59,160:INFO:SubProcess create_model() called ==================================
2023-04-06 18:21:59,161:INFO:Initializing create_model()
2023-04-06 18:21:59,161:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x28b9cb5b0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:21:59,161:INFO:Checking exceptions
2023-04-06 18:21:59,161:INFO:Importing libraries
2023-04-06 18:21:59,161:INFO:Copying training dataset
2023-04-06 18:21:59,164:INFO:Defining folds
2023-04-06 18:21:59,164:INFO:Declaring metric variables
2023-04-06 18:21:59,166:INFO:Importing untrained model
2023-04-06 18:21:59,168:INFO:Decision Tree Regressor Imported successfully
2023-04-06 18:21:59,172:INFO:Starting cross validation
2023-04-06 18:21:59,173:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:22:03,646:INFO:Calculating mean and std
2023-04-06 18:22:03,647:INFO:Creating metrics dataframe
2023-04-06 18:22:04,079:INFO:Uploading results into container
2023-04-06 18:22:04,079:INFO:Uploading model into container now
2023-04-06 18:22:04,079:INFO:_master_model_container: 21
2023-04-06 18:22:04,079:INFO:_display_container: 3
2023-04-06 18:22:04,080:INFO:DecisionTreeRegressor(random_state=123)
2023-04-06 18:22:04,080:INFO:create_model() successfully completed......................................
2023-04-06 18:22:04,146:INFO:SubProcess create_model() end ==================================
2023-04-06 18:22:04,146:INFO:Creating metrics dataframe
2023-04-06 18:22:04,150:INFO:Initializing Random Forest Regressor
2023-04-06 18:22:04,150:INFO:Total runtime is 0.08319536447525025 minutes
2023-04-06 18:22:04,152:INFO:SubProcess create_model() called ==================================
2023-04-06 18:22:04,152:INFO:Initializing create_model()
2023-04-06 18:22:04,152:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x28b9cb5b0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:22:04,152:INFO:Checking exceptions
2023-04-06 18:22:04,152:INFO:Importing libraries
2023-04-06 18:22:04,152:INFO:Copying training dataset
2023-04-06 18:22:04,154:INFO:Defining folds
2023-04-06 18:22:04,154:INFO:Declaring metric variables
2023-04-06 18:22:04,156:INFO:Importing untrained model
2023-04-06 18:22:04,157:INFO:Random Forest Regressor Imported successfully
2023-04-06 18:22:04,160:INFO:Starting cross validation
2023-04-06 18:22:04,160:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:22:08,707:INFO:Calculating mean and std
2023-04-06 18:22:08,708:INFO:Creating metrics dataframe
2023-04-06 18:22:09,198:INFO:Uploading results into container
2023-04-06 18:22:09,198:INFO:Uploading model into container now
2023-04-06 18:22:09,199:INFO:_master_model_container: 22
2023-04-06 18:22:09,199:INFO:_display_container: 3
2023-04-06 18:22:09,199:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-04-06 18:22:09,199:INFO:create_model() successfully completed......................................
2023-04-06 18:22:09,268:INFO:SubProcess create_model() end ==================================
2023-04-06 18:22:09,268:INFO:Creating metrics dataframe
2023-04-06 18:22:09,272:INFO:Initializing Extra Trees Regressor
2023-04-06 18:22:09,272:INFO:Total runtime is 0.16855273246765137 minutes
2023-04-06 18:22:09,273:INFO:SubProcess create_model() called ==================================
2023-04-06 18:22:09,273:INFO:Initializing create_model()
2023-04-06 18:22:09,274:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x28b9cb5b0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:22:09,274:INFO:Checking exceptions
2023-04-06 18:22:09,274:INFO:Importing libraries
2023-04-06 18:22:09,274:INFO:Copying training dataset
2023-04-06 18:22:09,276:INFO:Defining folds
2023-04-06 18:22:09,276:INFO:Declaring metric variables
2023-04-06 18:22:09,277:INFO:Importing untrained model
2023-04-06 18:22:09,279:INFO:Extra Trees Regressor Imported successfully
2023-04-06 18:22:09,282:INFO:Starting cross validation
2023-04-06 18:22:09,282:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:22:13,768:INFO:Calculating mean and std
2023-04-06 18:22:13,769:INFO:Creating metrics dataframe
2023-04-06 18:22:14,214:INFO:Uploading results into container
2023-04-06 18:22:14,214:INFO:Uploading model into container now
2023-04-06 18:22:14,215:INFO:_master_model_container: 23
2023-04-06 18:22:14,215:INFO:_display_container: 3
2023-04-06 18:22:14,215:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-04-06 18:22:14,215:INFO:create_model() successfully completed......................................
2023-04-06 18:22:14,282:INFO:SubProcess create_model() end ==================================
2023-04-06 18:22:14,282:INFO:Creating metrics dataframe
2023-04-06 18:22:14,286:INFO:Initializing Gradient Boosting Regressor
2023-04-06 18:22:14,286:INFO:Total runtime is 0.25212653080622355 minutes
2023-04-06 18:22:14,288:INFO:SubProcess create_model() called ==================================
2023-04-06 18:22:14,288:INFO:Initializing create_model()
2023-04-06 18:22:14,288:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x28b9cb5b0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:22:14,288:INFO:Checking exceptions
2023-04-06 18:22:14,288:INFO:Importing libraries
2023-04-06 18:22:14,288:INFO:Copying training dataset
2023-04-06 18:22:14,289:INFO:Defining folds
2023-04-06 18:22:14,289:INFO:Declaring metric variables
2023-04-06 18:22:14,291:INFO:Importing untrained model
2023-04-06 18:22:14,292:INFO:Gradient Boosting Regressor Imported successfully
2023-04-06 18:22:14,295:INFO:Starting cross validation
2023-04-06 18:22:14,295:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:22:18,786:INFO:Calculating mean and std
2023-04-06 18:22:18,786:INFO:Creating metrics dataframe
2023-04-06 18:22:19,232:INFO:Uploading results into container
2023-04-06 18:22:19,232:INFO:Uploading model into container now
2023-04-06 18:22:19,232:INFO:_master_model_container: 24
2023-04-06 18:22:19,232:INFO:_display_container: 3
2023-04-06 18:22:19,233:INFO:GradientBoostingRegressor(random_state=123)
2023-04-06 18:22:19,233:INFO:create_model() successfully completed......................................
2023-04-06 18:22:19,299:INFO:SubProcess create_model() end ==================================
2023-04-06 18:22:19,299:INFO:Creating metrics dataframe
2023-04-06 18:22:19,303:INFO:Initializing Extreme Gradient Boosting
2023-04-06 18:22:19,303:INFO:Total runtime is 0.33574481805165607 minutes
2023-04-06 18:22:19,305:INFO:SubProcess create_model() called ==================================
2023-04-06 18:22:19,305:INFO:Initializing create_model()
2023-04-06 18:22:19,305:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x28b9cb5b0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:22:19,305:INFO:Checking exceptions
2023-04-06 18:22:19,305:INFO:Importing libraries
2023-04-06 18:22:19,305:INFO:Copying training dataset
2023-04-06 18:22:19,307:INFO:Defining folds
2023-04-06 18:22:19,307:INFO:Declaring metric variables
2023-04-06 18:22:19,309:INFO:Importing untrained model
2023-04-06 18:22:19,310:INFO:Extreme Gradient Boosting Imported successfully
2023-04-06 18:22:19,313:INFO:Starting cross validation
2023-04-06 18:22:19,314:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:22:23,616:INFO:Calculating mean and std
2023-04-06 18:22:23,616:INFO:Creating metrics dataframe
2023-04-06 18:22:24,085:INFO:Uploading results into container
2023-04-06 18:22:24,086:INFO:Uploading model into container now
2023-04-06 18:22:24,086:INFO:_master_model_container: 25
2023-04-06 18:22:24,086:INFO:_display_container: 3
2023-04-06 18:22:24,086:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=123, ...)
2023-04-06 18:22:24,086:INFO:create_model() successfully completed......................................
2023-04-06 18:22:24,150:INFO:SubProcess create_model() end ==================================
2023-04-06 18:22:24,150:INFO:Creating metrics dataframe
2023-04-06 18:22:24,154:INFO:Initializing Light Gradient Boosting Machine
2023-04-06 18:22:24,154:INFO:Total runtime is 0.4165879329045613 minutes
2023-04-06 18:22:24,155:INFO:SubProcess create_model() called ==================================
2023-04-06 18:22:24,156:INFO:Initializing create_model()
2023-04-06 18:22:24,156:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x28b9cb5b0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:22:24,156:INFO:Checking exceptions
2023-04-06 18:22:24,156:INFO:Importing libraries
2023-04-06 18:22:24,156:INFO:Copying training dataset
2023-04-06 18:22:24,158:INFO:Defining folds
2023-04-06 18:22:24,158:INFO:Declaring metric variables
2023-04-06 18:22:24,159:INFO:Importing untrained model
2023-04-06 18:22:24,161:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-06 18:22:24,165:INFO:Starting cross validation
2023-04-06 18:22:24,165:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:22:28,412:INFO:Calculating mean and std
2023-04-06 18:22:28,413:INFO:Creating metrics dataframe
2023-04-06 18:22:28,862:INFO:Uploading results into container
2023-04-06 18:22:28,862:INFO:Uploading model into container now
2023-04-06 18:22:28,862:INFO:_master_model_container: 26
2023-04-06 18:22:28,862:INFO:_display_container: 3
2023-04-06 18:22:28,862:INFO:LGBMRegressor(random_state=123)
2023-04-06 18:22:28,862:INFO:create_model() successfully completed......................................
2023-04-06 18:22:28,926:INFO:SubProcess create_model() end ==================================
2023-04-06 18:22:28,926:INFO:Creating metrics dataframe
2023-04-06 18:22:28,930:INFO:Initializing CatBoost Regressor
2023-04-06 18:22:28,930:INFO:Total runtime is 0.4961896657943725 minutes
2023-04-06 18:22:28,932:INFO:SubProcess create_model() called ==================================
2023-04-06 18:22:28,932:INFO:Initializing create_model()
2023-04-06 18:22:28,932:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x28b9cb5b0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:22:28,932:INFO:Checking exceptions
2023-04-06 18:22:28,932:INFO:Importing libraries
2023-04-06 18:22:28,932:INFO:Copying training dataset
2023-04-06 18:22:28,934:INFO:Defining folds
2023-04-06 18:22:28,934:INFO:Declaring metric variables
2023-04-06 18:22:28,936:INFO:Importing untrained model
2023-04-06 18:22:28,937:INFO:CatBoost Regressor Imported successfully
2023-04-06 18:22:28,939:INFO:Starting cross validation
2023-04-06 18:22:28,940:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:22:33,152:INFO:Calculating mean and std
2023-04-06 18:22:33,154:INFO:Creating metrics dataframe
2023-04-06 18:22:33,590:INFO:Uploading results into container
2023-04-06 18:22:33,591:INFO:Uploading model into container now
2023-04-06 18:22:33,591:INFO:_master_model_container: 27
2023-04-06 18:22:33,591:INFO:_display_container: 3
2023-04-06 18:22:33,591:INFO:<catboost.core.CatBoostRegressor object at 0x28ba2aca0>
2023-04-06 18:22:33,591:INFO:create_model() successfully completed......................................
2023-04-06 18:22:33,656:INFO:SubProcess create_model() end ==================================
2023-04-06 18:22:33,656:INFO:Creating metrics dataframe
2023-04-06 18:22:33,663:INFO:Initializing create_model()
2023-04-06 18:22:33,664:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:22:33,664:INFO:Checking exceptions
2023-04-06 18:22:33,664:INFO:Importing libraries
2023-04-06 18:22:33,664:INFO:Copying training dataset
2023-04-06 18:22:33,666:INFO:Defining folds
2023-04-06 18:22:33,666:INFO:Declaring metric variables
2023-04-06 18:22:33,666:INFO:Importing untrained model
2023-04-06 18:22:33,666:INFO:Declaring custom model
2023-04-06 18:22:33,666:INFO:Gradient Boosting Regressor Imported successfully
2023-04-06 18:22:33,667:INFO:Cross validation set to False
2023-04-06 18:22:33,667:INFO:Fitting Model
2023-04-06 18:22:34,129:INFO:GradientBoostingRegressor(random_state=123)
2023-04-06 18:22:34,129:INFO:create_model() successfully completed......................................
2023-04-06 18:22:34,203:INFO:_master_model_container: 27
2023-04-06 18:22:34,203:INFO:_display_container: 3
2023-04-06 18:22:34,203:INFO:GradientBoostingRegressor(random_state=123)
2023-04-06 18:22:34,203:INFO:compare_models() successfully completed......................................
2023-04-06 18:23:19,830:INFO:Initializing compare_models()
2023-04-06 18:23:19,831:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, include=None, fold=None, round=4, cross_validation=True, sort=MAE, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-06 18:23:19,831:INFO:Checking exceptions
2023-04-06 18:23:19,835:INFO:Preparing display monitor
2023-04-06 18:23:19,861:INFO:Initializing Linear Regression
2023-04-06 18:23:19,861:INFO:Total runtime is 3.03188959757487e-06 minutes
2023-04-06 18:23:19,863:INFO:SubProcess create_model() called ==================================
2023-04-06 18:23:19,864:INFO:Initializing create_model()
2023-04-06 18:23:19,864:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x28c139ac0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:23:19,864:INFO:Checking exceptions
2023-04-06 18:23:19,864:INFO:Importing libraries
2023-04-06 18:23:19,864:INFO:Copying training dataset
2023-04-06 18:23:19,867:INFO:Defining folds
2023-04-06 18:23:19,867:INFO:Declaring metric variables
2023-04-06 18:23:19,869:INFO:Importing untrained model
2023-04-06 18:23:19,871:INFO:Linear Regression Imported successfully
2023-04-06 18:23:19,874:INFO:Starting cross validation
2023-04-06 18:23:19,875:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:23:24,341:INFO:Calculating mean and std
2023-04-06 18:23:24,342:INFO:Creating metrics dataframe
2023-04-06 18:23:24,782:INFO:Uploading results into container
2023-04-06 18:23:24,783:INFO:Uploading model into container now
2023-04-06 18:23:24,784:INFO:_master_model_container: 28
2023-04-06 18:23:24,784:INFO:_display_container: 4
2023-04-06 18:23:24,784:INFO:LinearRegression(n_jobs=-1)
2023-04-06 18:23:24,784:INFO:create_model() successfully completed......................................
2023-04-06 18:23:24,896:INFO:SubProcess create_model() end ==================================
2023-04-06 18:23:24,896:INFO:Creating metrics dataframe
2023-04-06 18:23:24,900:INFO:Initializing Lasso Regression
2023-04-06 18:23:24,900:INFO:Total runtime is 0.08398056427637736 minutes
2023-04-06 18:23:24,901:INFO:SubProcess create_model() called ==================================
2023-04-06 18:23:24,901:INFO:Initializing create_model()
2023-04-06 18:23:24,901:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x28c139ac0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:23:24,901:INFO:Checking exceptions
2023-04-06 18:23:24,902:INFO:Importing libraries
2023-04-06 18:23:24,902:INFO:Copying training dataset
2023-04-06 18:23:24,903:INFO:Defining folds
2023-04-06 18:23:24,903:INFO:Declaring metric variables
2023-04-06 18:23:24,905:INFO:Importing untrained model
2023-04-06 18:23:24,907:INFO:Lasso Regression Imported successfully
2023-04-06 18:23:24,909:INFO:Starting cross validation
2023-04-06 18:23:24,910:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:23:29,372:INFO:Calculating mean and std
2023-04-06 18:23:29,373:INFO:Creating metrics dataframe
2023-04-06 18:23:29,818:INFO:Uploading results into container
2023-04-06 18:23:29,819:INFO:Uploading model into container now
2023-04-06 18:23:29,819:INFO:_master_model_container: 29
2023-04-06 18:23:29,819:INFO:_display_container: 4
2023-04-06 18:23:29,819:INFO:Lasso(random_state=123)
2023-04-06 18:23:29,819:INFO:create_model() successfully completed......................................
2023-04-06 18:23:29,883:INFO:SubProcess create_model() end ==================================
2023-04-06 18:23:29,883:INFO:Creating metrics dataframe
2023-04-06 18:23:29,888:INFO:Initializing Ridge Regression
2023-04-06 18:23:29,888:INFO:Total runtime is 0.1671142299969991 minutes
2023-04-06 18:23:29,889:INFO:SubProcess create_model() called ==================================
2023-04-06 18:23:29,889:INFO:Initializing create_model()
2023-04-06 18:23:29,889:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x28c139ac0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:23:29,889:INFO:Checking exceptions
2023-04-06 18:23:29,889:INFO:Importing libraries
2023-04-06 18:23:29,889:INFO:Copying training dataset
2023-04-06 18:23:29,891:INFO:Defining folds
2023-04-06 18:23:29,891:INFO:Declaring metric variables
2023-04-06 18:23:29,892:INFO:Importing untrained model
2023-04-06 18:23:29,893:INFO:Ridge Regression Imported successfully
2023-04-06 18:23:29,896:INFO:Starting cross validation
2023-04-06 18:23:29,897:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:23:34,463:INFO:Calculating mean and std
2023-04-06 18:23:34,464:INFO:Creating metrics dataframe
2023-04-06 18:23:34,902:INFO:Uploading results into container
2023-04-06 18:23:34,902:INFO:Uploading model into container now
2023-04-06 18:23:34,903:INFO:_master_model_container: 30
2023-04-06 18:23:34,903:INFO:_display_container: 4
2023-04-06 18:23:34,903:INFO:Ridge(random_state=123)
2023-04-06 18:23:34,903:INFO:create_model() successfully completed......................................
2023-04-06 18:23:34,969:INFO:SubProcess create_model() end ==================================
2023-04-06 18:23:34,969:INFO:Creating metrics dataframe
2023-04-06 18:23:34,973:INFO:Initializing Elastic Net
2023-04-06 18:23:34,973:INFO:Total runtime is 0.2518664002418518 minutes
2023-04-06 18:23:34,974:INFO:SubProcess create_model() called ==================================
2023-04-06 18:23:34,974:INFO:Initializing create_model()
2023-04-06 18:23:34,974:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x28c139ac0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:23:34,974:INFO:Checking exceptions
2023-04-06 18:23:34,975:INFO:Importing libraries
2023-04-06 18:23:34,975:INFO:Copying training dataset
2023-04-06 18:23:34,976:INFO:Defining folds
2023-04-06 18:23:34,976:INFO:Declaring metric variables
2023-04-06 18:23:34,978:INFO:Importing untrained model
2023-04-06 18:23:34,979:INFO:Elastic Net Imported successfully
2023-04-06 18:23:34,981:INFO:Starting cross validation
2023-04-06 18:23:34,982:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:23:39,294:INFO:Calculating mean and std
2023-04-06 18:23:39,294:INFO:Creating metrics dataframe
2023-04-06 18:23:39,757:INFO:Uploading results into container
2023-04-06 18:23:39,757:INFO:Uploading model into container now
2023-04-06 18:23:39,758:INFO:_master_model_container: 31
2023-04-06 18:23:39,758:INFO:_display_container: 4
2023-04-06 18:23:39,758:INFO:ElasticNet(random_state=123)
2023-04-06 18:23:39,758:INFO:create_model() successfully completed......................................
2023-04-06 18:23:39,824:INFO:SubProcess create_model() end ==================================
2023-04-06 18:23:39,824:INFO:Creating metrics dataframe
2023-04-06 18:23:39,828:INFO:Initializing Least Angle Regression
2023-04-06 18:23:39,828:INFO:Total runtime is 0.3327868143717448 minutes
2023-04-06 18:23:39,829:INFO:SubProcess create_model() called ==================================
2023-04-06 18:23:39,830:INFO:Initializing create_model()
2023-04-06 18:23:39,830:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x28c139ac0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:23:39,830:INFO:Checking exceptions
2023-04-06 18:23:39,830:INFO:Importing libraries
2023-04-06 18:23:39,830:INFO:Copying training dataset
2023-04-06 18:23:39,832:INFO:Defining folds
2023-04-06 18:23:39,832:INFO:Declaring metric variables
2023-04-06 18:23:39,833:INFO:Importing untrained model
2023-04-06 18:23:39,835:INFO:Least Angle Regression Imported successfully
2023-04-06 18:23:39,838:INFO:Starting cross validation
2023-04-06 18:23:39,838:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:23:39,893:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:23:39,896:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:23:39,909:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:23:39,913:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:23:39,922:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:23:39,926:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:23:39,928:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:23:39,929:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:23:39,935:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:23:39,941:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:23:44,183:INFO:Calculating mean and std
2023-04-06 18:23:44,185:INFO:Creating metrics dataframe
2023-04-06 18:23:44,609:INFO:Uploading results into container
2023-04-06 18:23:44,609:INFO:Uploading model into container now
2023-04-06 18:23:44,610:INFO:_master_model_container: 32
2023-04-06 18:23:44,610:INFO:_display_container: 4
2023-04-06 18:23:44,610:INFO:Lars(random_state=123)
2023-04-06 18:23:44,610:INFO:create_model() successfully completed......................................
2023-04-06 18:23:44,673:INFO:SubProcess create_model() end ==================================
2023-04-06 18:23:44,673:INFO:Creating metrics dataframe
2023-04-06 18:23:44,676:INFO:Initializing Lasso Least Angle Regression
2023-04-06 18:23:44,677:INFO:Total runtime is 0.41359190146128333 minutes
2023-04-06 18:23:44,678:INFO:SubProcess create_model() called ==================================
2023-04-06 18:23:44,678:INFO:Initializing create_model()
2023-04-06 18:23:44,678:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x28c139ac0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:23:44,678:INFO:Checking exceptions
2023-04-06 18:23:44,678:INFO:Importing libraries
2023-04-06 18:23:44,678:INFO:Copying training dataset
2023-04-06 18:23:44,679:INFO:Defining folds
2023-04-06 18:23:44,679:INFO:Declaring metric variables
2023-04-06 18:23:44,681:INFO:Importing untrained model
2023-04-06 18:23:44,682:INFO:Lasso Least Angle Regression Imported successfully
2023-04-06 18:23:44,684:INFO:Starting cross validation
2023-04-06 18:23:44,685:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:23:44,737:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 18:23:44,741:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 18:23:44,743:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 18:23:44,754:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 18:23:44,757:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 18:23:44,764:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 18:23:44,773:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 18:23:44,776:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 18:23:44,795:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 18:23:44,796:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 18:23:48,873:INFO:Calculating mean and std
2023-04-06 18:23:48,874:INFO:Creating metrics dataframe
2023-04-06 18:23:49,312:INFO:Uploading results into container
2023-04-06 18:23:49,313:INFO:Uploading model into container now
2023-04-06 18:23:49,313:INFO:_master_model_container: 33
2023-04-06 18:23:49,313:INFO:_display_container: 4
2023-04-06 18:23:49,313:INFO:LassoLars(random_state=123)
2023-04-06 18:23:49,313:INFO:create_model() successfully completed......................................
2023-04-06 18:23:49,377:INFO:SubProcess create_model() end ==================================
2023-04-06 18:23:49,377:INFO:Creating metrics dataframe
2023-04-06 18:23:49,381:INFO:Initializing Orthogonal Matching Pursuit
2023-04-06 18:23:49,381:INFO:Total runtime is 0.49199337959289546 minutes
2023-04-06 18:23:49,382:INFO:SubProcess create_model() called ==================================
2023-04-06 18:23:49,382:INFO:Initializing create_model()
2023-04-06 18:23:49,382:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x28c139ac0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:23:49,382:INFO:Checking exceptions
2023-04-06 18:23:49,382:INFO:Importing libraries
2023-04-06 18:23:49,382:INFO:Copying training dataset
2023-04-06 18:23:49,384:INFO:Defining folds
2023-04-06 18:23:49,384:INFO:Declaring metric variables
2023-04-06 18:23:49,385:INFO:Importing untrained model
2023-04-06 18:23:49,386:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-06 18:23:49,388:INFO:Starting cross validation
2023-04-06 18:23:49,389:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:23:49,444:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:23:49,445:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:23:49,451:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:23:49,454:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:23:49,460:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:23:49,468:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:23:49,469:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:23:49,470:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:23:49,477:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:23:49,495:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 18:23:53,643:INFO:Calculating mean and std
2023-04-06 18:23:53,643:INFO:Creating metrics dataframe
2023-04-06 18:23:54,091:INFO:Uploading results into container
2023-04-06 18:23:54,092:INFO:Uploading model into container now
2023-04-06 18:23:54,092:INFO:_master_model_container: 34
2023-04-06 18:23:54,092:INFO:_display_container: 4
2023-04-06 18:23:54,092:INFO:OrthogonalMatchingPursuit()
2023-04-06 18:23:54,092:INFO:create_model() successfully completed......................................
2023-04-06 18:23:54,160:INFO:SubProcess create_model() end ==================================
2023-04-06 18:23:54,160:INFO:Creating metrics dataframe
2023-04-06 18:23:54,164:INFO:Initializing Bayesian Ridge
2023-04-06 18:23:54,164:INFO:Total runtime is 0.5717213829358418 minutes
2023-04-06 18:23:54,166:INFO:SubProcess create_model() called ==================================
2023-04-06 18:23:54,166:INFO:Initializing create_model()
2023-04-06 18:23:54,166:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x28c139ac0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:23:54,166:INFO:Checking exceptions
2023-04-06 18:23:54,166:INFO:Importing libraries
2023-04-06 18:23:54,166:INFO:Copying training dataset
2023-04-06 18:23:54,168:INFO:Defining folds
2023-04-06 18:23:54,168:INFO:Declaring metric variables
2023-04-06 18:23:54,169:INFO:Importing untrained model
2023-04-06 18:23:54,171:INFO:Bayesian Ridge Imported successfully
2023-04-06 18:23:54,173:INFO:Starting cross validation
2023-04-06 18:23:54,174:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:23:58,420:INFO:Calculating mean and std
2023-04-06 18:23:58,420:INFO:Creating metrics dataframe
2023-04-06 18:23:58,863:INFO:Uploading results into container
2023-04-06 18:23:58,863:INFO:Uploading model into container now
2023-04-06 18:23:58,864:INFO:_master_model_container: 35
2023-04-06 18:23:58,864:INFO:_display_container: 4
2023-04-06 18:23:58,864:INFO:BayesianRidge()
2023-04-06 18:23:58,864:INFO:create_model() successfully completed......................................
2023-04-06 18:23:58,928:INFO:SubProcess create_model() end ==================================
2023-04-06 18:23:58,929:INFO:Creating metrics dataframe
2023-04-06 18:23:58,933:INFO:Initializing Passive Aggressive Regressor
2023-04-06 18:23:58,933:INFO:Total runtime is 0.651196265220642 minutes
2023-04-06 18:23:58,934:INFO:SubProcess create_model() called ==================================
2023-04-06 18:23:58,934:INFO:Initializing create_model()
2023-04-06 18:23:58,934:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x28c139ac0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:23:58,934:INFO:Checking exceptions
2023-04-06 18:23:58,934:INFO:Importing libraries
2023-04-06 18:23:58,934:INFO:Copying training dataset
2023-04-06 18:23:58,936:INFO:Defining folds
2023-04-06 18:23:58,936:INFO:Declaring metric variables
2023-04-06 18:23:58,937:INFO:Importing untrained model
2023-04-06 18:23:58,938:INFO:Passive Aggressive Regressor Imported successfully
2023-04-06 18:23:58,940:INFO:Starting cross validation
2023-04-06 18:23:58,941:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:23:59,086:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-04-06 18:24:03,243:INFO:Calculating mean and std
2023-04-06 18:24:03,244:INFO:Creating metrics dataframe
2023-04-06 18:24:03,695:INFO:Uploading results into container
2023-04-06 18:24:03,695:INFO:Uploading model into container now
2023-04-06 18:24:03,695:INFO:_master_model_container: 36
2023-04-06 18:24:03,695:INFO:_display_container: 4
2023-04-06 18:24:03,696:INFO:PassiveAggressiveRegressor(random_state=123)
2023-04-06 18:24:03,696:INFO:create_model() successfully completed......................................
2023-04-06 18:24:03,762:INFO:SubProcess create_model() end ==================================
2023-04-06 18:24:03,762:INFO:Creating metrics dataframe
2023-04-06 18:24:03,767:INFO:Initializing Huber Regressor
2023-04-06 18:24:03,767:INFO:Total runtime is 0.7317626317342122 minutes
2023-04-06 18:24:03,768:INFO:SubProcess create_model() called ==================================
2023-04-06 18:24:03,768:INFO:Initializing create_model()
2023-04-06 18:24:03,768:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x28c139ac0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:24:03,769:INFO:Checking exceptions
2023-04-06 18:24:03,769:INFO:Importing libraries
2023-04-06 18:24:03,769:INFO:Copying training dataset
2023-04-06 18:24:03,771:INFO:Defining folds
2023-04-06 18:24:03,771:INFO:Declaring metric variables
2023-04-06 18:24:03,772:INFO:Importing untrained model
2023-04-06 18:24:03,774:INFO:Huber Regressor Imported successfully
2023-04-06 18:24:03,777:INFO:Starting cross validation
2023-04-06 18:24:03,778:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:24:08,127:INFO:Calculating mean and std
2023-04-06 18:24:08,128:INFO:Creating metrics dataframe
2023-04-06 18:24:08,594:INFO:Uploading results into container
2023-04-06 18:24:08,594:INFO:Uploading model into container now
2023-04-06 18:24:08,594:INFO:_master_model_container: 37
2023-04-06 18:24:08,594:INFO:_display_container: 4
2023-04-06 18:24:08,595:INFO:HuberRegressor()
2023-04-06 18:24:08,595:INFO:create_model() successfully completed......................................
2023-04-06 18:24:08,666:INFO:SubProcess create_model() end ==================================
2023-04-06 18:24:08,667:INFO:Creating metrics dataframe
2023-04-06 18:24:08,672:INFO:Initializing K Neighbors Regressor
2023-04-06 18:24:08,672:INFO:Total runtime is 0.8135103146235148 minutes
2023-04-06 18:24:08,673:INFO:SubProcess create_model() called ==================================
2023-04-06 18:24:08,674:INFO:Initializing create_model()
2023-04-06 18:24:08,674:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x28c139ac0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:24:08,674:INFO:Checking exceptions
2023-04-06 18:24:08,674:INFO:Importing libraries
2023-04-06 18:24:08,674:INFO:Copying training dataset
2023-04-06 18:24:08,676:INFO:Defining folds
2023-04-06 18:24:08,676:INFO:Declaring metric variables
2023-04-06 18:24:08,677:INFO:Importing untrained model
2023-04-06 18:24:08,679:INFO:K Neighbors Regressor Imported successfully
2023-04-06 18:24:08,681:INFO:Starting cross validation
2023-04-06 18:24:08,682:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:24:13,291:INFO:Calculating mean and std
2023-04-06 18:24:13,292:INFO:Creating metrics dataframe
2023-04-06 18:24:13,762:INFO:Uploading results into container
2023-04-06 18:24:13,762:INFO:Uploading model into container now
2023-04-06 18:24:13,762:INFO:_master_model_container: 38
2023-04-06 18:24:13,762:INFO:_display_container: 4
2023-04-06 18:24:13,763:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-06 18:24:13,763:INFO:create_model() successfully completed......................................
2023-04-06 18:24:13,837:INFO:SubProcess create_model() end ==================================
2023-04-06 18:24:13,837:INFO:Creating metrics dataframe
2023-04-06 18:24:13,841:INFO:Initializing Decision Tree Regressor
2023-04-06 18:24:13,841:INFO:Total runtime is 0.8996729969978332 minutes
2023-04-06 18:24:13,843:INFO:SubProcess create_model() called ==================================
2023-04-06 18:24:13,843:INFO:Initializing create_model()
2023-04-06 18:24:13,843:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x28c139ac0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:24:13,843:INFO:Checking exceptions
2023-04-06 18:24:13,843:INFO:Importing libraries
2023-04-06 18:24:13,843:INFO:Copying training dataset
2023-04-06 18:24:13,845:INFO:Defining folds
2023-04-06 18:24:13,845:INFO:Declaring metric variables
2023-04-06 18:24:13,846:INFO:Importing untrained model
2023-04-06 18:24:13,847:INFO:Decision Tree Regressor Imported successfully
2023-04-06 18:24:13,850:INFO:Starting cross validation
2023-04-06 18:24:13,851:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:24:18,192:INFO:Calculating mean and std
2023-04-06 18:24:18,192:INFO:Creating metrics dataframe
2023-04-06 18:24:18,640:INFO:Uploading results into container
2023-04-06 18:24:18,641:INFO:Uploading model into container now
2023-04-06 18:24:18,641:INFO:_master_model_container: 39
2023-04-06 18:24:18,641:INFO:_display_container: 4
2023-04-06 18:24:18,642:INFO:DecisionTreeRegressor(random_state=123)
2023-04-06 18:24:18,642:INFO:create_model() successfully completed......................................
2023-04-06 18:24:18,708:INFO:SubProcess create_model() end ==================================
2023-04-06 18:24:18,708:INFO:Creating metrics dataframe
2023-04-06 18:24:18,713:INFO:Initializing Random Forest Regressor
2023-04-06 18:24:18,713:INFO:Total runtime is 0.9808687130610148 minutes
2023-04-06 18:24:18,715:INFO:SubProcess create_model() called ==================================
2023-04-06 18:24:18,715:INFO:Initializing create_model()
2023-04-06 18:24:18,715:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x28c139ac0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:24:18,715:INFO:Checking exceptions
2023-04-06 18:24:18,715:INFO:Importing libraries
2023-04-06 18:24:18,715:INFO:Copying training dataset
2023-04-06 18:24:18,717:INFO:Defining folds
2023-04-06 18:24:18,717:INFO:Declaring metric variables
2023-04-06 18:24:18,718:INFO:Importing untrained model
2023-04-06 18:24:18,720:INFO:Random Forest Regressor Imported successfully
2023-04-06 18:24:18,723:INFO:Starting cross validation
2023-04-06 18:24:18,724:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:24:23,316:INFO:Calculating mean and std
2023-04-06 18:24:23,317:INFO:Creating metrics dataframe
2023-04-06 18:24:23,829:INFO:Uploading results into container
2023-04-06 18:24:23,829:INFO:Uploading model into container now
2023-04-06 18:24:23,829:INFO:_master_model_container: 40
2023-04-06 18:24:23,829:INFO:_display_container: 4
2023-04-06 18:24:23,830:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-04-06 18:24:23,830:INFO:create_model() successfully completed......................................
2023-04-06 18:24:23,902:INFO:SubProcess create_model() end ==================================
2023-04-06 18:24:23,903:INFO:Creating metrics dataframe
2023-04-06 18:24:23,908:INFO:Initializing Extra Trees Regressor
2023-04-06 18:24:23,908:INFO:Total runtime is 1.0674537499745687 minutes
2023-04-06 18:24:23,910:INFO:SubProcess create_model() called ==================================
2023-04-06 18:24:23,910:INFO:Initializing create_model()
2023-04-06 18:24:23,910:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x28c139ac0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:24:23,910:INFO:Checking exceptions
2023-04-06 18:24:23,910:INFO:Importing libraries
2023-04-06 18:24:23,910:INFO:Copying training dataset
2023-04-06 18:24:23,912:INFO:Defining folds
2023-04-06 18:24:23,912:INFO:Declaring metric variables
2023-04-06 18:24:23,914:INFO:Importing untrained model
2023-04-06 18:24:23,916:INFO:Extra Trees Regressor Imported successfully
2023-04-06 18:24:23,919:INFO:Starting cross validation
2023-04-06 18:24:23,920:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:24:28,341:INFO:Calculating mean and std
2023-04-06 18:24:28,342:INFO:Creating metrics dataframe
2023-04-06 18:24:28,785:INFO:Uploading results into container
2023-04-06 18:24:28,786:INFO:Uploading model into container now
2023-04-06 18:24:28,786:INFO:_master_model_container: 41
2023-04-06 18:24:28,786:INFO:_display_container: 4
2023-04-06 18:24:28,786:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-04-06 18:24:28,786:INFO:create_model() successfully completed......................................
2023-04-06 18:24:28,849:INFO:SubProcess create_model() end ==================================
2023-04-06 18:24:28,849:INFO:Creating metrics dataframe
2023-04-06 18:24:28,854:INFO:Initializing AdaBoost Regressor
2023-04-06 18:24:28,854:INFO:Total runtime is 1.1498767018318177 minutes
2023-04-06 18:24:28,855:INFO:SubProcess create_model() called ==================================
2023-04-06 18:24:28,855:INFO:Initializing create_model()
2023-04-06 18:24:28,855:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x28c139ac0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:24:28,855:INFO:Checking exceptions
2023-04-06 18:24:28,855:INFO:Importing libraries
2023-04-06 18:24:28,855:INFO:Copying training dataset
2023-04-06 18:24:28,857:INFO:Defining folds
2023-04-06 18:24:28,857:INFO:Declaring metric variables
2023-04-06 18:24:28,858:INFO:Importing untrained model
2023-04-06 18:24:28,859:INFO:AdaBoost Regressor Imported successfully
2023-04-06 18:24:28,861:INFO:Starting cross validation
2023-04-06 18:24:28,862:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:24:33,014:INFO:Calculating mean and std
2023-04-06 18:24:33,016:INFO:Creating metrics dataframe
2023-04-06 18:24:33,461:INFO:Uploading results into container
2023-04-06 18:24:33,462:INFO:Uploading model into container now
2023-04-06 18:24:33,462:INFO:_master_model_container: 42
2023-04-06 18:24:33,462:INFO:_display_container: 4
2023-04-06 18:24:33,462:INFO:AdaBoostRegressor(random_state=123)
2023-04-06 18:24:33,462:INFO:create_model() successfully completed......................................
2023-04-06 18:24:33,527:INFO:SubProcess create_model() end ==================================
2023-04-06 18:24:33,527:INFO:Creating metrics dataframe
2023-04-06 18:24:33,532:INFO:Initializing Gradient Boosting Regressor
2023-04-06 18:24:33,532:INFO:Total runtime is 1.2278574307759604 minutes
2023-04-06 18:24:33,534:INFO:SubProcess create_model() called ==================================
2023-04-06 18:24:33,534:INFO:Initializing create_model()
2023-04-06 18:24:33,534:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x28c139ac0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:24:33,534:INFO:Checking exceptions
2023-04-06 18:24:33,534:INFO:Importing libraries
2023-04-06 18:24:33,534:INFO:Copying training dataset
2023-04-06 18:24:33,536:INFO:Defining folds
2023-04-06 18:24:33,536:INFO:Declaring metric variables
2023-04-06 18:24:33,537:INFO:Importing untrained model
2023-04-06 18:24:33,539:INFO:Gradient Boosting Regressor Imported successfully
2023-04-06 18:24:33,541:INFO:Starting cross validation
2023-04-06 18:24:33,542:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:24:38,114:INFO:Calculating mean and std
2023-04-06 18:24:38,115:INFO:Creating metrics dataframe
2023-04-06 18:24:38,573:INFO:Uploading results into container
2023-04-06 18:24:38,573:INFO:Uploading model into container now
2023-04-06 18:24:38,573:INFO:_master_model_container: 43
2023-04-06 18:24:38,573:INFO:_display_container: 4
2023-04-06 18:24:38,574:INFO:GradientBoostingRegressor(random_state=123)
2023-04-06 18:24:38,574:INFO:create_model() successfully completed......................................
2023-04-06 18:24:38,636:INFO:SubProcess create_model() end ==================================
2023-04-06 18:24:38,636:INFO:Creating metrics dataframe
2023-04-06 18:24:38,641:INFO:Initializing Extreme Gradient Boosting
2023-04-06 18:24:38,641:INFO:Total runtime is 1.3129985650380454 minutes
2023-04-06 18:24:38,642:INFO:SubProcess create_model() called ==================================
2023-04-06 18:24:38,642:INFO:Initializing create_model()
2023-04-06 18:24:38,642:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x28c139ac0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:24:38,642:INFO:Checking exceptions
2023-04-06 18:24:38,642:INFO:Importing libraries
2023-04-06 18:24:38,642:INFO:Copying training dataset
2023-04-06 18:24:38,644:INFO:Defining folds
2023-04-06 18:24:38,644:INFO:Declaring metric variables
2023-04-06 18:24:38,645:INFO:Importing untrained model
2023-04-06 18:24:38,647:INFO:Extreme Gradient Boosting Imported successfully
2023-04-06 18:24:38,649:INFO:Starting cross validation
2023-04-06 18:24:38,650:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:24:43,186:INFO:Calculating mean and std
2023-04-06 18:24:43,187:INFO:Creating metrics dataframe
2023-04-06 18:24:43,628:INFO:Uploading results into container
2023-04-06 18:24:43,628:INFO:Uploading model into container now
2023-04-06 18:24:43,628:INFO:_master_model_container: 44
2023-04-06 18:24:43,629:INFO:_display_container: 4
2023-04-06 18:24:43,629:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=123, ...)
2023-04-06 18:24:43,629:INFO:create_model() successfully completed......................................
2023-04-06 18:24:43,694:INFO:SubProcess create_model() end ==================================
2023-04-06 18:24:43,694:INFO:Creating metrics dataframe
2023-04-06 18:24:43,699:INFO:Initializing Light Gradient Boosting Machine
2023-04-06 18:24:43,699:INFO:Total runtime is 1.3972984155019126 minutes
2023-04-06 18:24:43,700:INFO:SubProcess create_model() called ==================================
2023-04-06 18:24:43,701:INFO:Initializing create_model()
2023-04-06 18:24:43,701:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x28c139ac0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:24:43,701:INFO:Checking exceptions
2023-04-06 18:24:43,701:INFO:Importing libraries
2023-04-06 18:24:43,701:INFO:Copying training dataset
2023-04-06 18:24:43,703:INFO:Defining folds
2023-04-06 18:24:43,703:INFO:Declaring metric variables
2023-04-06 18:24:43,704:INFO:Importing untrained model
2023-04-06 18:24:43,705:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-06 18:24:43,708:INFO:Starting cross validation
2023-04-06 18:24:43,709:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:24:48,003:INFO:Calculating mean and std
2023-04-06 18:24:48,003:INFO:Creating metrics dataframe
2023-04-06 18:24:48,447:INFO:Uploading results into container
2023-04-06 18:24:48,447:INFO:Uploading model into container now
2023-04-06 18:24:48,447:INFO:_master_model_container: 45
2023-04-06 18:24:48,447:INFO:_display_container: 4
2023-04-06 18:24:48,447:INFO:LGBMRegressor(random_state=123)
2023-04-06 18:24:48,448:INFO:create_model() successfully completed......................................
2023-04-06 18:24:48,512:INFO:SubProcess create_model() end ==================================
2023-04-06 18:24:48,512:INFO:Creating metrics dataframe
2023-04-06 18:24:48,517:INFO:Initializing CatBoost Regressor
2023-04-06 18:24:48,517:INFO:Total runtime is 1.4776066978772482 minutes
2023-04-06 18:24:48,519:INFO:SubProcess create_model() called ==================================
2023-04-06 18:24:48,519:INFO:Initializing create_model()
2023-04-06 18:24:48,519:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x28c139ac0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:24:48,519:INFO:Checking exceptions
2023-04-06 18:24:48,519:INFO:Importing libraries
2023-04-06 18:24:48,520:INFO:Copying training dataset
2023-04-06 18:24:48,521:INFO:Defining folds
2023-04-06 18:24:48,521:INFO:Declaring metric variables
2023-04-06 18:24:48,523:INFO:Importing untrained model
2023-04-06 18:24:48,527:INFO:CatBoost Regressor Imported successfully
2023-04-06 18:24:48,531:INFO:Starting cross validation
2023-04-06 18:24:48,532:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:24:52,832:INFO:Calculating mean and std
2023-04-06 18:24:52,832:INFO:Creating metrics dataframe
2023-04-06 18:24:53,274:INFO:Uploading results into container
2023-04-06 18:24:53,274:INFO:Uploading model into container now
2023-04-06 18:24:53,274:INFO:_master_model_container: 46
2023-04-06 18:24:53,274:INFO:_display_container: 4
2023-04-06 18:24:53,274:INFO:<catboost.core.CatBoostRegressor object at 0x28ba0d220>
2023-04-06 18:24:53,275:INFO:create_model() successfully completed......................................
2023-04-06 18:24:53,337:INFO:SubProcess create_model() end ==================================
2023-04-06 18:24:53,337:INFO:Creating metrics dataframe
2023-04-06 18:24:53,343:INFO:Initializing Dummy Regressor
2023-04-06 18:24:53,343:INFO:Total runtime is 1.5580280979474386 minutes
2023-04-06 18:24:53,344:INFO:SubProcess create_model() called ==================================
2023-04-06 18:24:53,344:INFO:Initializing create_model()
2023-04-06 18:24:53,344:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x28c139ac0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:24:53,344:INFO:Checking exceptions
2023-04-06 18:24:53,344:INFO:Importing libraries
2023-04-06 18:24:53,344:INFO:Copying training dataset
2023-04-06 18:24:53,346:INFO:Defining folds
2023-04-06 18:24:53,346:INFO:Declaring metric variables
2023-04-06 18:24:53,348:INFO:Importing untrained model
2023-04-06 18:24:53,349:INFO:Dummy Regressor Imported successfully
2023-04-06 18:24:53,351:INFO:Starting cross validation
2023-04-06 18:24:53,352:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:24:57,563:INFO:Calculating mean and std
2023-04-06 18:24:57,565:INFO:Creating metrics dataframe
2023-04-06 18:24:58,005:INFO:Uploading results into container
2023-04-06 18:24:58,005:INFO:Uploading model into container now
2023-04-06 18:24:58,005:INFO:_master_model_container: 47
2023-04-06 18:24:58,005:INFO:_display_container: 4
2023-04-06 18:24:58,006:INFO:DummyRegressor()
2023-04-06 18:24:58,006:INFO:create_model() successfully completed......................................
2023-04-06 18:24:58,068:INFO:SubProcess create_model() end ==================================
2023-04-06 18:24:58,068:INFO:Creating metrics dataframe
2023-04-06 18:24:58,077:INFO:Initializing create_model()
2023-04-06 18:24:58,077:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:24:58,077:INFO:Checking exceptions
2023-04-06 18:24:58,078:INFO:Importing libraries
2023-04-06 18:24:58,078:INFO:Copying training dataset
2023-04-06 18:24:58,080:INFO:Defining folds
2023-04-06 18:24:58,080:INFO:Declaring metric variables
2023-04-06 18:24:58,080:INFO:Importing untrained model
2023-04-06 18:24:58,080:INFO:Declaring custom model
2023-04-06 18:24:58,081:INFO:Gradient Boosting Regressor Imported successfully
2023-04-06 18:24:58,081:INFO:Cross validation set to False
2023-04-06 18:24:58,081:INFO:Fitting Model
2023-04-06 18:24:58,531:INFO:GradientBoostingRegressor(random_state=123)
2023-04-06 18:24:58,531:INFO:create_model() successfully completed......................................
2023-04-06 18:24:58,595:INFO:Initializing create_model()
2023-04-06 18:24:58,595:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:24:58,596:INFO:Checking exceptions
2023-04-06 18:24:58,596:INFO:Importing libraries
2023-04-06 18:24:58,596:INFO:Copying training dataset
2023-04-06 18:24:58,598:INFO:Defining folds
2023-04-06 18:24:58,598:INFO:Declaring metric variables
2023-04-06 18:24:58,598:INFO:Importing untrained model
2023-04-06 18:24:58,598:INFO:Declaring custom model
2023-04-06 18:24:58,598:INFO:Random Forest Regressor Imported successfully
2023-04-06 18:24:58,599:INFO:Cross validation set to False
2023-04-06 18:24:58,599:INFO:Fitting Model
2023-04-06 18:24:59,089:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-04-06 18:24:59,090:INFO:create_model() successfully completed......................................
2023-04-06 18:24:59,154:INFO:Initializing create_model()
2023-04-06 18:24:59,154:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:24:59,154:INFO:Checking exceptions
2023-04-06 18:24:59,155:INFO:Importing libraries
2023-04-06 18:24:59,155:INFO:Copying training dataset
2023-04-06 18:24:59,157:INFO:Defining folds
2023-04-06 18:24:59,157:INFO:Declaring metric variables
2023-04-06 18:24:59,157:INFO:Importing untrained model
2023-04-06 18:24:59,157:INFO:Declaring custom model
2023-04-06 18:24:59,157:INFO:Extra Trees Regressor Imported successfully
2023-04-06 18:24:59,158:INFO:Cross validation set to False
2023-04-06 18:24:59,158:INFO:Fitting Model
2023-04-06 18:24:59,624:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-04-06 18:24:59,624:INFO:create_model() successfully completed......................................
2023-04-06 18:24:59,701:INFO:_master_model_container: 47
2023-04-06 18:24:59,702:INFO:_display_container: 4
2023-04-06 18:24:59,702:INFO:[GradientBoostingRegressor(random_state=123), RandomForestRegressor(n_jobs=-1, random_state=123), ExtraTreesRegressor(n_jobs=-1, random_state=123)]
2023-04-06 18:24:59,702:INFO:compare_models() successfully completed......................................
2023-04-06 18:28:16,344:INFO:gpu_param set to False
2023-04-06 18:28:16,418:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:28:16,420:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:28:16,468:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 18:28:16,469:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 18:28:25,792:INFO:Initializing create_model()
2023-04-06 18:28:25,793:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:28:25,793:INFO:Checking exceptions
2023-04-06 18:28:25,816:INFO:Importing libraries
2023-04-06 18:28:25,816:INFO:Copying training dataset
2023-04-06 18:28:25,820:INFO:Defining folds
2023-04-06 18:28:25,820:INFO:Declaring metric variables
2023-04-06 18:28:25,822:INFO:Importing untrained model
2023-04-06 18:28:25,824:INFO:Linear Regression Imported successfully
2023-04-06 18:28:25,829:INFO:Starting cross validation
2023-04-06 18:28:25,831:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:28:30,274:INFO:Calculating mean and std
2023-04-06 18:28:30,275:INFO:Creating metrics dataframe
2023-04-06 18:28:30,277:INFO:Finalizing model
2023-04-06 18:28:30,768:INFO:Uploading results into container
2023-04-06 18:28:30,769:INFO:Uploading model into container now
2023-04-06 18:28:30,772:INFO:_master_model_container: 48
2023-04-06 18:28:30,773:INFO:_display_container: 5
2023-04-06 18:28:30,773:INFO:LinearRegression(n_jobs=-1)
2023-04-06 18:28:30,773:INFO:create_model() successfully completed......................................
2023-04-06 18:28:55,283:INFO:Initializing create_model()
2023-04-06 18:28:55,286:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=lr, fold=3, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 18:28:55,286:INFO:Checking exceptions
2023-04-06 18:28:55,308:INFO:Importing libraries
2023-04-06 18:28:55,308:INFO:Copying training dataset
2023-04-06 18:28:55,311:INFO:Defining folds
2023-04-06 18:28:55,312:INFO:Declaring metric variables
2023-04-06 18:28:55,314:INFO:Importing untrained model
2023-04-06 18:28:55,316:INFO:Linear Regression Imported successfully
2023-04-06 18:28:55,319:INFO:Starting cross validation
2023-04-06 18:28:55,320:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:28:56,303:INFO:Calculating mean and std
2023-04-06 18:28:56,304:INFO:Creating metrics dataframe
2023-04-06 18:28:56,307:INFO:Finalizing model
2023-04-06 18:28:56,770:INFO:Uploading results into container
2023-04-06 18:28:56,770:INFO:Uploading model into container now
2023-04-06 18:28:56,774:INFO:_master_model_container: 49
2023-04-06 18:28:56,774:INFO:_display_container: 6
2023-04-06 18:28:56,775:INFO:LinearRegression(n_jobs=-1)
2023-04-06 18:28:56,775:INFO:create_model() successfully completed......................................
2023-04-06 18:29:06,031:INFO:Initializing create_model()
2023-04-06 18:29:06,032:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={'fit_intercept': False})
2023-04-06 18:29:06,033:INFO:Checking exceptions
2023-04-06 18:29:06,050:INFO:Importing libraries
2023-04-06 18:29:06,050:INFO:Copying training dataset
2023-04-06 18:29:06,053:INFO:Defining folds
2023-04-06 18:29:06,053:INFO:Declaring metric variables
2023-04-06 18:29:06,056:INFO:Importing untrained model
2023-04-06 18:29:06,058:INFO:Linear Regression Imported successfully
2023-04-06 18:29:06,061:INFO:Starting cross validation
2023-04-06 18:29:06,062:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:29:10,452:INFO:Calculating mean and std
2023-04-06 18:29:10,453:INFO:Creating metrics dataframe
2023-04-06 18:29:10,456:INFO:Finalizing model
2023-04-06 18:29:10,943:INFO:Uploading results into container
2023-04-06 18:29:10,943:INFO:Uploading model into container now
2023-04-06 18:29:10,947:INFO:_master_model_container: 50
2023-04-06 18:29:10,947:INFO:_display_container: 7
2023-04-06 18:29:10,947:INFO:LinearRegression(fit_intercept=False, n_jobs=-1)
2023-04-06 18:29:10,948:INFO:create_model() successfully completed......................................
2023-04-06 18:29:20,770:INFO:Initializing create_model()
2023-04-06 18:29:20,771:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=True, kwargs={})
2023-04-06 18:29:20,771:INFO:Checking exceptions
2023-04-06 18:29:20,791:INFO:Importing libraries
2023-04-06 18:29:20,791:INFO:Copying training dataset
2023-04-06 18:29:20,794:INFO:Defining folds
2023-04-06 18:29:20,795:INFO:Declaring metric variables
2023-04-06 18:29:20,797:INFO:Importing untrained model
2023-04-06 18:29:20,799:INFO:Linear Regression Imported successfully
2023-04-06 18:29:20,802:INFO:Starting cross validation
2023-04-06 18:29:20,803:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 18:29:25,363:INFO:Calculating mean and std
2023-04-06 18:29:25,364:INFO:Creating metrics dataframe
2023-04-06 18:29:25,368:INFO:Finalizing model
2023-04-06 18:29:25,417:INFO:Initializing predict_model()
2023-04-06 18:29:25,417:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x28b8d44f0>, estimator=Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encodin...
dtype: int64},
                                                                        {'col': 'smoker',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['region'],
                                    transformer=OneHotEncoder(cols=['region'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('actual_estimator', LinearRegression(n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x28bdf8310>)
2023-04-06 18:29:25,418:INFO:Checking exceptions
2023-04-06 18:29:25,418:INFO:Preloading libraries
2023-04-06 18:29:25,418:INFO:Set up data.
2023-04-06 18:29:25,419:INFO:Set up index.
2023-04-06 18:29:25,949:INFO:Uploading results into container
2023-04-06 18:29:25,950:INFO:Uploading model into container now
2023-04-06 18:29:25,957:INFO:_master_model_container: 51
2023-04-06 18:29:25,957:INFO:_display_container: 8
2023-04-06 18:29:25,957:INFO:LinearRegression(n_jobs=-1)
2023-04-06 18:29:25,957:INFO:create_model() successfully completed......................................
2023-04-06 22:09:53,136:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-06 22:09:53,137:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-06 22:09:53,137:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-06 22:09:53,137:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-06 22:09:53,707:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-06 22:09:54,582:INFO:PyCaret ClassificationExperiment
2023-04-06 22:09:54,582:INFO:Logging name: clf-default-name
2023-04-06 22:09:54,583:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-06 22:09:54,583:INFO:version 3.0.0
2023-04-06 22:09:54,583:INFO:Initializing setup()
2023-04-06 22:09:54,583:INFO:self.USI: 42b8
2023-04-06 22:09:54,583:INFO:self._variable_keys: {'is_multiclass', 'exp_id', 'exp_name_log', 'idx', 'USI', 'memory', 'fix_imbalance', 'gpu_n_jobs_param', '_available_plots', 'y', 'data', 'logging_param', '_ml_usecase', 'y_train', 'log_plots_param', 'X_train', 'X', 'seed', 'fold_groups_param', 'n_jobs_param', 'y_test', 'target_param', 'fold_generator', 'fold_shuffle_param', 'gpu_param', 'X_test', 'html_param', 'pipeline'}
2023-04-06 22:09:54,583:INFO:Checking environment
2023-04-06 22:09:54,583:INFO:python_version: 3.9.15
2023-04-06 22:09:54,583:INFO:python_build: ('main', 'Nov 24 2022 08:28:41')
2023-04-06 22:09:54,583:INFO:machine: arm64
2023-04-06 22:09:54,583:INFO:platform: macOS-13.2-arm64-arm-64bit
2023-04-06 22:09:54,583:INFO:Memory: svmem(total=17179869184, available=4232495104, percent=75.4, used=6395478016, free=45826048, active=4208541696, inactive=4132470784, wired=2186936320)
2023-04-06 22:09:54,583:INFO:Physical Core: 10
2023-04-06 22:09:54,583:INFO:Logical Core: 10
2023-04-06 22:09:54,583:INFO:Checking libraries
2023-04-06 22:09:54,583:INFO:System:
2023-04-06 22:09:54,583:INFO:    python: 3.9.15 (main, Nov 24 2022, 08:28:41)  [Clang 14.0.6 ]
2023-04-06 22:09:54,583:INFO:executable: /Users/a06411/opt/anaconda3/bin/python
2023-04-06 22:09:54,583:INFO:   machine: macOS-13.2-arm64-arm-64bit
2023-04-06 22:09:54,583:INFO:PyCaret required dependencies:
2023-04-06 22:09:54,583:INFO:                 pip: 22.3.1
2023-04-06 22:09:54,583:INFO:          setuptools: 65.5.0
2023-04-06 22:09:54,583:INFO:             pycaret: 3.0.0
2023-04-06 22:09:54,583:INFO:             IPython: 8.7.0
2023-04-06 22:09:54,583:INFO:          ipywidgets: 7.6.5
2023-04-06 22:09:54,583:INFO:                tqdm: 4.64.1
2023-04-06 22:09:54,583:INFO:               numpy: 1.21.5
2023-04-06 22:09:54,583:INFO:              pandas: 1.4.4
2023-04-06 22:09:54,583:INFO:              jinja2: 2.11.3
2023-04-06 22:09:54,583:INFO:               scipy: 1.9.3
2023-04-06 22:09:54,583:INFO:              joblib: 1.2.0
2023-04-06 22:09:54,583:INFO:             sklearn: 1.1.3
2023-04-06 22:09:54,583:INFO:                pyod: 1.0.9
2023-04-06 22:09:54,583:INFO:            imblearn: 0.10.1
2023-04-06 22:09:54,583:INFO:   category_encoders: 2.6.0
2023-04-06 22:09:54,583:INFO:            lightgbm: 3.3.5
2023-04-06 22:09:54,583:INFO:               numba: 0.56.4
2023-04-06 22:09:54,583:INFO:            requests: 2.28.1
2023-04-06 22:09:54,583:INFO:          matplotlib: 3.6.2
2023-04-06 22:09:54,583:INFO:          scikitplot: 0.3.7
2023-04-06 22:09:54,583:INFO:         yellowbrick: 1.5
2023-04-06 22:09:54,583:INFO:              plotly: 5.9.0
2023-04-06 22:09:54,583:INFO:             kaleido: 0.2.1
2023-04-06 22:09:54,583:INFO:         statsmodels: 0.13.2
2023-04-06 22:09:54,583:INFO:              sktime: 0.16.1
2023-04-06 22:09:54,583:INFO:               tbats: 1.1.2
2023-04-06 22:09:54,583:INFO:            pmdarima: 2.0.3
2023-04-06 22:09:54,583:INFO:              psutil: 5.9.0
2023-04-06 22:09:54,583:INFO:PyCaret optional dependencies:
2023-04-06 22:09:54,588:INFO:                shap: 0.41.0
2023-04-06 22:09:54,588:INFO:           interpret: Not installed
2023-04-06 22:09:54,588:INFO:                umap: 0.5.3
2023-04-06 22:09:54,588:INFO:    pandas_profiling: 4.1.2
2023-04-06 22:09:54,588:INFO:  explainerdashboard: 0.4.2.1
2023-04-06 22:09:54,588:INFO:             autoviz: Not installed
2023-04-06 22:09:54,588:INFO:           fairlearn: Not installed
2023-04-06 22:09:54,588:INFO:             xgboost: 1.7.2
2023-04-06 22:09:54,588:INFO:            catboost: 1.1.1
2023-04-06 22:09:54,589:INFO:              kmodes: Not installed
2023-04-06 22:09:54,589:INFO:             mlxtend: Not installed
2023-04-06 22:09:54,589:INFO:       statsforecast: Not installed
2023-04-06 22:09:54,589:INFO:        tune_sklearn: Not installed
2023-04-06 22:09:54,589:INFO:                 ray: Not installed
2023-04-06 22:09:54,589:INFO:            hyperopt: 0.2.7
2023-04-06 22:09:54,589:INFO:              optuna: 3.1.0
2023-04-06 22:09:54,589:INFO:               skopt: 0.9.0
2023-04-06 22:09:54,589:INFO:              mlflow: 2.2.2
2023-04-06 22:09:54,589:INFO:              gradio: Not installed
2023-04-06 22:09:54,589:INFO:             fastapi: Not installed
2023-04-06 22:09:54,589:INFO:             uvicorn: Not installed
2023-04-06 22:09:54,589:INFO:              m2cgen: Not installed
2023-04-06 22:09:54,589:INFO:           evidently: Not installed
2023-04-06 22:09:54,589:INFO:               fugue: Not installed
2023-04-06 22:09:54,589:INFO:           streamlit: Not installed
2023-04-06 22:09:54,589:INFO:             prophet: Not installed
2023-04-06 22:09:54,589:INFO:None
2023-04-06 22:09:54,589:INFO:Set up data.
2023-04-06 22:09:54,591:INFO:Set up train/test split.
2023-04-06 22:09:54,593:INFO:Set up index.
2023-04-06 22:09:54,593:INFO:Set up folding strategy.
2023-04-06 22:09:54,593:INFO:Assigning column types.
2023-04-06 22:09:54,594:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-06 22:09:54,614:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 22:09:54,616:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-06 22:09:54,631:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 22:09:54,767:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 22:09:54,798:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 22:09:54,798:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-06 22:09:54,810:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 22:09:54,811:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 22:09:54,812:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-06 22:09:54,831:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-06 22:09:54,843:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 22:09:54,844:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 22:09:54,864:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-06 22:09:54,876:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 22:09:54,877:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 22:09:54,878:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-04-06 22:09:54,909:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 22:09:54,910:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 22:09:54,942:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 22:09:54,943:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 22:09:54,945:INFO:Preparing preprocessing pipeline...
2023-04-06 22:09:54,946:INFO:Set up simple imputation.
2023-04-06 22:09:54,946:INFO:Set up column name cleaning.
2023-04-06 22:09:54,956:INFO:Finished creating preprocessing pipeline.
2023-04-06 22:09:54,958:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Number of times pregnant',
                                             'Plasma glucose concentration a 2 '
                                             'hours in an oral glucose '
                                             'tolerance test',
                                             'Diastolic blood pressure (mm Hg)',
                                             'Triceps skin fold thickness (mm)',
                                             '2-Hour serum insulin (mu U/ml)',
                                             'Body...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-04-06 22:09:54,958:INFO:Creating final display dataframe.
2023-04-06 22:09:54,989:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target    Class variable
2                   Target type            Binary
3           Original data shape          (768, 9)
4        Transformed data shape          (768, 9)
5   Transformed train set shape          (537, 9)
6    Transformed test set shape          (231, 9)
7              Numeric features                 8
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              42b8
2023-04-06 22:09:55,024:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 22:09:55,025:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 22:09:55,058:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 22:09:55,059:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 22:09:55,060:INFO:setup() successfully completed in 1.03s...............
2023-04-06 22:11:46,468:INFO:PyCaret ClassificationExperiment
2023-04-06 22:11:46,468:INFO:Logging name: clf-default-name
2023-04-06 22:11:46,468:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-06 22:11:46,468:INFO:version 3.0.0
2023-04-06 22:11:46,468:INFO:Initializing setup()
2023-04-06 22:11:46,468:INFO:self.USI: 4dd8
2023-04-06 22:11:46,468:INFO:self._variable_keys: {'is_multiclass', 'exp_id', 'exp_name_log', 'idx', 'USI', 'memory', 'fix_imbalance', 'gpu_n_jobs_param', '_available_plots', 'y', 'data', 'logging_param', '_ml_usecase', 'y_train', 'log_plots_param', 'X_train', 'X', 'seed', 'fold_groups_param', 'n_jobs_param', 'y_test', 'target_param', 'fold_generator', 'fold_shuffle_param', 'gpu_param', 'X_test', 'html_param', 'pipeline'}
2023-04-06 22:11:46,468:INFO:Checking environment
2023-04-06 22:11:46,468:INFO:python_version: 3.9.15
2023-04-06 22:11:46,468:INFO:python_build: ('main', 'Nov 24 2022 08:28:41')
2023-04-06 22:11:46,468:INFO:machine: arm64
2023-04-06 22:11:46,468:INFO:platform: macOS-13.2-arm64-arm-64bit
2023-04-06 22:11:46,468:INFO:Memory: svmem(total=17179869184, available=4521558016, percent=73.7, used=6429802496, free=213696512, active=4321607680, inactive=4296507392, wired=2108194816)
2023-04-06 22:11:46,468:INFO:Physical Core: 10
2023-04-06 22:11:46,469:INFO:Logical Core: 10
2023-04-06 22:11:46,469:INFO:Checking libraries
2023-04-06 22:11:46,469:INFO:System:
2023-04-06 22:11:46,469:INFO:    python: 3.9.15 (main, Nov 24 2022, 08:28:41)  [Clang 14.0.6 ]
2023-04-06 22:11:46,469:INFO:executable: /Users/a06411/opt/anaconda3/bin/python
2023-04-06 22:11:46,469:INFO:   machine: macOS-13.2-arm64-arm-64bit
2023-04-06 22:11:46,469:INFO:PyCaret required dependencies:
2023-04-06 22:11:46,469:INFO:                 pip: 22.3.1
2023-04-06 22:11:46,469:INFO:          setuptools: 65.5.0
2023-04-06 22:11:46,469:INFO:             pycaret: 3.0.0
2023-04-06 22:11:46,469:INFO:             IPython: 8.7.0
2023-04-06 22:11:46,469:INFO:          ipywidgets: 7.6.5
2023-04-06 22:11:46,469:INFO:                tqdm: 4.64.1
2023-04-06 22:11:46,469:INFO:               numpy: 1.21.5
2023-04-06 22:11:46,469:INFO:              pandas: 1.4.4
2023-04-06 22:11:46,469:INFO:              jinja2: 2.11.3
2023-04-06 22:11:46,469:INFO:               scipy: 1.9.3
2023-04-06 22:11:46,469:INFO:              joblib: 1.2.0
2023-04-06 22:11:46,469:INFO:             sklearn: 1.1.3
2023-04-06 22:11:46,469:INFO:                pyod: 1.0.9
2023-04-06 22:11:46,469:INFO:            imblearn: 0.10.1
2023-04-06 22:11:46,469:INFO:   category_encoders: 2.6.0
2023-04-06 22:11:46,469:INFO:            lightgbm: 3.3.5
2023-04-06 22:11:46,469:INFO:               numba: 0.56.4
2023-04-06 22:11:46,469:INFO:            requests: 2.28.1
2023-04-06 22:11:46,469:INFO:          matplotlib: 3.6.2
2023-04-06 22:11:46,469:INFO:          scikitplot: 0.3.7
2023-04-06 22:11:46,469:INFO:         yellowbrick: 1.5
2023-04-06 22:11:46,469:INFO:              plotly: 5.9.0
2023-04-06 22:11:46,469:INFO:             kaleido: 0.2.1
2023-04-06 22:11:46,469:INFO:         statsmodels: 0.13.2
2023-04-06 22:11:46,469:INFO:              sktime: 0.16.1
2023-04-06 22:11:46,469:INFO:               tbats: 1.1.2
2023-04-06 22:11:46,469:INFO:            pmdarima: 2.0.3
2023-04-06 22:11:46,469:INFO:              psutil: 5.9.0
2023-04-06 22:11:46,469:INFO:PyCaret optional dependencies:
2023-04-06 22:11:46,469:INFO:                shap: 0.41.0
2023-04-06 22:11:46,469:INFO:           interpret: Not installed
2023-04-06 22:11:46,469:INFO:                umap: 0.5.3
2023-04-06 22:11:46,469:INFO:    pandas_profiling: 4.1.2
2023-04-06 22:11:46,469:INFO:  explainerdashboard: 0.4.2.1
2023-04-06 22:11:46,469:INFO:             autoviz: Not installed
2023-04-06 22:11:46,469:INFO:           fairlearn: Not installed
2023-04-06 22:11:46,469:INFO:             xgboost: 1.7.2
2023-04-06 22:11:46,469:INFO:            catboost: 1.1.1
2023-04-06 22:11:46,469:INFO:              kmodes: Not installed
2023-04-06 22:11:46,469:INFO:             mlxtend: Not installed
2023-04-06 22:11:46,469:INFO:       statsforecast: Not installed
2023-04-06 22:11:46,469:INFO:        tune_sklearn: Not installed
2023-04-06 22:11:46,469:INFO:                 ray: Not installed
2023-04-06 22:11:46,469:INFO:            hyperopt: 0.2.7
2023-04-06 22:11:46,469:INFO:              optuna: 3.1.0
2023-04-06 22:11:46,469:INFO:               skopt: 0.9.0
2023-04-06 22:11:46,469:INFO:              mlflow: 2.2.2
2023-04-06 22:11:46,469:INFO:              gradio: Not installed
2023-04-06 22:11:46,469:INFO:             fastapi: Not installed
2023-04-06 22:11:46,469:INFO:             uvicorn: Not installed
2023-04-06 22:11:46,469:INFO:              m2cgen: Not installed
2023-04-06 22:11:46,469:INFO:           evidently: Not installed
2023-04-06 22:11:46,469:INFO:               fugue: Not installed
2023-04-06 22:11:46,469:INFO:           streamlit: Not installed
2023-04-06 22:11:46,469:INFO:             prophet: Not installed
2023-04-06 22:11:46,469:INFO:None
2023-04-06 22:11:46,469:INFO:Set up data.
2023-04-06 22:11:46,471:INFO:Set up train/test split.
2023-04-06 22:11:46,472:INFO:Set up index.
2023-04-06 22:11:46,472:INFO:Set up folding strategy.
2023-04-06 22:11:46,473:INFO:Assigning column types.
2023-04-06 22:11:46,473:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-06 22:11:46,493:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 22:11:46,493:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-06 22:11:46,506:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 22:11:46,507:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 22:11:46,526:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 22:11:46,527:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-06 22:11:46,539:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 22:11:46,540:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 22:11:46,540:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-06 22:11:46,559:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-06 22:11:46,571:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 22:11:46,572:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 22:11:46,592:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-06 22:11:46,604:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 22:11:46,605:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 22:11:46,606:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-04-06 22:11:46,638:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 22:11:46,639:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 22:11:46,672:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 22:11:46,673:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 22:11:46,673:INFO:Preparing preprocessing pipeline...
2023-04-06 22:11:46,674:INFO:Set up simple imputation.
2023-04-06 22:11:46,674:INFO:Set up column name cleaning.
2023-04-06 22:11:46,683:INFO:Finished creating preprocessing pipeline.
2023-04-06 22:11:46,685:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Number of times pregnant',
                                             'Plasma glucose concentration a 2 '
                                             'hours in an oral glucose '
                                             'tolerance test',
                                             'Diastolic blood pressure (mm Hg)',
                                             'Triceps skin fold thickness (mm)',
                                             '2-Hour serum insulin (mu U/ml)',
                                             'Body...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-04-06 22:11:46,685:INFO:Creating final display dataframe.
2023-04-06 22:11:46,713:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target    Class variable
2                   Target type            Binary
3           Original data shape          (768, 9)
4        Transformed data shape          (768, 9)
5   Transformed train set shape          (537, 9)
6    Transformed test set shape          (231, 9)
7              Numeric features                 8
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              4dd8
2023-04-06 22:11:46,747:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 22:11:46,749:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 22:11:46,782:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 22:11:46,783:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 22:11:46,784:INFO:setup() successfully completed in 0.71s...............
2023-04-06 22:12:16,830:INFO:Initializing compare_models()
2023-04-06 22:12:16,832:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-04-06 22:12:16,833:INFO:Checking exceptions
2023-04-06 22:12:16,842:INFO:Preparing display monitor
2023-04-06 22:12:16,883:INFO:Initializing Logistic Regression
2023-04-06 22:12:16,883:INFO:Total runtime is 5.1657358805338544e-06 minutes
2023-04-06 22:12:16,885:INFO:SubProcess create_model() called ==================================
2023-04-06 22:12:16,885:INFO:Initializing create_model()
2023-04-06 22:12:16,885:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17b102c40>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:12:16,885:INFO:Checking exceptions
2023-04-06 22:12:16,885:INFO:Importing libraries
2023-04-06 22:12:16,885:INFO:Copying training dataset
2023-04-06 22:12:16,888:INFO:Defining folds
2023-04-06 22:12:16,888:INFO:Declaring metric variables
2023-04-06 22:12:16,890:INFO:Importing untrained model
2023-04-06 22:12:16,892:INFO:Logistic Regression Imported successfully
2023-04-06 22:12:16,895:INFO:Starting cross validation
2023-04-06 22:12:16,896:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:12:24,489:INFO:Calculating mean and std
2023-04-06 22:12:24,491:INFO:Creating metrics dataframe
2023-04-06 22:12:24,928:INFO:Uploading results into container
2023-04-06 22:12:24,929:INFO:Uploading model into container now
2023-04-06 22:12:24,929:INFO:_master_model_container: 1
2023-04-06 22:12:24,929:INFO:_display_container: 2
2023-04-06 22:12:24,930:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-06 22:12:24,930:INFO:create_model() successfully completed......................................
2023-04-06 22:12:25,025:INFO:SubProcess create_model() end ==================================
2023-04-06 22:12:25,025:INFO:Creating metrics dataframe
2023-04-06 22:12:25,030:INFO:Initializing K Neighbors Classifier
2023-04-06 22:12:25,031:INFO:Total runtime is 0.1357990543047587 minutes
2023-04-06 22:12:25,033:INFO:SubProcess create_model() called ==================================
2023-04-06 22:12:25,033:INFO:Initializing create_model()
2023-04-06 22:12:25,033:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17b102c40>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:12:25,033:INFO:Checking exceptions
2023-04-06 22:12:25,034:INFO:Importing libraries
2023-04-06 22:12:25,034:INFO:Copying training dataset
2023-04-06 22:12:25,036:INFO:Defining folds
2023-04-06 22:12:25,037:INFO:Declaring metric variables
2023-04-06 22:12:25,038:INFO:Importing untrained model
2023-04-06 22:12:25,040:INFO:K Neighbors Classifier Imported successfully
2023-04-06 22:12:25,044:INFO:Starting cross validation
2023-04-06 22:12:25,044:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:12:29,271:INFO:Calculating mean and std
2023-04-06 22:12:29,271:INFO:Creating metrics dataframe
2023-04-06 22:12:29,704:INFO:Uploading results into container
2023-04-06 22:12:29,704:INFO:Uploading model into container now
2023-04-06 22:12:29,704:INFO:_master_model_container: 2
2023-04-06 22:12:29,704:INFO:_display_container: 2
2023-04-06 22:12:29,705:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-06 22:12:29,705:INFO:create_model() successfully completed......................................
2023-04-06 22:12:29,761:INFO:SubProcess create_model() end ==================================
2023-04-06 22:12:29,761:INFO:Creating metrics dataframe
2023-04-06 22:12:29,765:INFO:Initializing Naive Bayes
2023-04-06 22:12:29,765:INFO:Total runtime is 0.2147082527478536 minutes
2023-04-06 22:12:29,766:INFO:SubProcess create_model() called ==================================
2023-04-06 22:12:29,767:INFO:Initializing create_model()
2023-04-06 22:12:29,767:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17b102c40>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:12:29,767:INFO:Checking exceptions
2023-04-06 22:12:29,767:INFO:Importing libraries
2023-04-06 22:12:29,767:INFO:Copying training dataset
2023-04-06 22:12:29,768:INFO:Defining folds
2023-04-06 22:12:29,768:INFO:Declaring metric variables
2023-04-06 22:12:29,769:INFO:Importing untrained model
2023-04-06 22:12:29,770:INFO:Naive Bayes Imported successfully
2023-04-06 22:12:29,773:INFO:Starting cross validation
2023-04-06 22:12:29,773:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:12:34,050:INFO:Calculating mean and std
2023-04-06 22:12:34,051:INFO:Creating metrics dataframe
2023-04-06 22:12:34,491:INFO:Uploading results into container
2023-04-06 22:12:34,492:INFO:Uploading model into container now
2023-04-06 22:12:34,492:INFO:_master_model_container: 3
2023-04-06 22:12:34,492:INFO:_display_container: 2
2023-04-06 22:12:34,492:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-04-06 22:12:34,492:INFO:create_model() successfully completed......................................
2023-04-06 22:12:34,548:INFO:SubProcess create_model() end ==================================
2023-04-06 22:12:34,548:INFO:Creating metrics dataframe
2023-04-06 22:12:34,552:INFO:Initializing Decision Tree Classifier
2023-04-06 22:12:34,552:INFO:Total runtime is 0.2944931507110596 minutes
2023-04-06 22:12:34,554:INFO:SubProcess create_model() called ==================================
2023-04-06 22:12:34,554:INFO:Initializing create_model()
2023-04-06 22:12:34,554:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17b102c40>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:12:34,554:INFO:Checking exceptions
2023-04-06 22:12:34,554:INFO:Importing libraries
2023-04-06 22:12:34,554:INFO:Copying training dataset
2023-04-06 22:12:34,555:INFO:Defining folds
2023-04-06 22:12:34,555:INFO:Declaring metric variables
2023-04-06 22:12:34,557:INFO:Importing untrained model
2023-04-06 22:12:34,559:INFO:Decision Tree Classifier Imported successfully
2023-04-06 22:12:34,565:INFO:Starting cross validation
2023-04-06 22:12:34,565:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:12:38,756:INFO:Calculating mean and std
2023-04-06 22:12:38,757:INFO:Creating metrics dataframe
2023-04-06 22:12:39,208:INFO:Uploading results into container
2023-04-06 22:12:39,209:INFO:Uploading model into container now
2023-04-06 22:12:39,209:INFO:_master_model_container: 4
2023-04-06 22:12:39,209:INFO:_display_container: 2
2023-04-06 22:12:39,209:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-04-06 22:12:39,209:INFO:create_model() successfully completed......................................
2023-04-06 22:12:39,270:INFO:SubProcess create_model() end ==================================
2023-04-06 22:12:39,270:INFO:Creating metrics dataframe
2023-04-06 22:12:39,274:INFO:Initializing SVM - Linear Kernel
2023-04-06 22:12:39,274:INFO:Total runtime is 0.3731925845146179 minutes
2023-04-06 22:12:39,276:INFO:SubProcess create_model() called ==================================
2023-04-06 22:12:39,276:INFO:Initializing create_model()
2023-04-06 22:12:39,276:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17b102c40>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:12:39,276:INFO:Checking exceptions
2023-04-06 22:12:39,276:INFO:Importing libraries
2023-04-06 22:12:39,276:INFO:Copying training dataset
2023-04-06 22:12:39,277:INFO:Defining folds
2023-04-06 22:12:39,278:INFO:Declaring metric variables
2023-04-06 22:12:39,279:INFO:Importing untrained model
2023-04-06 22:12:39,280:INFO:SVM - Linear Kernel Imported successfully
2023-04-06 22:12:39,283:INFO:Starting cross validation
2023-04-06 22:12:39,283:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:12:39,313:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py", line 127, in __get__
    if not self.check(obj):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1222, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-06 22:12:39,313:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py", line 127, in __get__
    if not self.check(obj):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1222, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-06 22:12:39,315:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py", line 127, in __get__
    if not self.check(obj):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1222, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-06 22:12:39,320:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py", line 127, in __get__
    if not self.check(obj):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1222, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-06 22:12:39,321:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py", line 127, in __get__
    if not self.check(obj):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1222, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-06 22:12:39,324:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-06 22:12:39,332:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py", line 127, in __get__
    if not self.check(obj):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1222, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-06 22:12:39,337:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py", line 127, in __get__
    if not self.check(obj):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1222, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-06 22:12:39,338:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py", line 127, in __get__
    if not self.check(obj):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1222, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-06 22:12:39,339:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-06 22:12:39,339:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py", line 127, in __get__
    if not self.check(obj):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1222, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-06 22:12:39,359:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py", line 127, in __get__
    if not self.check(obj):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1222, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-06 22:12:43,731:INFO:Calculating mean and std
2023-04-06 22:12:43,732:INFO:Creating metrics dataframe
2023-04-06 22:12:44,178:INFO:Uploading results into container
2023-04-06 22:12:44,178:INFO:Uploading model into container now
2023-04-06 22:12:44,178:INFO:_master_model_container: 5
2023-04-06 22:12:44,178:INFO:_display_container: 2
2023-04-06 22:12:44,179:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-04-06 22:12:44,179:INFO:create_model() successfully completed......................................
2023-04-06 22:12:44,237:INFO:SubProcess create_model() end ==================================
2023-04-06 22:12:44,237:INFO:Creating metrics dataframe
2023-04-06 22:12:44,241:INFO:Initializing Ridge Classifier
2023-04-06 22:12:44,242:INFO:Total runtime is 0.45598036845525103 minutes
2023-04-06 22:12:44,243:INFO:SubProcess create_model() called ==================================
2023-04-06 22:12:44,243:INFO:Initializing create_model()
2023-04-06 22:12:44,243:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17b102c40>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:12:44,243:INFO:Checking exceptions
2023-04-06 22:12:44,243:INFO:Importing libraries
2023-04-06 22:12:44,243:INFO:Copying training dataset
2023-04-06 22:12:44,245:INFO:Defining folds
2023-04-06 22:12:44,245:INFO:Declaring metric variables
2023-04-06 22:12:44,246:INFO:Importing untrained model
2023-04-06 22:12:44,248:INFO:Ridge Classifier Imported successfully
2023-04-06 22:12:44,250:INFO:Starting cross validation
2023-04-06 22:12:44,251:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:12:44,278:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-06 22:12:44,280:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-06 22:12:44,282:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-06 22:12:44,285:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-06 22:12:44,293:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-06 22:12:44,297:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-06 22:12:44,300:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-06 22:12:44,302:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-06 22:12:44,302:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-06 22:12:44,325:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-06 22:12:48,529:INFO:Calculating mean and std
2023-04-06 22:12:48,529:INFO:Creating metrics dataframe
2023-04-06 22:12:48,994:INFO:Uploading results into container
2023-04-06 22:12:48,995:INFO:Uploading model into container now
2023-04-06 22:12:48,995:INFO:_master_model_container: 6
2023-04-06 22:12:48,995:INFO:_display_container: 2
2023-04-06 22:12:48,995:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=123, solver='auto', tol=0.001)
2023-04-06 22:12:48,995:INFO:create_model() successfully completed......................................
2023-04-06 22:12:49,055:INFO:SubProcess create_model() end ==================================
2023-04-06 22:12:49,055:INFO:Creating metrics dataframe
2023-04-06 22:12:49,061:INFO:Initializing Random Forest Classifier
2023-04-06 22:12:49,061:INFO:Total runtime is 0.5363054156303405 minutes
2023-04-06 22:12:49,063:INFO:SubProcess create_model() called ==================================
2023-04-06 22:12:49,063:INFO:Initializing create_model()
2023-04-06 22:12:49,063:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17b102c40>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:12:49,063:INFO:Checking exceptions
2023-04-06 22:12:49,063:INFO:Importing libraries
2023-04-06 22:12:49,063:INFO:Copying training dataset
2023-04-06 22:12:49,065:INFO:Defining folds
2023-04-06 22:12:49,065:INFO:Declaring metric variables
2023-04-06 22:12:49,066:INFO:Importing untrained model
2023-04-06 22:12:49,075:INFO:Random Forest Classifier Imported successfully
2023-04-06 22:12:49,084:INFO:Starting cross validation
2023-04-06 22:12:49,085:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:12:53,667:INFO:Calculating mean and std
2023-04-06 22:12:53,667:INFO:Creating metrics dataframe
2023-04-06 22:12:54,171:INFO:Uploading results into container
2023-04-06 22:12:54,172:INFO:Uploading model into container now
2023-04-06 22:12:54,172:INFO:_master_model_container: 7
2023-04-06 22:12:54,172:INFO:_display_container: 2
2023-04-06 22:12:54,172:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-04-06 22:12:54,173:INFO:create_model() successfully completed......................................
2023-04-06 22:12:54,235:INFO:SubProcess create_model() end ==================================
2023-04-06 22:12:54,235:INFO:Creating metrics dataframe
2023-04-06 22:12:54,240:INFO:Initializing Quadratic Discriminant Analysis
2023-04-06 22:12:54,240:INFO:Total runtime is 0.6226291020711262 minutes
2023-04-06 22:12:54,242:INFO:SubProcess create_model() called ==================================
2023-04-06 22:12:54,242:INFO:Initializing create_model()
2023-04-06 22:12:54,242:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17b102c40>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:12:54,242:INFO:Checking exceptions
2023-04-06 22:12:54,242:INFO:Importing libraries
2023-04-06 22:12:54,242:INFO:Copying training dataset
2023-04-06 22:12:54,244:INFO:Defining folds
2023-04-06 22:12:54,244:INFO:Declaring metric variables
2023-04-06 22:12:54,246:INFO:Importing untrained model
2023-04-06 22:12:54,248:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-06 22:12:54,251:INFO:Starting cross validation
2023-04-06 22:12:54,252:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:12:58,953:INFO:Calculating mean and std
2023-04-06 22:12:58,953:INFO:Creating metrics dataframe
2023-04-06 22:12:59,389:INFO:Uploading results into container
2023-04-06 22:12:59,389:INFO:Uploading model into container now
2023-04-06 22:12:59,390:INFO:_master_model_container: 8
2023-04-06 22:12:59,390:INFO:_display_container: 2
2023-04-06 22:12:59,390:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-06 22:12:59,390:INFO:create_model() successfully completed......................................
2023-04-06 22:12:59,444:INFO:SubProcess create_model() end ==================================
2023-04-06 22:12:59,444:INFO:Creating metrics dataframe
2023-04-06 22:12:59,449:INFO:Initializing Ada Boost Classifier
2023-04-06 22:12:59,449:INFO:Total runtime is 0.7094369371732075 minutes
2023-04-06 22:12:59,450:INFO:SubProcess create_model() called ==================================
2023-04-06 22:12:59,450:INFO:Initializing create_model()
2023-04-06 22:12:59,450:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17b102c40>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:12:59,450:INFO:Checking exceptions
2023-04-06 22:12:59,450:INFO:Importing libraries
2023-04-06 22:12:59,450:INFO:Copying training dataset
2023-04-06 22:12:59,452:INFO:Defining folds
2023-04-06 22:12:59,452:INFO:Declaring metric variables
2023-04-06 22:12:59,453:INFO:Importing untrained model
2023-04-06 22:12:59,454:INFO:Ada Boost Classifier Imported successfully
2023-04-06 22:12:59,456:INFO:Starting cross validation
2023-04-06 22:12:59,457:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:13:03,920:INFO:Calculating mean and std
2023-04-06 22:13:03,920:INFO:Creating metrics dataframe
2023-04-06 22:13:04,363:INFO:Uploading results into container
2023-04-06 22:13:04,363:INFO:Uploading model into container now
2023-04-06 22:13:04,364:INFO:_master_model_container: 9
2023-04-06 22:13:04,364:INFO:_display_container: 2
2023-04-06 22:13:04,364:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2023-04-06 22:13:04,364:INFO:create_model() successfully completed......................................
2023-04-06 22:13:04,422:INFO:SubProcess create_model() end ==================================
2023-04-06 22:13:04,422:INFO:Creating metrics dataframe
2023-04-06 22:13:04,426:INFO:Initializing Gradient Boosting Classifier
2023-04-06 22:13:04,427:INFO:Total runtime is 0.7923973043759663 minutes
2023-04-06 22:13:04,428:INFO:SubProcess create_model() called ==================================
2023-04-06 22:13:04,428:INFO:Initializing create_model()
2023-04-06 22:13:04,428:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17b102c40>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:13:04,428:INFO:Checking exceptions
2023-04-06 22:13:04,428:INFO:Importing libraries
2023-04-06 22:13:04,428:INFO:Copying training dataset
2023-04-06 22:13:04,430:INFO:Defining folds
2023-04-06 22:13:04,430:INFO:Declaring metric variables
2023-04-06 22:13:04,431:INFO:Importing untrained model
2023-04-06 22:13:04,432:INFO:Gradient Boosting Classifier Imported successfully
2023-04-06 22:13:04,435:INFO:Starting cross validation
2023-04-06 22:13:04,436:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:13:08,749:INFO:Calculating mean and std
2023-04-06 22:13:08,749:INFO:Creating metrics dataframe
2023-04-06 22:13:09,215:INFO:Uploading results into container
2023-04-06 22:13:09,216:INFO:Uploading model into container now
2023-04-06 22:13:09,216:INFO:_master_model_container: 10
2023-04-06 22:13:09,216:INFO:_display_container: 2
2023-04-06 22:13:09,216:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-04-06 22:13:09,216:INFO:create_model() successfully completed......................................
2023-04-06 22:13:09,276:INFO:SubProcess create_model() end ==================================
2023-04-06 22:13:09,276:INFO:Creating metrics dataframe
2023-04-06 22:13:09,280:INFO:Initializing Linear Discriminant Analysis
2023-04-06 22:13:09,280:INFO:Total runtime is 0.8732947508494059 minutes
2023-04-06 22:13:09,282:INFO:SubProcess create_model() called ==================================
2023-04-06 22:13:09,282:INFO:Initializing create_model()
2023-04-06 22:13:09,282:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17b102c40>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:13:09,282:INFO:Checking exceptions
2023-04-06 22:13:09,282:INFO:Importing libraries
2023-04-06 22:13:09,282:INFO:Copying training dataset
2023-04-06 22:13:09,284:INFO:Defining folds
2023-04-06 22:13:09,284:INFO:Declaring metric variables
2023-04-06 22:13:09,285:INFO:Importing untrained model
2023-04-06 22:13:09,286:INFO:Linear Discriminant Analysis Imported successfully
2023-04-06 22:13:09,297:INFO:Starting cross validation
2023-04-06 22:13:09,298:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:13:13,673:INFO:Calculating mean and std
2023-04-06 22:13:13,673:INFO:Creating metrics dataframe
2023-04-06 22:13:14,121:INFO:Uploading results into container
2023-04-06 22:13:14,122:INFO:Uploading model into container now
2023-04-06 22:13:14,122:INFO:_master_model_container: 11
2023-04-06 22:13:14,122:INFO:_display_container: 2
2023-04-06 22:13:14,122:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-04-06 22:13:14,122:INFO:create_model() successfully completed......................................
2023-04-06 22:13:14,178:INFO:SubProcess create_model() end ==================================
2023-04-06 22:13:14,178:INFO:Creating metrics dataframe
2023-04-06 22:13:14,183:INFO:Initializing Extra Trees Classifier
2023-04-06 22:13:14,183:INFO:Total runtime is 0.9550010681152343 minutes
2023-04-06 22:13:14,184:INFO:SubProcess create_model() called ==================================
2023-04-06 22:13:14,184:INFO:Initializing create_model()
2023-04-06 22:13:14,184:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17b102c40>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:13:14,184:INFO:Checking exceptions
2023-04-06 22:13:14,184:INFO:Importing libraries
2023-04-06 22:13:14,184:INFO:Copying training dataset
2023-04-06 22:13:14,186:INFO:Defining folds
2023-04-06 22:13:14,186:INFO:Declaring metric variables
2023-04-06 22:13:14,187:INFO:Importing untrained model
2023-04-06 22:13:14,188:INFO:Extra Trees Classifier Imported successfully
2023-04-06 22:13:14,191:INFO:Starting cross validation
2023-04-06 22:13:14,192:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:13:18,573:INFO:Calculating mean and std
2023-04-06 22:13:18,573:INFO:Creating metrics dataframe
2023-04-06 22:13:19,015:INFO:Uploading results into container
2023-04-06 22:13:19,016:INFO:Uploading model into container now
2023-04-06 22:13:19,016:INFO:_master_model_container: 12
2023-04-06 22:13:19,016:INFO:_display_container: 2
2023-04-06 22:13:19,016:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-04-06 22:13:19,016:INFO:create_model() successfully completed......................................
2023-04-06 22:13:19,072:INFO:SubProcess create_model() end ==================================
2023-04-06 22:13:19,072:INFO:Creating metrics dataframe
2023-04-06 22:13:19,077:INFO:Initializing Extreme Gradient Boosting
2023-04-06 22:13:19,077:INFO:Total runtime is 1.0365709344546 minutes
2023-04-06 22:13:19,078:INFO:SubProcess create_model() called ==================================
2023-04-06 22:13:19,078:INFO:Initializing create_model()
2023-04-06 22:13:19,079:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17b102c40>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:13:19,079:INFO:Checking exceptions
2023-04-06 22:13:19,079:INFO:Importing libraries
2023-04-06 22:13:19,079:INFO:Copying training dataset
2023-04-06 22:13:19,080:INFO:Defining folds
2023-04-06 22:13:19,080:INFO:Declaring metric variables
2023-04-06 22:13:19,081:INFO:Importing untrained model
2023-04-06 22:13:19,082:INFO:Extreme Gradient Boosting Imported successfully
2023-04-06 22:13:19,085:INFO:Starting cross validation
2023-04-06 22:13:19,085:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:13:23,535:INFO:Calculating mean and std
2023-04-06 22:13:23,536:INFO:Creating metrics dataframe
2023-04-06 22:13:23,957:INFO:Uploading results into container
2023-04-06 22:13:23,958:INFO:Uploading model into container now
2023-04-06 22:13:23,958:INFO:_master_model_container: 13
2023-04-06 22:13:23,958:INFO:_display_container: 2
2023-04-06 22:13:23,959:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-04-06 22:13:23,959:INFO:create_model() successfully completed......................................
2023-04-06 22:13:24,016:INFO:SubProcess create_model() end ==================================
2023-04-06 22:13:24,016:INFO:Creating metrics dataframe
2023-04-06 22:13:24,022:INFO:Initializing Light Gradient Boosting Machine
2023-04-06 22:13:24,022:INFO:Total runtime is 1.1189841349919636 minutes
2023-04-06 22:13:24,023:INFO:SubProcess create_model() called ==================================
2023-04-06 22:13:24,024:INFO:Initializing create_model()
2023-04-06 22:13:24,024:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17b102c40>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:13:24,024:INFO:Checking exceptions
2023-04-06 22:13:24,024:INFO:Importing libraries
2023-04-06 22:13:24,024:INFO:Copying training dataset
2023-04-06 22:13:24,026:INFO:Defining folds
2023-04-06 22:13:24,026:INFO:Declaring metric variables
2023-04-06 22:13:24,027:INFO:Importing untrained model
2023-04-06 22:13:24,029:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-06 22:13:24,031:INFO:Starting cross validation
2023-04-06 22:13:24,032:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:13:29,378:INFO:Calculating mean and std
2023-04-06 22:13:29,379:INFO:Creating metrics dataframe
2023-04-06 22:13:29,850:INFO:Uploading results into container
2023-04-06 22:13:29,851:INFO:Uploading model into container now
2023-04-06 22:13:29,852:INFO:_master_model_container: 14
2023-04-06 22:13:29,852:INFO:_display_container: 2
2023-04-06 22:13:29,852:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-06 22:13:29,852:INFO:create_model() successfully completed......................................
2023-04-06 22:13:29,913:INFO:SubProcess create_model() end ==================================
2023-04-06 22:13:29,914:INFO:Creating metrics dataframe
2023-04-06 22:13:29,918:INFO:Initializing CatBoost Classifier
2023-04-06 22:13:29,919:INFO:Total runtime is 1.217264167467753 minutes
2023-04-06 22:13:29,920:INFO:SubProcess create_model() called ==================================
2023-04-06 22:13:29,920:INFO:Initializing create_model()
2023-04-06 22:13:29,920:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17b102c40>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:13:29,920:INFO:Checking exceptions
2023-04-06 22:13:29,920:INFO:Importing libraries
2023-04-06 22:13:29,920:INFO:Copying training dataset
2023-04-06 22:13:29,922:INFO:Defining folds
2023-04-06 22:13:29,922:INFO:Declaring metric variables
2023-04-06 22:13:29,923:INFO:Importing untrained model
2023-04-06 22:13:29,924:INFO:CatBoost Classifier Imported successfully
2023-04-06 22:13:29,927:INFO:Starting cross validation
2023-04-06 22:13:29,927:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:13:36,054:INFO:Calculating mean and std
2023-04-06 22:13:36,055:INFO:Creating metrics dataframe
2023-04-06 22:13:36,491:INFO:Uploading results into container
2023-04-06 22:13:36,492:INFO:Uploading model into container now
2023-04-06 22:13:36,492:INFO:_master_model_container: 15
2023-04-06 22:13:36,493:INFO:_display_container: 2
2023-04-06 22:13:36,493:INFO:<catboost.core.CatBoostClassifier object at 0x17afd82e0>
2023-04-06 22:13:36,493:INFO:create_model() successfully completed......................................
2023-04-06 22:13:36,579:INFO:SubProcess create_model() end ==================================
2023-04-06 22:13:36,579:INFO:Creating metrics dataframe
2023-04-06 22:13:36,585:INFO:Initializing Dummy Classifier
2023-04-06 22:13:36,585:INFO:Total runtime is 1.3283785184224444 minutes
2023-04-06 22:13:36,587:INFO:SubProcess create_model() called ==================================
2023-04-06 22:13:36,587:INFO:Initializing create_model()
2023-04-06 22:13:36,587:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17b102c40>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:13:36,587:INFO:Checking exceptions
2023-04-06 22:13:36,587:INFO:Importing libraries
2023-04-06 22:13:36,588:INFO:Copying training dataset
2023-04-06 22:13:36,589:INFO:Defining folds
2023-04-06 22:13:36,589:INFO:Declaring metric variables
2023-04-06 22:13:36,591:INFO:Importing untrained model
2023-04-06 22:13:36,593:INFO:Dummy Classifier Imported successfully
2023-04-06 22:13:36,595:INFO:Starting cross validation
2023-04-06 22:13:36,596:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:13:36,632:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-06 22:13:36,634:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-06 22:13:36,636:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-06 22:13:36,638:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-06 22:13:36,642:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-06 22:13:36,652:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-06 22:13:36,652:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-06 22:13:36,657:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-06 22:13:36,660:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-06 22:13:36,667:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-06 22:13:40,986:INFO:Calculating mean and std
2023-04-06 22:13:40,987:INFO:Creating metrics dataframe
2023-04-06 22:13:41,428:INFO:Uploading results into container
2023-04-06 22:13:41,429:INFO:Uploading model into container now
2023-04-06 22:13:41,430:INFO:_master_model_container: 16
2023-04-06 22:13:41,430:INFO:_display_container: 2
2023-04-06 22:13:41,430:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-04-06 22:13:41,430:INFO:create_model() successfully completed......................................
2023-04-06 22:13:41,488:INFO:SubProcess create_model() end ==================================
2023-04-06 22:13:41,488:INFO:Creating metrics dataframe
2023-04-06 22:13:41,497:INFO:Initializing create_model()
2023-04-06 22:13:41,497:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:13:41,497:INFO:Checking exceptions
2023-04-06 22:13:41,498:INFO:Importing libraries
2023-04-06 22:13:41,498:INFO:Copying training dataset
2023-04-06 22:13:41,499:INFO:Defining folds
2023-04-06 22:13:41,499:INFO:Declaring metric variables
2023-04-06 22:13:41,499:INFO:Importing untrained model
2023-04-06 22:13:41,499:INFO:Declaring custom model
2023-04-06 22:13:41,500:INFO:Logistic Regression Imported successfully
2023-04-06 22:13:41,500:INFO:Cross validation set to False
2023-04-06 22:13:41,500:INFO:Fitting Model
2023-04-06 22:13:41,890:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-06 22:13:41,891:INFO:create_model() successfully completed......................................
2023-04-06 22:13:41,957:INFO:_master_model_container: 16
2023-04-06 22:13:41,957:INFO:_display_container: 2
2023-04-06 22:13:41,957:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-06 22:13:41,957:INFO:compare_models() successfully completed......................................
2023-04-06 22:13:41,960:INFO:Initializing compare_models()
2023-04-06 22:13:41,960:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17b0cf0d0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x17b0cf0d0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-04-06 22:13:41,960:INFO:Checking exceptions
2023-04-06 22:13:41,962:INFO:Preparing display monitor
2023-04-06 22:13:41,973:INFO:Initializing Logistic Regression
2023-04-06 22:13:41,973:INFO:Total runtime is 2.11795171101888e-06 minutes
2023-04-06 22:13:41,974:INFO:SubProcess create_model() called ==================================
2023-04-06 22:13:41,975:INFO:Initializing create_model()
2023-04-06 22:13:41,975:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17b0cf0d0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1799aff10>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:13:41,975:INFO:Checking exceptions
2023-04-06 22:13:41,975:INFO:Importing libraries
2023-04-06 22:13:41,975:INFO:Copying training dataset
2023-04-06 22:13:41,977:INFO:Defining folds
2023-04-06 22:13:41,977:INFO:Declaring metric variables
2023-04-06 22:13:41,979:INFO:Importing untrained model
2023-04-06 22:13:41,980:INFO:Logistic Regression Imported successfully
2023-04-06 22:13:41,983:INFO:Starting cross validation
2023-04-06 22:13:41,984:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:13:46,261:INFO:Calculating mean and std
2023-04-06 22:13:46,263:INFO:Creating metrics dataframe
2023-04-06 22:13:46,720:INFO:Uploading results into container
2023-04-06 22:13:46,720:INFO:Uploading model into container now
2023-04-06 22:13:46,720:INFO:_master_model_container: 1
2023-04-06 22:13:46,721:INFO:_display_container: 2
2023-04-06 22:13:46,721:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-06 22:13:46,721:INFO:create_model() successfully completed......................................
2023-04-06 22:13:46,780:INFO:SubProcess create_model() end ==================================
2023-04-06 22:13:46,780:INFO:Creating metrics dataframe
2023-04-06 22:13:46,783:INFO:Initializing K Neighbors Classifier
2023-04-06 22:13:46,783:INFO:Total runtime is 0.08017913103103638 minutes
2023-04-06 22:13:46,784:INFO:SubProcess create_model() called ==================================
2023-04-06 22:13:46,785:INFO:Initializing create_model()
2023-04-06 22:13:46,785:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17b0cf0d0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1799aff10>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:13:46,785:INFO:Checking exceptions
2023-04-06 22:13:46,785:INFO:Importing libraries
2023-04-06 22:13:46,785:INFO:Copying training dataset
2023-04-06 22:13:46,786:INFO:Defining folds
2023-04-06 22:13:46,786:INFO:Declaring metric variables
2023-04-06 22:13:46,787:INFO:Importing untrained model
2023-04-06 22:13:46,789:INFO:K Neighbors Classifier Imported successfully
2023-04-06 22:13:46,792:INFO:Starting cross validation
2023-04-06 22:13:46,792:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:13:51,143:INFO:Calculating mean and std
2023-04-06 22:13:51,144:INFO:Creating metrics dataframe
2023-04-06 22:13:51,608:INFO:Uploading results into container
2023-04-06 22:13:51,608:INFO:Uploading model into container now
2023-04-06 22:13:51,608:INFO:_master_model_container: 2
2023-04-06 22:13:51,608:INFO:_display_container: 2
2023-04-06 22:13:51,608:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-06 22:13:51,608:INFO:create_model() successfully completed......................................
2023-04-06 22:13:51,667:INFO:SubProcess create_model() end ==================================
2023-04-06 22:13:51,668:INFO:Creating metrics dataframe
2023-04-06 22:13:51,672:INFO:Initializing Naive Bayes
2023-04-06 22:13:51,672:INFO:Total runtime is 0.16166383425394693 minutes
2023-04-06 22:13:51,674:INFO:SubProcess create_model() called ==================================
2023-04-06 22:13:51,674:INFO:Initializing create_model()
2023-04-06 22:13:51,674:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17b0cf0d0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1799aff10>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:13:51,674:INFO:Checking exceptions
2023-04-06 22:13:51,674:INFO:Importing libraries
2023-04-06 22:13:51,675:INFO:Copying training dataset
2023-04-06 22:13:51,676:INFO:Defining folds
2023-04-06 22:13:51,676:INFO:Declaring metric variables
2023-04-06 22:13:51,677:INFO:Importing untrained model
2023-04-06 22:13:51,679:INFO:Naive Bayes Imported successfully
2023-04-06 22:13:51,681:INFO:Starting cross validation
2023-04-06 22:13:51,681:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:13:55,915:INFO:Calculating mean and std
2023-04-06 22:13:55,916:INFO:Creating metrics dataframe
2023-04-06 22:13:56,402:INFO:Uploading results into container
2023-04-06 22:13:56,403:INFO:Uploading model into container now
2023-04-06 22:13:56,403:INFO:_master_model_container: 3
2023-04-06 22:13:56,403:INFO:_display_container: 2
2023-04-06 22:13:56,403:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-04-06 22:13:56,403:INFO:create_model() successfully completed......................................
2023-04-06 22:13:56,460:INFO:SubProcess create_model() end ==================================
2023-04-06 22:13:56,460:INFO:Creating metrics dataframe
2023-04-06 22:13:56,465:INFO:Initializing Decision Tree Classifier
2023-04-06 22:13:56,465:INFO:Total runtime is 0.24154365062713623 minutes
2023-04-06 22:13:56,467:INFO:SubProcess create_model() called ==================================
2023-04-06 22:13:56,467:INFO:Initializing create_model()
2023-04-06 22:13:56,467:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17b0cf0d0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1799aff10>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:13:56,467:INFO:Checking exceptions
2023-04-06 22:13:56,467:INFO:Importing libraries
2023-04-06 22:13:56,467:INFO:Copying training dataset
2023-04-06 22:13:56,468:INFO:Defining folds
2023-04-06 22:13:56,468:INFO:Declaring metric variables
2023-04-06 22:13:56,470:INFO:Importing untrained model
2023-04-06 22:13:56,471:INFO:Decision Tree Classifier Imported successfully
2023-04-06 22:13:56,473:INFO:Starting cross validation
2023-04-06 22:13:56,474:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:14:00,675:INFO:Calculating mean and std
2023-04-06 22:14:00,676:INFO:Creating metrics dataframe
2023-04-06 22:14:01,140:INFO:Uploading results into container
2023-04-06 22:14:01,140:INFO:Uploading model into container now
2023-04-06 22:14:01,140:INFO:_master_model_container: 4
2023-04-06 22:14:01,140:INFO:_display_container: 2
2023-04-06 22:14:01,141:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-04-06 22:14:01,141:INFO:create_model() successfully completed......................................
2023-04-06 22:14:01,199:INFO:SubProcess create_model() end ==================================
2023-04-06 22:14:01,199:INFO:Creating metrics dataframe
2023-04-06 22:14:01,203:INFO:Initializing SVM - Linear Kernel
2023-04-06 22:14:01,203:INFO:Total runtime is 0.3205061157544454 minutes
2023-04-06 22:14:01,204:INFO:SubProcess create_model() called ==================================
2023-04-06 22:14:01,204:INFO:Initializing create_model()
2023-04-06 22:14:01,204:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17b0cf0d0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1799aff10>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:14:01,204:INFO:Checking exceptions
2023-04-06 22:14:01,204:INFO:Importing libraries
2023-04-06 22:14:01,204:INFO:Copying training dataset
2023-04-06 22:14:01,206:INFO:Defining folds
2023-04-06 22:14:01,206:INFO:Declaring metric variables
2023-04-06 22:14:01,207:INFO:Importing untrained model
2023-04-06 22:14:01,209:INFO:SVM - Linear Kernel Imported successfully
2023-04-06 22:14:01,211:INFO:Starting cross validation
2023-04-06 22:14:01,212:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:14:01,241:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py", line 127, in __get__
    if not self.check(obj):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1222, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-06 22:14:01,250:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py", line 127, in __get__
    if not self.check(obj):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1222, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-06 22:14:01,250:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py", line 127, in __get__
    if not self.check(obj):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1222, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-06 22:14:01,252:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py", line 127, in __get__
    if not self.check(obj):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1222, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-06 22:14:01,254:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py", line 127, in __get__
    if not self.check(obj):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1222, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-06 22:14:01,255:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-06 22:14:01,256:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py", line 127, in __get__
    if not self.check(obj):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1222, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-06 22:14:01,261:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py", line 127, in __get__
    if not self.check(obj):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1222, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-06 22:14:01,274:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py", line 127, in __get__
    if not self.check(obj):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1222, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-06 22:14:01,274:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-06 22:14:01,275:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py", line 127, in __get__
    if not self.check(obj):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1222, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-06 22:14:01,299:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py", line 127, in __get__
    if not self.check(obj):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1222, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-06 22:14:05,539:INFO:Calculating mean and std
2023-04-06 22:14:05,540:INFO:Creating metrics dataframe
2023-04-06 22:14:05,985:INFO:Uploading results into container
2023-04-06 22:14:05,985:INFO:Uploading model into container now
2023-04-06 22:14:05,986:INFO:_master_model_container: 5
2023-04-06 22:14:05,986:INFO:_display_container: 2
2023-04-06 22:14:05,986:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-04-06 22:14:05,986:INFO:create_model() successfully completed......................................
2023-04-06 22:14:06,041:INFO:SubProcess create_model() end ==================================
2023-04-06 22:14:06,041:INFO:Creating metrics dataframe
2023-04-06 22:14:06,045:INFO:Initializing Ridge Classifier
2023-04-06 22:14:06,045:INFO:Total runtime is 0.40121546586354573 minutes
2023-04-06 22:14:06,047:INFO:SubProcess create_model() called ==================================
2023-04-06 22:14:06,047:INFO:Initializing create_model()
2023-04-06 22:14:06,047:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17b0cf0d0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1799aff10>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:14:06,047:INFO:Checking exceptions
2023-04-06 22:14:06,047:INFO:Importing libraries
2023-04-06 22:14:06,047:INFO:Copying training dataset
2023-04-06 22:14:06,049:INFO:Defining folds
2023-04-06 22:14:06,049:INFO:Declaring metric variables
2023-04-06 22:14:06,050:INFO:Importing untrained model
2023-04-06 22:14:06,051:INFO:Ridge Classifier Imported successfully
2023-04-06 22:14:06,054:INFO:Starting cross validation
2023-04-06 22:14:06,054:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:14:06,077:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-06 22:14:06,084:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-06 22:14:06,084:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-06 22:14:06,086:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-06 22:14:06,091:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-06 22:14:06,096:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-06 22:14:06,102:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-06 22:14:06,108:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-06 22:14:06,111:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-06 22:14:06,112:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-06 22:14:10,436:INFO:Calculating mean and std
2023-04-06 22:14:10,437:INFO:Creating metrics dataframe
2023-04-06 22:14:10,943:INFO:Uploading results into container
2023-04-06 22:14:10,943:INFO:Uploading model into container now
2023-04-06 22:14:10,943:INFO:_master_model_container: 6
2023-04-06 22:14:10,943:INFO:_display_container: 2
2023-04-06 22:14:10,944:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=123, solver='auto', tol=0.001)
2023-04-06 22:14:10,944:INFO:create_model() successfully completed......................................
2023-04-06 22:14:11,006:INFO:SubProcess create_model() end ==================================
2023-04-06 22:14:11,006:INFO:Creating metrics dataframe
2023-04-06 22:14:11,011:INFO:Initializing Random Forest Classifier
2023-04-06 22:14:11,011:INFO:Total runtime is 0.48397349913915 minutes
2023-04-06 22:14:11,013:INFO:SubProcess create_model() called ==================================
2023-04-06 22:14:11,013:INFO:Initializing create_model()
2023-04-06 22:14:11,013:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17b0cf0d0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1799aff10>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:14:11,013:INFO:Checking exceptions
2023-04-06 22:14:11,013:INFO:Importing libraries
2023-04-06 22:14:11,013:INFO:Copying training dataset
2023-04-06 22:14:11,015:INFO:Defining folds
2023-04-06 22:14:11,015:INFO:Declaring metric variables
2023-04-06 22:14:11,016:INFO:Importing untrained model
2023-04-06 22:14:11,017:INFO:Random Forest Classifier Imported successfully
2023-04-06 22:14:11,020:INFO:Starting cross validation
2023-04-06 22:14:11,020:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:14:15,463:INFO:Calculating mean and std
2023-04-06 22:14:15,465:INFO:Creating metrics dataframe
2023-04-06 22:14:15,911:INFO:Uploading results into container
2023-04-06 22:14:15,911:INFO:Uploading model into container now
2023-04-06 22:14:15,912:INFO:_master_model_container: 7
2023-04-06 22:14:15,912:INFO:_display_container: 2
2023-04-06 22:14:15,912:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-04-06 22:14:15,912:INFO:create_model() successfully completed......................................
2023-04-06 22:14:15,967:INFO:SubProcess create_model() end ==================================
2023-04-06 22:14:15,967:INFO:Creating metrics dataframe
2023-04-06 22:14:15,971:INFO:Initializing Quadratic Discriminant Analysis
2023-04-06 22:14:15,972:INFO:Total runtime is 0.5666504661242168 minutes
2023-04-06 22:14:15,973:INFO:SubProcess create_model() called ==================================
2023-04-06 22:14:15,973:INFO:Initializing create_model()
2023-04-06 22:14:15,973:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17b0cf0d0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1799aff10>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:14:15,973:INFO:Checking exceptions
2023-04-06 22:14:15,973:INFO:Importing libraries
2023-04-06 22:14:15,973:INFO:Copying training dataset
2023-04-06 22:14:15,974:INFO:Defining folds
2023-04-06 22:14:15,974:INFO:Declaring metric variables
2023-04-06 22:14:15,975:INFO:Importing untrained model
2023-04-06 22:14:15,977:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-06 22:14:15,979:INFO:Starting cross validation
2023-04-06 22:14:15,979:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:14:20,098:INFO:Calculating mean and std
2023-04-06 22:14:20,099:INFO:Creating metrics dataframe
2023-04-06 22:14:20,544:INFO:Uploading results into container
2023-04-06 22:14:20,544:INFO:Uploading model into container now
2023-04-06 22:14:20,545:INFO:_master_model_container: 8
2023-04-06 22:14:20,545:INFO:_display_container: 2
2023-04-06 22:14:20,545:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-06 22:14:20,545:INFO:create_model() successfully completed......................................
2023-04-06 22:14:20,601:INFO:SubProcess create_model() end ==================================
2023-04-06 22:14:20,601:INFO:Creating metrics dataframe
2023-04-06 22:14:20,606:INFO:Initializing Ada Boost Classifier
2023-04-06 22:14:20,606:INFO:Total runtime is 0.643894636631012 minutes
2023-04-06 22:14:20,607:INFO:SubProcess create_model() called ==================================
2023-04-06 22:14:20,608:INFO:Initializing create_model()
2023-04-06 22:14:20,608:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17b0cf0d0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1799aff10>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:14:20,608:INFO:Checking exceptions
2023-04-06 22:14:20,608:INFO:Importing libraries
2023-04-06 22:14:20,608:INFO:Copying training dataset
2023-04-06 22:14:20,609:INFO:Defining folds
2023-04-06 22:14:20,609:INFO:Declaring metric variables
2023-04-06 22:14:20,610:INFO:Importing untrained model
2023-04-06 22:14:20,611:INFO:Ada Boost Classifier Imported successfully
2023-04-06 22:14:20,614:INFO:Starting cross validation
2023-04-06 22:14:20,614:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:14:24,805:INFO:Calculating mean and std
2023-04-06 22:14:24,806:INFO:Creating metrics dataframe
2023-04-06 22:14:25,254:INFO:Uploading results into container
2023-04-06 22:14:25,255:INFO:Uploading model into container now
2023-04-06 22:14:25,256:INFO:_master_model_container: 9
2023-04-06 22:14:25,256:INFO:_display_container: 2
2023-04-06 22:14:25,256:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2023-04-06 22:14:25,256:INFO:create_model() successfully completed......................................
2023-04-06 22:14:25,312:INFO:SubProcess create_model() end ==================================
2023-04-06 22:14:25,312:INFO:Creating metrics dataframe
2023-04-06 22:14:25,317:INFO:Initializing Gradient Boosting Classifier
2023-04-06 22:14:25,317:INFO:Total runtime is 0.7224041978518169 minutes
2023-04-06 22:14:25,318:INFO:SubProcess create_model() called ==================================
2023-04-06 22:14:25,318:INFO:Initializing create_model()
2023-04-06 22:14:25,318:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17b0cf0d0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1799aff10>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:14:25,318:INFO:Checking exceptions
2023-04-06 22:14:25,318:INFO:Importing libraries
2023-04-06 22:14:25,318:INFO:Copying training dataset
2023-04-06 22:14:25,320:INFO:Defining folds
2023-04-06 22:14:25,320:INFO:Declaring metric variables
2023-04-06 22:14:25,321:INFO:Importing untrained model
2023-04-06 22:14:25,322:INFO:Gradient Boosting Classifier Imported successfully
2023-04-06 22:14:25,324:INFO:Starting cross validation
2023-04-06 22:14:25,325:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:14:30,041:INFO:Calculating mean and std
2023-04-06 22:14:30,042:INFO:Creating metrics dataframe
2023-04-06 22:14:30,496:INFO:Uploading results into container
2023-04-06 22:14:30,497:INFO:Uploading model into container now
2023-04-06 22:14:30,497:INFO:_master_model_container: 10
2023-04-06 22:14:30,497:INFO:_display_container: 2
2023-04-06 22:14:30,497:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-04-06 22:14:30,497:INFO:create_model() successfully completed......................................
2023-04-06 22:14:30,556:INFO:SubProcess create_model() end ==================================
2023-04-06 22:14:30,557:INFO:Creating metrics dataframe
2023-04-06 22:14:30,561:INFO:Initializing Linear Discriminant Analysis
2023-04-06 22:14:30,562:INFO:Total runtime is 0.8098185857137045 minutes
2023-04-06 22:14:30,563:INFO:SubProcess create_model() called ==================================
2023-04-06 22:14:30,563:INFO:Initializing create_model()
2023-04-06 22:14:30,563:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17b0cf0d0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1799aff10>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:14:30,563:INFO:Checking exceptions
2023-04-06 22:14:30,563:INFO:Importing libraries
2023-04-06 22:14:30,563:INFO:Copying training dataset
2023-04-06 22:14:30,565:INFO:Defining folds
2023-04-06 22:14:30,565:INFO:Declaring metric variables
2023-04-06 22:14:30,566:INFO:Importing untrained model
2023-04-06 22:14:30,568:INFO:Linear Discriminant Analysis Imported successfully
2023-04-06 22:14:30,570:INFO:Starting cross validation
2023-04-06 22:14:30,571:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:14:34,775:INFO:Calculating mean and std
2023-04-06 22:14:34,776:INFO:Creating metrics dataframe
2023-04-06 22:14:35,248:INFO:Uploading results into container
2023-04-06 22:14:35,248:INFO:Uploading model into container now
2023-04-06 22:14:35,249:INFO:_master_model_container: 11
2023-04-06 22:14:35,249:INFO:_display_container: 2
2023-04-06 22:14:35,249:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-04-06 22:14:35,249:INFO:create_model() successfully completed......................................
2023-04-06 22:14:35,312:INFO:SubProcess create_model() end ==================================
2023-04-06 22:14:35,312:INFO:Creating metrics dataframe
2023-04-06 22:14:35,318:INFO:Initializing Extra Trees Classifier
2023-04-06 22:14:35,318:INFO:Total runtime is 0.889090665181478 minutes
2023-04-06 22:14:35,319:INFO:SubProcess create_model() called ==================================
2023-04-06 22:14:35,320:INFO:Initializing create_model()
2023-04-06 22:14:35,320:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17b0cf0d0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1799aff10>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:14:35,320:INFO:Checking exceptions
2023-04-06 22:14:35,320:INFO:Importing libraries
2023-04-06 22:14:35,320:INFO:Copying training dataset
2023-04-06 22:14:35,321:INFO:Defining folds
2023-04-06 22:14:35,321:INFO:Declaring metric variables
2023-04-06 22:14:35,323:INFO:Importing untrained model
2023-04-06 22:14:35,324:INFO:Extra Trees Classifier Imported successfully
2023-04-06 22:14:35,327:INFO:Starting cross validation
2023-04-06 22:14:35,327:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:14:39,887:INFO:Calculating mean and std
2023-04-06 22:14:39,887:INFO:Creating metrics dataframe
2023-04-06 22:14:40,330:INFO:Uploading results into container
2023-04-06 22:14:40,330:INFO:Uploading model into container now
2023-04-06 22:14:40,330:INFO:_master_model_container: 12
2023-04-06 22:14:40,330:INFO:_display_container: 2
2023-04-06 22:14:40,331:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-04-06 22:14:40,331:INFO:create_model() successfully completed......................................
2023-04-06 22:14:40,386:INFO:SubProcess create_model() end ==================================
2023-04-06 22:14:40,386:INFO:Creating metrics dataframe
2023-04-06 22:14:40,391:INFO:Initializing Extreme Gradient Boosting
2023-04-06 22:14:40,391:INFO:Total runtime is 0.9736406842867534 minutes
2023-04-06 22:14:40,392:INFO:SubProcess create_model() called ==================================
2023-04-06 22:14:40,392:INFO:Initializing create_model()
2023-04-06 22:14:40,392:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17b0cf0d0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1799aff10>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:14:40,392:INFO:Checking exceptions
2023-04-06 22:14:40,393:INFO:Importing libraries
2023-04-06 22:14:40,393:INFO:Copying training dataset
2023-04-06 22:14:40,394:INFO:Defining folds
2023-04-06 22:14:40,394:INFO:Declaring metric variables
2023-04-06 22:14:40,395:INFO:Importing untrained model
2023-04-06 22:14:40,397:INFO:Extreme Gradient Boosting Imported successfully
2023-04-06 22:14:40,399:INFO:Starting cross validation
2023-04-06 22:14:40,399:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:14:44,990:INFO:Calculating mean and std
2023-04-06 22:14:44,992:INFO:Creating metrics dataframe
2023-04-06 22:14:45,498:INFO:Uploading results into container
2023-04-06 22:14:45,498:INFO:Uploading model into container now
2023-04-06 22:14:45,499:INFO:_master_model_container: 13
2023-04-06 22:14:45,499:INFO:_display_container: 2
2023-04-06 22:14:45,499:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-04-06 22:14:45,499:INFO:create_model() successfully completed......................................
2023-04-06 22:14:45,567:INFO:SubProcess create_model() end ==================================
2023-04-06 22:14:45,567:INFO:Creating metrics dataframe
2023-04-06 22:14:45,573:INFO:Initializing Light Gradient Boosting Machine
2023-04-06 22:14:45,573:INFO:Total runtime is 1.0600084344546001 minutes
2023-04-06 22:14:45,574:INFO:SubProcess create_model() called ==================================
2023-04-06 22:14:45,575:INFO:Initializing create_model()
2023-04-06 22:14:45,575:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17b0cf0d0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1799aff10>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:14:45,575:INFO:Checking exceptions
2023-04-06 22:14:45,575:INFO:Importing libraries
2023-04-06 22:14:45,575:INFO:Copying training dataset
2023-04-06 22:14:45,577:INFO:Defining folds
2023-04-06 22:14:45,577:INFO:Declaring metric variables
2023-04-06 22:14:45,578:INFO:Importing untrained model
2023-04-06 22:14:45,580:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-06 22:14:45,582:INFO:Starting cross validation
2023-04-06 22:14:45,583:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:14:50,183:INFO:Calculating mean and std
2023-04-06 22:14:50,185:INFO:Creating metrics dataframe
2023-04-06 22:14:50,650:INFO:Uploading results into container
2023-04-06 22:14:50,651:INFO:Uploading model into container now
2023-04-06 22:14:50,651:INFO:_master_model_container: 14
2023-04-06 22:14:50,651:INFO:_display_container: 2
2023-04-06 22:14:50,651:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-06 22:14:50,651:INFO:create_model() successfully completed......................................
2023-04-06 22:14:50,712:INFO:SubProcess create_model() end ==================================
2023-04-06 22:14:50,712:INFO:Creating metrics dataframe
2023-04-06 22:14:50,717:INFO:Initializing CatBoost Classifier
2023-04-06 22:14:50,717:INFO:Total runtime is 1.1457399328549704 minutes
2023-04-06 22:14:50,718:INFO:SubProcess create_model() called ==================================
2023-04-06 22:14:50,718:INFO:Initializing create_model()
2023-04-06 22:14:50,719:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17b0cf0d0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1799aff10>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:14:50,719:INFO:Checking exceptions
2023-04-06 22:14:50,719:INFO:Importing libraries
2023-04-06 22:14:50,719:INFO:Copying training dataset
2023-04-06 22:14:50,720:INFO:Defining folds
2023-04-06 22:14:50,720:INFO:Declaring metric variables
2023-04-06 22:14:50,722:INFO:Importing untrained model
2023-04-06 22:14:50,723:INFO:CatBoost Classifier Imported successfully
2023-04-06 22:14:50,726:INFO:Starting cross validation
2023-04-06 22:14:50,726:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:14:55,080:INFO:Calculating mean and std
2023-04-06 22:14:55,082:INFO:Creating metrics dataframe
2023-04-06 22:14:55,522:INFO:Uploading results into container
2023-04-06 22:14:55,522:INFO:Uploading model into container now
2023-04-06 22:14:55,523:INFO:_master_model_container: 15
2023-04-06 22:14:55,523:INFO:_display_container: 2
2023-04-06 22:14:55,523:INFO:<catboost.core.CatBoostClassifier object at 0x179bd1580>
2023-04-06 22:14:55,523:INFO:create_model() successfully completed......................................
2023-04-06 22:14:55,582:INFO:SubProcess create_model() end ==================================
2023-04-06 22:14:55,582:INFO:Creating metrics dataframe
2023-04-06 22:14:55,587:INFO:Initializing Dummy Classifier
2023-04-06 22:14:55,587:INFO:Total runtime is 1.2269126017888388 minutes
2023-04-06 22:14:55,589:INFO:SubProcess create_model() called ==================================
2023-04-06 22:14:55,589:INFO:Initializing create_model()
2023-04-06 22:14:55,589:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17b0cf0d0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1799aff10>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:14:55,589:INFO:Checking exceptions
2023-04-06 22:14:55,589:INFO:Importing libraries
2023-04-06 22:14:55,589:INFO:Copying training dataset
2023-04-06 22:14:55,591:INFO:Defining folds
2023-04-06 22:14:55,591:INFO:Declaring metric variables
2023-04-06 22:14:55,592:INFO:Importing untrained model
2023-04-06 22:14:55,593:INFO:Dummy Classifier Imported successfully
2023-04-06 22:14:55,597:INFO:Starting cross validation
2023-04-06 22:14:55,597:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:14:55,628:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-06 22:14:55,630:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-06 22:14:55,632:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-06 22:14:55,635:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-06 22:14:55,647:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-06 22:14:55,648:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-06 22:14:55,652:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-06 22:14:55,658:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-06 22:14:55,659:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-06 22:14:55,661:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-06 22:15:00,002:INFO:Calculating mean and std
2023-04-06 22:15:00,003:INFO:Creating metrics dataframe
2023-04-06 22:15:00,460:INFO:Uploading results into container
2023-04-06 22:15:00,460:INFO:Uploading model into container now
2023-04-06 22:15:00,460:INFO:_master_model_container: 16
2023-04-06 22:15:00,460:INFO:_display_container: 2
2023-04-06 22:15:00,461:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-04-06 22:15:00,461:INFO:create_model() successfully completed......................................
2023-04-06 22:15:00,527:INFO:SubProcess create_model() end ==================================
2023-04-06 22:15:00,527:INFO:Creating metrics dataframe
2023-04-06 22:15:00,536:INFO:Initializing create_model()
2023-04-06 22:15:00,536:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17b0cf0d0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:15:00,536:INFO:Checking exceptions
2023-04-06 22:15:00,537:INFO:Importing libraries
2023-04-06 22:15:00,537:INFO:Copying training dataset
2023-04-06 22:15:00,538:INFO:Defining folds
2023-04-06 22:15:00,538:INFO:Declaring metric variables
2023-04-06 22:15:00,538:INFO:Importing untrained model
2023-04-06 22:15:00,538:INFO:Declaring custom model
2023-04-06 22:15:00,539:INFO:Logistic Regression Imported successfully
2023-04-06 22:15:00,539:INFO:Cross validation set to False
2023-04-06 22:15:00,539:INFO:Fitting Model
2023-04-06 22:15:00,962:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-06 22:15:00,962:INFO:create_model() successfully completed......................................
2023-04-06 22:15:01,030:INFO:_master_model_container: 16
2023-04-06 22:15:01,030:INFO:_display_container: 2
2023-04-06 22:15:01,030:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-06 22:15:01,030:INFO:compare_models() successfully completed......................................
2023-04-06 22:15:01,034:INFO:Initializing plot_model()
2023-04-06 22:15:01,034:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>, system=True)
2023-04-06 22:15:01,034:INFO:Checking exceptions
2023-04-06 22:15:01,035:INFO:Preloading libraries
2023-04-06 22:15:01,035:INFO:Copying training dataset
2023-04-06 22:15:01,036:INFO:Plot type: confusion_matrix
2023-04-06 22:15:01,063:INFO:Fitting Model
2023-04-06 22:15:01,065:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2023-04-06 22:15:01,065:INFO:Scoring test/hold-out set
2023-04-06 22:15:01,149:INFO:Visual Rendered Successfully
2023-04-06 22:15:01,227:INFO:plot_model() successfully completed......................................
2023-04-06 22:15:01,241:INFO:Initializing plot_model()
2023-04-06 22:15:01,241:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>, system=True)
2023-04-06 22:15:01,241:INFO:Checking exceptions
2023-04-06 22:15:01,261:INFO:Preloading libraries
2023-04-06 22:15:01,261:INFO:Copying training dataset
2023-04-06 22:15:01,261:INFO:Plot type: auc
2023-04-06 22:15:01,351:INFO:Fitting Model
2023-04-06 22:15:01,351:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2023-04-06 22:15:01,351:INFO:Scoring test/hold-out set
2023-04-06 22:15:01,429:INFO:Visual Rendered Successfully
2023-04-06 22:15:01,493:INFO:plot_model() successfully completed......................................
2023-04-06 22:15:01,498:INFO:Initializing plot_model()
2023-04-06 22:15:01,499:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>, system=True)
2023-04-06 22:15:01,499:INFO:Checking exceptions
2023-04-06 22:15:01,501:INFO:Preloading libraries
2023-04-06 22:15:01,501:INFO:Copying training dataset
2023-04-06 22:15:01,501:INFO:Plot type: feature
2023-04-06 22:15:01,586:INFO:Visual Rendered Successfully
2023-04-06 22:15:01,649:INFO:plot_model() successfully completed......................................
2023-04-06 22:15:01,655:INFO:Initializing evaluate_model()
2023-04-06 22:15:01,655:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-04-06 22:15:01,664:INFO:Initializing plot_model()
2023-04-06 22:15:01,665:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>, system=True)
2023-04-06 22:15:01,665:INFO:Checking exceptions
2023-04-06 22:15:01,666:INFO:Preloading libraries
2023-04-06 22:15:01,666:INFO:Copying training dataset
2023-04-06 22:15:01,666:INFO:Plot type: pipeline
2023-04-06 22:15:11,947:INFO:Initializing predict_model()
2023-04-06 22:15:11,948:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x16b22e820>)
2023-04-06 22:15:11,949:INFO:Checking exceptions
2023-04-06 22:15:11,950:INFO:Preloading libraries
2023-04-06 22:15:54,411:INFO:Initializing predict_model()
2023-04-06 22:15:54,413:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x17dd81af0>)
2023-04-06 22:15:54,414:INFO:Checking exceptions
2023-04-06 22:15:54,414:INFO:Preloading libraries
2023-04-06 22:15:54,418:INFO:Set up data.
2023-04-06 22:15:54,424:INFO:Set up index.
2023-04-06 22:16:18,242:INFO:Initializing save_model()
2023-04-06 22:16:18,244:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=my_first_pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Number of times pregnant',
                                             'Plasma glucose concentration a 2 '
                                             'hours in an oral glucose '
                                             'tolerance test',
                                             'Diastolic blood pressure (mm Hg)',
                                             'Triceps skin fold thickness (mm)',
                                             '2-Hour serum insulin (mu U/ml)',
                                             'Body...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-04-06 22:16:18,244:INFO:Adding model into prep_pipe
2023-04-06 22:16:18,248:INFO:my_first_pipeline.pkl saved in current working directory
2023-04-06 22:16:18,252:INFO:Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Number of times pregnant',
                                             'Plasma glucose concentration a 2 '
                                             'hours in an oral glucose '
                                             'tolerance test',
                                             'Diastolic blood pressure (mm Hg)',
                                             'Triceps skin fold thickness (mm)',
                                             '2-Hour serum insulin (mu U/ml)',
                                             'Body...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=123,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2023-04-06 22:16:18,252:INFO:save_model() successfully completed......................................
2023-04-06 22:16:30,532:INFO:Initializing load_model()
2023-04-06 22:16:30,537:INFO:load_model(model_name=my_first_pipeline, platform=None, authentication=None, verbose=True)
2023-04-06 22:17:05,384:INFO:Initializing plot_model()
2023-04-06 22:17:05,385:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>, system=True)
2023-04-06 22:17:05,385:INFO:Checking exceptions
2023-04-06 22:17:05,390:INFO:Preloading libraries
2023-04-06 22:17:05,391:INFO:Copying training dataset
2023-04-06 22:17:05,392:INFO:Plot type: auc
2023-04-06 22:17:05,439:INFO:Fitting Model
2023-04-06 22:17:05,439:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2023-04-06 22:17:05,439:INFO:Scoring test/hold-out set
2023-04-06 22:17:05,519:INFO:Visual Rendered Successfully
2023-04-06 22:17:05,592:INFO:plot_model() successfully completed......................................
2023-04-06 22:17:28,529:INFO:Initializing compare_models()
2023-04-06 22:17:28,530:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17b0cf0d0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x17b0cf0d0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-04-06 22:17:28,530:INFO:Checking exceptions
2023-04-06 22:17:28,537:INFO:Preparing display monitor
2023-04-06 22:17:28,553:INFO:Initializing Logistic Regression
2023-04-06 22:17:28,553:INFO:Total runtime is 2.7100245157877605e-06 minutes
2023-04-06 22:17:28,555:INFO:SubProcess create_model() called ==================================
2023-04-06 22:17:28,555:INFO:Initializing create_model()
2023-04-06 22:17:28,555:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17b0cf0d0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17dea66a0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:17:28,555:INFO:Checking exceptions
2023-04-06 22:17:28,555:INFO:Importing libraries
2023-04-06 22:17:28,555:INFO:Copying training dataset
2023-04-06 22:17:28,558:INFO:Defining folds
2023-04-06 22:17:28,558:INFO:Declaring metric variables
2023-04-06 22:17:28,560:INFO:Importing untrained model
2023-04-06 22:17:28,561:INFO:Logistic Regression Imported successfully
2023-04-06 22:17:28,564:INFO:Starting cross validation
2023-04-06 22:17:28,565:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:17:32,909:INFO:Calculating mean and std
2023-04-06 22:17:32,909:INFO:Creating metrics dataframe
2023-04-06 22:17:33,353:INFO:Uploading results into container
2023-04-06 22:17:33,354:INFO:Uploading model into container now
2023-04-06 22:17:33,354:INFO:_master_model_container: 17
2023-04-06 22:17:33,354:INFO:_display_container: 3
2023-04-06 22:17:33,354:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-06 22:17:33,354:INFO:create_model() successfully completed......................................
2023-04-06 22:17:33,420:INFO:SubProcess create_model() end ==================================
2023-04-06 22:17:33,420:INFO:Creating metrics dataframe
2023-04-06 22:17:33,424:INFO:Initializing K Neighbors Classifier
2023-04-06 22:17:33,424:INFO:Total runtime is 0.08117759625116984 minutes
2023-04-06 22:17:33,425:INFO:SubProcess create_model() called ==================================
2023-04-06 22:17:33,425:INFO:Initializing create_model()
2023-04-06 22:17:33,425:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17b0cf0d0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17dea66a0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:17:33,425:INFO:Checking exceptions
2023-04-06 22:17:33,425:INFO:Importing libraries
2023-04-06 22:17:33,425:INFO:Copying training dataset
2023-04-06 22:17:33,427:INFO:Defining folds
2023-04-06 22:17:33,427:INFO:Declaring metric variables
2023-04-06 22:17:33,428:INFO:Importing untrained model
2023-04-06 22:17:33,430:INFO:K Neighbors Classifier Imported successfully
2023-04-06 22:17:33,433:INFO:Starting cross validation
2023-04-06 22:17:33,433:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:17:37,620:INFO:Calculating mean and std
2023-04-06 22:17:37,620:INFO:Creating metrics dataframe
2023-04-06 22:17:38,066:INFO:Uploading results into container
2023-04-06 22:17:38,066:INFO:Uploading model into container now
2023-04-06 22:17:38,066:INFO:_master_model_container: 18
2023-04-06 22:17:38,066:INFO:_display_container: 3
2023-04-06 22:17:38,067:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-06 22:17:38,067:INFO:create_model() successfully completed......................................
2023-04-06 22:17:38,134:INFO:SubProcess create_model() end ==================================
2023-04-06 22:17:38,134:INFO:Creating metrics dataframe
2023-04-06 22:17:38,139:INFO:Initializing Naive Bayes
2023-04-06 22:17:38,140:INFO:Total runtime is 0.1597740133603414 minutes
2023-04-06 22:17:38,141:INFO:SubProcess create_model() called ==================================
2023-04-06 22:17:38,141:INFO:Initializing create_model()
2023-04-06 22:17:38,141:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17b0cf0d0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17dea66a0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:17:38,141:INFO:Checking exceptions
2023-04-06 22:17:38,141:INFO:Importing libraries
2023-04-06 22:17:38,141:INFO:Copying training dataset
2023-04-06 22:17:38,143:INFO:Defining folds
2023-04-06 22:17:38,143:INFO:Declaring metric variables
2023-04-06 22:17:38,145:INFO:Importing untrained model
2023-04-06 22:17:38,146:INFO:Naive Bayes Imported successfully
2023-04-06 22:17:38,149:INFO:Starting cross validation
2023-04-06 22:17:38,150:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:17:42,321:INFO:Calculating mean and std
2023-04-06 22:17:42,321:INFO:Creating metrics dataframe
2023-04-06 22:17:42,759:INFO:Uploading results into container
2023-04-06 22:17:42,759:INFO:Uploading model into container now
2023-04-06 22:17:42,760:INFO:_master_model_container: 19
2023-04-06 22:17:42,760:INFO:_display_container: 3
2023-04-06 22:17:42,760:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-04-06 22:17:42,760:INFO:create_model() successfully completed......................................
2023-04-06 22:17:42,823:INFO:SubProcess create_model() end ==================================
2023-04-06 22:17:42,823:INFO:Creating metrics dataframe
2023-04-06 22:17:42,826:INFO:Initializing Decision Tree Classifier
2023-04-06 22:17:42,826:INFO:Total runtime is 0.23788864612579347 minutes
2023-04-06 22:17:42,828:INFO:SubProcess create_model() called ==================================
2023-04-06 22:17:42,828:INFO:Initializing create_model()
2023-04-06 22:17:42,828:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17b0cf0d0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17dea66a0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:17:42,828:INFO:Checking exceptions
2023-04-06 22:17:42,828:INFO:Importing libraries
2023-04-06 22:17:42,828:INFO:Copying training dataset
2023-04-06 22:17:42,829:INFO:Defining folds
2023-04-06 22:17:42,829:INFO:Declaring metric variables
2023-04-06 22:17:42,830:INFO:Importing untrained model
2023-04-06 22:17:42,831:INFO:Decision Tree Classifier Imported successfully
2023-04-06 22:17:42,833:INFO:Starting cross validation
2023-04-06 22:17:42,834:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:17:46,962:INFO:Calculating mean and std
2023-04-06 22:17:46,964:INFO:Creating metrics dataframe
2023-04-06 22:17:47,404:INFO:Uploading results into container
2023-04-06 22:17:47,404:INFO:Uploading model into container now
2023-04-06 22:17:47,404:INFO:_master_model_container: 20
2023-04-06 22:17:47,404:INFO:_display_container: 3
2023-04-06 22:17:47,405:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-04-06 22:17:47,405:INFO:create_model() successfully completed......................................
2023-04-06 22:17:47,471:INFO:SubProcess create_model() end ==================================
2023-04-06 22:17:47,471:INFO:Creating metrics dataframe
2023-04-06 22:17:47,476:INFO:Initializing SVM - Linear Kernel
2023-04-06 22:17:47,476:INFO:Total runtime is 0.31537543137868246 minutes
2023-04-06 22:17:47,477:INFO:SubProcess create_model() called ==================================
2023-04-06 22:17:47,477:INFO:Initializing create_model()
2023-04-06 22:17:47,477:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17b0cf0d0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17dea66a0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:17:47,477:INFO:Checking exceptions
2023-04-06 22:17:47,477:INFO:Importing libraries
2023-04-06 22:17:47,478:INFO:Copying training dataset
2023-04-06 22:17:47,479:INFO:Defining folds
2023-04-06 22:17:47,479:INFO:Declaring metric variables
2023-04-06 22:17:47,480:INFO:Importing untrained model
2023-04-06 22:17:47,481:INFO:SVM - Linear Kernel Imported successfully
2023-04-06 22:17:47,484:INFO:Starting cross validation
2023-04-06 22:17:47,484:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:17:47,512:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py", line 127, in __get__
    if not self.check(obj):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1222, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-06 22:17:47,515:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py", line 127, in __get__
    if not self.check(obj):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1222, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-06 22:17:47,518:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py", line 127, in __get__
    if not self.check(obj):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1222, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-06 22:17:47,520:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py", line 127, in __get__
    if not self.check(obj):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1222, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-06 22:17:47,526:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py", line 127, in __get__
    if not self.check(obj):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1222, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-06 22:17:47,527:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-06 22:17:47,528:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py", line 127, in __get__
    if not self.check(obj):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1222, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-06 22:17:47,530:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py", line 127, in __get__
    if not self.check(obj):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1222, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-06 22:17:47,531:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py", line 127, in __get__
    if not self.check(obj):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1222, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-06 22:17:47,532:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-06 22:17:47,550:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py", line 127, in __get__
    if not self.check(obj):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1222, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-06 22:17:47,551:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py", line 127, in __get__
    if not self.check(obj):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1222, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-06 22:17:51,950:INFO:Calculating mean and std
2023-04-06 22:17:51,952:INFO:Creating metrics dataframe
2023-04-06 22:17:52,424:INFO:Uploading results into container
2023-04-06 22:17:52,424:INFO:Uploading model into container now
2023-04-06 22:17:52,424:INFO:_master_model_container: 21
2023-04-06 22:17:52,425:INFO:_display_container: 3
2023-04-06 22:17:52,425:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-04-06 22:17:52,425:INFO:create_model() successfully completed......................................
2023-04-06 22:17:52,540:INFO:SubProcess create_model() end ==================================
2023-04-06 22:17:52,540:INFO:Creating metrics dataframe
2023-04-06 22:17:52,544:INFO:Initializing Ridge Classifier
2023-04-06 22:17:52,545:INFO:Total runtime is 0.3998577316602071 minutes
2023-04-06 22:17:52,546:INFO:SubProcess create_model() called ==================================
2023-04-06 22:17:52,546:INFO:Initializing create_model()
2023-04-06 22:17:52,546:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17b0cf0d0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17dea66a0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:17:52,546:INFO:Checking exceptions
2023-04-06 22:17:52,546:INFO:Importing libraries
2023-04-06 22:17:52,546:INFO:Copying training dataset
2023-04-06 22:17:52,548:INFO:Defining folds
2023-04-06 22:17:52,548:INFO:Declaring metric variables
2023-04-06 22:17:52,550:INFO:Importing untrained model
2023-04-06 22:17:52,552:INFO:Ridge Classifier Imported successfully
2023-04-06 22:17:52,555:INFO:Starting cross validation
2023-04-06 22:17:52,555:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:17:52,581:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-06 22:17:52,583:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-06 22:17:52,588:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-06 22:17:52,594:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-06 22:17:52,603:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-06 22:17:52,605:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-06 22:17:52,606:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-06 22:17:52,608:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-06 22:17:52,619:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-06 22:17:52,629:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 301, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-06 22:17:56,867:INFO:Calculating mean and std
2023-04-06 22:17:56,868:INFO:Creating metrics dataframe
2023-04-06 22:17:57,311:INFO:Uploading results into container
2023-04-06 22:17:57,311:INFO:Uploading model into container now
2023-04-06 22:17:57,311:INFO:_master_model_container: 22
2023-04-06 22:17:57,311:INFO:_display_container: 3
2023-04-06 22:17:57,311:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=123, solver='auto', tol=0.001)
2023-04-06 22:17:57,311:INFO:create_model() successfully completed......................................
2023-04-06 22:17:57,376:INFO:SubProcess create_model() end ==================================
2023-04-06 22:17:57,376:INFO:Creating metrics dataframe
2023-04-06 22:17:57,381:INFO:Initializing Random Forest Classifier
2023-04-06 22:17:57,381:INFO:Total runtime is 0.4804710110028585 minutes
2023-04-06 22:17:57,383:INFO:SubProcess create_model() called ==================================
2023-04-06 22:17:57,383:INFO:Initializing create_model()
2023-04-06 22:17:57,383:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17b0cf0d0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17dea66a0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:17:57,383:INFO:Checking exceptions
2023-04-06 22:17:57,383:INFO:Importing libraries
2023-04-06 22:17:57,383:INFO:Copying training dataset
2023-04-06 22:17:57,384:INFO:Defining folds
2023-04-06 22:17:57,384:INFO:Declaring metric variables
2023-04-06 22:17:57,386:INFO:Importing untrained model
2023-04-06 22:17:57,387:INFO:Random Forest Classifier Imported successfully
2023-04-06 22:17:57,389:INFO:Starting cross validation
2023-04-06 22:17:57,390:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:18:02,006:INFO:Calculating mean and std
2023-04-06 22:18:02,008:INFO:Creating metrics dataframe
2023-04-06 22:18:02,476:INFO:Uploading results into container
2023-04-06 22:18:02,477:INFO:Uploading model into container now
2023-04-06 22:18:02,477:INFO:_master_model_container: 23
2023-04-06 22:18:02,477:INFO:_display_container: 3
2023-04-06 22:18:02,477:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-04-06 22:18:02,477:INFO:create_model() successfully completed......................................
2023-04-06 22:18:02,545:INFO:SubProcess create_model() end ==================================
2023-04-06 22:18:02,545:INFO:Creating metrics dataframe
2023-04-06 22:18:02,549:INFO:Initializing Quadratic Discriminant Analysis
2023-04-06 22:18:02,549:INFO:Total runtime is 0.5666030605634054 minutes
2023-04-06 22:18:02,551:INFO:SubProcess create_model() called ==================================
2023-04-06 22:18:02,551:INFO:Initializing create_model()
2023-04-06 22:18:02,551:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17b0cf0d0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17dea66a0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:18:02,551:INFO:Checking exceptions
2023-04-06 22:18:02,551:INFO:Importing libraries
2023-04-06 22:18:02,551:INFO:Copying training dataset
2023-04-06 22:18:02,553:INFO:Defining folds
2023-04-06 22:18:02,553:INFO:Declaring metric variables
2023-04-06 22:18:02,554:INFO:Importing untrained model
2023-04-06 22:18:02,555:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-06 22:18:02,558:INFO:Starting cross validation
2023-04-06 22:18:02,558:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:18:06,962:INFO:Calculating mean and std
2023-04-06 22:18:06,963:INFO:Creating metrics dataframe
2023-04-06 22:18:07,423:INFO:Uploading results into container
2023-04-06 22:18:07,423:INFO:Uploading model into container now
2023-04-06 22:18:07,424:INFO:_master_model_container: 24
2023-04-06 22:18:07,424:INFO:_display_container: 3
2023-04-06 22:18:07,424:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-06 22:18:07,424:INFO:create_model() successfully completed......................................
2023-04-06 22:18:07,491:INFO:SubProcess create_model() end ==================================
2023-04-06 22:18:07,491:INFO:Creating metrics dataframe
2023-04-06 22:18:07,497:INFO:Initializing Ada Boost Classifier
2023-04-06 22:18:07,497:INFO:Total runtime is 0.6490663448969524 minutes
2023-04-06 22:18:07,498:INFO:SubProcess create_model() called ==================================
2023-04-06 22:18:07,499:INFO:Initializing create_model()
2023-04-06 22:18:07,499:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17b0cf0d0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17dea66a0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:18:07,499:INFO:Checking exceptions
2023-04-06 22:18:07,499:INFO:Importing libraries
2023-04-06 22:18:07,499:INFO:Copying training dataset
2023-04-06 22:18:07,500:INFO:Defining folds
2023-04-06 22:18:07,500:INFO:Declaring metric variables
2023-04-06 22:18:07,501:INFO:Importing untrained model
2023-04-06 22:18:07,503:INFO:Ada Boost Classifier Imported successfully
2023-04-06 22:18:07,505:INFO:Starting cross validation
2023-04-06 22:18:07,506:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:18:12,017:INFO:Calculating mean and std
2023-04-06 22:18:12,018:INFO:Creating metrics dataframe
2023-04-06 22:18:12,514:INFO:Uploading results into container
2023-04-06 22:18:12,515:INFO:Uploading model into container now
2023-04-06 22:18:12,515:INFO:_master_model_container: 25
2023-04-06 22:18:12,515:INFO:_display_container: 3
2023-04-06 22:18:12,516:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2023-04-06 22:18:12,516:INFO:create_model() successfully completed......................................
2023-04-06 22:18:12,583:INFO:SubProcess create_model() end ==================================
2023-04-06 22:18:12,583:INFO:Creating metrics dataframe
2023-04-06 22:18:12,588:INFO:Initializing Gradient Boosting Classifier
2023-04-06 22:18:12,588:INFO:Total runtime is 0.7339139819145203 minutes
2023-04-06 22:18:12,589:INFO:SubProcess create_model() called ==================================
2023-04-06 22:18:12,590:INFO:Initializing create_model()
2023-04-06 22:18:12,590:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17b0cf0d0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17dea66a0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:18:12,590:INFO:Checking exceptions
2023-04-06 22:18:12,590:INFO:Importing libraries
2023-04-06 22:18:12,590:INFO:Copying training dataset
2023-04-06 22:18:12,591:INFO:Defining folds
2023-04-06 22:18:12,591:INFO:Declaring metric variables
2023-04-06 22:18:12,593:INFO:Importing untrained model
2023-04-06 22:18:12,595:INFO:Gradient Boosting Classifier Imported successfully
2023-04-06 22:18:12,597:INFO:Starting cross validation
2023-04-06 22:18:12,598:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:18:16,777:INFO:Calculating mean and std
2023-04-06 22:18:16,778:INFO:Creating metrics dataframe
2023-04-06 22:18:17,219:INFO:Uploading results into container
2023-04-06 22:18:17,219:INFO:Uploading model into container now
2023-04-06 22:18:17,219:INFO:_master_model_container: 26
2023-04-06 22:18:17,219:INFO:_display_container: 3
2023-04-06 22:18:17,220:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-04-06 22:18:17,220:INFO:create_model() successfully completed......................................
2023-04-06 22:18:17,282:INFO:SubProcess create_model() end ==================================
2023-04-06 22:18:17,283:INFO:Creating metrics dataframe
2023-04-06 22:18:17,287:INFO:Initializing Linear Discriminant Analysis
2023-04-06 22:18:17,287:INFO:Total runtime is 0.8122310121854146 minutes
2023-04-06 22:18:17,288:INFO:SubProcess create_model() called ==================================
2023-04-06 22:18:17,288:INFO:Initializing create_model()
2023-04-06 22:18:17,288:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17b0cf0d0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17dea66a0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:18:17,288:INFO:Checking exceptions
2023-04-06 22:18:17,289:INFO:Importing libraries
2023-04-06 22:18:17,289:INFO:Copying training dataset
2023-04-06 22:18:17,290:INFO:Defining folds
2023-04-06 22:18:17,290:INFO:Declaring metric variables
2023-04-06 22:18:17,291:INFO:Importing untrained model
2023-04-06 22:18:17,292:INFO:Linear Discriminant Analysis Imported successfully
2023-04-06 22:18:17,295:INFO:Starting cross validation
2023-04-06 22:18:17,295:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:18:21,416:INFO:Calculating mean and std
2023-04-06 22:18:21,417:INFO:Creating metrics dataframe
2023-04-06 22:18:21,867:INFO:Uploading results into container
2023-04-06 22:18:21,868:INFO:Uploading model into container now
2023-04-06 22:18:21,868:INFO:_master_model_container: 27
2023-04-06 22:18:21,868:INFO:_display_container: 3
2023-04-06 22:18:21,868:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-04-06 22:18:21,868:INFO:create_model() successfully completed......................................
2023-04-06 22:18:21,933:INFO:SubProcess create_model() end ==================================
2023-04-06 22:18:21,933:INFO:Creating metrics dataframe
2023-04-06 22:18:21,939:INFO:Initializing Extra Trees Classifier
2023-04-06 22:18:21,939:INFO:Total runtime is 0.8897617141405741 minutes
2023-04-06 22:18:21,940:INFO:SubProcess create_model() called ==================================
2023-04-06 22:18:21,940:INFO:Initializing create_model()
2023-04-06 22:18:21,940:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17b0cf0d0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17dea66a0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:18:21,940:INFO:Checking exceptions
2023-04-06 22:18:21,940:INFO:Importing libraries
2023-04-06 22:18:21,940:INFO:Copying training dataset
2023-04-06 22:18:21,942:INFO:Defining folds
2023-04-06 22:18:21,942:INFO:Declaring metric variables
2023-04-06 22:18:21,943:INFO:Importing untrained model
2023-04-06 22:18:21,944:INFO:Extra Trees Classifier Imported successfully
2023-04-06 22:18:21,946:INFO:Starting cross validation
2023-04-06 22:18:21,947:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:18:26,342:INFO:Calculating mean and std
2023-04-06 22:18:26,343:INFO:Creating metrics dataframe
2023-04-06 22:18:26,786:INFO:Uploading results into container
2023-04-06 22:18:26,786:INFO:Uploading model into container now
2023-04-06 22:18:26,786:INFO:_master_model_container: 28
2023-04-06 22:18:26,786:INFO:_display_container: 3
2023-04-06 22:18:26,787:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-04-06 22:18:26,787:INFO:create_model() successfully completed......................................
2023-04-06 22:18:26,849:INFO:SubProcess create_model() end ==================================
2023-04-06 22:18:26,850:INFO:Creating metrics dataframe
2023-04-06 22:18:26,854:INFO:Initializing Extreme Gradient Boosting
2023-04-06 22:18:26,854:INFO:Total runtime is 0.9716824293136597 minutes
2023-04-06 22:18:26,855:INFO:SubProcess create_model() called ==================================
2023-04-06 22:18:26,855:INFO:Initializing create_model()
2023-04-06 22:18:26,855:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17b0cf0d0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17dea66a0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:18:26,855:INFO:Checking exceptions
2023-04-06 22:18:26,855:INFO:Importing libraries
2023-04-06 22:18:26,855:INFO:Copying training dataset
2023-04-06 22:18:26,857:INFO:Defining folds
2023-04-06 22:18:26,857:INFO:Declaring metric variables
2023-04-06 22:18:26,858:INFO:Importing untrained model
2023-04-06 22:18:26,859:INFO:Extreme Gradient Boosting Imported successfully
2023-04-06 22:18:26,862:INFO:Starting cross validation
2023-04-06 22:18:26,862:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:18:31,152:INFO:Calculating mean and std
2023-04-06 22:18:31,153:INFO:Creating metrics dataframe
2023-04-06 22:18:31,595:INFO:Uploading results into container
2023-04-06 22:18:31,595:INFO:Uploading model into container now
2023-04-06 22:18:31,596:INFO:_master_model_container: 29
2023-04-06 22:18:31,596:INFO:_display_container: 3
2023-04-06 22:18:31,596:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-04-06 22:18:31,596:INFO:create_model() successfully completed......................................
2023-04-06 22:18:31,660:INFO:SubProcess create_model() end ==================================
2023-04-06 22:18:31,660:INFO:Creating metrics dataframe
2023-04-06 22:18:31,665:INFO:Initializing Light Gradient Boosting Machine
2023-04-06 22:18:31,665:INFO:Total runtime is 1.0518633286158243 minutes
2023-04-06 22:18:31,666:INFO:SubProcess create_model() called ==================================
2023-04-06 22:18:31,666:INFO:Initializing create_model()
2023-04-06 22:18:31,666:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17b0cf0d0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17dea66a0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:18:31,666:INFO:Checking exceptions
2023-04-06 22:18:31,666:INFO:Importing libraries
2023-04-06 22:18:31,666:INFO:Copying training dataset
2023-04-06 22:18:31,668:INFO:Defining folds
2023-04-06 22:18:31,668:INFO:Declaring metric variables
2023-04-06 22:18:31,669:INFO:Importing untrained model
2023-04-06 22:18:31,670:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-06 22:18:31,673:INFO:Starting cross validation
2023-04-06 22:18:31,673:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:18:35,885:INFO:Calculating mean and std
2023-04-06 22:18:35,886:INFO:Creating metrics dataframe
2023-04-06 22:18:36,378:INFO:Uploading results into container
2023-04-06 22:18:36,379:INFO:Uploading model into container now
2023-04-06 22:18:36,379:INFO:_master_model_container: 30
2023-04-06 22:18:36,379:INFO:_display_container: 3
2023-04-06 22:18:36,379:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-06 22:18:36,379:INFO:create_model() successfully completed......................................
2023-04-06 22:18:36,444:INFO:SubProcess create_model() end ==================================
2023-04-06 22:18:36,444:INFO:Creating metrics dataframe
2023-04-06 22:18:36,450:INFO:Initializing CatBoost Classifier
2023-04-06 22:18:36,450:INFO:Total runtime is 1.131613544623057 minutes
2023-04-06 22:18:36,451:INFO:SubProcess create_model() called ==================================
2023-04-06 22:18:36,451:INFO:Initializing create_model()
2023-04-06 22:18:36,451:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17b0cf0d0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17dea66a0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:18:36,452:INFO:Checking exceptions
2023-04-06 22:18:36,452:INFO:Importing libraries
2023-04-06 22:18:36,452:INFO:Copying training dataset
2023-04-06 22:18:36,453:INFO:Defining folds
2023-04-06 22:18:36,453:INFO:Declaring metric variables
2023-04-06 22:18:36,454:INFO:Importing untrained model
2023-04-06 22:18:36,455:INFO:CatBoost Classifier Imported successfully
2023-04-06 22:18:36,458:INFO:Starting cross validation
2023-04-06 22:18:36,459:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:18:40,691:INFO:Calculating mean and std
2023-04-06 22:18:40,691:INFO:Creating metrics dataframe
2023-04-06 22:18:41,137:INFO:Uploading results into container
2023-04-06 22:18:41,138:INFO:Uploading model into container now
2023-04-06 22:18:41,138:INFO:_master_model_container: 31
2023-04-06 22:18:41,138:INFO:_display_container: 3
2023-04-06 22:18:41,138:INFO:<catboost.core.CatBoostClassifier object at 0x179b637f0>
2023-04-06 22:18:41,138:INFO:create_model() successfully completed......................................
2023-04-06 22:18:41,201:INFO:SubProcess create_model() end ==================================
2023-04-06 22:18:41,201:INFO:Creating metrics dataframe
2023-04-06 22:18:41,206:INFO:Initializing Dummy Classifier
2023-04-06 22:18:41,206:INFO:Total runtime is 1.2108888983726502 minutes
2023-04-06 22:18:41,208:INFO:SubProcess create_model() called ==================================
2023-04-06 22:18:41,208:INFO:Initializing create_model()
2023-04-06 22:18:41,208:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17b0cf0d0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17dea66a0>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:18:41,208:INFO:Checking exceptions
2023-04-06 22:18:41,208:INFO:Importing libraries
2023-04-06 22:18:41,208:INFO:Copying training dataset
2023-04-06 22:18:41,209:INFO:Defining folds
2023-04-06 22:18:41,209:INFO:Declaring metric variables
2023-04-06 22:18:41,210:INFO:Importing untrained model
2023-04-06 22:18:41,212:INFO:Dummy Classifier Imported successfully
2023-04-06 22:18:41,214:INFO:Starting cross validation
2023-04-06 22:18:41,214:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:18:41,243:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-06 22:18:41,246:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-06 22:18:41,254:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-06 22:18:41,254:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-06 22:18:41,256:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-06 22:18:41,262:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-06 22:18:41,262:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-06 22:18:41,279:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-06 22:18:41,304:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-06 22:18:41,330:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-06 22:18:45,436:INFO:Calculating mean and std
2023-04-06 22:18:45,437:INFO:Creating metrics dataframe
2023-04-06 22:18:45,940:INFO:Uploading results into container
2023-04-06 22:18:45,941:INFO:Uploading model into container now
2023-04-06 22:18:45,941:INFO:_master_model_container: 32
2023-04-06 22:18:45,941:INFO:_display_container: 3
2023-04-06 22:18:45,941:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-04-06 22:18:45,941:INFO:create_model() successfully completed......................................
2023-04-06 22:18:46,028:INFO:SubProcess create_model() end ==================================
2023-04-06 22:18:46,028:INFO:Creating metrics dataframe
2023-04-06 22:18:46,037:INFO:Initializing create_model()
2023-04-06 22:18:46,038:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17b0cf0d0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:18:46,038:INFO:Checking exceptions
2023-04-06 22:18:46,039:INFO:Importing libraries
2023-04-06 22:18:46,039:INFO:Copying training dataset
2023-04-06 22:18:46,041:INFO:Defining folds
2023-04-06 22:18:46,041:INFO:Declaring metric variables
2023-04-06 22:18:46,041:INFO:Importing untrained model
2023-04-06 22:18:46,041:INFO:Declaring custom model
2023-04-06 22:18:46,041:INFO:Logistic Regression Imported successfully
2023-04-06 22:18:46,042:INFO:Cross validation set to False
2023-04-06 22:18:46,042:INFO:Fitting Model
2023-04-06 22:18:46,478:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-06 22:18:46,478:INFO:create_model() successfully completed......................................
2023-04-06 22:18:46,604:INFO:_master_model_container: 32
2023-04-06 22:18:46,604:INFO:_display_container: 3
2023-04-06 22:18:46,605:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-06 22:18:46,605:INFO:compare_models() successfully completed......................................
2023-04-06 22:20:27,973:INFO:Initializing get_config()
2023-04-06 22:20:27,974:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>, variable=None)
2023-04-06 22:20:44,055:INFO:Initializing get_config()
2023-04-06 22:20:44,057:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>, variable=X_train_transformed)
2023-04-06 22:20:44,099:INFO:Variable: X_train returned as      Number of times pregnant  \
323                      13.0   
448                       0.0   
84                        5.0   
529                       0.0   
329                       6.0   
..                        ...   
327                      10.0   
57                        0.0   
112                       1.0   
751                       1.0   
213                       0.0   

     Plasma glucose concentration a 2 hours in an oral glucose tolerance test  \
323                                              152.0                          
448                                              104.0                          
84                                               137.0                          
529                                              111.0                          
329                                              105.0                          
..                                                 ...                          
327                                              179.0                          
57                                               100.0                          
112                                               89.0                          
751                                              121.0                          
213                                              140.0                          

     Diastolic blood pressure (mm Hg)  Triceps skin fold thickness (mm)  \
323                              90.0                              33.0   
448                              64.0                              37.0   
84                              108.0                               0.0   
529                              65.0                               0.0   
329                              70.0                              32.0   
..                                ...                               ...   
327                              70.0                               0.0   
57                               88.0                              60.0   
112                              76.0                              34.0   
751                              78.0                              39.0   
213                              65.0                              26.0   

     2-Hour serum insulin (mu U/ml)  \
323                            29.0   
448                            64.0   
84                              0.0   
529                             0.0   
329                            68.0   
..                              ...   
327                             0.0   
57                            110.0   
112                            37.0   
751                            74.0   
213                           130.0   

     Body mass index (weight in kg/(height in m)^2)  \
323                                       26.799999   
448                                       33.599998   
84                                        48.799999   
529                                       24.600000   
329                                       30.799999   
..                                              ...   
327                                       35.099998   
57                                        46.799999   
112                                       31.200001   
751                                       39.000000   
213                                       42.599998   

     Diabetes pedigree function  Age (years)  
323                       0.731         43.0  
448                       0.510         22.0  
84                        0.227         37.0  
529                       0.660         31.0  
329                       0.122         37.0  
..                          ...          ...  
327                       0.200         37.0  
57                        0.962         31.0  
112                       0.192         23.0  
751                       0.261         28.0  
213                       0.431         24.0  

[537 rows x 8 columns]
2023-04-06 22:20:44,099:INFO:get_config() successfully completed......................................
2023-04-06 22:21:01,986:INFO:Initializing get_config()
2023-04-06 22:21:01,986:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>, variable=X_test_transformed)
2023-04-06 22:21:02,018:INFO:Variable: X_test returned as      Number of times pregnant  \
552                       6.0   
438                       1.0   
149                       2.0   
373                       2.0   
36                       11.0   
..                        ...   
85                        2.0   
7                        10.0   
298                      14.0   
341                       1.0   
472                       0.0   

     Plasma glucose concentration a 2 hours in an oral glucose tolerance test  \
552                                              114.0                          
438                                               97.0                          
149                                               90.0                          
373                                              105.0                          
36                                               138.0                          
..                                                 ...                          
85                                               110.0                          
7                                                115.0                          
298                                              100.0                          
341                                               95.0                          
472                                              119.0                          

     Diastolic blood pressure (mm Hg)  Triceps skin fold thickness (mm)  \
552                              88.0                               0.0   
438                              70.0                              15.0   
149                              70.0                              17.0   
373                              58.0                              40.0   
36                               76.0                               0.0   
..                                ...                               ...   
85                               74.0                              29.0   
7                                 0.0                               0.0   
298                              78.0                              25.0   
341                              74.0                              21.0   
472                              66.0                              27.0   

     2-Hour serum insulin (mu U/ml)  \
552                             0.0   
438                             0.0   
149                             0.0   
373                            94.0   
36                              0.0   
..                              ...   
85                            125.0   
7                               0.0   
298                           184.0   
341                            73.0   
472                             0.0   

     Body mass index (weight in kg/(height in m)^2)  \
552                                       27.799999   
438                                       18.200001   
149                                       27.299999   
373                                       34.900002   
36                                        33.200001   
..                                              ...   
85                                        32.400002   
7                                         35.299999   
298                                       36.599998   
341                                       25.900000   
472                                       38.799999   

     Diabetes pedigree function  Age (years)  
552                       0.247         66.0  
438                       0.147         21.0  
149                       0.085         22.0  
373                       0.225         25.0  
36                        0.420         35.0  
..                          ...          ...  
85                        0.698         27.0  
7                         0.134         29.0  
298                       0.412         46.0  
341                       0.673         36.0  
472                       0.259         22.0  

[231 rows x 8 columns]
2023-04-06 22:21:02,018:INFO:get_config() successfully completed......................................
2023-04-06 22:22:09,627:INFO:gpu_param set to False
2023-04-06 22:22:09,676:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 22:22:09,678:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 22:22:09,712:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 22:22:09,713:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 22:22:39,570:INFO:Initializing compare_models()
2023-04-06 22:22:39,573:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>, include=['dt', 'rf', 'et', 'gbc', 'xgboost', 'lightgbm', 'catboost'], fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>, 'include': ['dt', 'rf', 'et', 'gbc', 'xgboost', 'lightgbm', 'catboost'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-04-06 22:22:39,573:INFO:Checking exceptions
2023-04-06 22:22:39,577:INFO:Preparing display monitor
2023-04-06 22:22:39,601:INFO:Initializing Decision Tree Classifier
2023-04-06 22:22:39,601:INFO:Total runtime is 2.8649965922037762e-06 minutes
2023-04-06 22:22:39,602:INFO:SubProcess create_model() called ==================================
2023-04-06 22:22:39,603:INFO:Initializing create_model()
2023-04-06 22:22:39,603:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17dee7190>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:22:39,603:INFO:Checking exceptions
2023-04-06 22:22:39,603:INFO:Importing libraries
2023-04-06 22:22:39,603:INFO:Copying training dataset
2023-04-06 22:22:39,606:INFO:Defining folds
2023-04-06 22:22:39,606:INFO:Declaring metric variables
2023-04-06 22:22:39,608:INFO:Importing untrained model
2023-04-06 22:22:39,610:INFO:Decision Tree Classifier Imported successfully
2023-04-06 22:22:39,613:INFO:Starting cross validation
2023-04-06 22:22:39,614:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:22:43,935:INFO:Calculating mean and std
2023-04-06 22:22:43,936:INFO:Creating metrics dataframe
2023-04-06 22:22:44,379:INFO:Uploading results into container
2023-04-06 22:22:44,380:INFO:Uploading model into container now
2023-04-06 22:22:44,380:INFO:_master_model_container: 17
2023-04-06 22:22:44,380:INFO:_display_container: 4
2023-04-06 22:22:44,380:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-04-06 22:22:44,380:INFO:create_model() successfully completed......................................
2023-04-06 22:22:44,460:INFO:SubProcess create_model() end ==================================
2023-04-06 22:22:44,460:INFO:Creating metrics dataframe
2023-04-06 22:22:44,463:INFO:Initializing Random Forest Classifier
2023-04-06 22:22:44,463:INFO:Total runtime is 0.08104981581370035 minutes
2023-04-06 22:22:44,465:INFO:SubProcess create_model() called ==================================
2023-04-06 22:22:44,465:INFO:Initializing create_model()
2023-04-06 22:22:44,465:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17dee7190>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:22:44,465:INFO:Checking exceptions
2023-04-06 22:22:44,465:INFO:Importing libraries
2023-04-06 22:22:44,465:INFO:Copying training dataset
2023-04-06 22:22:44,466:INFO:Defining folds
2023-04-06 22:22:44,466:INFO:Declaring metric variables
2023-04-06 22:22:44,467:INFO:Importing untrained model
2023-04-06 22:22:44,469:INFO:Random Forest Classifier Imported successfully
2023-04-06 22:22:44,471:INFO:Starting cross validation
2023-04-06 22:22:44,471:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:22:48,697:INFO:Calculating mean and std
2023-04-06 22:22:48,698:INFO:Creating metrics dataframe
2023-04-06 22:22:49,148:INFO:Uploading results into container
2023-04-06 22:22:49,148:INFO:Uploading model into container now
2023-04-06 22:22:49,149:INFO:_master_model_container: 18
2023-04-06 22:22:49,149:INFO:_display_container: 4
2023-04-06 22:22:49,149:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-04-06 22:22:49,149:INFO:create_model() successfully completed......................................
2023-04-06 22:22:49,212:INFO:SubProcess create_model() end ==================================
2023-04-06 22:22:49,212:INFO:Creating metrics dataframe
2023-04-06 22:22:49,217:INFO:Initializing Extra Trees Classifier
2023-04-06 22:22:49,217:INFO:Total runtime is 0.16026858091354368 minutes
2023-04-06 22:22:49,218:INFO:SubProcess create_model() called ==================================
2023-04-06 22:22:49,218:INFO:Initializing create_model()
2023-04-06 22:22:49,218:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17dee7190>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:22:49,218:INFO:Checking exceptions
2023-04-06 22:22:49,218:INFO:Importing libraries
2023-04-06 22:22:49,218:INFO:Copying training dataset
2023-04-06 22:22:49,220:INFO:Defining folds
2023-04-06 22:22:49,220:INFO:Declaring metric variables
2023-04-06 22:22:49,222:INFO:Importing untrained model
2023-04-06 22:22:49,223:INFO:Extra Trees Classifier Imported successfully
2023-04-06 22:22:49,226:INFO:Starting cross validation
2023-04-06 22:22:49,226:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:22:53,484:INFO:Calculating mean and std
2023-04-06 22:22:53,484:INFO:Creating metrics dataframe
2023-04-06 22:22:53,928:INFO:Uploading results into container
2023-04-06 22:22:53,928:INFO:Uploading model into container now
2023-04-06 22:22:53,928:INFO:_master_model_container: 19
2023-04-06 22:22:53,928:INFO:_display_container: 4
2023-04-06 22:22:53,929:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-04-06 22:22:53,929:INFO:create_model() successfully completed......................................
2023-04-06 22:22:53,991:INFO:SubProcess create_model() end ==================================
2023-04-06 22:22:53,992:INFO:Creating metrics dataframe
2023-04-06 22:22:53,996:INFO:Initializing Gradient Boosting Classifier
2023-04-06 22:22:53,996:INFO:Total runtime is 0.23992819786071776 minutes
2023-04-06 22:22:53,997:INFO:SubProcess create_model() called ==================================
2023-04-06 22:22:53,998:INFO:Initializing create_model()
2023-04-06 22:22:53,998:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17dee7190>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:22:53,998:INFO:Checking exceptions
2023-04-06 22:22:53,998:INFO:Importing libraries
2023-04-06 22:22:53,998:INFO:Copying training dataset
2023-04-06 22:22:53,999:INFO:Defining folds
2023-04-06 22:22:53,999:INFO:Declaring metric variables
2023-04-06 22:22:54,001:INFO:Importing untrained model
2023-04-06 22:22:54,002:INFO:Gradient Boosting Classifier Imported successfully
2023-04-06 22:22:54,005:INFO:Starting cross validation
2023-04-06 22:22:54,005:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:22:58,176:INFO:Calculating mean and std
2023-04-06 22:22:58,176:INFO:Creating metrics dataframe
2023-04-06 22:22:58,617:INFO:Uploading results into container
2023-04-06 22:22:58,617:INFO:Uploading model into container now
2023-04-06 22:22:58,617:INFO:_master_model_container: 20
2023-04-06 22:22:58,617:INFO:_display_container: 4
2023-04-06 22:22:58,618:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-04-06 22:22:58,618:INFO:create_model() successfully completed......................................
2023-04-06 22:22:58,680:INFO:SubProcess create_model() end ==================================
2023-04-06 22:22:58,680:INFO:Creating metrics dataframe
2023-04-06 22:22:58,684:INFO:Initializing Extreme Gradient Boosting
2023-04-06 22:22:58,684:INFO:Total runtime is 0.31805615027745565 minutes
2023-04-06 22:22:58,685:INFO:SubProcess create_model() called ==================================
2023-04-06 22:22:58,685:INFO:Initializing create_model()
2023-04-06 22:22:58,685:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17dee7190>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:22:58,685:INFO:Checking exceptions
2023-04-06 22:22:58,685:INFO:Importing libraries
2023-04-06 22:22:58,685:INFO:Copying training dataset
2023-04-06 22:22:58,687:INFO:Defining folds
2023-04-06 22:22:58,687:INFO:Declaring metric variables
2023-04-06 22:22:58,688:INFO:Importing untrained model
2023-04-06 22:22:58,690:INFO:Extreme Gradient Boosting Imported successfully
2023-04-06 22:22:58,692:INFO:Starting cross validation
2023-04-06 22:22:58,693:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:23:02,935:INFO:Calculating mean and std
2023-04-06 22:23:02,935:INFO:Creating metrics dataframe
2023-04-06 22:23:03,384:INFO:Uploading results into container
2023-04-06 22:23:03,384:INFO:Uploading model into container now
2023-04-06 22:23:03,384:INFO:_master_model_container: 21
2023-04-06 22:23:03,384:INFO:_display_container: 4
2023-04-06 22:23:03,385:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-04-06 22:23:03,385:INFO:create_model() successfully completed......................................
2023-04-06 22:23:03,447:INFO:SubProcess create_model() end ==================================
2023-04-06 22:23:03,447:INFO:Creating metrics dataframe
2023-04-06 22:23:03,451:INFO:Initializing Light Gradient Boosting Machine
2023-04-06 22:23:03,451:INFO:Total runtime is 0.3975124994913737 minutes
2023-04-06 22:23:03,453:INFO:SubProcess create_model() called ==================================
2023-04-06 22:23:03,453:INFO:Initializing create_model()
2023-04-06 22:23:03,453:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17dee7190>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:23:03,453:INFO:Checking exceptions
2023-04-06 22:23:03,453:INFO:Importing libraries
2023-04-06 22:23:03,453:INFO:Copying training dataset
2023-04-06 22:23:03,454:INFO:Defining folds
2023-04-06 22:23:03,454:INFO:Declaring metric variables
2023-04-06 22:23:03,456:INFO:Importing untrained model
2023-04-06 22:23:03,457:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-06 22:23:03,460:INFO:Starting cross validation
2023-04-06 22:23:03,460:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:23:07,553:INFO:Calculating mean and std
2023-04-06 22:23:07,554:INFO:Creating metrics dataframe
2023-04-06 22:23:07,996:INFO:Uploading results into container
2023-04-06 22:23:07,997:INFO:Uploading model into container now
2023-04-06 22:23:07,997:INFO:_master_model_container: 22
2023-04-06 22:23:07,997:INFO:_display_container: 4
2023-04-06 22:23:07,998:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-06 22:23:07,998:INFO:create_model() successfully completed......................................
2023-04-06 22:23:08,061:INFO:SubProcess create_model() end ==================================
2023-04-06 22:23:08,061:INFO:Creating metrics dataframe
2023-04-06 22:23:08,065:INFO:Initializing CatBoost Classifier
2023-04-06 22:23:08,065:INFO:Total runtime is 0.4744142492612203 minutes
2023-04-06 22:23:08,067:INFO:SubProcess create_model() called ==================================
2023-04-06 22:23:08,067:INFO:Initializing create_model()
2023-04-06 22:23:08,067:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17dee7190>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:23:08,067:INFO:Checking exceptions
2023-04-06 22:23:08,067:INFO:Importing libraries
2023-04-06 22:23:08,067:INFO:Copying training dataset
2023-04-06 22:23:08,068:INFO:Defining folds
2023-04-06 22:23:08,068:INFO:Declaring metric variables
2023-04-06 22:23:08,070:INFO:Importing untrained model
2023-04-06 22:23:08,071:INFO:CatBoost Classifier Imported successfully
2023-04-06 22:23:08,073:INFO:Starting cross validation
2023-04-06 22:23:08,074:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:23:12,156:INFO:Calculating mean and std
2023-04-06 22:23:12,157:INFO:Creating metrics dataframe
2023-04-06 22:23:12,601:INFO:Uploading results into container
2023-04-06 22:23:12,602:INFO:Uploading model into container now
2023-04-06 22:23:12,602:INFO:_master_model_container: 23
2023-04-06 22:23:12,602:INFO:_display_container: 4
2023-04-06 22:23:12,602:INFO:<catboost.core.CatBoostClassifier object at 0x17dea66d0>
2023-04-06 22:23:12,602:INFO:create_model() successfully completed......................................
2023-04-06 22:23:12,664:INFO:SubProcess create_model() end ==================================
2023-04-06 22:23:12,664:INFO:Creating metrics dataframe
2023-04-06 22:23:12,671:INFO:Initializing create_model()
2023-04-06 22:23:12,671:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:23:12,672:INFO:Checking exceptions
2023-04-06 22:23:12,672:INFO:Importing libraries
2023-04-06 22:23:12,672:INFO:Copying training dataset
2023-04-06 22:23:12,673:INFO:Defining folds
2023-04-06 22:23:12,673:INFO:Declaring metric variables
2023-04-06 22:23:12,674:INFO:Importing untrained model
2023-04-06 22:23:12,674:INFO:Declaring custom model
2023-04-06 22:23:12,674:INFO:Random Forest Classifier Imported successfully
2023-04-06 22:23:12,674:INFO:Cross validation set to False
2023-04-06 22:23:12,674:INFO:Fitting Model
2023-04-06 22:23:13,148:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-04-06 22:23:13,148:INFO:create_model() successfully completed......................................
2023-04-06 22:23:13,219:INFO:_master_model_container: 23
2023-04-06 22:23:13,219:INFO:_display_container: 4
2023-04-06 22:23:13,219:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-04-06 22:23:13,219:INFO:compare_models() successfully completed......................................
2023-04-06 22:24:05,519:INFO:Initializing interpret_model()
2023-04-06 22:24:05,521:INFO:interpret_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>)
2023-04-06 22:24:05,522:INFO:Checking exceptions
2023-04-06 22:24:05,522:INFO:Soft dependency imported: shap: 0.41.0
2023-04-06 22:24:06,119:INFO:plot type: summary
2023-04-06 22:24:06,119:INFO:Creating TreeExplainer
2023-04-06 22:24:06,121:INFO:Compiling shap values
2023-04-06 22:24:06,359:WARNING:No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored

2023-04-06 22:24:06,460:INFO:Visual Rendered Successfully
2023-04-06 22:24:06,460:INFO:interpret_model() successfully completed......................................
2023-04-06 22:25:03,915:INFO:Initializing compare_models()
2023-04-06 22:25:03,916:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>, include=['dt', 'rf', 'et', 'gbc', 'xgboost', 'lightgbm', 'catboost'], fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>, 'include': ['dt', 'rf', 'et', 'gbc', 'xgboost', 'lightgbm', 'catboost'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-04-06 22:25:03,917:INFO:Checking exceptions
2023-04-06 22:25:03,922:INFO:Preparing display monitor
2023-04-06 22:25:03,937:INFO:Initializing Decision Tree Classifier
2023-04-06 22:25:03,937:INFO:Total runtime is 2.284844716389974e-06 minutes
2023-04-06 22:25:03,939:INFO:SubProcess create_model() called ==================================
2023-04-06 22:25:03,939:INFO:Initializing create_model()
2023-04-06 22:25:03,939:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17df34100>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:25:03,940:INFO:Checking exceptions
2023-04-06 22:25:03,940:INFO:Importing libraries
2023-04-06 22:25:03,940:INFO:Copying training dataset
2023-04-06 22:25:03,942:INFO:Defining folds
2023-04-06 22:25:03,942:INFO:Declaring metric variables
2023-04-06 22:25:03,943:INFO:Importing untrained model
2023-04-06 22:25:03,945:INFO:Decision Tree Classifier Imported successfully
2023-04-06 22:25:03,948:INFO:Starting cross validation
2023-04-06 22:25:03,949:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:25:07,955:INFO:Calculating mean and std
2023-04-06 22:25:07,955:INFO:Creating metrics dataframe
2023-04-06 22:25:08,387:INFO:Uploading results into container
2023-04-06 22:25:08,388:INFO:Uploading model into container now
2023-04-06 22:25:08,388:INFO:_master_model_container: 24
2023-04-06 22:25:08,388:INFO:_display_container: 5
2023-04-06 22:25:08,388:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-04-06 22:25:08,388:INFO:create_model() successfully completed......................................
2023-04-06 22:25:08,471:INFO:SubProcess create_model() end ==================================
2023-04-06 22:25:08,471:INFO:Creating metrics dataframe
2023-04-06 22:25:08,474:INFO:Initializing Random Forest Classifier
2023-04-06 22:25:08,474:INFO:Total runtime is 0.07561131715774536 minutes
2023-04-06 22:25:08,475:INFO:SubProcess create_model() called ==================================
2023-04-06 22:25:08,475:INFO:Initializing create_model()
2023-04-06 22:25:08,475:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17df34100>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:25:08,475:INFO:Checking exceptions
2023-04-06 22:25:08,475:INFO:Importing libraries
2023-04-06 22:25:08,476:INFO:Copying training dataset
2023-04-06 22:25:08,477:INFO:Defining folds
2023-04-06 22:25:08,477:INFO:Declaring metric variables
2023-04-06 22:25:08,478:INFO:Importing untrained model
2023-04-06 22:25:08,479:INFO:Random Forest Classifier Imported successfully
2023-04-06 22:25:08,482:INFO:Starting cross validation
2023-04-06 22:25:08,482:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:25:12,749:INFO:Calculating mean and std
2023-04-06 22:25:12,750:INFO:Creating metrics dataframe
2023-04-06 22:25:13,205:INFO:Uploading results into container
2023-04-06 22:25:13,205:INFO:Uploading model into container now
2023-04-06 22:25:13,206:INFO:_master_model_container: 25
2023-04-06 22:25:13,206:INFO:_display_container: 5
2023-04-06 22:25:13,206:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-04-06 22:25:13,206:INFO:create_model() successfully completed......................................
2023-04-06 22:25:13,291:INFO:SubProcess create_model() end ==================================
2023-04-06 22:25:13,291:INFO:Creating metrics dataframe
2023-04-06 22:25:13,294:INFO:Initializing Extra Trees Classifier
2023-04-06 22:25:13,294:INFO:Total runtime is 0.15594891707102457 minutes
2023-04-06 22:25:13,295:INFO:SubProcess create_model() called ==================================
2023-04-06 22:25:13,296:INFO:Initializing create_model()
2023-04-06 22:25:13,296:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17df34100>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:25:13,296:INFO:Checking exceptions
2023-04-06 22:25:13,296:INFO:Importing libraries
2023-04-06 22:25:13,296:INFO:Copying training dataset
2023-04-06 22:25:13,297:INFO:Defining folds
2023-04-06 22:25:13,297:INFO:Declaring metric variables
2023-04-06 22:25:13,298:INFO:Importing untrained model
2023-04-06 22:25:13,299:INFO:Extra Trees Classifier Imported successfully
2023-04-06 22:25:13,302:INFO:Starting cross validation
2023-04-06 22:25:13,303:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:25:17,790:INFO:Calculating mean and std
2023-04-06 22:25:17,790:INFO:Creating metrics dataframe
2023-04-06 22:25:18,251:INFO:Uploading results into container
2023-04-06 22:25:18,252:INFO:Uploading model into container now
2023-04-06 22:25:18,252:INFO:_master_model_container: 26
2023-04-06 22:25:18,252:INFO:_display_container: 5
2023-04-06 22:25:18,252:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-04-06 22:25:18,252:INFO:create_model() successfully completed......................................
2023-04-06 22:25:18,338:INFO:SubProcess create_model() end ==================================
2023-04-06 22:25:18,338:INFO:Creating metrics dataframe
2023-04-06 22:25:18,342:INFO:Initializing Gradient Boosting Classifier
2023-04-06 22:25:18,342:INFO:Total runtime is 0.24007216691970823 minutes
2023-04-06 22:25:18,343:INFO:SubProcess create_model() called ==================================
2023-04-06 22:25:18,343:INFO:Initializing create_model()
2023-04-06 22:25:18,343:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17df34100>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:25:18,343:INFO:Checking exceptions
2023-04-06 22:25:18,343:INFO:Importing libraries
2023-04-06 22:25:18,343:INFO:Copying training dataset
2023-04-06 22:25:18,345:INFO:Defining folds
2023-04-06 22:25:18,345:INFO:Declaring metric variables
2023-04-06 22:25:18,346:INFO:Importing untrained model
2023-04-06 22:25:18,347:INFO:Gradient Boosting Classifier Imported successfully
2023-04-06 22:25:18,349:INFO:Starting cross validation
2023-04-06 22:25:18,350:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:25:22,776:INFO:Calculating mean and std
2023-04-06 22:25:22,777:INFO:Creating metrics dataframe
2023-04-06 22:25:23,212:INFO:Uploading results into container
2023-04-06 22:25:23,212:INFO:Uploading model into container now
2023-04-06 22:25:23,213:INFO:_master_model_container: 27
2023-04-06 22:25:23,213:INFO:_display_container: 5
2023-04-06 22:25:23,213:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-04-06 22:25:23,213:INFO:create_model() successfully completed......................................
2023-04-06 22:25:23,294:INFO:SubProcess create_model() end ==================================
2023-04-06 22:25:23,294:INFO:Creating metrics dataframe
2023-04-06 22:25:23,298:INFO:Initializing Extreme Gradient Boosting
2023-04-06 22:25:23,298:INFO:Total runtime is 0.3226767818133036 minutes
2023-04-06 22:25:23,299:INFO:SubProcess create_model() called ==================================
2023-04-06 22:25:23,299:INFO:Initializing create_model()
2023-04-06 22:25:23,299:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17df34100>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:25:23,300:INFO:Checking exceptions
2023-04-06 22:25:23,300:INFO:Importing libraries
2023-04-06 22:25:23,300:INFO:Copying training dataset
2023-04-06 22:25:23,301:INFO:Defining folds
2023-04-06 22:25:23,301:INFO:Declaring metric variables
2023-04-06 22:25:23,302:INFO:Importing untrained model
2023-04-06 22:25:23,304:INFO:Extreme Gradient Boosting Imported successfully
2023-04-06 22:25:23,306:INFO:Starting cross validation
2023-04-06 22:25:23,307:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:25:27,545:INFO:Calculating mean and std
2023-04-06 22:25:27,547:INFO:Creating metrics dataframe
2023-04-06 22:25:27,991:INFO:Uploading results into container
2023-04-06 22:25:27,991:INFO:Uploading model into container now
2023-04-06 22:25:27,991:INFO:_master_model_container: 28
2023-04-06 22:25:27,992:INFO:_display_container: 5
2023-04-06 22:25:27,992:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-04-06 22:25:27,992:INFO:create_model() successfully completed......................................
2023-04-06 22:25:28,075:INFO:SubProcess create_model() end ==================================
2023-04-06 22:25:28,075:INFO:Creating metrics dataframe
2023-04-06 22:25:28,079:INFO:Initializing Light Gradient Boosting Machine
2023-04-06 22:25:28,079:INFO:Total runtime is 0.40235875050226844 minutes
2023-04-06 22:25:28,080:INFO:SubProcess create_model() called ==================================
2023-04-06 22:25:28,080:INFO:Initializing create_model()
2023-04-06 22:25:28,080:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17df34100>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:25:28,080:INFO:Checking exceptions
2023-04-06 22:25:28,080:INFO:Importing libraries
2023-04-06 22:25:28,080:INFO:Copying training dataset
2023-04-06 22:25:28,082:INFO:Defining folds
2023-04-06 22:25:28,082:INFO:Declaring metric variables
2023-04-06 22:25:28,083:INFO:Importing untrained model
2023-04-06 22:25:28,084:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-06 22:25:28,087:INFO:Starting cross validation
2023-04-06 22:25:28,087:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:25:32,411:INFO:Calculating mean and std
2023-04-06 22:25:32,411:INFO:Creating metrics dataframe
2023-04-06 22:25:32,857:INFO:Uploading results into container
2023-04-06 22:25:32,858:INFO:Uploading model into container now
2023-04-06 22:25:32,858:INFO:_master_model_container: 29
2023-04-06 22:25:32,858:INFO:_display_container: 5
2023-04-06 22:25:32,858:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-06 22:25:32,858:INFO:create_model() successfully completed......................................
2023-04-06 22:25:32,944:INFO:SubProcess create_model() end ==================================
2023-04-06 22:25:32,945:INFO:Creating metrics dataframe
2023-04-06 22:25:32,949:INFO:Initializing CatBoost Classifier
2023-04-06 22:25:32,949:INFO:Total runtime is 0.48352201382319127 minutes
2023-04-06 22:25:32,950:INFO:SubProcess create_model() called ==================================
2023-04-06 22:25:32,950:INFO:Initializing create_model()
2023-04-06 22:25:32,950:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17df34100>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:25:32,950:INFO:Checking exceptions
2023-04-06 22:25:32,950:INFO:Importing libraries
2023-04-06 22:25:32,950:INFO:Copying training dataset
2023-04-06 22:25:32,952:INFO:Defining folds
2023-04-06 22:25:32,952:INFO:Declaring metric variables
2023-04-06 22:25:32,953:INFO:Importing untrained model
2023-04-06 22:25:32,954:INFO:CatBoost Classifier Imported successfully
2023-04-06 22:25:32,957:INFO:Starting cross validation
2023-04-06 22:25:32,957:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 22:25:37,233:INFO:Calculating mean and std
2023-04-06 22:25:37,234:INFO:Creating metrics dataframe
2023-04-06 22:25:37,685:INFO:Uploading results into container
2023-04-06 22:25:37,686:INFO:Uploading model into container now
2023-04-06 22:25:37,686:INFO:_master_model_container: 30
2023-04-06 22:25:37,686:INFO:_display_container: 5
2023-04-06 22:25:37,686:INFO:<catboost.core.CatBoostClassifier object at 0x29d944070>
2023-04-06 22:25:37,686:INFO:create_model() successfully completed......................................
2023-04-06 22:25:37,776:INFO:SubProcess create_model() end ==================================
2023-04-06 22:25:37,776:INFO:Creating metrics dataframe
2023-04-06 22:25:37,786:INFO:Initializing create_model()
2023-04-06 22:25:37,786:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:25:37,786:INFO:Checking exceptions
2023-04-06 22:25:37,787:INFO:Importing libraries
2023-04-06 22:25:37,787:INFO:Copying training dataset
2023-04-06 22:25:37,789:INFO:Defining folds
2023-04-06 22:25:37,789:INFO:Declaring metric variables
2023-04-06 22:25:37,789:INFO:Importing untrained model
2023-04-06 22:25:37,789:INFO:Declaring custom model
2023-04-06 22:25:37,790:INFO:Random Forest Classifier Imported successfully
2023-04-06 22:25:37,790:INFO:Cross validation set to False
2023-04-06 22:25:37,790:INFO:Fitting Model
2023-04-06 22:25:38,283:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-04-06 22:25:38,283:INFO:create_model() successfully completed......................................
2023-04-06 22:25:38,367:INFO:Initializing create_model()
2023-04-06 22:25:38,367:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>, estimator=<catboost.core.CatBoostClassifier object at 0x29d944070>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:25:38,367:INFO:Checking exceptions
2023-04-06 22:25:38,368:INFO:Importing libraries
2023-04-06 22:25:38,368:INFO:Copying training dataset
2023-04-06 22:25:38,369:INFO:Defining folds
2023-04-06 22:25:38,369:INFO:Declaring metric variables
2023-04-06 22:25:38,369:INFO:Importing untrained model
2023-04-06 22:25:38,369:INFO:Declaring custom model
2023-04-06 22:25:38,370:INFO:CatBoost Classifier Imported successfully
2023-04-06 22:25:38,370:INFO:Cross validation set to False
2023-04-06 22:25:38,370:INFO:Fitting Model
2023-04-06 22:25:39,592:INFO:<catboost.core.CatBoostClassifier object at 0x29d83ca30>
2023-04-06 22:25:39,592:INFO:create_model() successfully completed......................................
2023-04-06 22:25:39,675:INFO:Initializing create_model()
2023-04-06 22:25:39,675:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 22:25:39,675:INFO:Checking exceptions
2023-04-06 22:25:39,676:INFO:Importing libraries
2023-04-06 22:25:39,676:INFO:Copying training dataset
2023-04-06 22:25:39,677:INFO:Defining folds
2023-04-06 22:25:39,677:INFO:Declaring metric variables
2023-04-06 22:25:39,677:INFO:Importing untrained model
2023-04-06 22:25:39,677:INFO:Declaring custom model
2023-04-06 22:25:39,678:INFO:Gradient Boosting Classifier Imported successfully
2023-04-06 22:25:39,678:INFO:Cross validation set to False
2023-04-06 22:25:39,678:INFO:Fitting Model
2023-04-06 22:25:40,106:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-04-06 22:25:40,106:INFO:create_model() successfully completed......................................
2023-04-06 22:25:40,195:INFO:_master_model_container: 30
2023-04-06 22:25:40,195:INFO:_display_container: 5
2023-04-06 22:25:40,196:INFO:[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), <catboost.core.CatBoostClassifier object at 0x29d83ca30>, GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)]
2023-04-06 22:25:40,196:INFO:compare_models() successfully completed......................................
2023-04-06 22:25:53,866:INFO:Initializing interpret_model()
2023-04-06 22:25:53,868:INFO:interpret_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>)
2023-04-06 22:25:53,868:INFO:Checking exceptions
2023-04-06 22:25:53,869:INFO:Soft dependency imported: shap: 0.41.0
2023-04-06 22:25:53,890:INFO:plot type: summary
2023-04-06 22:25:53,890:INFO:Creating TreeExplainer
2023-04-06 22:25:53,893:INFO:Compiling shap values
2023-04-06 22:25:54,158:WARNING:No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored

2023-04-06 22:25:54,261:INFO:Visual Rendered Successfully
2023-04-06 22:25:54,261:INFO:interpret_model() successfully completed......................................
2023-04-06 22:26:02,121:INFO:Initializing interpret_model()
2023-04-06 22:26:02,122:INFO:interpret_model(estimator=<catboost.core.CatBoostClassifier object at 0x29d83ca30>, use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>)
2023-04-06 22:26:02,123:INFO:Checking exceptions
2023-04-06 22:26:02,123:INFO:Soft dependency imported: shap: 0.41.0
2023-04-06 22:26:02,147:INFO:plot type: summary
2023-04-06 22:26:02,147:INFO:Creating TreeExplainer
2023-04-06 22:26:02,280:INFO:Compiling shap values
2023-04-06 22:26:02,565:WARNING:No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored

2023-04-06 22:26:02,663:INFO:Visual Rendered Successfully
2023-04-06 22:26:02,663:INFO:interpret_model() successfully completed......................................
2023-04-06 22:26:16,962:INFO:Initializing interpret_model()
2023-04-06 22:26:16,964:INFO:interpret_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x1799b8250>)
2023-04-06 22:26:16,964:INFO:Checking exceptions
2023-04-06 22:26:16,964:INFO:Soft dependency imported: shap: 0.41.0
