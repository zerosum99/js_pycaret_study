2023-04-06 16:33:58,368:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-06 16:33:58,369:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-06 16:33:58,369:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-06 16:33:58,369:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-06 16:33:59,004:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-06 16:34:07,810:INFO:PyCaret RegressionExperiment
2023-04-06 16:34:07,810:INFO:Logging name: reg-default-name
2023-04-06 16:34:07,810:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-06 16:34:07,810:INFO:version 3.0.0
2023-04-06 16:34:07,810:INFO:Initializing setup()
2023-04-06 16:34:07,810:INFO:self.USI: f987
2023-04-06 16:34:07,810:INFO:self._variable_keys: {'pipeline', 'y_test', 'memory', 'y', 'X', 'target_param', 'gpu_n_jobs_param', 'X_train', 'fold_shuffle_param', 'fold_generator', 'exp_id', 'X_test', '_available_plots', 'n_jobs_param', 'seed', 'fold_groups_param', 'data', 'exp_name_log', 'html_param', 'idx', 'logging_param', '_ml_usecase', 'USI', 'log_plots_param', 'y_train', 'gpu_param', 'transform_target_param'}
2023-04-06 16:34:07,810:INFO:Checking environment
2023-04-06 16:34:07,810:INFO:python_version: 3.9.15
2023-04-06 16:34:07,810:INFO:python_build: ('main', 'Nov 24 2022 08:28:41')
2023-04-06 16:34:07,810:INFO:machine: arm64
2023-04-06 16:34:07,810:INFO:platform: macOS-13.2-arm64-arm-64bit
2023-04-06 16:34:07,810:INFO:Memory: svmem(total=17179869184, available=5218369536, percent=69.6, used=7342784512, free=103514112, active=5127684096, inactive=5085642752, wired=2215100416)
2023-04-06 16:34:07,810:INFO:Physical Core: 10
2023-04-06 16:34:07,810:INFO:Logical Core: 10
2023-04-06 16:34:07,810:INFO:Checking libraries
2023-04-06 16:34:07,810:INFO:System:
2023-04-06 16:34:07,810:INFO:    python: 3.9.15 (main, Nov 24 2022, 08:28:41)  [Clang 14.0.6 ]
2023-04-06 16:34:07,810:INFO:executable: /Users/a06411/opt/anaconda3/bin/python
2023-04-06 16:34:07,810:INFO:   machine: macOS-13.2-arm64-arm-64bit
2023-04-06 16:34:07,810:INFO:PyCaret required dependencies:
2023-04-06 16:34:07,811:INFO:                 pip: 22.3.1
2023-04-06 16:34:07,811:INFO:          setuptools: 65.5.0
2023-04-06 16:34:07,811:INFO:             pycaret: 3.0.0
2023-04-06 16:34:07,811:INFO:             IPython: 8.7.0
2023-04-06 16:34:07,811:INFO:          ipywidgets: 7.6.5
2023-04-06 16:34:07,811:INFO:                tqdm: 4.64.1
2023-04-06 16:34:07,811:INFO:               numpy: 1.21.5
2023-04-06 16:34:07,811:INFO:              pandas: 1.4.4
2023-04-06 16:34:07,811:INFO:              jinja2: 2.11.3
2023-04-06 16:34:07,811:INFO:               scipy: 1.9.3
2023-04-06 16:34:07,811:INFO:              joblib: 1.1.1
2023-04-06 16:34:07,811:INFO:             sklearn: 1.1.3
2023-04-06 16:34:07,811:INFO:                pyod: 1.0.9
2023-04-06 16:34:07,811:INFO:            imblearn: 0.10.1
2023-04-06 16:34:07,811:INFO:   category_encoders: 2.6.0
2023-04-06 16:34:07,811:INFO:            lightgbm: 3.3.5
2023-04-06 16:34:07,811:INFO:               numba: 0.56.4
2023-04-06 16:34:07,811:INFO:            requests: 2.28.1
2023-04-06 16:34:07,811:INFO:          matplotlib: 3.6.2
2023-04-06 16:34:07,811:INFO:          scikitplot: 0.3.7
2023-04-06 16:34:07,811:INFO:         yellowbrick: 1.5
2023-04-06 16:34:07,811:INFO:              plotly: 5.9.0
2023-04-06 16:34:07,811:INFO:             kaleido: Not installed
2023-04-06 16:34:07,811:INFO:         statsmodels: 0.13.2
2023-04-06 16:34:07,811:INFO:              sktime: 0.16.1
2023-04-06 16:34:07,811:INFO:               tbats: Not installed
2023-04-06 16:34:07,811:INFO:            pmdarima: 2.0.3
2023-04-06 16:34:07,811:INFO:              psutil: 5.9.0
2023-04-06 16:34:07,811:INFO:PyCaret optional dependencies:
2023-04-06 16:34:07,813:INFO:                shap: 0.41.0
2023-04-06 16:34:07,813:INFO:           interpret: Not installed
2023-04-06 16:34:07,813:INFO:                umap: 0.5.3
2023-04-06 16:34:07,813:INFO:    pandas_profiling: Not installed
2023-04-06 16:34:07,813:INFO:  explainerdashboard: 0.4.2.1
2023-04-06 16:34:07,813:INFO:             autoviz: Not installed
2023-04-06 16:34:07,813:INFO:           fairlearn: Not installed
2023-04-06 16:34:07,813:INFO:             xgboost: 1.7.2
2023-04-06 16:34:07,813:INFO:            catboost: 1.1.1
2023-04-06 16:34:07,813:INFO:              kmodes: Not installed
2023-04-06 16:34:07,813:INFO:             mlxtend: Not installed
2023-04-06 16:34:07,813:INFO:       statsforecast: Not installed
2023-04-06 16:34:07,813:INFO:        tune_sklearn: Not installed
2023-04-06 16:34:07,813:INFO:                 ray: Not installed
2023-04-06 16:34:07,813:INFO:            hyperopt: 0.2.7
2023-04-06 16:34:07,813:INFO:              optuna: 3.1.0
2023-04-06 16:34:07,813:INFO:               skopt: 0.9.0
2023-04-06 16:34:07,813:INFO:              mlflow: 2.2.2
2023-04-06 16:34:07,813:INFO:              gradio: Not installed
2023-04-06 16:34:07,813:INFO:             fastapi: Not installed
2023-04-06 16:34:07,813:INFO:             uvicorn: Not installed
2023-04-06 16:34:07,813:INFO:              m2cgen: Not installed
2023-04-06 16:34:07,813:INFO:           evidently: Not installed
2023-04-06 16:34:07,813:INFO:               fugue: Not installed
2023-04-06 16:34:07,813:INFO:           streamlit: Not installed
2023-04-06 16:34:07,813:INFO:             prophet: Not installed
2023-04-06 16:34:07,813:INFO:None
2023-04-06 16:34:07,813:INFO:Set up data.
2023-04-06 16:34:07,817:INFO:Set up train/test split.
2023-04-06 16:34:07,819:INFO:Set up index.
2023-04-06 16:34:07,819:INFO:Set up folding strategy.
2023-04-06 16:34:07,819:INFO:Assigning column types.
2023-04-06 16:34:07,820:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-06 16:34:07,820:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-06 16:34:07,822:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-06 16:34:07,823:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 16:34:07,847:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:34:07,865:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 16:34:07,865:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:34:08,005:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:34:08,041:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,043:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,045:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,069:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,087:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,088:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:34:08,089:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:34:08,089:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-06 16:34:08,091:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,093:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,117:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,136:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,136:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:34:08,137:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:34:08,139:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,141:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,165:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,184:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,184:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:34:08,186:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:34:08,186:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-06 16:34:08,190:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,213:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,233:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,233:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:34:08,234:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:34:08,238:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,262:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,280:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,281:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:34:08,282:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:34:08,282:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-06 16:34:08,310:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,329:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,329:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:34:08,330:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:34:08,358:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,377:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,377:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:34:08,378:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:34:08,378:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-06 16:34:08,406:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,424:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:34:08,425:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:34:08,454:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:34:08,472:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:34:08,473:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:34:08,473:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-06 16:34:08,520:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:34:08,521:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:34:08,571:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:34:08,572:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:34:08,574:INFO:Preparing preprocessing pipeline...
2023-04-06 16:34:08,574:INFO:Set up simple imputation.
2023-04-06 16:34:08,576:INFO:Set up encoding of ordinal features.
2023-04-06 16:34:08,577:INFO:Set up encoding of categorical features.
2023-04-06 16:34:08,577:INFO:Set up column name cleaning.
2023-04-06 16:34:08,640:INFO:Finished creating preprocessing pipeline.
2023-04-06 16:34:08,649:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry', 'Report'],
                                    transformer=SimpleImputer(strategy='most_frequent')...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': AGSL    0
GIA     1
NaN    -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry'],
                                    transformer=OneHotEncoder(cols=['Cut',
                                                                    'Color',
                                                                    'Clarity',
                                                                    'Polish',
                                                                    'Symmetry'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-06 16:34:08,649:INFO:Creating final display dataframe.
2023-04-06 16:34:08,775:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             Price
2                   Target type        Regression
3           Original data shape         (5400, 8)
4        Transformed data shape        (5400, 29)
5   Transformed train set shape        (3779, 29)
6    Transformed test set shape        (1621, 29)
7              Ordinal features                 1
8              Numeric features                 1
9          Categorical features                 6
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              f987
2023-04-06 16:34:08,826:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:34:08,827:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:34:08,874:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:34:08,875:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:34:08,876:INFO:setup() successfully completed in 1.55s...............
2023-04-06 16:36:45,372:INFO:Initializing compare_models()
2023-04-06 16:36:45,375:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-06 16:36:45,375:INFO:Checking exceptions
2023-04-06 16:36:45,379:INFO:Preparing display monitor
2023-04-06 16:36:45,414:INFO:Initializing Linear Regression
2023-04-06 16:36:45,414:INFO:Total runtime is 3.850460052490234e-06 minutes
2023-04-06 16:36:45,416:INFO:SubProcess create_model() called ==================================
2023-04-06 16:36:45,416:INFO:Initializing create_model()
2023-04-06 16:36:45,416:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:36:45,416:INFO:Checking exceptions
2023-04-06 16:36:45,417:INFO:Importing libraries
2023-04-06 16:36:45,417:INFO:Copying training dataset
2023-04-06 16:36:45,421:INFO:Defining folds
2023-04-06 16:36:45,421:INFO:Declaring metric variables
2023-04-06 16:36:45,423:INFO:Importing untrained model
2023-04-06 16:36:45,424:INFO:Linear Regression Imported successfully
2023-04-06 16:36:45,428:INFO:Starting cross validation
2023-04-06 16:36:45,434:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:36:51,843:INFO:Calculating mean and std
2023-04-06 16:36:51,844:INFO:Creating metrics dataframe
2023-04-06 16:36:52,239:INFO:Uploading results into container
2023-04-06 16:36:52,240:INFO:Uploading model into container now
2023-04-06 16:36:52,241:INFO:_master_model_container: 1
2023-04-06 16:36:52,241:INFO:_display_container: 2
2023-04-06 16:36:52,241:INFO:LinearRegression(n_jobs=-1)
2023-04-06 16:36:52,241:INFO:create_model() successfully completed......................................
2023-04-06 16:36:52,358:INFO:SubProcess create_model() end ==================================
2023-04-06 16:36:52,358:INFO:Creating metrics dataframe
2023-04-06 16:36:52,361:INFO:Initializing Lasso Regression
2023-04-06 16:36:52,361:INFO:Total runtime is 0.11578671932220459 minutes
2023-04-06 16:36:52,363:INFO:SubProcess create_model() called ==================================
2023-04-06 16:36:52,363:INFO:Initializing create_model()
2023-04-06 16:36:52,363:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:36:52,363:INFO:Checking exceptions
2023-04-06 16:36:52,363:INFO:Importing libraries
2023-04-06 16:36:52,363:INFO:Copying training dataset
2023-04-06 16:36:52,366:INFO:Defining folds
2023-04-06 16:36:52,366:INFO:Declaring metric variables
2023-04-06 16:36:52,367:INFO:Importing untrained model
2023-04-06 16:36:52,370:INFO:Lasso Regression Imported successfully
2023-04-06 16:36:52,373:INFO:Starting cross validation
2023-04-06 16:36:52,374:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:36:56,238:INFO:Calculating mean and std
2023-04-06 16:36:56,238:INFO:Creating metrics dataframe
2023-04-06 16:36:56,606:INFO:Uploading results into container
2023-04-06 16:36:56,606:INFO:Uploading model into container now
2023-04-06 16:36:56,606:INFO:_master_model_container: 2
2023-04-06 16:36:56,606:INFO:_display_container: 2
2023-04-06 16:36:56,607:INFO:Lasso(random_state=123)
2023-04-06 16:36:56,607:INFO:create_model() successfully completed......................................
2023-04-06 16:36:56,681:INFO:SubProcess create_model() end ==================================
2023-04-06 16:36:56,681:INFO:Creating metrics dataframe
2023-04-06 16:36:56,685:INFO:Initializing Ridge Regression
2023-04-06 16:36:56,686:INFO:Total runtime is 0.18785916566848754 minutes
2023-04-06 16:36:56,687:INFO:SubProcess create_model() called ==================================
2023-04-06 16:36:56,687:INFO:Initializing create_model()
2023-04-06 16:36:56,687:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:36:56,687:INFO:Checking exceptions
2023-04-06 16:36:56,687:INFO:Importing libraries
2023-04-06 16:36:56,687:INFO:Copying training dataset
2023-04-06 16:36:56,690:INFO:Defining folds
2023-04-06 16:36:56,690:INFO:Declaring metric variables
2023-04-06 16:36:56,691:INFO:Importing untrained model
2023-04-06 16:36:56,692:INFO:Ridge Regression Imported successfully
2023-04-06 16:36:56,695:INFO:Starting cross validation
2023-04-06 16:36:56,695:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:37:00,409:INFO:Calculating mean and std
2023-04-06 16:37:00,410:INFO:Creating metrics dataframe
2023-04-06 16:37:00,767:INFO:Uploading results into container
2023-04-06 16:37:00,768:INFO:Uploading model into container now
2023-04-06 16:37:00,768:INFO:_master_model_container: 3
2023-04-06 16:37:00,768:INFO:_display_container: 2
2023-04-06 16:37:00,768:INFO:Ridge(random_state=123)
2023-04-06 16:37:00,768:INFO:create_model() successfully completed......................................
2023-04-06 16:37:00,842:INFO:SubProcess create_model() end ==================================
2023-04-06 16:37:00,842:INFO:Creating metrics dataframe
2023-04-06 16:37:00,846:INFO:Initializing Elastic Net
2023-04-06 16:37:00,846:INFO:Total runtime is 0.25719326734542847 minutes
2023-04-06 16:37:00,847:INFO:SubProcess create_model() called ==================================
2023-04-06 16:37:00,847:INFO:Initializing create_model()
2023-04-06 16:37:00,847:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:37:00,847:INFO:Checking exceptions
2023-04-06 16:37:00,847:INFO:Importing libraries
2023-04-06 16:37:00,847:INFO:Copying training dataset
2023-04-06 16:37:00,850:INFO:Defining folds
2023-04-06 16:37:00,850:INFO:Declaring metric variables
2023-04-06 16:37:00,851:INFO:Importing untrained model
2023-04-06 16:37:00,852:INFO:Elastic Net Imported successfully
2023-04-06 16:37:00,855:INFO:Starting cross validation
2023-04-06 16:37:00,856:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:37:04,709:INFO:Calculating mean and std
2023-04-06 16:37:04,710:INFO:Creating metrics dataframe
2023-04-06 16:37:05,085:INFO:Uploading results into container
2023-04-06 16:37:05,086:INFO:Uploading model into container now
2023-04-06 16:37:05,086:INFO:_master_model_container: 4
2023-04-06 16:37:05,086:INFO:_display_container: 2
2023-04-06 16:37:05,086:INFO:ElasticNet(random_state=123)
2023-04-06 16:37:05,086:INFO:create_model() successfully completed......................................
2023-04-06 16:37:05,159:INFO:SubProcess create_model() end ==================================
2023-04-06 16:37:05,159:INFO:Creating metrics dataframe
2023-04-06 16:37:05,163:INFO:Initializing Least Angle Regression
2023-04-06 16:37:05,163:INFO:Total runtime is 0.3291534185409546 minutes
2023-04-06 16:37:05,165:INFO:SubProcess create_model() called ==================================
2023-04-06 16:37:05,165:INFO:Initializing create_model()
2023-04-06 16:37:05,165:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:37:05,165:INFO:Checking exceptions
2023-04-06 16:37:05,165:INFO:Importing libraries
2023-04-06 16:37:05,165:INFO:Copying training dataset
2023-04-06 16:37:05,167:INFO:Defining folds
2023-04-06 16:37:05,167:INFO:Declaring metric variables
2023-04-06 16:37:05,169:INFO:Importing untrained model
2023-04-06 16:37:05,170:INFO:Least Angle Regression Imported successfully
2023-04-06 16:37:05,173:INFO:Starting cross validation
2023-04-06 16:37:05,174:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:37:05,272:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:05,278:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:05,280:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:05,286:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:05,289:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:05,289:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=6.036e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 16:37:05,290:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=4.789e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 16:37:05,290:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.582e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 16:37:05,290:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.117e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 16:37:05,290:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.036e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 16:37:05,290:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:05,310:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:05,321:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:05,322:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:05,346:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:09,006:INFO:Calculating mean and std
2023-04-06 16:37:09,007:INFO:Creating metrics dataframe
2023-04-06 16:37:09,398:INFO:Uploading results into container
2023-04-06 16:37:09,399:INFO:Uploading model into container now
2023-04-06 16:37:09,399:INFO:_master_model_container: 5
2023-04-06 16:37:09,400:INFO:_display_container: 2
2023-04-06 16:37:09,400:INFO:Lars(random_state=123)
2023-04-06 16:37:09,400:INFO:create_model() successfully completed......................................
2023-04-06 16:37:09,485:INFO:SubProcess create_model() end ==================================
2023-04-06 16:37:09,485:INFO:Creating metrics dataframe
2023-04-06 16:37:09,490:INFO:Initializing Lasso Least Angle Regression
2023-04-06 16:37:09,490:INFO:Total runtime is 0.4012604514757792 minutes
2023-04-06 16:37:09,491:INFO:SubProcess create_model() called ==================================
2023-04-06 16:37:09,492:INFO:Initializing create_model()
2023-04-06 16:37:09,492:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:37:09,492:INFO:Checking exceptions
2023-04-06 16:37:09,492:INFO:Importing libraries
2023-04-06 16:37:09,492:INFO:Copying training dataset
2023-04-06 16:37:09,494:INFO:Defining folds
2023-04-06 16:37:09,494:INFO:Declaring metric variables
2023-04-06 16:37:09,496:INFO:Importing untrained model
2023-04-06 16:37:09,497:INFO:Lasso Least Angle Regression Imported successfully
2023-04-06 16:37:09,500:INFO:Starting cross validation
2023-04-06 16:37:09,501:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:37:09,584:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:37:09,584:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:37:09,596:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:37:09,606:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:37:09,612:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:37:09,626:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:37:09,630:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:37:09,643:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:37:09,663:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:37:09,672:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:37:13,209:INFO:Calculating mean and std
2023-04-06 16:37:13,209:INFO:Creating metrics dataframe
2023-04-06 16:37:13,584:INFO:Uploading results into container
2023-04-06 16:37:13,584:INFO:Uploading model into container now
2023-04-06 16:37:13,584:INFO:_master_model_container: 6
2023-04-06 16:37:13,584:INFO:_display_container: 2
2023-04-06 16:37:13,584:INFO:LassoLars(random_state=123)
2023-04-06 16:37:13,585:INFO:create_model() successfully completed......................................
2023-04-06 16:37:13,658:INFO:SubProcess create_model() end ==================================
2023-04-06 16:37:13,658:INFO:Creating metrics dataframe
2023-04-06 16:37:13,662:INFO:Initializing Orthogonal Matching Pursuit
2023-04-06 16:37:13,662:INFO:Total runtime is 0.4707941969235738 minutes
2023-04-06 16:37:13,663:INFO:SubProcess create_model() called ==================================
2023-04-06 16:37:13,663:INFO:Initializing create_model()
2023-04-06 16:37:13,663:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:37:13,663:INFO:Checking exceptions
2023-04-06 16:37:13,663:INFO:Importing libraries
2023-04-06 16:37:13,663:INFO:Copying training dataset
2023-04-06 16:37:13,665:INFO:Defining folds
2023-04-06 16:37:13,665:INFO:Declaring metric variables
2023-04-06 16:37:13,667:INFO:Importing untrained model
2023-04-06 16:37:13,668:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-06 16:37:13,670:INFO:Starting cross validation
2023-04-06 16:37:13,671:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:37:13,746:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:13,758:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:13,761:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:13,771:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:13,771:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:13,774:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:13,777:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:13,783:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:13,791:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:13,804:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:37:17,359:INFO:Calculating mean and std
2023-04-06 16:37:17,360:INFO:Creating metrics dataframe
2023-04-06 16:37:17,743:INFO:Uploading results into container
2023-04-06 16:37:17,744:INFO:Uploading model into container now
2023-04-06 16:37:17,744:INFO:_master_model_container: 7
2023-04-06 16:37:17,744:INFO:_display_container: 2
2023-04-06 16:37:17,744:INFO:OrthogonalMatchingPursuit()
2023-04-06 16:37:17,744:INFO:create_model() successfully completed......................................
2023-04-06 16:37:17,818:INFO:SubProcess create_model() end ==================================
2023-04-06 16:37:17,818:INFO:Creating metrics dataframe
2023-04-06 16:37:17,823:INFO:Initializing Bayesian Ridge
2023-04-06 16:37:17,823:INFO:Total runtime is 0.5401495019594829 minutes
2023-04-06 16:37:17,824:INFO:SubProcess create_model() called ==================================
2023-04-06 16:37:17,825:INFO:Initializing create_model()
2023-04-06 16:37:17,825:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:37:17,825:INFO:Checking exceptions
2023-04-06 16:37:17,825:INFO:Importing libraries
2023-04-06 16:37:17,825:INFO:Copying training dataset
2023-04-06 16:37:17,827:INFO:Defining folds
2023-04-06 16:37:17,827:INFO:Declaring metric variables
2023-04-06 16:37:17,829:INFO:Importing untrained model
2023-04-06 16:37:17,830:INFO:Bayesian Ridge Imported successfully
2023-04-06 16:37:17,832:INFO:Starting cross validation
2023-04-06 16:37:17,833:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:37:21,526:INFO:Calculating mean and std
2023-04-06 16:37:21,527:INFO:Creating metrics dataframe
2023-04-06 16:37:21,914:INFO:Uploading results into container
2023-04-06 16:37:21,915:INFO:Uploading model into container now
2023-04-06 16:37:21,915:INFO:_master_model_container: 8
2023-04-06 16:37:21,915:INFO:_display_container: 2
2023-04-06 16:37:21,915:INFO:BayesianRidge()
2023-04-06 16:37:21,915:INFO:create_model() successfully completed......................................
2023-04-06 16:37:21,993:INFO:SubProcess create_model() end ==================================
2023-04-06 16:37:21,993:INFO:Creating metrics dataframe
2023-04-06 16:37:21,997:INFO:Initializing Passive Aggressive Regressor
2023-04-06 16:37:21,998:INFO:Total runtime is 0.6097239176432292 minutes
2023-04-06 16:37:21,999:INFO:SubProcess create_model() called ==================================
2023-04-06 16:37:22,000:INFO:Initializing create_model()
2023-04-06 16:37:22,000:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:37:22,000:INFO:Checking exceptions
2023-04-06 16:37:22,000:INFO:Importing libraries
2023-04-06 16:37:22,000:INFO:Copying training dataset
2023-04-06 16:37:22,002:INFO:Defining folds
2023-04-06 16:37:22,002:INFO:Declaring metric variables
2023-04-06 16:37:22,004:INFO:Importing untrained model
2023-04-06 16:37:22,005:INFO:Passive Aggressive Regressor Imported successfully
2023-04-06 16:37:22,008:INFO:Starting cross validation
2023-04-06 16:37:22,008:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:37:25,776:INFO:Calculating mean and std
2023-04-06 16:37:25,777:INFO:Creating metrics dataframe
2023-04-06 16:37:26,166:INFO:Uploading results into container
2023-04-06 16:37:26,167:INFO:Uploading model into container now
2023-04-06 16:37:26,167:INFO:_master_model_container: 9
2023-04-06 16:37:26,167:INFO:_display_container: 2
2023-04-06 16:37:26,167:INFO:PassiveAggressiveRegressor(random_state=123)
2023-04-06 16:37:26,167:INFO:create_model() successfully completed......................................
2023-04-06 16:37:26,239:INFO:SubProcess create_model() end ==================================
2023-04-06 16:37:26,239:INFO:Creating metrics dataframe
2023-04-06 16:37:26,244:INFO:Initializing Huber Regressor
2023-04-06 16:37:26,244:INFO:Total runtime is 0.6804990967114767 minutes
2023-04-06 16:37:26,245:INFO:SubProcess create_model() called ==================================
2023-04-06 16:37:26,245:INFO:Initializing create_model()
2023-04-06 16:37:26,245:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:37:26,245:INFO:Checking exceptions
2023-04-06 16:37:26,246:INFO:Importing libraries
2023-04-06 16:37:26,246:INFO:Copying training dataset
2023-04-06 16:37:26,248:INFO:Defining folds
2023-04-06 16:37:26,248:INFO:Declaring metric variables
2023-04-06 16:37:26,249:INFO:Importing untrained model
2023-04-06 16:37:26,250:INFO:Huber Regressor Imported successfully
2023-04-06 16:37:26,253:INFO:Starting cross validation
2023-04-06 16:37:26,254:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:37:26,400:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 16:37:26,404:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 16:37:26,405:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 16:37:26,405:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 16:37:26,412:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 16:37:26,412:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 16:37:26,454:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 16:37:26,464:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 16:37:30,008:INFO:Calculating mean and std
2023-04-06 16:37:30,009:INFO:Creating metrics dataframe
2023-04-06 16:37:30,392:INFO:Uploading results into container
2023-04-06 16:37:30,392:INFO:Uploading model into container now
2023-04-06 16:37:30,392:INFO:_master_model_container: 10
2023-04-06 16:37:30,393:INFO:_display_container: 2
2023-04-06 16:37:30,393:INFO:HuberRegressor()
2023-04-06 16:37:30,393:INFO:create_model() successfully completed......................................
2023-04-06 16:37:30,470:INFO:SubProcess create_model() end ==================================
2023-04-06 16:37:30,470:INFO:Creating metrics dataframe
2023-04-06 16:37:30,476:INFO:Initializing K Neighbors Regressor
2023-04-06 16:37:30,476:INFO:Total runtime is 0.7510249654452006 minutes
2023-04-06 16:37:30,477:INFO:SubProcess create_model() called ==================================
2023-04-06 16:37:30,477:INFO:Initializing create_model()
2023-04-06 16:37:30,477:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:37:30,477:INFO:Checking exceptions
2023-04-06 16:37:30,477:INFO:Importing libraries
2023-04-06 16:37:30,477:INFO:Copying training dataset
2023-04-06 16:37:30,480:INFO:Defining folds
2023-04-06 16:37:30,480:INFO:Declaring metric variables
2023-04-06 16:37:30,481:INFO:Importing untrained model
2023-04-06 16:37:30,483:INFO:K Neighbors Regressor Imported successfully
2023-04-06 16:37:30,485:INFO:Starting cross validation
2023-04-06 16:37:30,486:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:37:34,293:INFO:Calculating mean and std
2023-04-06 16:37:34,294:INFO:Creating metrics dataframe
2023-04-06 16:37:34,661:INFO:Uploading results into container
2023-04-06 16:37:34,662:INFO:Uploading model into container now
2023-04-06 16:37:34,662:INFO:_master_model_container: 11
2023-04-06 16:37:34,662:INFO:_display_container: 2
2023-04-06 16:37:34,662:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-06 16:37:34,662:INFO:create_model() successfully completed......................................
2023-04-06 16:37:34,738:INFO:SubProcess create_model() end ==================================
2023-04-06 16:37:34,738:INFO:Creating metrics dataframe
2023-04-06 16:37:34,743:INFO:Initializing Decision Tree Regressor
2023-04-06 16:37:34,743:INFO:Total runtime is 0.8221426645914713 minutes
2023-04-06 16:37:34,744:INFO:SubProcess create_model() called ==================================
2023-04-06 16:37:34,744:INFO:Initializing create_model()
2023-04-06 16:37:34,744:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:37:34,744:INFO:Checking exceptions
2023-04-06 16:37:34,744:INFO:Importing libraries
2023-04-06 16:37:34,744:INFO:Copying training dataset
2023-04-06 16:37:34,747:INFO:Defining folds
2023-04-06 16:37:34,747:INFO:Declaring metric variables
2023-04-06 16:37:34,748:INFO:Importing untrained model
2023-04-06 16:37:34,754:INFO:Decision Tree Regressor Imported successfully
2023-04-06 16:37:34,758:INFO:Starting cross validation
2023-04-06 16:37:34,759:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:37:38,646:INFO:Calculating mean and std
2023-04-06 16:37:38,646:INFO:Creating metrics dataframe
2023-04-06 16:37:39,030:INFO:Uploading results into container
2023-04-06 16:37:39,030:INFO:Uploading model into container now
2023-04-06 16:37:39,031:INFO:_master_model_container: 12
2023-04-06 16:37:39,031:INFO:_display_container: 2
2023-04-06 16:37:39,031:INFO:DecisionTreeRegressor(random_state=123)
2023-04-06 16:37:39,031:INFO:create_model() successfully completed......................................
2023-04-06 16:37:39,106:INFO:SubProcess create_model() end ==================================
2023-04-06 16:37:39,106:INFO:Creating metrics dataframe
2023-04-06 16:37:39,111:INFO:Initializing Random Forest Regressor
2023-04-06 16:37:39,112:INFO:Total runtime is 0.8949593504269917 minutes
2023-04-06 16:37:39,113:INFO:SubProcess create_model() called ==================================
2023-04-06 16:37:39,113:INFO:Initializing create_model()
2023-04-06 16:37:39,114:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:37:39,114:INFO:Checking exceptions
2023-04-06 16:37:39,114:INFO:Importing libraries
2023-04-06 16:37:39,114:INFO:Copying training dataset
2023-04-06 16:37:39,116:INFO:Defining folds
2023-04-06 16:37:39,116:INFO:Declaring metric variables
2023-04-06 16:37:39,117:INFO:Importing untrained model
2023-04-06 16:37:39,119:INFO:Random Forest Regressor Imported successfully
2023-04-06 16:37:39,121:INFO:Starting cross validation
2023-04-06 16:37:39,122:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:37:43,756:INFO:Calculating mean and std
2023-04-06 16:37:43,757:INFO:Creating metrics dataframe
2023-04-06 16:37:44,138:INFO:Uploading results into container
2023-04-06 16:37:44,139:INFO:Uploading model into container now
2023-04-06 16:37:44,139:INFO:_master_model_container: 13
2023-04-06 16:37:44,139:INFO:_display_container: 2
2023-04-06 16:37:44,139:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-04-06 16:37:44,139:INFO:create_model() successfully completed......................................
2023-04-06 16:37:44,212:INFO:SubProcess create_model() end ==================================
2023-04-06 16:37:44,212:INFO:Creating metrics dataframe
2023-04-06 16:37:44,216:INFO:Initializing Extra Trees Regressor
2023-04-06 16:37:44,216:INFO:Total runtime is 0.980039616425832 minutes
2023-04-06 16:37:44,218:INFO:SubProcess create_model() called ==================================
2023-04-06 16:37:44,218:INFO:Initializing create_model()
2023-04-06 16:37:44,218:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:37:44,218:INFO:Checking exceptions
2023-04-06 16:37:44,218:INFO:Importing libraries
2023-04-06 16:37:44,218:INFO:Copying training dataset
2023-04-06 16:37:44,220:INFO:Defining folds
2023-04-06 16:37:44,220:INFO:Declaring metric variables
2023-04-06 16:37:44,221:INFO:Importing untrained model
2023-04-06 16:37:44,223:INFO:Extra Trees Regressor Imported successfully
2023-04-06 16:37:44,225:INFO:Starting cross validation
2023-04-06 16:37:44,226:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:37:49,133:INFO:Calculating mean and std
2023-04-06 16:37:49,134:INFO:Creating metrics dataframe
2023-04-06 16:37:49,520:INFO:Uploading results into container
2023-04-06 16:37:49,520:INFO:Uploading model into container now
2023-04-06 16:37:49,520:INFO:_master_model_container: 14
2023-04-06 16:37:49,520:INFO:_display_container: 2
2023-04-06 16:37:49,521:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-04-06 16:37:49,521:INFO:create_model() successfully completed......................................
2023-04-06 16:37:49,599:INFO:SubProcess create_model() end ==================================
2023-04-06 16:37:49,599:INFO:Creating metrics dataframe
2023-04-06 16:37:49,603:INFO:Initializing AdaBoost Regressor
2023-04-06 16:37:49,603:INFO:Total runtime is 1.0698230822881063 minutes
2023-04-06 16:37:49,605:INFO:SubProcess create_model() called ==================================
2023-04-06 16:37:49,605:INFO:Initializing create_model()
2023-04-06 16:37:49,605:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:37:49,605:INFO:Checking exceptions
2023-04-06 16:37:49,605:INFO:Importing libraries
2023-04-06 16:37:49,605:INFO:Copying training dataset
2023-04-06 16:37:49,608:INFO:Defining folds
2023-04-06 16:37:49,608:INFO:Declaring metric variables
2023-04-06 16:37:49,609:INFO:Importing untrained model
2023-04-06 16:37:49,611:INFO:AdaBoost Regressor Imported successfully
2023-04-06 16:37:49,613:INFO:Starting cross validation
2023-04-06 16:37:49,614:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:37:53,697:INFO:Calculating mean and std
2023-04-06 16:37:53,699:INFO:Creating metrics dataframe
2023-04-06 16:37:54,108:INFO:Uploading results into container
2023-04-06 16:37:54,109:INFO:Uploading model into container now
2023-04-06 16:37:54,110:INFO:_master_model_container: 15
2023-04-06 16:37:54,110:INFO:_display_container: 2
2023-04-06 16:37:54,110:INFO:AdaBoostRegressor(random_state=123)
2023-04-06 16:37:54,110:INFO:create_model() successfully completed......................................
2023-04-06 16:37:54,187:INFO:SubProcess create_model() end ==================================
2023-04-06 16:37:54,187:INFO:Creating metrics dataframe
2023-04-06 16:37:54,192:INFO:Initializing Gradient Boosting Regressor
2023-04-06 16:37:54,193:INFO:Total runtime is 1.1463085333506267 minutes
2023-04-06 16:37:54,194:INFO:SubProcess create_model() called ==================================
2023-04-06 16:37:54,194:INFO:Initializing create_model()
2023-04-06 16:37:54,194:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:37:54,194:INFO:Checking exceptions
2023-04-06 16:37:54,194:INFO:Importing libraries
2023-04-06 16:37:54,194:INFO:Copying training dataset
2023-04-06 16:37:54,197:INFO:Defining folds
2023-04-06 16:37:54,197:INFO:Declaring metric variables
2023-04-06 16:37:54,200:INFO:Importing untrained model
2023-04-06 16:37:54,202:INFO:Gradient Boosting Regressor Imported successfully
2023-04-06 16:37:54,206:INFO:Starting cross validation
2023-04-06 16:37:54,207:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:37:58,167:INFO:Calculating mean and std
2023-04-06 16:37:58,168:INFO:Creating metrics dataframe
2023-04-06 16:37:58,573:INFO:Uploading results into container
2023-04-06 16:37:58,574:INFO:Uploading model into container now
2023-04-06 16:37:58,574:INFO:_master_model_container: 16
2023-04-06 16:37:58,574:INFO:_display_container: 2
2023-04-06 16:37:58,575:INFO:GradientBoostingRegressor(random_state=123)
2023-04-06 16:37:58,575:INFO:create_model() successfully completed......................................
2023-04-06 16:37:58,652:INFO:SubProcess create_model() end ==================================
2023-04-06 16:37:58,652:INFO:Creating metrics dataframe
2023-04-06 16:37:58,657:INFO:Initializing Extreme Gradient Boosting
2023-04-06 16:37:58,657:INFO:Total runtime is 1.2207218170166017 minutes
2023-04-06 16:37:58,659:INFO:SubProcess create_model() called ==================================
2023-04-06 16:37:58,659:INFO:Initializing create_model()
2023-04-06 16:37:58,659:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:37:58,659:INFO:Checking exceptions
2023-04-06 16:37:58,659:INFO:Importing libraries
2023-04-06 16:37:58,660:INFO:Copying training dataset
2023-04-06 16:37:58,662:INFO:Defining folds
2023-04-06 16:37:58,662:INFO:Declaring metric variables
2023-04-06 16:37:58,663:INFO:Importing untrained model
2023-04-06 16:37:58,665:INFO:Extreme Gradient Boosting Imported successfully
2023-04-06 16:37:58,668:INFO:Starting cross validation
2023-04-06 16:37:58,669:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:38:03,010:INFO:Calculating mean and std
2023-04-06 16:38:03,011:INFO:Creating metrics dataframe
2023-04-06 16:38:03,399:INFO:Uploading results into container
2023-04-06 16:38:03,399:INFO:Uploading model into container now
2023-04-06 16:38:03,399:INFO:_master_model_container: 17
2023-04-06 16:38:03,399:INFO:_display_container: 2
2023-04-06 16:38:03,400:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=123, ...)
2023-04-06 16:38:03,400:INFO:create_model() successfully completed......................................
2023-04-06 16:38:03,479:INFO:SubProcess create_model() end ==================================
2023-04-06 16:38:03,479:INFO:Creating metrics dataframe
2023-04-06 16:38:03,485:INFO:Initializing Light Gradient Boosting Machine
2023-04-06 16:38:03,486:INFO:Total runtime is 1.301191798845927 minutes
2023-04-06 16:38:03,487:INFO:SubProcess create_model() called ==================================
2023-04-06 16:38:03,487:INFO:Initializing create_model()
2023-04-06 16:38:03,487:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:38:03,488:INFO:Checking exceptions
2023-04-06 16:38:03,488:INFO:Importing libraries
2023-04-06 16:38:03,488:INFO:Copying training dataset
2023-04-06 16:38:03,490:INFO:Defining folds
2023-04-06 16:38:03,490:INFO:Declaring metric variables
2023-04-06 16:38:03,492:INFO:Importing untrained model
2023-04-06 16:38:03,494:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-06 16:38:03,498:INFO:Starting cross validation
2023-04-06 16:38:03,499:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:38:08,047:INFO:Calculating mean and std
2023-04-06 16:38:08,049:INFO:Creating metrics dataframe
2023-04-06 16:38:08,427:INFO:Uploading results into container
2023-04-06 16:38:08,428:INFO:Uploading model into container now
2023-04-06 16:38:08,428:INFO:_master_model_container: 18
2023-04-06 16:38:08,428:INFO:_display_container: 2
2023-04-06 16:38:08,429:INFO:LGBMRegressor(random_state=123)
2023-04-06 16:38:08,429:INFO:create_model() successfully completed......................................
2023-04-06 16:38:08,501:INFO:SubProcess create_model() end ==================================
2023-04-06 16:38:08,502:INFO:Creating metrics dataframe
2023-04-06 16:38:08,507:INFO:Initializing CatBoost Regressor
2023-04-06 16:38:08,507:INFO:Total runtime is 1.3848868648211161 minutes
2023-04-06 16:38:08,509:INFO:SubProcess create_model() called ==================================
2023-04-06 16:38:08,509:INFO:Initializing create_model()
2023-04-06 16:38:08,509:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:38:08,509:INFO:Checking exceptions
2023-04-06 16:38:08,509:INFO:Importing libraries
2023-04-06 16:38:08,509:INFO:Copying training dataset
2023-04-06 16:38:08,511:INFO:Defining folds
2023-04-06 16:38:08,511:INFO:Declaring metric variables
2023-04-06 16:38:08,512:INFO:Importing untrained model
2023-04-06 16:38:08,515:INFO:CatBoost Regressor Imported successfully
2023-04-06 16:38:08,518:INFO:Starting cross validation
2023-04-06 16:38:08,518:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:38:13,900:INFO:Calculating mean and std
2023-04-06 16:38:13,900:INFO:Creating metrics dataframe
2023-04-06 16:38:14,292:INFO:Uploading results into container
2023-04-06 16:38:14,293:INFO:Uploading model into container now
2023-04-06 16:38:14,294:INFO:_master_model_container: 19
2023-04-06 16:38:14,294:INFO:_display_container: 2
2023-04-06 16:38:14,294:INFO:<catboost.core.CatBoostRegressor object at 0x177019f40>
2023-04-06 16:38:14,294:INFO:create_model() successfully completed......................................
2023-04-06 16:38:14,368:INFO:SubProcess create_model() end ==================================
2023-04-06 16:38:14,368:INFO:Creating metrics dataframe
2023-04-06 16:38:14,373:INFO:Initializing Dummy Regressor
2023-04-06 16:38:14,373:INFO:Total runtime is 1.4826469699541727 minutes
2023-04-06 16:38:14,374:INFO:SubProcess create_model() called ==================================
2023-04-06 16:38:14,374:INFO:Initializing create_model()
2023-04-06 16:38:14,374:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1653c8b20>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:38:14,374:INFO:Checking exceptions
2023-04-06 16:38:14,374:INFO:Importing libraries
2023-04-06 16:38:14,374:INFO:Copying training dataset
2023-04-06 16:38:14,377:INFO:Defining folds
2023-04-06 16:38:14,377:INFO:Declaring metric variables
2023-04-06 16:38:14,378:INFO:Importing untrained model
2023-04-06 16:38:14,379:INFO:Dummy Regressor Imported successfully
2023-04-06 16:38:14,381:INFO:Starting cross validation
2023-04-06 16:38:14,382:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:38:18,250:INFO:Calculating mean and std
2023-04-06 16:38:18,251:INFO:Creating metrics dataframe
2023-04-06 16:38:18,643:INFO:Uploading results into container
2023-04-06 16:38:18,644:INFO:Uploading model into container now
2023-04-06 16:38:18,644:INFO:_master_model_container: 20
2023-04-06 16:38:18,645:INFO:_display_container: 2
2023-04-06 16:38:18,645:INFO:DummyRegressor()
2023-04-06 16:38:18,645:INFO:create_model() successfully completed......................................
2023-04-06 16:38:18,721:INFO:SubProcess create_model() end ==================================
2023-04-06 16:38:18,721:INFO:Creating metrics dataframe
2023-04-06 16:38:18,731:INFO:Initializing create_model()
2023-04-06 16:38:18,732:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=<catboost.core.CatBoostRegressor object at 0x177019f40>, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:38:18,732:INFO:Checking exceptions
2023-04-06 16:38:18,733:INFO:Importing libraries
2023-04-06 16:38:18,733:INFO:Copying training dataset
2023-04-06 16:38:18,738:INFO:Defining folds
2023-04-06 16:38:18,738:INFO:Declaring metric variables
2023-04-06 16:38:18,739:INFO:Importing untrained model
2023-04-06 16:38:18,739:INFO:Declaring custom model
2023-04-06 16:38:18,739:INFO:CatBoost Regressor Imported successfully
2023-04-06 16:38:18,744:INFO:Cross validation set to False
2023-04-06 16:38:18,744:INFO:Fitting Model
2023-04-06 16:38:20,121:INFO:<catboost.core.CatBoostRegressor object at 0x176baee20>
2023-04-06 16:38:20,121:INFO:create_model() successfully completed......................................
2023-04-06 16:38:20,210:INFO:_master_model_container: 20
2023-04-06 16:38:20,210:INFO:_display_container: 2
2023-04-06 16:38:20,210:INFO:<catboost.core.CatBoostRegressor object at 0x176baee20>
2023-04-06 16:38:20,210:INFO:compare_models() successfully completed......................................
2023-04-06 16:38:58,855:INFO:Initializing create_model()
2023-04-06 16:38:58,856:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=ada, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:38:58,856:INFO:Checking exceptions
2023-04-06 16:38:58,878:INFO:Importing libraries
2023-04-06 16:38:58,878:INFO:Copying training dataset
2023-04-06 16:38:58,883:INFO:Defining folds
2023-04-06 16:38:58,883:INFO:Declaring metric variables
2023-04-06 16:38:58,885:INFO:Importing untrained model
2023-04-06 16:38:58,886:INFO:AdaBoost Regressor Imported successfully
2023-04-06 16:38:58,890:INFO:Starting cross validation
2023-04-06 16:38:58,891:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:39:02,604:INFO:Calculating mean and std
2023-04-06 16:39:02,604:INFO:Creating metrics dataframe
2023-04-06 16:39:02,607:INFO:Finalizing model
2023-04-06 16:39:03,196:INFO:Uploading results into container
2023-04-06 16:39:03,197:INFO:Uploading model into container now
2023-04-06 16:39:03,200:INFO:_master_model_container: 21
2023-04-06 16:39:03,200:INFO:_display_container: 3
2023-04-06 16:39:03,200:INFO:AdaBoostRegressor(random_state=123)
2023-04-06 16:39:03,200:INFO:create_model() successfully completed......................................
2023-04-06 16:39:03,285:INFO:Initializing create_model()
2023-04-06 16:39:03,286:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:39:03,286:INFO:Checking exceptions
2023-04-06 16:39:03,293:INFO:Importing libraries
2023-04-06 16:39:03,293:INFO:Copying training dataset
2023-04-06 16:39:03,297:INFO:Defining folds
2023-04-06 16:39:03,297:INFO:Declaring metric variables
2023-04-06 16:39:03,298:INFO:Importing untrained model
2023-04-06 16:39:03,299:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-06 16:39:03,302:INFO:Starting cross validation
2023-04-06 16:39:03,303:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:39:07,055:INFO:Calculating mean and std
2023-04-06 16:39:07,056:INFO:Creating metrics dataframe
2023-04-06 16:39:07,058:INFO:Finalizing model
2023-04-06 16:39:07,526:INFO:Uploading results into container
2023-04-06 16:39:07,527:INFO:Uploading model into container now
2023-04-06 16:39:07,530:INFO:_master_model_container: 22
2023-04-06 16:39:07,530:INFO:_display_container: 4
2023-04-06 16:39:07,530:INFO:LGBMRegressor(random_state=123)
2023-04-06 16:39:07,530:INFO:create_model() successfully completed......................................
2023-04-06 16:39:07,608:INFO:Initializing create_model()
2023-04-06 16:39:07,608:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>, estimator=dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:39:07,608:INFO:Checking exceptions
2023-04-06 16:39:07,615:INFO:Importing libraries
2023-04-06 16:39:07,615:INFO:Copying training dataset
2023-04-06 16:39:07,619:INFO:Defining folds
2023-04-06 16:39:07,620:INFO:Declaring metric variables
2023-04-06 16:39:07,621:INFO:Importing untrained model
2023-04-06 16:39:07,623:INFO:Decision Tree Regressor Imported successfully
2023-04-06 16:39:07,626:INFO:Starting cross validation
2023-04-06 16:39:07,627:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:39:11,458:INFO:Calculating mean and std
2023-04-06 16:39:11,460:INFO:Creating metrics dataframe
2023-04-06 16:39:11,462:INFO:Finalizing model
2023-04-06 16:39:11,926:INFO:Uploading results into container
2023-04-06 16:39:11,926:INFO:Uploading model into container now
2023-04-06 16:39:11,931:INFO:_master_model_container: 23
2023-04-06 16:39:11,931:INFO:_display_container: 5
2023-04-06 16:39:11,931:INFO:DecisionTreeRegressor(random_state=123)
2023-04-06 16:39:11,931:INFO:create_model() successfully completed......................................
2023-04-06 16:39:12,012:INFO:Initializing tune_model()
2023-04-06 16:39:12,012:INFO:tune_model(estimator=ada, fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>)
2023-04-06 16:39:12,012:INFO:Checking exceptions
2023-04-06 16:40:21,117:INFO:Initializing tune_model()
2023-04-06 16:40:21,118:INFO:tune_model(estimator=lightgbm, fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>)
2023-04-06 16:40:21,119:INFO:Checking exceptions
2023-04-06 16:40:28,849:INFO:Initializing tune_model()
2023-04-06 16:40:28,850:INFO:tune_model(estimator=dt, fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x16c7be850>)
2023-04-06 16:40:28,850:INFO:Checking exceptions
2023-04-06 16:43:27,395:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-06 16:43:27,396:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-06 16:43:27,396:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-06 16:43:27,396:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-06 16:43:27,990:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-06 16:43:28,617:INFO:PyCaret RegressionExperiment
2023-04-06 16:43:28,617:INFO:Logging name: reg-default-name
2023-04-06 16:43:28,617:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-06 16:43:28,617:INFO:version 3.0.0
2023-04-06 16:43:28,617:INFO:Initializing setup()
2023-04-06 16:43:28,617:INFO:self.USI: a2b4
2023-04-06 16:43:28,617:INFO:self._variable_keys: {'X_test', 'USI', 'fold_groups_param', 'X_train', 'transform_target_param', 'n_jobs_param', 'y_test', 'exp_name_log', 'y_train', 'exp_id', '_available_plots', 'idx', 'logging_param', 'fold_generator', 'target_param', 'data', 'log_plots_param', 'gpu_n_jobs_param', 'seed', 'pipeline', 'X', '_ml_usecase', 'html_param', 'gpu_param', 'fold_shuffle_param', 'y', 'memory'}
2023-04-06 16:43:28,617:INFO:Checking environment
2023-04-06 16:43:28,617:INFO:python_version: 3.9.15
2023-04-06 16:43:28,617:INFO:python_build: ('main', 'Nov 24 2022 08:28:41')
2023-04-06 16:43:28,617:INFO:machine: arm64
2023-04-06 16:43:28,617:INFO:platform: macOS-13.2-arm64-arm-64bit
2023-04-06 16:43:28,617:INFO:Memory: svmem(total=17179869184, available=4853432320, percent=71.7, used=6362988544, free=803487744, active=4054876160, inactive=3897278464, wired=2308112384)
2023-04-06 16:43:28,617:INFO:Physical Core: 10
2023-04-06 16:43:28,617:INFO:Logical Core: 10
2023-04-06 16:43:28,617:INFO:Checking libraries
2023-04-06 16:43:28,617:INFO:System:
2023-04-06 16:43:28,617:INFO:    python: 3.9.15 (main, Nov 24 2022, 08:28:41)  [Clang 14.0.6 ]
2023-04-06 16:43:28,617:INFO:executable: /Users/a06411/opt/anaconda3/bin/python
2023-04-06 16:43:28,617:INFO:   machine: macOS-13.2-arm64-arm-64bit
2023-04-06 16:43:28,617:INFO:PyCaret required dependencies:
2023-04-06 16:43:28,617:INFO:                 pip: 22.3.1
2023-04-06 16:43:28,617:INFO:          setuptools: 65.5.0
2023-04-06 16:43:28,617:INFO:             pycaret: 3.0.0
2023-04-06 16:43:28,617:INFO:             IPython: 8.7.0
2023-04-06 16:43:28,617:INFO:          ipywidgets: 7.6.5
2023-04-06 16:43:28,617:INFO:                tqdm: 4.64.1
2023-04-06 16:43:28,617:INFO:               numpy: 1.21.5
2023-04-06 16:43:28,617:INFO:              pandas: 1.4.4
2023-04-06 16:43:28,617:INFO:              jinja2: 2.11.3
2023-04-06 16:43:28,617:INFO:               scipy: 1.9.3
2023-04-06 16:43:28,617:INFO:              joblib: 1.2.0
2023-04-06 16:43:28,617:INFO:             sklearn: 1.1.3
2023-04-06 16:43:28,617:INFO:                pyod: 1.0.9
2023-04-06 16:43:28,617:INFO:            imblearn: 0.10.1
2023-04-06 16:43:28,617:INFO:   category_encoders: 2.6.0
2023-04-06 16:43:28,617:INFO:            lightgbm: 3.3.5
2023-04-06 16:43:28,617:INFO:               numba: 0.56.4
2023-04-06 16:43:28,617:INFO:            requests: 2.28.1
2023-04-06 16:43:28,617:INFO:          matplotlib: 3.6.2
2023-04-06 16:43:28,617:INFO:          scikitplot: 0.3.7
2023-04-06 16:43:28,617:INFO:         yellowbrick: 1.5
2023-04-06 16:43:28,617:INFO:              plotly: 5.9.0
2023-04-06 16:43:28,617:INFO:             kaleido: 0.2.1
2023-04-06 16:43:28,617:INFO:         statsmodels: 0.13.2
2023-04-06 16:43:28,617:INFO:              sktime: 0.16.1
2023-04-06 16:43:28,617:INFO:               tbats: 1.1.2
2023-04-06 16:43:28,617:INFO:            pmdarima: 2.0.3
2023-04-06 16:43:28,617:INFO:              psutil: 5.9.0
2023-04-06 16:43:28,617:INFO:PyCaret optional dependencies:
2023-04-06 16:43:28,622:INFO:                shap: 0.41.0
2023-04-06 16:43:28,622:INFO:           interpret: Not installed
2023-04-06 16:43:28,622:INFO:                umap: 0.5.3
2023-04-06 16:43:28,622:INFO:    pandas_profiling: Not installed
2023-04-06 16:43:28,622:INFO:  explainerdashboard: 0.4.2.1
2023-04-06 16:43:28,622:INFO:             autoviz: Not installed
2023-04-06 16:43:28,622:INFO:           fairlearn: Not installed
2023-04-06 16:43:28,622:INFO:             xgboost: 1.7.2
2023-04-06 16:43:28,622:INFO:            catboost: 1.1.1
2023-04-06 16:43:28,622:INFO:              kmodes: Not installed
2023-04-06 16:43:28,622:INFO:             mlxtend: Not installed
2023-04-06 16:43:28,622:INFO:       statsforecast: Not installed
2023-04-06 16:43:28,622:INFO:        tune_sklearn: Not installed
2023-04-06 16:43:28,622:INFO:                 ray: Not installed
2023-04-06 16:43:28,622:INFO:            hyperopt: 0.2.7
2023-04-06 16:43:28,622:INFO:              optuna: 3.1.0
2023-04-06 16:43:28,622:INFO:               skopt: 0.9.0
2023-04-06 16:43:28,622:INFO:              mlflow: 2.2.2
2023-04-06 16:43:28,622:INFO:              gradio: Not installed
2023-04-06 16:43:28,622:INFO:             fastapi: Not installed
2023-04-06 16:43:28,622:INFO:             uvicorn: Not installed
2023-04-06 16:43:28,622:INFO:              m2cgen: Not installed
2023-04-06 16:43:28,622:INFO:           evidently: Not installed
2023-04-06 16:43:28,622:INFO:               fugue: Not installed
2023-04-06 16:43:28,622:INFO:           streamlit: Not installed
2023-04-06 16:43:28,622:INFO:             prophet: Not installed
2023-04-06 16:43:28,622:INFO:None
2023-04-06 16:43:28,622:INFO:Set up data.
2023-04-06 16:43:28,626:INFO:Set up train/test split.
2023-04-06 16:43:28,627:INFO:Set up index.
2023-04-06 16:43:28,627:INFO:Set up folding strategy.
2023-04-06 16:43:28,627:INFO:Assigning column types.
2023-04-06 16:43:28,628:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-06 16:43:28,629:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,630:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,632:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,655:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,673:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,673:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:43:28,806:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:43:28,818:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,820:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,822:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,846:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,864:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,864:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:43:28,865:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:43:28,866:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-06 16:43:28,867:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,869:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,893:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,911:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,911:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:43:28,912:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:43:28,914:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,916:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,939:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,956:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,957:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:43:28,958:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:43:28,958:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-06 16:43:28,961:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 16:43:28,984:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:43:29,002:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 16:43:29,002:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:43:29,003:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:43:29,007:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-06 16:43:29,030:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:43:29,048:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 16:43:29,048:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:43:29,049:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:43:29,050:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-06 16:43:29,078:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:43:29,096:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 16:43:29,096:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:43:29,097:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:43:29,123:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:43:29,142:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-06 16:43:29,142:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:43:29,143:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:43:29,143:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-06 16:43:29,170:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:43:29,188:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:43:29,189:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:43:29,215:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-06 16:43:29,233:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:43:29,234:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:43:29,235:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-06 16:43:29,279:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:43:29,280:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:43:29,325:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:43:29,326:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:43:29,328:INFO:Preparing preprocessing pipeline...
2023-04-06 16:43:29,328:INFO:Set up simple imputation.
2023-04-06 16:43:29,330:INFO:Set up encoding of ordinal features.
2023-04-06 16:43:29,330:INFO:Set up encoding of categorical features.
2023-04-06 16:43:29,331:INFO:Set up column name cleaning.
2023-04-06 16:43:29,389:INFO:Finished creating preprocessing pipeline.
2023-04-06 16:43:29,400:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry', 'Report'],
                                    transformer=SimpleImputer(strategy='most_frequent')...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': AGSL    0
GIA     1
NaN    -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry'],
                                    transformer=OneHotEncoder(cols=['Cut',
                                                                    'Color',
                                                                    'Clarity',
                                                                    'Polish',
                                                                    'Symmetry'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-06 16:43:29,400:INFO:Creating final display dataframe.
2023-04-06 16:43:29,533:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             Price
2                   Target type        Regression
3           Original data shape         (5400, 8)
4        Transformed data shape        (5400, 29)
5   Transformed train set shape        (3779, 29)
6    Transformed test set shape        (1621, 29)
7              Ordinal features                 1
8              Numeric features                 1
9          Categorical features                 6
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              a2b4
2023-04-06 16:43:29,583:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:43:29,584:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:43:29,630:INFO:Soft dependency imported: xgboost: 1.7.2
2023-04-06 16:43:29,631:INFO:Soft dependency imported: catboost: 1.1.1
2023-04-06 16:43:29,631:INFO:setup() successfully completed in 1.46s...............
2023-04-06 16:43:29,634:INFO:Initializing compare_models()
2023-04-06 16:43:29,634:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-06 16:43:29,634:INFO:Checking exceptions
2023-04-06 16:43:29,635:INFO:Preparing display monitor
2023-04-06 16:43:29,659:INFO:Initializing Linear Regression
2023-04-06 16:43:29,659:INFO:Total runtime is 3.417332967122396e-06 minutes
2023-04-06 16:43:29,661:INFO:SubProcess create_model() called ==================================
2023-04-06 16:43:29,662:INFO:Initializing create_model()
2023-04-06 16:43:29,662:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:43:29,662:INFO:Checking exceptions
2023-04-06 16:43:29,662:INFO:Importing libraries
2023-04-06 16:43:29,662:INFO:Copying training dataset
2023-04-06 16:43:29,666:INFO:Defining folds
2023-04-06 16:43:29,666:INFO:Declaring metric variables
2023-04-06 16:43:29,667:INFO:Importing untrained model
2023-04-06 16:43:29,669:INFO:Linear Regression Imported successfully
2023-04-06 16:43:29,672:INFO:Starting cross validation
2023-04-06 16:43:29,677:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:43:35,991:INFO:Calculating mean and std
2023-04-06 16:43:35,992:INFO:Creating metrics dataframe
2023-04-06 16:43:36,373:INFO:Uploading results into container
2023-04-06 16:43:36,374:INFO:Uploading model into container now
2023-04-06 16:43:36,374:INFO:_master_model_container: 1
2023-04-06 16:43:36,374:INFO:_display_container: 2
2023-04-06 16:43:36,374:INFO:LinearRegression(n_jobs=-1)
2023-04-06 16:43:36,375:INFO:create_model() successfully completed......................................
2023-04-06 16:43:36,442:INFO:SubProcess create_model() end ==================================
2023-04-06 16:43:36,442:INFO:Creating metrics dataframe
2023-04-06 16:43:36,445:INFO:Initializing Lasso Regression
2023-04-06 16:43:36,445:INFO:Total runtime is 0.11309589942296346 minutes
2023-04-06 16:43:36,446:INFO:SubProcess create_model() called ==================================
2023-04-06 16:43:36,447:INFO:Initializing create_model()
2023-04-06 16:43:36,447:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:43:36,447:INFO:Checking exceptions
2023-04-06 16:43:36,447:INFO:Importing libraries
2023-04-06 16:43:36,447:INFO:Copying training dataset
2023-04-06 16:43:36,449:INFO:Defining folds
2023-04-06 16:43:36,449:INFO:Declaring metric variables
2023-04-06 16:43:36,450:INFO:Importing untrained model
2023-04-06 16:43:36,451:INFO:Lasso Regression Imported successfully
2023-04-06 16:43:36,454:INFO:Starting cross validation
2023-04-06 16:43:36,455:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:43:40,174:INFO:Calculating mean and std
2023-04-06 16:43:40,174:INFO:Creating metrics dataframe
2023-04-06 16:43:40,565:INFO:Uploading results into container
2023-04-06 16:43:40,566:INFO:Uploading model into container now
2023-04-06 16:43:40,566:INFO:_master_model_container: 2
2023-04-06 16:43:40,566:INFO:_display_container: 2
2023-04-06 16:43:40,566:INFO:Lasso(random_state=123)
2023-04-06 16:43:40,566:INFO:create_model() successfully completed......................................
2023-04-06 16:43:40,621:INFO:SubProcess create_model() end ==================================
2023-04-06 16:43:40,621:INFO:Creating metrics dataframe
2023-04-06 16:43:40,624:INFO:Initializing Ridge Regression
2023-04-06 16:43:40,624:INFO:Total runtime is 0.18275176684061686 minutes
2023-04-06 16:43:40,626:INFO:SubProcess create_model() called ==================================
2023-04-06 16:43:40,626:INFO:Initializing create_model()
2023-04-06 16:43:40,626:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:43:40,626:INFO:Checking exceptions
2023-04-06 16:43:40,626:INFO:Importing libraries
2023-04-06 16:43:40,626:INFO:Copying training dataset
2023-04-06 16:43:40,628:INFO:Defining folds
2023-04-06 16:43:40,628:INFO:Declaring metric variables
2023-04-06 16:43:40,629:INFO:Importing untrained model
2023-04-06 16:43:40,630:INFO:Ridge Regression Imported successfully
2023-04-06 16:43:40,632:INFO:Starting cross validation
2023-04-06 16:43:40,633:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:43:44,334:INFO:Calculating mean and std
2023-04-06 16:43:44,335:INFO:Creating metrics dataframe
2023-04-06 16:43:44,720:INFO:Uploading results into container
2023-04-06 16:43:44,720:INFO:Uploading model into container now
2023-04-06 16:43:44,721:INFO:_master_model_container: 3
2023-04-06 16:43:44,721:INFO:_display_container: 2
2023-04-06 16:43:44,721:INFO:Ridge(random_state=123)
2023-04-06 16:43:44,721:INFO:create_model() successfully completed......................................
2023-04-06 16:43:44,777:INFO:SubProcess create_model() end ==================================
2023-04-06 16:43:44,777:INFO:Creating metrics dataframe
2023-04-06 16:43:44,781:INFO:Initializing Elastic Net
2023-04-06 16:43:44,781:INFO:Total runtime is 0.25202696720759077 minutes
2023-04-06 16:43:44,782:INFO:SubProcess create_model() called ==================================
2023-04-06 16:43:44,782:INFO:Initializing create_model()
2023-04-06 16:43:44,782:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:43:44,782:INFO:Checking exceptions
2023-04-06 16:43:44,782:INFO:Importing libraries
2023-04-06 16:43:44,782:INFO:Copying training dataset
2023-04-06 16:43:44,784:INFO:Defining folds
2023-04-06 16:43:44,784:INFO:Declaring metric variables
2023-04-06 16:43:44,785:INFO:Importing untrained model
2023-04-06 16:43:44,787:INFO:Elastic Net Imported successfully
2023-04-06 16:43:44,789:INFO:Starting cross validation
2023-04-06 16:43:44,790:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:43:48,617:INFO:Calculating mean and std
2023-04-06 16:43:48,618:INFO:Creating metrics dataframe
2023-04-06 16:43:48,988:INFO:Uploading results into container
2023-04-06 16:43:48,989:INFO:Uploading model into container now
2023-04-06 16:43:48,989:INFO:_master_model_container: 4
2023-04-06 16:43:48,989:INFO:_display_container: 2
2023-04-06 16:43:48,989:INFO:ElasticNet(random_state=123)
2023-04-06 16:43:48,989:INFO:create_model() successfully completed......................................
2023-04-06 16:43:49,046:INFO:SubProcess create_model() end ==================================
2023-04-06 16:43:49,046:INFO:Creating metrics dataframe
2023-04-06 16:43:49,050:INFO:Initializing Least Angle Regression
2023-04-06 16:43:49,050:INFO:Total runtime is 0.32318618297576907 minutes
2023-04-06 16:43:49,052:INFO:SubProcess create_model() called ==================================
2023-04-06 16:43:49,052:INFO:Initializing create_model()
2023-04-06 16:43:49,052:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:43:49,052:INFO:Checking exceptions
2023-04-06 16:43:49,052:INFO:Importing libraries
2023-04-06 16:43:49,052:INFO:Copying training dataset
2023-04-06 16:43:49,054:INFO:Defining folds
2023-04-06 16:43:49,054:INFO:Declaring metric variables
2023-04-06 16:43:49,055:INFO:Importing untrained model
2023-04-06 16:43:49,057:INFO:Least Angle Regression Imported successfully
2023-04-06 16:43:49,060:INFO:Starting cross validation
2023-04-06 16:43:49,061:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:43:49,144:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:49,149:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:49,157:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:49,162:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:49,173:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:49,175:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:49,176:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=6.036e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 16:43:49,176:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=4.789e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 16:43:49,176:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.582e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 16:43:49,176:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.117e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 16:43:49,176:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.036e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-06 16:43:49,180:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:49,194:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:49,207:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:49,231:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:52,873:INFO:Calculating mean and std
2023-04-06 16:43:52,874:INFO:Creating metrics dataframe
2023-04-06 16:43:53,278:INFO:Uploading results into container
2023-04-06 16:43:53,278:INFO:Uploading model into container now
2023-04-06 16:43:53,278:INFO:_master_model_container: 5
2023-04-06 16:43:53,278:INFO:_display_container: 2
2023-04-06 16:43:53,279:INFO:Lars(random_state=123)
2023-04-06 16:43:53,279:INFO:create_model() successfully completed......................................
2023-04-06 16:43:53,333:INFO:SubProcess create_model() end ==================================
2023-04-06 16:43:53,333:INFO:Creating metrics dataframe
2023-04-06 16:43:53,337:INFO:Initializing Lasso Least Angle Regression
2023-04-06 16:43:53,337:INFO:Total runtime is 0.39463286399841313 minutes
2023-04-06 16:43:53,338:INFO:SubProcess create_model() called ==================================
2023-04-06 16:43:53,339:INFO:Initializing create_model()
2023-04-06 16:43:53,339:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:43:53,339:INFO:Checking exceptions
2023-04-06 16:43:53,339:INFO:Importing libraries
2023-04-06 16:43:53,339:INFO:Copying training dataset
2023-04-06 16:43:53,341:INFO:Defining folds
2023-04-06 16:43:53,341:INFO:Declaring metric variables
2023-04-06 16:43:53,342:INFO:Importing untrained model
2023-04-06 16:43:53,344:INFO:Lasso Least Angle Regression Imported successfully
2023-04-06 16:43:53,346:INFO:Starting cross validation
2023-04-06 16:43:53,347:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:43:53,427:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:43:53,434:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:43:53,443:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:43:53,443:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:43:53,450:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:43:53,457:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:43:53,461:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:43:53,466:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:43:53,488:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:43:53,492:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-06 16:43:57,046:INFO:Calculating mean and std
2023-04-06 16:43:57,047:INFO:Creating metrics dataframe
2023-04-06 16:43:57,435:INFO:Uploading results into container
2023-04-06 16:43:57,436:INFO:Uploading model into container now
2023-04-06 16:43:57,436:INFO:_master_model_container: 6
2023-04-06 16:43:57,436:INFO:_display_container: 2
2023-04-06 16:43:57,436:INFO:LassoLars(random_state=123)
2023-04-06 16:43:57,436:INFO:create_model() successfully completed......................................
2023-04-06 16:43:57,493:INFO:SubProcess create_model() end ==================================
2023-04-06 16:43:57,493:INFO:Creating metrics dataframe
2023-04-06 16:43:57,498:INFO:Initializing Orthogonal Matching Pursuit
2023-04-06 16:43:57,498:INFO:Total runtime is 0.46398140192031867 minutes
2023-04-06 16:43:57,500:INFO:SubProcess create_model() called ==================================
2023-04-06 16:43:57,500:INFO:Initializing create_model()
2023-04-06 16:43:57,500:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:43:57,500:INFO:Checking exceptions
2023-04-06 16:43:57,500:INFO:Importing libraries
2023-04-06 16:43:57,500:INFO:Copying training dataset
2023-04-06 16:43:57,503:INFO:Defining folds
2023-04-06 16:43:57,503:INFO:Declaring metric variables
2023-04-06 16:43:57,504:INFO:Importing untrained model
2023-04-06 16:43:57,505:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-06 16:43:57,508:INFO:Starting cross validation
2023-04-06 16:43:57,508:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:43:57,589:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:57,598:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:57,601:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:57,601:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:57,612:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:57,624:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:57,625:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:57,636:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:57,648:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:43:57,649:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-06 16:44:01,286:INFO:Calculating mean and std
2023-04-06 16:44:01,286:INFO:Creating metrics dataframe
2023-04-06 16:44:01,676:INFO:Uploading results into container
2023-04-06 16:44:01,676:INFO:Uploading model into container now
2023-04-06 16:44:01,677:INFO:_master_model_container: 7
2023-04-06 16:44:01,677:INFO:_display_container: 2
2023-04-06 16:44:01,677:INFO:OrthogonalMatchingPursuit()
2023-04-06 16:44:01,677:INFO:create_model() successfully completed......................................
2023-04-06 16:44:01,735:INFO:SubProcess create_model() end ==================================
2023-04-06 16:44:01,736:INFO:Creating metrics dataframe
2023-04-06 16:44:01,740:INFO:Initializing Bayesian Ridge
2023-04-06 16:44:01,740:INFO:Total runtime is 0.5346790154774984 minutes
2023-04-06 16:44:01,742:INFO:SubProcess create_model() called ==================================
2023-04-06 16:44:01,742:INFO:Initializing create_model()
2023-04-06 16:44:01,742:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:44:01,742:INFO:Checking exceptions
2023-04-06 16:44:01,742:INFO:Importing libraries
2023-04-06 16:44:01,742:INFO:Copying training dataset
2023-04-06 16:44:01,744:INFO:Defining folds
2023-04-06 16:44:01,744:INFO:Declaring metric variables
2023-04-06 16:44:01,745:INFO:Importing untrained model
2023-04-06 16:44:01,747:INFO:Bayesian Ridge Imported successfully
2023-04-06 16:44:01,750:INFO:Starting cross validation
2023-04-06 16:44:01,751:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:44:05,764:INFO:Calculating mean and std
2023-04-06 16:44:05,765:INFO:Creating metrics dataframe
2023-04-06 16:44:06,165:INFO:Uploading results into container
2023-04-06 16:44:06,165:INFO:Uploading model into container now
2023-04-06 16:44:06,166:INFO:_master_model_container: 8
2023-04-06 16:44:06,166:INFO:_display_container: 2
2023-04-06 16:44:06,166:INFO:BayesianRidge()
2023-04-06 16:44:06,166:INFO:create_model() successfully completed......................................
2023-04-06 16:44:06,222:INFO:SubProcess create_model() end ==================================
2023-04-06 16:44:06,222:INFO:Creating metrics dataframe
2023-04-06 16:44:06,227:INFO:Initializing Passive Aggressive Regressor
2023-04-06 16:44:06,227:INFO:Total runtime is 0.6094612836837769 minutes
2023-04-06 16:44:06,228:INFO:SubProcess create_model() called ==================================
2023-04-06 16:44:06,228:INFO:Initializing create_model()
2023-04-06 16:44:06,228:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:44:06,229:INFO:Checking exceptions
2023-04-06 16:44:06,229:INFO:Importing libraries
2023-04-06 16:44:06,229:INFO:Copying training dataset
2023-04-06 16:44:06,231:INFO:Defining folds
2023-04-06 16:44:06,231:INFO:Declaring metric variables
2023-04-06 16:44:06,232:INFO:Importing untrained model
2023-04-06 16:44:06,234:INFO:Passive Aggressive Regressor Imported successfully
2023-04-06 16:44:06,236:INFO:Starting cross validation
2023-04-06 16:44:06,237:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:44:10,069:INFO:Calculating mean and std
2023-04-06 16:44:10,070:INFO:Creating metrics dataframe
2023-04-06 16:44:10,462:INFO:Uploading results into container
2023-04-06 16:44:10,462:INFO:Uploading model into container now
2023-04-06 16:44:10,462:INFO:_master_model_container: 9
2023-04-06 16:44:10,462:INFO:_display_container: 2
2023-04-06 16:44:10,462:INFO:PassiveAggressiveRegressor(random_state=123)
2023-04-06 16:44:10,462:INFO:create_model() successfully completed......................................
2023-04-06 16:44:10,517:INFO:SubProcess create_model() end ==================================
2023-04-06 16:44:10,518:INFO:Creating metrics dataframe
2023-04-06 16:44:10,522:INFO:Initializing Huber Regressor
2023-04-06 16:44:10,522:INFO:Total runtime is 0.681045432885488 minutes
2023-04-06 16:44:10,523:INFO:SubProcess create_model() called ==================================
2023-04-06 16:44:10,524:INFO:Initializing create_model()
2023-04-06 16:44:10,524:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:44:10,524:INFO:Checking exceptions
2023-04-06 16:44:10,524:INFO:Importing libraries
2023-04-06 16:44:10,524:INFO:Copying training dataset
2023-04-06 16:44:10,527:INFO:Defining folds
2023-04-06 16:44:10,527:INFO:Declaring metric variables
2023-04-06 16:44:10,528:INFO:Importing untrained model
2023-04-06 16:44:10,529:INFO:Huber Regressor Imported successfully
2023-04-06 16:44:10,532:INFO:Starting cross validation
2023-04-06 16:44:10,533:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:44:10,667:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 16:44:10,669:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 16:44:10,671:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 16:44:10,676:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 16:44:10,690:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 16:44:10,691:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 16:44:10,698:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 16:44:10,714:WARNING:/Users/a06411/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-06 16:44:14,313:INFO:Calculating mean and std
2023-04-06 16:44:14,313:INFO:Creating metrics dataframe
2023-04-06 16:44:14,695:INFO:Uploading results into container
2023-04-06 16:44:14,695:INFO:Uploading model into container now
2023-04-06 16:44:14,696:INFO:_master_model_container: 10
2023-04-06 16:44:14,696:INFO:_display_container: 2
2023-04-06 16:44:14,696:INFO:HuberRegressor()
2023-04-06 16:44:14,696:INFO:create_model() successfully completed......................................
2023-04-06 16:44:14,754:INFO:SubProcess create_model() end ==================================
2023-04-06 16:44:14,754:INFO:Creating metrics dataframe
2023-04-06 16:44:14,759:INFO:Initializing K Neighbors Regressor
2023-04-06 16:44:14,759:INFO:Total runtime is 0.75166658560435 minutes
2023-04-06 16:44:14,761:INFO:SubProcess create_model() called ==================================
2023-04-06 16:44:14,761:INFO:Initializing create_model()
2023-04-06 16:44:14,761:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:44:14,761:INFO:Checking exceptions
2023-04-06 16:44:14,761:INFO:Importing libraries
2023-04-06 16:44:14,761:INFO:Copying training dataset
2023-04-06 16:44:14,764:INFO:Defining folds
2023-04-06 16:44:14,764:INFO:Declaring metric variables
2023-04-06 16:44:14,765:INFO:Importing untrained model
2023-04-06 16:44:14,767:INFO:K Neighbors Regressor Imported successfully
2023-04-06 16:44:14,770:INFO:Starting cross validation
2023-04-06 16:44:14,770:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:44:18,550:INFO:Calculating mean and std
2023-04-06 16:44:18,550:INFO:Creating metrics dataframe
2023-04-06 16:44:18,936:INFO:Uploading results into container
2023-04-06 16:44:18,936:INFO:Uploading model into container now
2023-04-06 16:44:18,936:INFO:_master_model_container: 11
2023-04-06 16:44:18,936:INFO:_display_container: 2
2023-04-06 16:44:18,937:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-06 16:44:18,937:INFO:create_model() successfully completed......................................
2023-04-06 16:44:18,993:INFO:SubProcess create_model() end ==================================
2023-04-06 16:44:18,994:INFO:Creating metrics dataframe
2023-04-06 16:44:18,998:INFO:Initializing Decision Tree Regressor
2023-04-06 16:44:18,998:INFO:Total runtime is 0.8223115324974062 minutes
2023-04-06 16:44:18,999:INFO:SubProcess create_model() called ==================================
2023-04-06 16:44:18,999:INFO:Initializing create_model()
2023-04-06 16:44:18,999:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:44:18,999:INFO:Checking exceptions
2023-04-06 16:44:18,999:INFO:Importing libraries
2023-04-06 16:44:18,999:INFO:Copying training dataset
2023-04-06 16:44:19,001:INFO:Defining folds
2023-04-06 16:44:19,001:INFO:Declaring metric variables
2023-04-06 16:44:19,003:INFO:Importing untrained model
2023-04-06 16:44:19,004:INFO:Decision Tree Regressor Imported successfully
2023-04-06 16:44:19,006:INFO:Starting cross validation
2023-04-06 16:44:19,007:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:44:22,807:INFO:Calculating mean and std
2023-04-06 16:44:22,807:INFO:Creating metrics dataframe
2023-04-06 16:44:23,193:INFO:Uploading results into container
2023-04-06 16:44:23,194:INFO:Uploading model into container now
2023-04-06 16:44:23,194:INFO:_master_model_container: 12
2023-04-06 16:44:23,194:INFO:_display_container: 2
2023-04-06 16:44:23,194:INFO:DecisionTreeRegressor(random_state=123)
2023-04-06 16:44:23,194:INFO:create_model() successfully completed......................................
2023-04-06 16:44:23,252:INFO:SubProcess create_model() end ==================================
2023-04-06 16:44:23,253:INFO:Creating metrics dataframe
2023-04-06 16:44:23,258:INFO:Initializing Random Forest Regressor
2023-04-06 16:44:23,258:INFO:Total runtime is 0.8933154503504437 minutes
2023-04-06 16:44:23,260:INFO:SubProcess create_model() called ==================================
2023-04-06 16:44:23,260:INFO:Initializing create_model()
2023-04-06 16:44:23,260:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:44:23,260:INFO:Checking exceptions
2023-04-06 16:44:23,260:INFO:Importing libraries
2023-04-06 16:44:23,260:INFO:Copying training dataset
2023-04-06 16:44:23,263:INFO:Defining folds
2023-04-06 16:44:23,263:INFO:Declaring metric variables
2023-04-06 16:44:23,264:INFO:Importing untrained model
2023-04-06 16:44:23,266:INFO:Random Forest Regressor Imported successfully
2023-04-06 16:44:23,268:INFO:Starting cross validation
2023-04-06 16:44:23,269:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:44:27,142:INFO:Calculating mean and std
2023-04-06 16:44:27,143:INFO:Creating metrics dataframe
2023-04-06 16:44:27,532:INFO:Uploading results into container
2023-04-06 16:44:27,533:INFO:Uploading model into container now
2023-04-06 16:44:27,533:INFO:_master_model_container: 13
2023-04-06 16:44:27,533:INFO:_display_container: 2
2023-04-06 16:44:27,533:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-04-06 16:44:27,533:INFO:create_model() successfully completed......................................
2023-04-06 16:44:27,593:INFO:SubProcess create_model() end ==================================
2023-04-06 16:44:27,594:INFO:Creating metrics dataframe
2023-04-06 16:44:27,599:INFO:Initializing Extra Trees Regressor
2023-04-06 16:44:27,599:INFO:Total runtime is 0.9656657814979555 minutes
2023-04-06 16:44:27,601:INFO:SubProcess create_model() called ==================================
2023-04-06 16:44:27,601:INFO:Initializing create_model()
2023-04-06 16:44:27,601:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:44:27,601:INFO:Checking exceptions
2023-04-06 16:44:27,601:INFO:Importing libraries
2023-04-06 16:44:27,601:INFO:Copying training dataset
2023-04-06 16:44:27,603:INFO:Defining folds
2023-04-06 16:44:27,603:INFO:Declaring metric variables
2023-04-06 16:44:27,605:INFO:Importing untrained model
2023-04-06 16:44:27,606:INFO:Extra Trees Regressor Imported successfully
2023-04-06 16:44:27,609:INFO:Starting cross validation
2023-04-06 16:44:27,610:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:44:31,637:INFO:Calculating mean and std
2023-04-06 16:44:31,638:INFO:Creating metrics dataframe
2023-04-06 16:44:32,044:INFO:Uploading results into container
2023-04-06 16:44:32,046:INFO:Uploading model into container now
2023-04-06 16:44:32,047:INFO:_master_model_container: 14
2023-04-06 16:44:32,047:INFO:_display_container: 2
2023-04-06 16:44:32,047:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-04-06 16:44:32,047:INFO:create_model() successfully completed......................................
2023-04-06 16:44:32,147:INFO:SubProcess create_model() end ==================================
2023-04-06 16:44:32,147:INFO:Creating metrics dataframe
2023-04-06 16:44:32,152:INFO:Initializing AdaBoost Regressor
2023-04-06 16:44:32,152:INFO:Total runtime is 1.0415479501088463 minutes
2023-04-06 16:44:32,153:INFO:SubProcess create_model() called ==================================
2023-04-06 16:44:32,154:INFO:Initializing create_model()
2023-04-06 16:44:32,154:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:44:32,154:INFO:Checking exceptions
2023-04-06 16:44:32,154:INFO:Importing libraries
2023-04-06 16:44:32,154:INFO:Copying training dataset
2023-04-06 16:44:32,156:INFO:Defining folds
2023-04-06 16:44:32,156:INFO:Declaring metric variables
2023-04-06 16:44:32,158:INFO:Importing untrained model
2023-04-06 16:44:32,160:INFO:AdaBoost Regressor Imported successfully
2023-04-06 16:44:32,163:INFO:Starting cross validation
2023-04-06 16:44:32,164:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:44:35,924:INFO:Calculating mean and std
2023-04-06 16:44:35,925:INFO:Creating metrics dataframe
2023-04-06 16:44:36,311:INFO:Uploading results into container
2023-04-06 16:44:36,311:INFO:Uploading model into container now
2023-04-06 16:44:36,312:INFO:_master_model_container: 15
2023-04-06 16:44:36,312:INFO:_display_container: 2
2023-04-06 16:44:36,312:INFO:AdaBoostRegressor(random_state=123)
2023-04-06 16:44:36,312:INFO:create_model() successfully completed......................................
2023-04-06 16:44:36,369:INFO:SubProcess create_model() end ==================================
2023-04-06 16:44:36,369:INFO:Creating metrics dataframe
2023-04-06 16:44:36,374:INFO:Initializing Gradient Boosting Regressor
2023-04-06 16:44:36,374:INFO:Total runtime is 1.1119085669517519 minutes
2023-04-06 16:44:36,375:INFO:SubProcess create_model() called ==================================
2023-04-06 16:44:36,375:INFO:Initializing create_model()
2023-04-06 16:44:36,375:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:44:36,375:INFO:Checking exceptions
2023-04-06 16:44:36,375:INFO:Importing libraries
2023-04-06 16:44:36,375:INFO:Copying training dataset
2023-04-06 16:44:36,377:INFO:Defining folds
2023-04-06 16:44:36,377:INFO:Declaring metric variables
2023-04-06 16:44:36,378:INFO:Importing untrained model
2023-04-06 16:44:36,380:INFO:Gradient Boosting Regressor Imported successfully
2023-04-06 16:44:36,382:INFO:Starting cross validation
2023-04-06 16:44:36,383:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:44:40,184:INFO:Calculating mean and std
2023-04-06 16:44:40,184:INFO:Creating metrics dataframe
2023-04-06 16:44:40,574:INFO:Uploading results into container
2023-04-06 16:44:40,574:INFO:Uploading model into container now
2023-04-06 16:44:40,575:INFO:_master_model_container: 16
2023-04-06 16:44:40,575:INFO:_display_container: 2
2023-04-06 16:44:40,575:INFO:GradientBoostingRegressor(random_state=123)
2023-04-06 16:44:40,575:INFO:create_model() successfully completed......................................
2023-04-06 16:44:40,629:INFO:SubProcess create_model() end ==================================
2023-04-06 16:44:40,630:INFO:Creating metrics dataframe
2023-04-06 16:44:40,635:INFO:Initializing Extreme Gradient Boosting
2023-04-06 16:44:40,635:INFO:Total runtime is 1.1829238017400108 minutes
2023-04-06 16:44:40,636:INFO:SubProcess create_model() called ==================================
2023-04-06 16:44:40,636:INFO:Initializing create_model()
2023-04-06 16:44:40,636:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:44:40,636:INFO:Checking exceptions
2023-04-06 16:44:40,636:INFO:Importing libraries
2023-04-06 16:44:40,636:INFO:Copying training dataset
2023-04-06 16:44:40,638:INFO:Defining folds
2023-04-06 16:44:40,639:INFO:Declaring metric variables
2023-04-06 16:44:40,640:INFO:Importing untrained model
2023-04-06 16:44:40,641:INFO:Extreme Gradient Boosting Imported successfully
2023-04-06 16:44:40,643:INFO:Starting cross validation
2023-04-06 16:44:40,644:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:44:44,415:INFO:Calculating mean and std
2023-04-06 16:44:44,415:INFO:Creating metrics dataframe
2023-04-06 16:44:44,802:INFO:Uploading results into container
2023-04-06 16:44:44,803:INFO:Uploading model into container now
2023-04-06 16:44:44,803:INFO:_master_model_container: 17
2023-04-06 16:44:44,803:INFO:_display_container: 2
2023-04-06 16:44:44,804:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=123, ...)
2023-04-06 16:44:44,804:INFO:create_model() successfully completed......................................
2023-04-06 16:44:44,862:INFO:SubProcess create_model() end ==================================
2023-04-06 16:44:44,862:INFO:Creating metrics dataframe
2023-04-06 16:44:44,867:INFO:Initializing Light Gradient Boosting Machine
2023-04-06 16:44:44,867:INFO:Total runtime is 1.2534611304601035 minutes
2023-04-06 16:44:44,868:INFO:SubProcess create_model() called ==================================
2023-04-06 16:44:44,868:INFO:Initializing create_model()
2023-04-06 16:44:44,868:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:44:44,868:INFO:Checking exceptions
2023-04-06 16:44:44,869:INFO:Importing libraries
2023-04-06 16:44:44,869:INFO:Copying training dataset
2023-04-06 16:44:44,870:INFO:Defining folds
2023-04-06 16:44:44,870:INFO:Declaring metric variables
2023-04-06 16:44:44,871:INFO:Importing untrained model
2023-04-06 16:44:44,873:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-06 16:44:44,875:INFO:Starting cross validation
2023-04-06 16:44:44,876:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:44:49,406:INFO:Calculating mean and std
2023-04-06 16:44:49,407:INFO:Creating metrics dataframe
2023-04-06 16:44:49,803:INFO:Uploading results into container
2023-04-06 16:44:49,803:INFO:Uploading model into container now
2023-04-06 16:44:49,803:INFO:_master_model_container: 18
2023-04-06 16:44:49,803:INFO:_display_container: 2
2023-04-06 16:44:49,804:INFO:LGBMRegressor(random_state=123)
2023-04-06 16:44:49,804:INFO:create_model() successfully completed......................................
2023-04-06 16:44:49,863:INFO:SubProcess create_model() end ==================================
2023-04-06 16:44:49,864:INFO:Creating metrics dataframe
2023-04-06 16:44:49,869:INFO:Initializing CatBoost Regressor
2023-04-06 16:44:49,869:INFO:Total runtime is 1.3368359684944155 minutes
2023-04-06 16:44:49,871:INFO:SubProcess create_model() called ==================================
2023-04-06 16:44:49,872:INFO:Initializing create_model()
2023-04-06 16:44:49,872:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:44:49,872:INFO:Checking exceptions
2023-04-06 16:44:49,872:INFO:Importing libraries
2023-04-06 16:44:49,872:INFO:Copying training dataset
2023-04-06 16:44:49,874:INFO:Defining folds
2023-04-06 16:44:49,874:INFO:Declaring metric variables
2023-04-06 16:44:49,875:INFO:Importing untrained model
2023-04-06 16:44:49,880:INFO:CatBoost Regressor Imported successfully
2023-04-06 16:44:49,883:INFO:Starting cross validation
2023-04-06 16:44:49,884:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:44:54,247:INFO:Calculating mean and std
2023-04-06 16:44:54,248:INFO:Creating metrics dataframe
2023-04-06 16:44:54,642:INFO:Uploading results into container
2023-04-06 16:44:54,642:INFO:Uploading model into container now
2023-04-06 16:44:54,642:INFO:_master_model_container: 19
2023-04-06 16:44:54,642:INFO:_display_container: 2
2023-04-06 16:44:54,642:INFO:<catboost.core.CatBoostRegressor object at 0x16b5790d0>
2023-04-06 16:44:54,642:INFO:create_model() successfully completed......................................
2023-04-06 16:44:54,698:INFO:SubProcess create_model() end ==================================
2023-04-06 16:44:54,698:INFO:Creating metrics dataframe
2023-04-06 16:44:54,704:INFO:Initializing Dummy Regressor
2023-04-06 16:44:54,704:INFO:Total runtime is 1.4174164017041526 minutes
2023-04-06 16:44:54,706:INFO:SubProcess create_model() called ==================================
2023-04-06 16:44:54,706:INFO:Initializing create_model()
2023-04-06 16:44:54,706:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1656f1040>, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:44:54,706:INFO:Checking exceptions
2023-04-06 16:44:54,706:INFO:Importing libraries
2023-04-06 16:44:54,706:INFO:Copying training dataset
2023-04-06 16:44:54,708:INFO:Defining folds
2023-04-06 16:44:54,708:INFO:Declaring metric variables
2023-04-06 16:44:54,709:INFO:Importing untrained model
2023-04-06 16:44:54,711:INFO:Dummy Regressor Imported successfully
2023-04-06 16:44:54,713:INFO:Starting cross validation
2023-04-06 16:44:54,714:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:44:58,515:INFO:Calculating mean and std
2023-04-06 16:44:58,516:INFO:Creating metrics dataframe
2023-04-06 16:44:58,934:INFO:Uploading results into container
2023-04-06 16:44:58,935:INFO:Uploading model into container now
2023-04-06 16:44:58,935:INFO:_master_model_container: 20
2023-04-06 16:44:58,935:INFO:_display_container: 2
2023-04-06 16:44:58,935:INFO:DummyRegressor()
2023-04-06 16:44:58,935:INFO:create_model() successfully completed......................................
2023-04-06 16:44:58,991:INFO:SubProcess create_model() end ==================================
2023-04-06 16:44:58,991:INFO:Creating metrics dataframe
2023-04-06 16:44:58,999:INFO:Initializing create_model()
2023-04-06 16:44:59,000:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=<catboost.core.CatBoostRegressor object at 0x16b5790d0>, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:44:59,000:INFO:Checking exceptions
2023-04-06 16:44:59,001:INFO:Importing libraries
2023-04-06 16:44:59,001:INFO:Copying training dataset
2023-04-06 16:44:59,003:INFO:Defining folds
2023-04-06 16:44:59,003:INFO:Declaring metric variables
2023-04-06 16:44:59,003:INFO:Importing untrained model
2023-04-06 16:44:59,003:INFO:Declaring custom model
2023-04-06 16:44:59,004:INFO:CatBoost Regressor Imported successfully
2023-04-06 16:44:59,004:INFO:Cross validation set to False
2023-04-06 16:44:59,004:INFO:Fitting Model
2023-04-06 16:44:59,391:INFO:<catboost.core.CatBoostRegressor object at 0x16b579b80>
2023-04-06 16:44:59,391:INFO:create_model() successfully completed......................................
2023-04-06 16:44:59,459:INFO:_master_model_container: 20
2023-04-06 16:44:59,459:INFO:_display_container: 2
2023-04-06 16:44:59,459:INFO:<catboost.core.CatBoostRegressor object at 0x16b579b80>
2023-04-06 16:44:59,459:INFO:compare_models() successfully completed......................................
2023-04-06 16:44:59,463:INFO:Initializing create_model()
2023-04-06 16:44:59,463:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=ada, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:44:59,463:INFO:Checking exceptions
2023-04-06 16:44:59,470:INFO:Importing libraries
2023-04-06 16:44:59,470:INFO:Copying training dataset
2023-04-06 16:44:59,476:INFO:Defining folds
2023-04-06 16:44:59,476:INFO:Declaring metric variables
2023-04-06 16:44:59,477:INFO:Importing untrained model
2023-04-06 16:44:59,479:INFO:AdaBoost Regressor Imported successfully
2023-04-06 16:44:59,482:INFO:Starting cross validation
2023-04-06 16:44:59,483:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:45:03,213:INFO:Calculating mean and std
2023-04-06 16:45:03,214:INFO:Creating metrics dataframe
2023-04-06 16:45:03,216:INFO:Finalizing model
2023-04-06 16:45:03,693:INFO:Uploading results into container
2023-04-06 16:45:03,694:INFO:Uploading model into container now
2023-04-06 16:45:03,698:INFO:_master_model_container: 21
2023-04-06 16:45:03,698:INFO:_display_container: 3
2023-04-06 16:45:03,698:INFO:AdaBoostRegressor(random_state=123)
2023-04-06 16:45:03,698:INFO:create_model() successfully completed......................................
2023-04-06 16:45:03,764:INFO:Initializing create_model()
2023-04-06 16:45:03,764:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:45:03,764:INFO:Checking exceptions
2023-04-06 16:45:03,771:INFO:Importing libraries
2023-04-06 16:45:03,771:INFO:Copying training dataset
2023-04-06 16:45:03,775:INFO:Defining folds
2023-04-06 16:45:03,775:INFO:Declaring metric variables
2023-04-06 16:45:03,777:INFO:Importing untrained model
2023-04-06 16:45:03,778:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-06 16:45:03,781:INFO:Starting cross validation
2023-04-06 16:45:03,782:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:45:07,575:INFO:Calculating mean and std
2023-04-06 16:45:07,576:INFO:Creating metrics dataframe
2023-04-06 16:45:07,578:INFO:Finalizing model
2023-04-06 16:45:08,054:INFO:Uploading results into container
2023-04-06 16:45:08,054:INFO:Uploading model into container now
2023-04-06 16:45:08,058:INFO:_master_model_container: 22
2023-04-06 16:45:08,058:INFO:_display_container: 4
2023-04-06 16:45:08,058:INFO:LGBMRegressor(random_state=123)
2023-04-06 16:45:08,059:INFO:create_model() successfully completed......................................
2023-04-06 16:45:08,125:INFO:Initializing create_model()
2023-04-06 16:45:08,125:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:45:08,125:INFO:Checking exceptions
2023-04-06 16:45:08,132:INFO:Importing libraries
2023-04-06 16:45:08,132:INFO:Copying training dataset
2023-04-06 16:45:08,137:INFO:Defining folds
2023-04-06 16:45:08,137:INFO:Declaring metric variables
2023-04-06 16:45:08,139:INFO:Importing untrained model
2023-04-06 16:45:08,140:INFO:Decision Tree Regressor Imported successfully
2023-04-06 16:45:08,143:INFO:Starting cross validation
2023-04-06 16:45:08,144:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:45:11,950:INFO:Calculating mean and std
2023-04-06 16:45:11,951:INFO:Creating metrics dataframe
2023-04-06 16:45:11,953:INFO:Finalizing model
2023-04-06 16:45:12,403:INFO:Uploading results into container
2023-04-06 16:45:12,404:INFO:Uploading model into container now
2023-04-06 16:45:12,407:INFO:_master_model_container: 23
2023-04-06 16:45:12,407:INFO:_display_container: 5
2023-04-06 16:45:12,407:INFO:DecisionTreeRegressor(random_state=123)
2023-04-06 16:45:12,407:INFO:create_model() successfully completed......................................
2023-04-06 16:45:12,468:INFO:Initializing tune_model()
2023-04-06 16:45:12,468:INFO:tune_model(estimator=ada, fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>)
2023-04-06 16:45:12,468:INFO:Checking exceptions
2023-04-06 16:45:37,311:INFO:Initializing tune_model()
2023-04-06 16:45:37,312:INFO:tune_model(estimator=LGBMRegressor(random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>)
2023-04-06 16:45:37,313:INFO:Checking exceptions
2023-04-06 16:45:37,332:INFO:Copying training dataset
2023-04-06 16:45:37,336:INFO:Checking base model
2023-04-06 16:45:37,336:INFO:Base model : Light Gradient Boosting Machine
2023-04-06 16:45:37,338:INFO:Declaring metric variables
2023-04-06 16:45:37,340:INFO:Defining Hyperparameters
2023-04-06 16:45:37,426:INFO:Tuning with n_jobs=-1
2023-04-06 16:45:37,426:INFO:Initializing RandomizedSearchCV
2023-04-06 16:46:14,438:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-04-06 16:46:14,439:INFO:Hyperparameter search completed
2023-04-06 16:46:14,439:INFO:SubProcess create_model() called ==================================
2023-04-06 16:46:14,440:INFO:Initializing create_model()
2023-04-06 16:46:14,440:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=LGBMRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1758acb50>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-04-06 16:46:14,440:INFO:Checking exceptions
2023-04-06 16:46:14,440:INFO:Importing libraries
2023-04-06 16:46:14,440:INFO:Copying training dataset
2023-04-06 16:46:14,442:INFO:Defining folds
2023-04-06 16:46:14,442:INFO:Declaring metric variables
2023-04-06 16:46:14,443:INFO:Importing untrained model
2023-04-06 16:46:14,443:INFO:Declaring custom model
2023-04-06 16:46:14,445:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-06 16:46:14,447:INFO:Starting cross validation
2023-04-06 16:46:14,448:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:46:18,117:INFO:Calculating mean and std
2023-04-06 16:46:18,118:INFO:Creating metrics dataframe
2023-04-06 16:46:18,120:INFO:Finalizing model
2023-04-06 16:46:18,710:INFO:Uploading results into container
2023-04-06 16:46:18,710:INFO:Uploading model into container now
2023-04-06 16:46:18,711:INFO:_master_model_container: 24
2023-04-06 16:46:18,711:INFO:_display_container: 6
2023-04-06 16:46:18,711:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              num_leaves=70, random_state=123, reg_alpha=2, reg_lambda=3)
2023-04-06 16:46:18,711:INFO:create_model() successfully completed......................................
2023-04-06 16:46:18,788:INFO:SubProcess create_model() end ==================================
2023-04-06 16:46:18,788:INFO:choose_better activated
2023-04-06 16:46:18,790:INFO:SubProcess create_model() called ==================================
2023-04-06 16:46:18,790:INFO:Initializing create_model()
2023-04-06 16:46:18,790:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=LGBMRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:46:18,790:INFO:Checking exceptions
2023-04-06 16:46:18,790:INFO:Importing libraries
2023-04-06 16:46:18,790:INFO:Copying training dataset
2023-04-06 16:46:18,793:INFO:Defining folds
2023-04-06 16:46:18,793:INFO:Declaring metric variables
2023-04-06 16:46:18,793:INFO:Importing untrained model
2023-04-06 16:46:18,793:INFO:Declaring custom model
2023-04-06 16:46:18,793:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-06 16:46:18,793:INFO:Starting cross validation
2023-04-06 16:46:18,794:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:46:22,566:INFO:Calculating mean and std
2023-04-06 16:46:22,566:INFO:Creating metrics dataframe
2023-04-06 16:46:22,567:INFO:Finalizing model
2023-04-06 16:46:23,029:INFO:Uploading results into container
2023-04-06 16:46:23,030:INFO:Uploading model into container now
2023-04-06 16:46:23,030:INFO:_master_model_container: 25
2023-04-06 16:46:23,030:INFO:_display_container: 7
2023-04-06 16:46:23,030:INFO:LGBMRegressor(random_state=123)
2023-04-06 16:46:23,030:INFO:create_model() successfully completed......................................
2023-04-06 16:46:23,108:INFO:SubProcess create_model() end ==================================
2023-04-06 16:46:23,109:INFO:LGBMRegressor(random_state=123) result for R2 is 0.9711
2023-04-06 16:46:23,109:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              num_leaves=70, random_state=123, reg_alpha=2, reg_lambda=3) result for R2 is 0.9651
2023-04-06 16:46:23,109:INFO:LGBMRegressor(random_state=123) is best model
2023-04-06 16:46:23,109:INFO:choose_better completed
2023-04-06 16:46:23,109:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-04-06 16:46:23,113:INFO:_master_model_container: 25
2023-04-06 16:46:23,113:INFO:_display_container: 6
2023-04-06 16:46:23,114:INFO:LGBMRegressor(random_state=123)
2023-04-06 16:46:23,114:INFO:tune_model() successfully completed......................................
2023-04-06 16:46:23,559:INFO:Initializing create_model()
2023-04-06 16:46:23,560:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=catboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:46:23,560:INFO:Checking exceptions
2023-04-06 16:46:23,566:INFO:Importing libraries
2023-04-06 16:46:23,567:INFO:Copying training dataset
2023-04-06 16:46:23,571:INFO:Defining folds
2023-04-06 16:46:23,571:INFO:Declaring metric variables
2023-04-06 16:46:23,573:INFO:Importing untrained model
2023-04-06 16:46:23,574:INFO:CatBoost Regressor Imported successfully
2023-04-06 16:46:23,577:INFO:Starting cross validation
2023-04-06 16:46:23,578:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:46:27,326:INFO:Calculating mean and std
2023-04-06 16:46:27,328:INFO:Creating metrics dataframe
2023-04-06 16:46:27,331:INFO:Finalizing model
2023-04-06 16:46:27,790:INFO:Uploading results into container
2023-04-06 16:46:27,790:INFO:Uploading model into container now
2023-04-06 16:46:27,794:INFO:_master_model_container: 26
2023-04-06 16:46:27,794:INFO:_display_container: 7
2023-04-06 16:46:27,794:INFO:<catboost.core.CatBoostRegressor object at 0x177e598b0>
2023-04-06 16:46:27,794:INFO:create_model() successfully completed......................................
2023-04-06 16:46:32,965:INFO:Initializing tune_model()
2023-04-06 16:46:32,966:INFO:tune_model(estimator=DecisionTreeRegressor(random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>)
2023-04-06 16:46:32,966:INFO:Checking exceptions
2023-04-06 16:46:32,986:INFO:Copying training dataset
2023-04-06 16:46:32,990:INFO:Checking base model
2023-04-06 16:46:32,990:INFO:Base model : Decision Tree Regressor
2023-04-06 16:46:32,992:INFO:Declaring metric variables
2023-04-06 16:46:32,994:INFO:Defining Hyperparameters
2023-04-06 16:46:33,076:INFO:Tuning with n_jobs=-1
2023-04-06 16:46:33,076:INFO:Initializing RandomizedSearchCV
2023-04-06 16:47:10,448:INFO:best_params: {'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.01, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 10, 'actual_estimator__criterion': 'friedman_mse'}
2023-04-06 16:47:10,449:INFO:Hyperparameter search completed
2023-04-06 16:47:10,449:INFO:SubProcess create_model() called ==================================
2023-04-06 16:47:10,449:INFO:Initializing create_model()
2023-04-06 16:47:10,449:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=DecisionTreeRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17b00afd0>, model_only=True, return_train_score=False, kwargs={'min_samples_split': 9, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.01, 'max_features': 1.0, 'max_depth': 10, 'criterion': 'friedman_mse'})
2023-04-06 16:47:10,449:INFO:Checking exceptions
2023-04-06 16:47:10,450:INFO:Importing libraries
2023-04-06 16:47:10,450:INFO:Copying training dataset
2023-04-06 16:47:10,452:INFO:Defining folds
2023-04-06 16:47:10,452:INFO:Declaring metric variables
2023-04-06 16:47:10,453:INFO:Importing untrained model
2023-04-06 16:47:10,453:INFO:Declaring custom model
2023-04-06 16:47:10,454:INFO:Decision Tree Regressor Imported successfully
2023-04-06 16:47:10,457:INFO:Starting cross validation
2023-04-06 16:47:10,458:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:47:14,262:INFO:Calculating mean and std
2023-04-06 16:47:14,263:INFO:Creating metrics dataframe
2023-04-06 16:47:14,265:INFO:Finalizing model
2023-04-06 16:47:14,717:INFO:Uploading results into container
2023-04-06 16:47:14,717:INFO:Uploading model into container now
2023-04-06 16:47:14,717:INFO:_master_model_container: 27
2023-04-06 16:47:14,717:INFO:_display_container: 8
2023-04-06 16:47:14,718:INFO:DecisionTreeRegressor(criterion='friedman_mse', max_depth=10, max_features=1.0,
                      min_impurity_decrease=0.01, min_samples_leaf=2,
                      min_samples_split=9, random_state=123)
2023-04-06 16:47:14,718:INFO:create_model() successfully completed......................................
2023-04-06 16:47:14,796:INFO:SubProcess create_model() end ==================================
2023-04-06 16:47:14,796:INFO:choose_better activated
2023-04-06 16:47:14,798:INFO:SubProcess create_model() called ==================================
2023-04-06 16:47:14,798:INFO:Initializing create_model()
2023-04-06 16:47:14,798:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=DecisionTreeRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:47:14,798:INFO:Checking exceptions
2023-04-06 16:47:14,798:INFO:Importing libraries
2023-04-06 16:47:14,799:INFO:Copying training dataset
2023-04-06 16:47:14,801:INFO:Defining folds
2023-04-06 16:47:14,801:INFO:Declaring metric variables
2023-04-06 16:47:14,801:INFO:Importing untrained model
2023-04-06 16:47:14,801:INFO:Declaring custom model
2023-04-06 16:47:14,801:INFO:Decision Tree Regressor Imported successfully
2023-04-06 16:47:14,801:INFO:Starting cross validation
2023-04-06 16:47:14,802:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:47:18,582:INFO:Calculating mean and std
2023-04-06 16:47:18,583:INFO:Creating metrics dataframe
2023-04-06 16:47:18,584:INFO:Finalizing model
2023-04-06 16:47:19,034:INFO:Uploading results into container
2023-04-06 16:47:19,035:INFO:Uploading model into container now
2023-04-06 16:47:19,035:INFO:_master_model_container: 28
2023-04-06 16:47:19,035:INFO:_display_container: 9
2023-04-06 16:47:19,035:INFO:DecisionTreeRegressor(random_state=123)
2023-04-06 16:47:19,035:INFO:create_model() successfully completed......................................
2023-04-06 16:47:19,110:INFO:SubProcess create_model() end ==================================
2023-04-06 16:47:19,111:INFO:DecisionTreeRegressor(random_state=123) result for R2 is 0.9465
2023-04-06 16:47:19,111:INFO:DecisionTreeRegressor(criterion='friedman_mse', max_depth=10, max_features=1.0,
                      min_impurity_decrease=0.01, min_samples_leaf=2,
                      min_samples_split=9, random_state=123) result for R2 is 0.9473
2023-04-06 16:47:19,111:INFO:DecisionTreeRegressor(criterion='friedman_mse', max_depth=10, max_features=1.0,
                      min_impurity_decrease=0.01, min_samples_leaf=2,
                      min_samples_split=9, random_state=123) is best model
2023-04-06 16:47:19,111:INFO:choose_better completed
2023-04-06 16:47:19,114:INFO:_master_model_container: 28
2023-04-06 16:47:19,115:INFO:_display_container: 8
2023-04-06 16:47:19,115:INFO:DecisionTreeRegressor(criterion='friedman_mse', max_depth=10, max_features=1.0,
                      min_impurity_decrease=0.01, min_samples_leaf=2,
                      min_samples_split=9, random_state=123)
2023-04-06 16:47:19,115:INFO:tune_model() successfully completed......................................
2023-04-06 16:48:11,885:INFO:Initializing tune_model()
2023-04-06 16:48:11,887:INFO:tune_model(estimator=<catboost.core.CatBoostRegressor object at 0x177e598b0>, fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>)
2023-04-06 16:48:11,887:INFO:Checking exceptions
2023-04-06 16:48:11,904:INFO:Copying training dataset
2023-04-06 16:48:11,909:INFO:Checking base model
2023-04-06 16:48:11,909:INFO:Base model : CatBoost Regressor
2023-04-06 16:48:11,911:INFO:Declaring metric variables
2023-04-06 16:48:11,913:INFO:Defining Hyperparameters
2023-04-06 16:48:12,000:INFO:Tuning with n_jobs=-1
2023-04-06 16:48:12,000:INFO:Initializing RandomizedSearchCV
2023-04-06 16:48:51,739:INFO:best_params: {'actual_estimator__random_strength': 0.2, 'actual_estimator__n_estimators': 180, 'actual_estimator__l2_leaf_reg': 30, 'actual_estimator__eta': 0.4, 'actual_estimator__depth': 8}
2023-04-06 16:48:51,740:INFO:Hyperparameter search completed
2023-04-06 16:48:51,740:INFO:SubProcess create_model() called ==================================
2023-04-06 16:48:51,741:INFO:Initializing create_model()
2023-04-06 16:48:51,741:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=<catboost.core.CatBoostRegressor object at 0x17b091fd0>, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x175b7cd30>, model_only=True, return_train_score=False, kwargs={'random_strength': 0.2, 'n_estimators': 180, 'l2_leaf_reg': 30, 'eta': 0.4, 'depth': 8})
2023-04-06 16:48:51,741:INFO:Checking exceptions
2023-04-06 16:48:51,741:INFO:Importing libraries
2023-04-06 16:48:51,741:INFO:Copying training dataset
2023-04-06 16:48:51,743:INFO:Defining folds
2023-04-06 16:48:51,743:INFO:Declaring metric variables
2023-04-06 16:48:51,745:INFO:Importing untrained model
2023-04-06 16:48:51,745:INFO:Declaring custom model
2023-04-06 16:48:51,747:INFO:CatBoost Regressor Imported successfully
2023-04-06 16:48:51,750:INFO:Starting cross validation
2023-04-06 16:48:51,751:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:48:55,879:INFO:Calculating mean and std
2023-04-06 16:48:55,880:INFO:Creating metrics dataframe
2023-04-06 16:48:55,883:INFO:Finalizing model
2023-04-06 16:48:56,680:INFO:Uploading results into container
2023-04-06 16:48:56,681:INFO:Uploading model into container now
2023-04-06 16:48:56,681:INFO:_master_model_container: 29
2023-04-06 16:48:56,681:INFO:_display_container: 9
2023-04-06 16:48:56,681:INFO:<catboost.core.CatBoostRegressor object at 0x17afb8e80>
2023-04-06 16:48:56,681:INFO:create_model() successfully completed......................................
2023-04-06 16:48:56,768:INFO:SubProcess create_model() end ==================================
2023-04-06 16:48:56,768:INFO:choose_better activated
2023-04-06 16:48:56,770:INFO:SubProcess create_model() called ==================================
2023-04-06 16:48:56,770:INFO:Initializing create_model()
2023-04-06 16:48:56,770:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=<catboost.core.CatBoostRegressor object at 0x177e598b0>, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 16:48:56,770:INFO:Checking exceptions
2023-04-06 16:48:56,771:INFO:Importing libraries
2023-04-06 16:48:56,771:INFO:Copying training dataset
2023-04-06 16:48:56,774:INFO:Defining folds
2023-04-06 16:48:56,774:INFO:Declaring metric variables
2023-04-06 16:48:56,774:INFO:Importing untrained model
2023-04-06 16:48:56,774:INFO:Declaring custom model
2023-04-06 16:48:56,774:INFO:CatBoost Regressor Imported successfully
2023-04-06 16:48:56,774:INFO:Starting cross validation
2023-04-06 16:48:56,775:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 16:49:00,739:INFO:Calculating mean and std
2023-04-06 16:49:00,740:INFO:Creating metrics dataframe
2023-04-06 16:49:00,741:INFO:Finalizing model
2023-04-06 16:49:01,200:INFO:Uploading results into container
2023-04-06 16:49:01,200:INFO:Uploading model into container now
2023-04-06 16:49:01,201:INFO:_master_model_container: 30
2023-04-06 16:49:01,201:INFO:_display_container: 10
2023-04-06 16:49:01,201:INFO:<catboost.core.CatBoostRegressor object at 0x17afd4d90>
2023-04-06 16:49:01,201:INFO:create_model() successfully completed......................................
2023-04-06 16:49:01,279:INFO:SubProcess create_model() end ==================================
2023-04-06 16:49:01,279:INFO:<catboost.core.CatBoostRegressor object at 0x17afd4d90> result for R2 is 0.9807
2023-04-06 16:49:01,279:INFO:<catboost.core.CatBoostRegressor object at 0x17afb8e80> result for R2 is 0.9769
2023-04-06 16:49:01,279:INFO:<catboost.core.CatBoostRegressor object at 0x17afd4d90> is best model
2023-04-06 16:49:01,279:INFO:choose_better completed
2023-04-06 16:49:01,280:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-04-06 16:49:01,284:INFO:_master_model_container: 30
2023-04-06 16:49:01,284:INFO:_display_container: 9
2023-04-06 16:49:01,284:INFO:<catboost.core.CatBoostRegressor object at 0x17afd4d90>
2023-04-06 16:49:01,284:INFO:tune_model() successfully completed......................................
2023-04-06 16:49:01,723:INFO:Initializing plot_model()
2023-04-06 16:49:01,723:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, system=True)
2023-04-06 16:49:01,723:INFO:Checking exceptions
2023-04-06 16:49:01,725:INFO:Preloading libraries
2023-04-06 16:49:01,731:INFO:Copying training dataset
2023-04-06 16:49:01,732:INFO:Plot type: residuals
2023-04-06 16:49:01,876:INFO:Fitting Model
2023-04-06 16:49:01,949:INFO:Scoring test/hold-out set
2023-04-06 16:49:02,281:INFO:Visual Rendered Successfully
2023-04-06 16:49:02,365:INFO:plot_model() successfully completed......................................
2023-04-06 16:49:02,370:INFO:Initializing plot_model()
2023-04-06 16:49:02,370:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, system=True)
2023-04-06 16:49:02,370:INFO:Checking exceptions
2023-04-06 16:49:02,372:INFO:Preloading libraries
2023-04-06 16:49:02,379:INFO:Copying training dataset
2023-04-06 16:49:02,379:INFO:Plot type: feature
2023-04-06 16:49:02,379:WARNING:No coef_ found. Trying feature_importances_
2023-04-06 16:49:02,472:INFO:Visual Rendered Successfully
2023-04-06 16:49:02,552:INFO:plot_model() successfully completed......................................
2023-04-06 16:49:02,556:INFO:Initializing plot_model()
2023-04-06 16:49:02,556:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, system=True)
2023-04-06 16:49:02,556:INFO:Checking exceptions
2023-04-06 16:49:02,558:INFO:Preloading libraries
2023-04-06 16:49:02,565:INFO:Copying training dataset
2023-04-06 16:49:02,565:INFO:Plot type: error
2023-04-06 16:49:02,729:INFO:Fitting Model
2023-04-06 16:49:02,729:INFO:Scoring test/hold-out set
2023-04-06 16:49:02,848:INFO:Visual Rendered Successfully
2023-04-06 16:49:02,928:INFO:plot_model() successfully completed......................................
2023-04-06 16:49:19,536:INFO:Initializing predict_model()
2023-04-06 16:49:19,537:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=LGBMRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x17afe09d0>)
2023-04-06 16:49:19,537:INFO:Checking exceptions
2023-04-06 16:49:19,538:INFO:Preloading libraries
2023-04-06 16:49:37,311:INFO:Initializing finalize_model()
2023-04-06 16:49:37,311:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=LGBMRegressor(random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-04-06 16:49:37,312:INFO:Finalizing LGBMRegressor(random_state=123)
2023-04-06 16:49:37,317:INFO:Initializing create_model()
2023-04-06 16:49:37,317:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=LGBMRegressor(random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-04-06 16:49:37,317:INFO:Checking exceptions
2023-04-06 16:49:37,321:INFO:Importing libraries
2023-04-06 16:49:37,321:INFO:Copying training dataset
2023-04-06 16:49:37,321:INFO:Defining folds
2023-04-06 16:49:37,321:INFO:Declaring metric variables
2023-04-06 16:49:37,321:INFO:Importing untrained model
2023-04-06 16:49:37,322:INFO:Declaring custom model
2023-04-06 16:49:37,323:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-06 16:49:37,325:INFO:Cross validation set to False
2023-04-06 16:49:37,325:INFO:Fitting Model
2023-04-06 16:49:37,450:INFO:Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry', 'Report'],
                                    transformer=SimpleImputer(strategy='most_frequent')...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry'],
                                    transformer=OneHotEncoder(cols=['Cut',
                                                                    'Color',
                                                                    'Clarity',
                                                                    'Polish',
                                                                    'Symmetry'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', LGBMRegressor(random_state=123))])
2023-04-06 16:49:37,450:INFO:create_model() successfully completed......................................
2023-04-06 16:49:37,528:INFO:_master_model_container: 30
2023-04-06 16:49:37,528:INFO:_display_container: 10
2023-04-06 16:49:37,537:INFO:Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry', 'Report'],
                                    transformer=SimpleImputer(strategy='most_frequent')...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry'],
                                    transformer=OneHotEncoder(cols=['Cut',
                                                                    'Color',
                                                                    'Clarity',
                                                                    'Polish',
                                                                    'Symmetry'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', LGBMRegressor(random_state=123))])
2023-04-06 16:49:37,537:INFO:finalize_model() successfully completed......................................
2023-04-06 16:50:01,724:INFO:Initializing predict_model()
2023-04-06 16:50:01,725:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry', 'Report'],
                                    transformer=SimpleImputer(strategy='most_frequent')...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry'],
                                    transformer=OneHotEncoder(cols=['Cut',
                                                                    'Color',
                                                                    'Clarity',
                                                                    'Polish',
                                                                    'Symmetry'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', LGBMRegressor(random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x17afe0820>)
2023-04-06 16:50:01,725:INFO:Checking exceptions
2023-04-06 16:50:01,725:INFO:Preloading libraries
2023-04-06 16:50:13,236:INFO:Initializing predict_model()
2023-04-06 16:50:13,236:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry', 'Report'],
                                    transformer=SimpleImputer(strategy='most_frequent')...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry'],
                                    transformer=OneHotEncoder(cols=['Cut',
                                                                    'Color',
                                                                    'Clarity',
                                                                    'Polish',
                                                                    'Symmetry'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', LGBMRegressor(random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x17afe00d0>)
2023-04-06 16:50:13,236:INFO:Checking exceptions
2023-04-06 16:50:13,237:INFO:Preloading libraries
2023-04-06 16:50:13,238:INFO:Set up data.
2023-04-06 16:50:13,242:INFO:Set up index.
2023-04-06 16:50:27,773:INFO:Initializing save_model()
2023-04-06 16:50:27,773:INFO:save_model(model=Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry', 'Report'],
                                    transformer=SimpleImputer(strategy='most_frequent')...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry'],
                                    transformer=OneHotEncoder(cols=['Cut',
                                                                    'Color',
                                                                    'Clarity',
                                                                    'Polish',
                                                                    'Symmetry'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', LGBMRegressor(random_state=123))]), model_name=Final Lightgbm Model 08Feb2020, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry', 'Report'],
                                    transformer=SimpleImputer(strategy='most_frequent')...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': AGSL    0
GIA     1
NaN    -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry'],
                                    transformer=OneHotEncoder(cols=['Cut',
                                                                    'Color',
                                                                    'Clarity',
                                                                    'Polish',
                                                                    'Symmetry'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-04-06 16:50:27,773:INFO:Adding model into prep_pipe
2023-04-06 16:50:27,784:WARNING:Only Model saved as it was a pipeline.
2023-04-06 16:50:27,798:INFO:Final Lightgbm Model 08Feb2020.pkl saved in current working directory
2023-04-06 16:50:27,809:INFO:Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry', 'Report'],
                                    transformer=SimpleImputer(strategy='most_frequent')...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry'],
                                    transformer=OneHotEncoder(cols=['Cut',
                                                                    'Color',
                                                                    'Clarity',
                                                                    'Polish',
                                                                    'Symmetry'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', LGBMRegressor(random_state=123))])
2023-04-06 16:50:27,809:INFO:save_model() successfully completed......................................
2023-04-06 16:51:33,177:INFO:Initializing load_model()
2023-04-06 16:51:33,179:INFO:load_model(model_name=Final Lightgbm Model 08Feb2020, platform=None, authentication=None, verbose=True)
2023-04-06 16:51:33,863:INFO:Initializing predict_model()
2023-04-06 16:51:33,863:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=Pipeline(memory=FastMemory(location=/var/folders/h4/44486vyn1_xbs13g1z50l5m00000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Carat Weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry', 'Report'],
                                    transformer=SimpleImputer(strategy='most_frequent')...
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Cut', 'Color', 'Clarity',
                                             'Polish', 'Symmetry'],
                                    transformer=OneHotEncoder(cols=['Cut',
                                                                    'Color',
                                                                    'Clarity',
                                                                    'Polish',
                                                                    'Symmetry'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', LGBMRegressor(random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x17afe0ca0>)
2023-04-06 16:51:33,863:INFO:Checking exceptions
2023-04-06 16:51:33,863:INFO:Preloading libraries
2023-04-06 16:51:33,864:INFO:Set up data.
2023-04-06 16:51:33,868:INFO:Set up index.
2023-04-06 17:03:48,745:INFO:Initializing create_model()
2023-04-06 17:03:48,747:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>, estimator=catboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-06 17:03:48,747:INFO:Checking exceptions
2023-04-06 17:03:48,767:INFO:Importing libraries
2023-04-06 17:03:48,768:INFO:Copying training dataset
2023-04-06 17:03:48,772:INFO:Defining folds
2023-04-06 17:03:48,772:INFO:Declaring metric variables
2023-04-06 17:03:48,774:INFO:Importing untrained model
2023-04-06 17:03:48,776:INFO:CatBoost Regressor Imported successfully
2023-04-06 17:03:48,779:INFO:Starting cross validation
2023-04-06 17:03:48,781:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-06 17:03:56,366:INFO:Calculating mean and std
2023-04-06 17:03:56,368:INFO:Creating metrics dataframe
2023-04-06 17:03:56,371:INFO:Finalizing model
2023-04-06 17:03:56,850:INFO:Uploading results into container
2023-04-06 17:03:56,850:INFO:Uploading model into container now
2023-04-06 17:03:56,855:INFO:_master_model_container: 31
2023-04-06 17:03:56,855:INFO:_display_container: 14
2023-04-06 17:03:56,855:INFO:<catboost.core.CatBoostRegressor object at 0x17af98e80>
2023-04-06 17:03:56,855:INFO:create_model() successfully completed......................................
2023-04-06 17:04:06,139:INFO:Initializing tune_model()
2023-04-06 17:04:06,140:INFO:tune_model(estimator=<catboost.core.CatBoostRegressor object at 0x17af98e80>, fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x16b561ac0>)
2023-04-06 17:04:06,141:INFO:Checking exceptions
2023-04-06 17:04:06,161:INFO:Copying training dataset
2023-04-06 17:04:06,165:INFO:Checking base model
2023-04-06 17:04:06,165:INFO:Base model : CatBoost Regressor
2023-04-06 17:04:06,167:INFO:Declaring metric variables
2023-04-06 17:04:06,169:INFO:Defining Hyperparameters
2023-04-06 17:04:06,254:INFO:Tuning with n_jobs=-1
2023-04-06 17:04:06,254:INFO:Initializing RandomizedSearchCV
